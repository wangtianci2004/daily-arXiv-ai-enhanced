<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 34]
- [cs.CL](#cs.CL) [Total: 32]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [eess.SP](#eess.SP) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.SD](#cs.SD) [Total: 3]
- [quant-ph](#quant-ph) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.HC](#cs.HC) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CY](#cs.CY) [Total: 2]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.LG](#cs.LG) [Total: 22]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Time-Archival Camera Virtualization for Sports and Visual Performances](https://arxiv.org/abs/2602.15181)
*Yunxiao Zhang,William Stone,Suryansh Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经体渲染的动态场景相机虚拟化方法，可实现高效的时间归档和新颖视角合成，尤其适用于体育赛事回放和分析，解决了现有方法在处理快速非刚体运动和时间回溯方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的相机虚拟化方法难以对动态场景进行空间和时间一致且逼真的渲染，尤其是在快速运动（如体育和舞台表演）中，并且缺乏高效的时间归档能力。基于3D高斯泼溅（3DGS）的方法受限于对精确3D点云的依赖，且无法处理大的、非刚性的、快速的多主体运动，多主体独立运动会破坏高斯跟踪假设。

Method: 本文重新考虑了神经体渲染公式，用于相机虚拟化和高效时间归档。通过将动态场景建模为在给定时间点跨多个同步相机视图的刚体变换，我们的方法执行神经表示学习。

Result: 该方法在测试时提供了增强的视觉渲染质量。其关键贡献是支持时间归档，即用户可以回溯动态场景的任何过去时间实例并进行新颖视角合成，从而实现实时事件的回放、分析和归档的追溯渲染。

Conclusion: 本文提出了一种支持高效时间归档和新颖视角合成的神经体渲染方法，通过建模动态场景中的刚体变换，克服了现有方法在处理复杂动态、多主体运动和时间回溯方面的限制，特别适用于体育广播和相关应用。

Abstract: Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...

</details>


### [2] [GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation](https://arxiv.org/abs/2602.15072)
*Abdul Joseph Fofanah,Lian Wen,Alpha Alimamy Kamara,Zhongyi Zhang,David Chen,Albert Patrick Sankoh*

Main category: cs.CV

TL;DR: GRAFNet是一种受生物学启发的结肠镜息肉分割架构，通过模拟人眼视觉系统，解决了传统方法的局限性，在多个公开基准测试上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜检查中的息肉准确分割对癌症预防至关重要，但面临挑战：1) 息肉形态变异性大；2) 与正常结构视觉相似度高；3) 需要鲁棒的多尺度检测。现有深度学习方法存在单向处理、多尺度融合弱以及缺乏解剖学约束的问题，常导致假阳性（正常结构过度分割）和假阴性（遗漏细微扁平病变）。

Method: GRAFNet是一种受生物学启发的架构，模仿人类视觉系统的分层组织。它包含三个关键模块：1) 引导式非对称注意力模块（GAAM），模拟定向调谐的皮层神经元以强调息肉边界；2) 多尺度视网膜模块（MSRM），复制视网膜神经节细胞通路以进行并行多特征分析；3) 引导式皮层注意力反馈模块（GCAFM），应用预测编码进行迭代细化。这些模块统一在息肉编码器-解码器模块（PEDM）中，通过分辨率自适应反馈强制实现空间-语义一致性。

Result: 在Kvasir-SEG、CVC-300、CVC-ColonDB、CVC-Clinic和PolypGen等五个公开基准测试中，GRAFNet持续实现了最先进的性能，与领先方法相比，Dice分数提高了3-8%，泛化能力提高了10-20%，同时提供了可解释的决策路径。

Conclusion: 这项工作建立了一个新范式，其中神经计算原理弥合了人工智能准确性与临床可信推理之间的鸿沟。

Abstract: Accurate polyp segmentation in colonoscopy is essential for cancer prevention but remains challenging due to: (1) high morphological variability (from flat to protruding lesions), (2) strong visual similarity to normal structures such as folds and vessels, and (3) the need for robust multi-scale detection. Existing deep learning approaches suffer from unidirectional processing, weak multi-scale fusion, and the absence of anatomical constraints, often leading to false positives (over-segmentation of normal structures) and false negatives (missed subtle flat lesions). We propose GRAFNet, a biologically inspired architecture that emulates the hierarchical organisation of the human visual system. GRAFNet integrates three key modules: (1) a Guided Asymmetric Attention Module (GAAM) that mimics orientation-tuned cortical neurones to emphasise polyp boundaries, (2) a MultiScale Retinal Module (MSRM) that replicates retinal ganglion cell pathways for parallel multi-feature analysis, and (3) a Guided Cortical Attention Feedback Module (GCAFM) that applies predictive coding for iterative refinement. These are unified in a Polyp Encoder-Decoder Module (PEDM) that enforces spatial-semantic consistency via resolution-adaptive feedback. Extensive experiments on five public benchmarks (Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen) demonstrate consistent state-of-the-art performance, with 3-8% Dice improvements and 10-20% higher generalisation over leading methods, while offering interpretable decision pathways. This work establishes a paradigm in which neural computation principles bridge the gap between AI accuracy and clinically trustworthy reasoning. Code is available at .

</details>


### [3] [Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124)
*Shiyu Xuan,Dongkai Wang,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: 该论文提出了一种解耦框架，将目标检测与交互识别分离，并利用多模态大语言模型（MLLMs）进行零样本人机交互（HOI）检测。通过确定性生成方法、空间感知池化模块和一次性确定性匹配方法，实现了优越的零样本性能和强大的跨数据集泛化能力，且可灵活集成到任何目标检测器中。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本人机交互检测方法，特别是交互识别（IR），由于交互组合的多样性而面临挑战。现有方法将IR与特定检测器紧密耦合，并依赖粗粒度视觉语言模型（VLM）特征，限制了对未见交互的泛化能力。

Method: 该研究提出一个解耦框架，将目标检测与交互识别分离。利用多模态大语言模型（MLLMs）进行零样本交互识别，并引入一种确定性生成方法，将交互识别表述为视觉问答任务，实现免训练的零样本IR。为了进一步提升性能和效率，设计了一个空间感知池化模块以整合外观和成对空间线索，以及一个一次性确定性匹配方法，可在单次前向传播中预测所有候选交互。

Result: 在HICO-DET和V-COCO数据集上的大量实验表明，该方法实现了卓越的零样本性能、强大的跨数据集泛化能力，并且可以灵活地与任何目标检测器集成而无需重新训练。

Conclusion: 该研究通过解耦框架和创新的确定性生成、匹配及空间感知模块，有效解决了零样本人机交互检测中交互识别的挑战，显著提升了泛化能力和系统集成灵活性。

Abstract: Zero-shot Human-object interaction (HOI) detection aims to locate humans and objects in images and recognize their interactions. While advances in open-vocabulary object detection provide promising solutions for object localization, interaction recognition (IR) remains challenging due to the combinatorial diversity of interactions. Existing methods, including two-stage methods, tightly couple IR with a specific detector and rely on coarse-grained vision-language model (VLM) features, which limit generalization to unseen interactions. In this work, we propose a decoupled framework that separates object detection from IR and leverages multi-modal large language models (MLLMs) for zero-shot IR. We introduce a deterministic generation method that formulates IR as a visual question answering task and enforces deterministic outputs, enabling training-free zero-shot IR. To further enhance performance and efficiency by fine-tuning the model, we design a spatial-aware pooling module that integrates appearance and pairwise spatial cues, and a one-pass deterministic matching method that predicts all candidate interactions in a single forward pass. Extensive experiments on HICO-DET and V-COCO demonstrate that our method achieves superior zero-shot performance, strong cross-dataset generalization, and the flexibility to integrate with any object detectors without retraining. The codes are publicly available at .

</details>


### [4] [Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories](https://arxiv.org/abs/2602.15154)
*Praditha Alwis,Soumyadeep Chandra,Deepak Ravikumar,Kaushik Roy*

Main category: cs.CV

TL;DR: 提出了一种模型无关的方法，通过分析累积样本损失（CSL）来检测视频数据集中的错误标注和乱序问题。该方法利用帧在训练过程中持续高或不规则的损失模式来识别注释错误，并在 EgoPER 和 Cholec80 数据集上展示了强大的检测能力。


<details>
  <summary>Details</summary>
Motivation: 高质量的视频数据集是训练动作识别、阶段检测和事件分割等任务中稳健模型的基础。然而，许多真实世界的视频数据集存在注释错误，如错误标注（segment 被分配了不正确的类别标签）和乱序（时间序列不遵循正确的进展）。这些错误在需要时间一致性的阶段标注任务中尤其有害，并损害了模型的训练。

Method: 该方法提出了一种模型无关的注释错误检测方法，通过分析累积样本损失（CSL）来实现。CSL 定义为帧在通过训练周期中保存的模型检查点时产生的平均损失。具体步骤包括：1) 训练一个视频分割模型，并在每个 epoch 存储其权重（即检查点）。2) 使用这些检查点来评估测试视频中每一帧的损失。3) 持续高或不规则 CSL 模式的帧被标记为潜在的注释错误，包括错误标注或时间错位。该方法不需要关于注释错误的真实标签，并且具有跨数据集的通用性。

Result: 在 EgoPER 和 Cholec80 数据集上进行了实验，结果显示出强大的检测性能，能够有效识别诸如错误标注和帧乱序等细微的不一致性。

Conclusion: 该方法为视频机器学习中的数据集审计和训练可靠性改进提供了一个强大的工具。

Abstract: High-quality video datasets are foundational for training robust models in tasks like action recognition, phase detection, and event segmentation. However, many real-world video datasets suffer from annotation errors such as *mislabeling*, where segments are assigned incorrect class labels, and *disordering*, where the temporal sequence does not follow the correct progression. These errors are particularly harmful in phase-annotated tasks, where temporal consistency is critical. We propose a novel, model-agnostic method for detecting annotation errors by analyzing the Cumulative Sample Loss (CSL)--defined as the average loss a frame incurs when passing through model checkpoints saved across training epochs. This per-frame loss trajectory acts as a dynamic fingerprint of frame-level learnability. Mislabeled or disordered frames tend to show consistently high or irregular loss patterns, as they remain difficult for the model to learn throughout training, while correctly labeled frames typically converge to low loss early. To compute CSL, we train a video segmentation model and store its weights at each epoch. These checkpoints are then used to evaluate the loss of each frame in a test video. Frames with persistently high CSL are flagged as likely candidates for annotation errors, including mislabeling or temporal misalignment. Our method does not require ground truth on annotation errors and is generalizable across datasets. Experiments on EgoPER and Cholec80 demonstrate strong detection performance, effectively identifying subtle inconsistencies such as mislabeling and frame disordering. The proposed approach provides a powerful tool for dataset auditing and improving training reliability in video-based machine learning.

</details>


### [5] [Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift](https://arxiv.org/abs/2602.15167)
*Xiaoyi Wen,Fei Jiang*

Main category: cs.CV

TL;DR: 本研究提出了一种分布深度学习框架，以解决医学图像超分辨率中因实际低分辨率数据采集机制与训练数据不匹配导致的领域偏移问题，并通过在4D Flow MRI上的应用，证明其在泛化能力和性能上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的超分辨率方法依赖于降采样和原始高分辨率图像的配对数据集进行训练，但在实际临床环境中，低分辨率数据通常源于与简单降采样显著不同的采集机制，导致输入数据超出训练域，引发领域偏移，从而导致模型泛化能力差。

Method: 提出了一种分布深度学习框架，旨在提高模型鲁棒性和领域泛化能力。该方法首先在高质量计算流体动力学(CFD)模拟及其降采样对应数据集上进行训练，然后在一个小型、经过协调的4D Flow MRI和CFD配对样本数据集上进行微调。研究还推导了其分布估计器的理论性质。

Result: 通过实际数据应用，该框架显著优于传统的深度学习方法，解决了领域偏移问题并提高了超分辨率性能。

Conclusion: 本研究证明了分布学习在解决领域偏移和提高临床实际场景下的超分辨率性能方面的有效性。

Abstract: Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.

</details>


### [6] [How to Train Your Long-Context Visual Document Model](https://arxiv.org/abs/2602.15257)
*Austin Veselka*

Main category: cs.CV

TL;DR: 该研究首次大规模且全面地探索了长上下文视觉语言模型（最高344K上下文）的训练，提出了可复现的方法，在MMLongBenchDoc上实现了SOTA性能，并揭示了多项关键训练策略，同时发布了改进的评估基准MMLBD-C。


<details>
  <summary>Details</summary>
Motivation: 现有的开源长上下文视觉语言模型（如Qwen3 VL和GLM 4.5/6V）的训练方案和数据管道缺乏可复现性。

Method: 研究系统地进行了持续预训练、监督微调和偏好优化，针对24B和32B参数模型，并通过广泛的LC评估和消融实验验证了方法。

Result: 1. 在MMLongBenchDoc上对24B和32B参数规模的模型均达到了最先进的性能（SOTA）。
2. 主要发现包括：
    *   在与评估上下文长度匹配的上下文长度上进行训练，效果优于在更长的上下文上进行训练。
    *   使用页面索引进行训练和评估，能简单有效地提升长文档性能。
    *   合成数据管道能通过持续预训练和监督微调实现模型自我提升。
    *   视觉长上下文训练可反向迁移到长上下文文本性能。
3. 发布了MMLBD-C，一个手动修正的MMLongBenchDoc版本，以减少基准中的错误和低质量示例。

Conclusion: 该研究首次全面、大规模地探索了长上下文视觉语言模型的训练，提供了可复现的方法，达到了最先进的性能，并揭示了多项有助于提升长文档VQA和长上下文文本性能的关键训练策略，同时发布了改进的评估基准。

Abstract: We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.

</details>


### [7] [Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization](https://arxiv.org/abs/2602.15277)
*Muhammad J. Alahmadi,Peng Gao,Feiyi Wang,Dongkuan*

Main category: cs.CV

TL;DR: E^2D是一种高效且准确的数据集蒸馏方法，通过两阶段优化策略，解决了大规模数据蒸馏中效率与准确性的权衡问题，在ImageNet-1K和ImageNet-21K上均显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模解耦式数据集蒸馏方法面临效率与准确性的权衡：基于优化的方法精度高但计算密集，而无优化方法效率高但牺牲了准确性。

Method: E^2D方法通过高效的管道最小化冗余计算。首先进行全图像初始化以保留语义完整性和特征多样性，然后采用两阶段优化策略：探索阶段执行统一更新并识别高损失区域，而利用阶段则将更新集中在这些区域以加速收敛。

Result: 在ImageNet-1K上，E^2D超越了最先进的方法，同时速度提高了18倍。在ImageNet-21K上，E^2D显著提高了准确性，同时速度仍快4.3倍。

Conclusion: E^2D通过有针对性、减少冗余的更新，而非暴力优化，弥合了大规模数据集蒸馏中准确性和效率之间的差距。

Abstract: Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at .

</details>


### [8] [Consistency-Preserving Diverse Video Generation](https://arxiv.org/abs/2602.15287)
*Xinshuang Liu,Runfa Blark Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种联合采样框架，用于流匹配视频生成器，可在提高批次多样性的同时保持视频时间一致性，并避免了昂贵的视频解码器反向传播。


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成成本高昂，每个提示词通常只能生成少量样本。在低样本量情况下，最大化每个批次价值需要高跨视频多样性。现有图像生成多样性方法在视频中常会降低帧内时间一致性，并需要通过视频解码器进行昂贵的反向传播。

Method: 提出了一种针对流匹配视频生成器的联合采样框架。该方法首先应用多样性驱动的更新，然后去除会降低时间一致性目标的组件。为了避免图像空间梯度，所有目标都通过轻量级潜在空间模型计算，从而避免了视频解码和解码器反向传播。

Result: 在最先进的文本到视频流匹配模型上进行的实验表明，该方法实现了与强大联合采样基线相当的多样性，同时显著改善了时间一致性和色彩自然度。

Conclusion: 该方法在文本到视频生成中实现了高多样性和时间一致性，同时避免了昂贵的图像空间梯度计算。

Abstract: Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.

</details>


### [9] [Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models](https://arxiv.org/abs/2602.15315)
*Tai Le-Gia,Jaehyun Ahn*

Main category: cs.CV

TL;DR: 提出了一种无训练的3D脑部MRI零样本异常检测框架，通过2D模型处理多轴切片聚合生成体积令牌，有效扩展了2D编码器到3D异常检测。


<details>
  <summary>Details</summary>
Motivation: 零样本异常检测（ZSAD）在医学图像中受关注，但主要限于2D数据集。将ZSAD扩展到3D图像面临挑战，现有方法依赖切片特征和视觉语言模型，未能捕获体积结构。

Method: 引入了一个完全无需训练的3D脑部MRI零样本异常检测框架。该框架通过聚合由2D基础模型处理的多轴切片来构建局部体积令牌，这些3D补丁令牌恢复了立方空间上下文，并直接与基于距离的批处理级异常检测管道集成。该框架提供紧凑的3D表示，可在标准GPU上计算，无需微调、提示或监督。

Result: 结果表明，无训练的、基于批处理的零样本异常检测可以有效地从2D编码器扩展到完整的3D MRI体积。

Conclusion: 该方法为体积异常检测提供了一种简单且鲁棒的途径。

Abstract: Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.

</details>


### [10] [Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs](https://arxiv.org/abs/2602.15318)
*Libo Zhang,Zhaoning Zhang,Wangyang Hong,Peng Qiao,Dongsheng Li*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Although speculative decoding is widely used to accelerate Vision-Language Models (VLMs) inference, it faces severe performance collapse when applied to Video Large Language Models (Vid-LLMs). The draft model typically falls into the trap of attention dilution and negative visual gain due to key-value cache explosion and context window mismatches. We observe a visual semantic internalization phenomenon in Vid-LLMs, indicating that critical visual semantics are implicitly encoded into text hidden states during deep-layer interactions, which renders raw visual inputs structurally redundant during deep inference. To address this, we propose the Sparrow framework, which first utilizes visually-aware text-anchored window attention via hidden state reuse to fully offload visual computation to the target model, and leverages intermediate-layer visual state bridging to train the draft model with semantic-rich intermediate states, thereby filtering out low-level visual noise. Additionally, a multi-token prediction strategy is introduced to bridge the training-inference distribution shift. Experiments show that Sparrow achieves an average speedup of 2.82x even with 25k visual tokens, effectively resolving the performance degradation in long sequences and offering a practical solution for real-time long video tasks.

</details>


### [11] [CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349)
*Jinho Baek,Houwei Cao,Kate Blackwell*

Main category: cs.CV

TL;DR: 本研究提出了一个名为CREMD的多模态犬类情感数据集，用于探究不同呈现模式（如上下文、音频、视频）和标注者特征（如狗主人身份、性别、专业经验）如何影响犬类情感的感知和标注。结果显示，视觉上下文能显著提高标注一致性；音频线索的影响尚无定论，但能增强标注者对特定情感（如愤怒、恐惧）的信心；此外，非狗主人和男性标注者表现出比狗主人和女性标注者更高的一致性，而专业人士的一致性更高。


<details>
  <summary>Details</summary>
Motivation: 犬类情感识别对于增进人与动物的互动、兽医护理以及开发监控犬类健康的自动化系统至关重要。然而，由于情感评估的主观性以及缺乏标准化的真实标签方法，准确解释犬类情感具有挑战性。因此，需要研究影响犬类情感感知和标注的因素。

Method: 研究创建了CREMD（众包情绪多模态犬类数据集），包含923个视频片段。视频片段以三种模式呈现：无上下文无音频、有上下文无音频、有上下文有音频。标注数据来自多样化的参与者，包括狗主人、专业人士以及具有不同人口统计背景和经验水平的个体。通过分析这些标注，研究旨在识别影响可靠犬类情感识别的因素。

Result: 1. 增加视觉上下文显著提高了标注一致性。
2. 由于设计限制（缺少无上下文有音频条件和洁净音频资源有限），音频线索的发现尚无定论。
3. 与预期相反，非狗主人和男性标注者比狗主人和女性标注者表现出更高的一致性水平；专业人士表现出更高的一致性水平，这与初始假设相符。
4. 音频的存在显著增加了标注者识别特定情感（尤其是愤怒和恐惧）的信心。

Conclusion: CREMD数据集及其分析揭示了影响犬类情感识别的因素。视觉上下文对注释一致性很重要。标注者特征（非狗主人/男性与狗主人/女性，专业人士）会影响一致性。音频，尽管在本研究中对一致性的影响尚无定论，但提高了标注者对特定情感的识别信心。

Abstract: Dog emotion recognition plays a crucial role in enhancing human-animal interactions, veterinary care, and the development of automated systems for monitoring canine well-being. However, accurately interpreting dog emotions is challenging due to the subjective nature of emotional assessments and the absence of standardized ground truth methods. We present the CREMD (Crowd-sourced Emotional Multimodal Dogs Dataset), a comprehensive dataset exploring how different presentation modes (e.g., context, audio, video) and annotator characteristics (e.g., dog ownership, gender, professional experience) influence the perception and labeling of dog emotions. The dataset consists of 923 video clips presented in three distinct modes: without context or audio, with context but no audio, and with both context and audio. We analyze annotations from diverse participants, including dog owners, professionals, and individuals with varying demographic backgrounds and experience levels, to identify factors that influence reliable dog emotion recognition. Our findings reveal several key insights: (1) while adding visual context significantly improved annotation agreement, our findings regarding audio cues are inconclusive due to design limitations (specifically, the absence of a no-context-with-audio condition and limited clean audio availability); (2) contrary to expectations, non-owners and male annotators showed higher agreement levels than dog owners and female annotators, respectively, while professionals showed higher agreement levels, aligned with our initial hypothesis; and (3) the presence of audio substantially increased annotators' confidence in identifying specific emotions, particularly anger and fear.

</details>


### [12] [DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles](https://arxiv.org/abs/2602.15355)
*Rong Fu,Jiekai Wu,Haiyun Wei,Yee Tan Jia,Wenxin Zhang,Yang Li,Xiaowen Ma,Wangyu Wu,Simon Fong*

Main category: cs.CV

TL;DR: DAV-GSWT是一个数据高效的框架，它利用扩散先验和主动视图采样，从最少输入观测中合成高保真3D高斯泼溅Wang Tiles，显著降低数据量需求，同时保持大型虚拟环境的视觉质量和交互性能。


<details>
  <summary>Details</summary>
Motivation: 现有的将Wang Tiles集成到3D高斯泼溅的方法通常受限于对密集采样示例重建的依赖，导致高数据量需求。

Method: DAV-GSWT通过整合扩散先验和主动视图采样来工作。具体而言，它将分层不确定性量化机制与生成扩散模型相结合，自主识别最具信息量的视点，同时补全缺失的结构细节以确保瓦片之间的无缝过渡。

Result: 实验结果表明，该系统显著减少了所需的数据量，同时保持了大型虚拟环境所需的视觉完整性和交互性能。

Conclusion: DAV-GSWT提供了一种数据高效的框架，用于生成高质量的3D高斯泼溅Wang Tiles，从而实现大型虚拟环境所需的视觉完整性和交互性能，同时显著减少数据需求。

Abstract: The emergence of 3D Gaussian Splatting has fundamentally redefined the capabilities of photorealistic neural rendering by enabling high-throughput synthesis of complex environments. While procedural methods like Wang Tiles have recently been integrated to facilitate the generation of expansive landscapes, these systems typically remain constrained by a reliance on densely sampled exemplar reconstructions. We present DAV-GSWT, a data-efficient framework that leverages diffusion priors and active view sampling to synthesize high-fidelity Gaussian Splatting Wang Tiles from minimal input observations. By integrating a hierarchical uncertainty quantification mechanism with generative diffusion models, our approach autonomously identifies the most informative viewpoints while hallucinating missing structural details to ensure seamless tile transitions. Experimental results indicate that our system significantly reduces the required data volume while maintaining the visual integrity and interactive performance necessary for large-scale virtual environments.

</details>


### [13] [GMAIL: Generative Modality Alignment for generated Image Learning](https://arxiv.org/abs/2602.15368)
*Shentong Mo,Sukmin Yun*

Main category: cs.CV

TL;DR: 本文提出了GMAIL框架，通过将生成图像视为独立模态并在潜在空间中对齐它们与真实图像，以判别性地利用生成图像，从而提升了视觉-语言模型的训练效果，避免了模态差异导致的模式崩溃。


<details>
  <summary>Details</summary>
Motivation: 生成模型虽然能合成高度逼真的图像，为机器学习模型训练提供丰富数据源，但将生成图像不加区分地用作真实图像进行训练，由于真实域和合成域之间的模态差异，可能导致模式崩溃。

Method: 本文提出了GMAIL框架，将生成图像明确视为一个独立于真实图像的模态。该方法通过多模态学习，在同一潜在空间中弥合了两种不同模态。具体来说，首先使用跨模态对齐损失在生成图像上微调一个模型，然后利用这个对齐后的模型进一步训练各种视觉-语言模型。

Result: GMAIL显著提高了图像字幕生成、零样本图像检索、零样本图像分类和长字幕检索等任务的性能。它还显示出积极的生成数据扩展趋势，并显著增强了大型多模态模型LLaVA的字幕生成性能。

Conclusion: GMAIL通过对齐生成图像和真实图像的模态，有效利用了生成模型的优势，提升了生成图像在各种视觉-语言任务中的学习效果，并且可以轻松集成到现有的视觉-语言模型中。

Abstract: Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.

</details>


### [14] [Bridging Day and Night: Target-Class Hallucination Suppression in Unpaired Image Translation](https://arxiv.org/abs/2602.15383)
*Shuwei Li,Lei Tan,Robby T. Tan*

Main category: cs.CV

TL;DR: 该论文提出了一种新的框架，用于检测和抑制昼夜非配对图像翻译中的语义幻觉。通过双头判别器进行幻觉检测，并利用类别特定原型进行幻觉抑制，最终显著提升了BDD100K数据集上15.5%的mAP，并对易幻觉类别（如交通灯）实现了31.7%的增益。


<details>
  <summary>Details</summary>
Motivation: 昼夜非配对图像翻译对下游任务很重要，但由于巨大的外观变化和缺乏直接的像素级监督而极具挑战性。现有方法常引入语义幻觉（如错误合成交通标志、车辆和人造光效果），严重影响下游性能。

Method: 提出了一种新颖的框架来检测和抑制幻觉。通过设计一个双头判别器（同时执行语义分割）来检测背景区域中的幻觉内容。通过引入类别特定的原型（通过聚合目标域标注对象的特征构建）作为语义锚点来抑制幻觉。该框架基于薛定谔桥（Schrodinger Bridge）翻译模型，通过迭代优化，将检测到的幻觉特征在特征空间中明确地推离类别原型，从而在翻译过程中保留对象语义。

Result: 在定性和定量方面均优于现有方法。在BDD100K数据集上，对于昼夜域适应，mAP提高了15.5%，对于容易出现幻觉的类别（如交通灯）取得了31.7%的显著增益。

Conclusion: 该框架有效地检测并抑制了非配对昼夜图像翻译中的语义幻觉，从而显著提升了下游任务的性能。

Abstract: Day-to-night unpaired image translation is important to downstream tasks but remains challenging due to large appearance shifts and the lack of direct pixel-level supervision. Existing methods often introduce semantic hallucinations, where objects from target classes such as traffic signs and vehicles, as well as man-made light effects, are incorrectly synthesized. These hallucinations significantly degrade downstream performance. We propose a novel framework that detects and suppresses hallucinations of target-class features during unpaired translation. To detect hallucination, we design a dual-head discriminator that additionally performs semantic segmentation to identify hallucinated content in background regions. To suppress these hallucinations, we introduce class-specific prototypes, constructed by aggregating features of annotated target-domain objects, which act as semantic anchors for each class. Built upon a Schrodinger Bridge-based translation model, our framework performs iterative refinement, where detected hallucination features are explicitly pushed away from class prototypes in feature space, thus preserving object semantics across the translation show that our method outperforms existing approaches both qualitatively and quantitatively. On the BDD100K dataset, it improves mAP by 15.5% for day-to-night domain adaptation, with a notable 31.7% gain for classes such as traffic lights that are prone to hallucinations.

</details>


### [15] [Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching](https://arxiv.org/abs/2602.15396)
*Jeongwoo Shin,Jinhwan Sul,Joonseok Lee,Jaewong Choi,Jaemoo Choi*

Main category: cs.CV

TL;DR: Adjoint Schrödinger Bridge Matching (ASBM) 是一种新的生成模型，通过学习薛定谔桥前向动态和优化后向动态，解决了扩散模型轨迹弯曲和效率低下的问题，生成更直、更高效的采样路径，并在图像生成中表现出更高的保真度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型通常会产生高度弯曲的轨迹和嘈杂的得分目标，这是由于其无信息、无记忆的前向过程导致数据-噪声耦合不独立。

Method: ASBM是一个两阶段的生成建模框架。首先，通过数据到能量采样的视角学习薛定谔桥（SB）前向动态，将数据传输到能量定义的先验。其次，通过由诱导的最优耦合监督的简单匹配损失来学习后向生成动态。

Result: ASBM生成更直、更高效的采样路径，提高了高维数据的稳定性和效率。在图像生成实验中，ASBM在更少的采样步骤下提高了保真度，并且其最优轨迹可有效蒸馏至一步生成器。

Conclusion: ASBM通过恢复最优轨迹，显著提高了生成模型的稳定性和效率，并在图像生成方面取得了更好的性能，甚至可以用于单步生成器蒸馏。

Abstract: Diffusion models often yield highly curved trajectories and noisy score targets due to an uninformative, memoryless forward process that induces independent data-noise coupling. We propose Adjoint Schrödinger Bridge Matching (ASBM), a generative modeling framework that recovers optimal trajectories in high dimensions via two stages. First, we view the Schrödinger Bridge (SB) forward dynamic as a coupling construction problem and learn it through a data-to-energy sampling perspective that transports data to an energy-defined prior. Then, we learn the backward generative dynamic with a simple matching loss supervised by the induced optimal coupling. By operating in a non-memoryless regime, ASBM produces significantly straighter and more efficient sampling paths. Compared to prior works, ASBM scales to high-dimensional data with notably improved stability and efficiency. Extensive experiments on image generation show that ASBM improves fidelity with fewer sampling steps. We further showcase the effectiveness of our optimal trajectory via distillation to a one-step generator.

</details>


### [16] [Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461)
*Marija Ivanovska,Vitomir Štruc*

Main category: cs.CV

TL;DR: 本文首次系统评估了开源多模态大语言模型（MLLMs）在零样本单图像活体攻击检测（MAD）中的表现，发现LLaVA1.6-Mistral-7B超越了现有基线，表明MLLMs在生物识别安全领域具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的活体攻击检测（MAD）系统通常需要针对特定任务进行训练，并且在面对未曾见过的攻击类型时泛化能力差。尽管开源多模态大语言模型（MLLMs）在视觉-语言推理方面表现出强大能力，但其在生物识别取证领域的潜力尚未被充分探索。

Method: 本文首次对开源多模态大语言模型（MLLMs）在单图像活体攻击检测（MAD）任务上进行了系统的零样本评估。研究使用了公开可用的模型权重和标准化的可复现协议，并在多种活体攻击技术上进行了测试，未进行任何微调或领域适应。

Result: 多模态大语言模型（MLLMs）在零样本设置下展现出显著的区分能力，其中LLaVA1.6-Mistral-7B模型在等错误率（EER）方面超越了目前最先进的特定任务活体攻击检测（MAD）基线至少23%，达到了最先进的性能。这表明多模态预训练能够隐式编码活体攻击伪影中细微的面部不一致性。

Conclusion: 开源多模态大语言模型（MLLMs）为生物识别安全和法医图像分析提供了可复现、可解释且具有竞争力的基础，并为通过微调或轻量级适应开发最先进的活体攻击检测（MAD）系统带来了新机遇。

Abstract: Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-linguistic reasoning, but their potential in biometric forensics remains underexplored. In this paper, we present the first systematic zero-shot evaluation of open-source MLLMs for single-image MAD, using publicly available weights and a standardized, reproducible protocol. Across diverse morphing techniques, many MLLMs show non-trivial discriminative ability without any fine-tuning or domain adaptation, and LLaVA1.6-Mistral-7B achieves state-of-the-art performance, surpassing highly competitive task-specific MAD baselines by at least 23% in terms of equal error rate (EER). The results indicate that multimodal pretraining can implicitly encode fine-grained facial inconsistencies indicative of morphing artifacts, enabling zero-shot forensic sensitivity. Our findings position open-source MLLMs as reproducible, interpretable, and competitive foundations for biometric security and forensic image analysis. This emergent capability also highlights new opportunities to develop state-of-the-art MAD systems through targeted fine-tuning or lightweight adaptation, further improving accuracy and efficiency while preserving interpretability. To support future research, all code and evaluation protocols will be released upon publication.

</details>


### [17] [RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution](https://arxiv.org/abs/2602.15490)
*Youngwan Jin,Incheol Park,Yagiz Nalcakan,Hyeongjin Ju,Sanghyeop Yeo,Shiho Kim*

Main category: cs.CV

TL;DR: RPT-SR是一种新型红外图像超分辨率模型，通过将场景布局信息编码到注意力机制中来解决现有模型在固定视点红外场景中的效率低下问题，利用区域先验令牌和局部令牌实现了最先进的性能，并适用于多种红外波段。


<details>
  <summary>Details</summary>
Motivation: 现有通用超分辨率模型（特别是Vision Transformers）在固定或准静态视点红外成像场景（如监控和自动驾驶）中效率低下。它们未能利用这些场景中固有的强大、持久的空间先验信息，导致冗余学习和次优性能。

Method: RPT-SR（Regional Prior attention Transformer for infrared image Super-Resolution）是一种新型架构，它将场景布局信息显式编码到注意力机制中。其核心是一个双令牌框架，融合了：1) 可学习的区域先验令牌（作为场景全局结构的持久记忆），与 2) 局部令牌（捕获当前输入的帧特定内容）。通过在注意力机制中利用这些令牌，模型允许先验信息动态地调节局部重建过程。

Result: 广泛的实验验证了RPT-SR方法的有效性。RPT-SR在涵盖长波（LWIR）和短波（SWIR）谱的各种数据集上建立了新的最先进性能，展示了其广泛适用性和多功能性。

Conclusion: RPT-SR通过有效利用红外场景中的空间先验信息，解决了现有超分辨率模型的局限性，并在多种红外波段上取得了突破性的性能，证明了其在红外图像超分辨率领域的先进性。

Abstract: General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra

</details>


### [18] [Semantic-Guided 3D Gaussian Splatting for Transient Object Removal](https://arxiv.org/abs/2602.15516)
*Aditi Prabakaran,Priyesh Shukla*

Main category: cs.CV

TL;DR: 提出了一种基于视觉-语言模型的语义过滤框架，通过语义分类而非运动模式解决3DGS中瞬态物体引起的伪影和视差模糊问题，实现了更好的重建质量和低内存开销。


<details>
  <summary>Details</summary>
Motivation: 随意多视角捕获中的瞬态物体导致3D高斯泼溅 (3DGS) 重建出现重影伪影。现有解决方案内存开销大或易受视差模糊影响。

Method: 提出了一种基于视觉-语言模型 (Vision-Language Models) 的语义过滤框架，用于类别感知 (category-aware) 的瞬态物体去除。该方法通过在训练迭代中累积渲染视图与干扰物文本提示 (distractor text prompts) 之间的CLIP相似度分数，对每个高斯进行处理。超过校准阈值的高斯会进行不透明度正则化 (opacity regularization) 和周期性修剪 (periodic pruning)。与基于运动的方法不同，语义分类通过独立于运动模式识别物体类别来解决视差模糊问题。

Result: 在RobustNeRF基准测试中，与原版3DGS相比，该方法在四个序列上持续提高了重建质量，同时保持了最小的内存开销和实时渲染性能。

Conclusion: 阈值校准和与基线的比较验证了语义引导在可预测干扰物类别场景中作为瞬态物体去除的实用策略。

Abstract: Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.

</details>


### [19] [Advanced Acceptance Score: A Holistic Measure for Biometric Quantification](https://arxiv.org/abs/2602.15535)
*Aman Verma,Seshan Srirangarajan,Sumantra Dutta Roy*

Main category: cs.CV

TL;DR: 本论文提出了一种新的、全面的手势生物识别适应度分数评估方法——“高级接受分数”，该方法通过考虑排名、分数相关性、趋势对应和身份特征解耦，被证明比现有错误率指标更合适且更可靠。


<details>
  <summary>Details</summary>
Motivation: 手势生物识别中的量化特征涉及从手势和身份感知特征空间推导出适应度分数。然而，评估这些分数的质量仍然是一个悬而未决的问题。现有的生物识别能力评估文献依赖于错误率，但这些错误率不能指示分数的优劣。因此，需要一种新的评估方法。

Method: 作者提出了一套详尽的评估指标。首先，将输出分数的排名顺序和相关性作为评估的主要依据，考虑了排名偏差以及对高排名手势的较高分数和低排名手势的较低分数的奖励。其次，补偿了输出分数和真实分数趋势之间的一致性。最后，将手势身份特征之间的解耦作为折扣因子。通过整合这些元素并进行适当加权，作者制定了“高级接受分数”作为一种整体评估指标。该方法在三个数据集和五个SOTA模型上进行了实验验证。

Result: 实验结果表明，使用本研究提出的度量方法选择的最优分数比现有其他度量方法更合适。此外，本研究提出的度量方法与现有度量方法显示出相关性，这进一步验证了其可靠性。

Conclusion: 本研究提出了一种高级接受分数，作为手势生物识别中适应度分数的整体评估指标，该指标比现有方法更合适且更可靠，并与现有方法显示出相关性。

Abstract: Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \href{ }{code} public.

</details>


### [20] [Spanning the Visual Analogy Space with a Weight Basis of LoRAs](https://arxiv.org/abs/2602.15727)
*Hila Manor,Rinon Gal,Haggai Maron,Tomer Michaeli,Gal Chechik*

Main category: cs.CV

TL;DR: 针对视觉类比学习中现有LoRA方法泛化能力受限的问题，本文提出了LoRWeB。该方法通过动态组合可学习的LoRA基模块和轻量级编码器，在推理时为每个类比任务专门化模型，实现了最先进的性能并显著提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通过单个LoRA模块将文本到图像模型应用于视觉类比学习，但受限于在一个固定的适应模块中捕获多样视觉变换空间的能力，从而限制了泛化能力。

Method: 本文提出了LoRWeB方法，通过动态组合学习到的变换原语，在推理时为每个类比任务专门化模型。该方法包含两个关键组件：1) 一个可学习的LoRA模块基，用于跨越不同视觉变换的空间；2) 一个轻量级编码器，根据输入的类比对动态选择和权衡这些基LoRA。

Result: 综合评估表明，所提出的方法实现了最先进的性能，并显著提高了对未见视觉变换的泛化能力。

Conclusion: LoRA基分解为灵活的视觉操作提供了一个有前景的方向。

Abstract: Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\{\mathbf{a}$, $\mathbf{a}'$, $\mathbf{b}\}$, the goal is to generate $\mathbf{b}'$ such that $\mathbf{a} : \mathbf{a}' :: \mathbf{b} : \mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a "space of LoRAs". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in

</details>


### [21] [Dynamic Training-Free Fusion of Subject and Style LoRAs](https://arxiv.org/abs/2602.15539)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种动态免训练的LoRA融合框架，通过在前向传播中进行特征级选择和在反向去噪中进行度量引导的潜在调整，实现了连贯的主题-风格合成，无需重新训练，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA融合方法大多采用静态统计启发式融合LoRA权重，这偏离了LoRA学习自适应特征调整的初衷，并且忽略了采样输入的随机性。

Method: 本文提出了一种动态、免训练的融合框架，贯穿整个生成过程。在前向传播阶段，在每个应用LoRA的层中，动态计算基础模型原始特征与主题和风格LoRA产生的特征之间的KL散度，并自适应地选择最合适的权重进行融合。在反向去噪阶段，通过动态应用基于CLIP和DINO分数等客观指标导出的梯度修正，进一步优化生成轨迹，提供持续的语义和风格指导。

Result: 通过对各种主题-风格组合的广泛实验证明，该方法在定性和定量上均持续优于现有的最先进的LoRA融合方法。

Conclusion: 该方法通过整合特征级选择和度量引导的潜在调整两种互补机制，实现了动态、连贯的主题-风格合成，无需重新训练，并在定性和定量上均优于现有最先进的LoRA融合方法。

Abstract: Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.

</details>


### [22] [Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2602.15556)
*Guangtao Lyu,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Xueting Li,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 针对LVLM幻觉问题，本文提出了一种免训练的注意力干预方法PADE，通过利用内部正向注意力动态，在多个LVLM和基准测试中有效改善了视觉定位并减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: LVLM存在幻觉问题，现有免训练方法（如对比解码、辅助专家模型、静态内部信号增强）计算开销大、可能引入干扰，且易受注意力汇聚现象影响。

Method: 提出了一种免训练的注意力干预方法PADE，其包括构建PAD图以识别核心视觉区域，应用每头中位数绝对偏差缩放自适应控制干预强度，以及利用系统-令牌补偿维持对复杂指令的注意力并支持长期输出一致性。

Result: 在多个LVLM和基准测试上的实验表明，PADE显著改善了视觉定位能力并减少了幻觉。

Conclusion: 内部注意力动态可有效提高多模态推理的可靠性。

Abstract: LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.

</details>


### [23] [Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning](https://arxiv.org/abs/2602.15579)
*Amal Lahchim,Lambros Athanasiou*

Main category: cs.CV

TL;DR: 本文提出了一种全自动OCT图像血管分割和分类流水线，通过集成图像预处理、K-means聚类和机器学习分类器，实现了高准确率和低计算复杂性，用于解决OCT图像分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉光学相干断层扫描（OCT）图像存在噪声、成像伪影和复杂的组织结构，使得血管可视化分析面临挑战，需要一种自动化的、高精度的分析方法。

Method: 该方法整合了图像预处理、导丝伪影去除、极坐标到笛卡尔坐标转换、无监督K-means聚类以及局部特征提取。这些特征用于训练逻辑回归和支持向量机分类器，以实现像素级的血管分类。

Result: 实验结果显示，该方法在血管分割和分类方面表现出色，精度、召回率和F1分数高达1.00，总体分类准确率达到99.68%。该方法提供了准确的血管边界检测，同时保持了较低的计算复杂性和最少的手动标注需求。

Conclusion: 该方法为自动OCT图像分析提供了一种可靠且高效的解决方案，在临床决策支持和实时医学图像处理方面具有潜在应用。

Abstract: Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.

</details>


### [24] [An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment](https://arxiv.org/abs/2602.15584)
*Flavien Armangeon,Thibaud Ehret,Enric Meinhardt-Llopis,Rafael Grompone von Gioi,Guillaume Thibault,Marc Petit,Gabriele Facciolo*

Main category: cs.CV

TL;DR: 该论文介绍了IRIS-v2数据集，并通过结合分割和图匹配的方法，旨在解决老旧工业设施中功能示意图与2D/3D场景对齐的挑战，以提高数字孪生构建的效率。


<details>
  <summary>Details</summary>
Motivation: 为缺乏原生数字模型的老旧工业设施构建数字孪生时，将功能示意图与2D和3D场景数据对齐至关重要。现有的手动对齐方法（使用图像和激光雷达数据）效率低下，无法规模化。此外，示意图与现实之间存在不一致性，且缺乏公开的工业数据集，使得该问题极具挑战性且研究不足。

Method: 引入了IRIS-v2综合数据集，包含图像、点云、2D标注框和分割掩模、CAD模型、3D管道路径信息以及P&ID。该方法通过结合分割（segmentation）和图匹配（graph matching）技术，在一个实际案例中进行了对齐实验。

Result: 该论文引入了IRIS-v2综合数据集，以支持进一步的研究。在实际案例研究中，通过结合分割和图匹配的实验，旨在减少功能示意图与三维场景对齐所需的时间。

Conclusion: 本论文通过引入IRIS-v2数据集和结合分割与图匹配的方法，为工业设施的数字孪生构建中的功能示意图与三维场景对齐问题提供了一个有前景的解决方案，并旨在提高对齐任务的效率。

Abstract: Aligning functional schematics with 2D and 3D scene acquisitions is crucial for building digital twins, especially for old industrial facilities that lack native digital models. Current manual alignment using images and LiDAR data does not scale due to tediousness and complexity of industrial sites. Inconsistencies between schematics and reality, and the scarcity of public industrial datasets, make the problem both challenging and underexplored. This paper introduces IRIS-v2, a comprehensive dataset to support further research. It includes images, point clouds, 2D annotated boxes and segmentation masks, a CAD model, 3D pipe routing information, and the P&ID (Piping and Instrumentation Diagram). The alignment is experimented on a practical case study, aiming at reducing the time required for this task by combining segmentation and graph matching.

</details>


### [25] [Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650)
*Marco Salmè,Federico Siciliano,Fabrizio Silvestri,Paolo Soda,Rosa Sicilia,Valerio Guarrasi*

Main category: cs.CV

TL;DR: 本研究提出了概念增强多模态RAG（CEMRAG）框架，通过将视觉表示分解为可解释的临床概念并与多模态RAG集成，以解决放射报告生成（RRG）中VLM缺乏可解释性和幻觉问题。实验证明，CEMRAG在临床准确性和NLP指标上优于现有方法，并挑战了可解释性与性能之间的权衡，为临床可信赖的AI辅助放射学提供了途径。


<details>
  <summary>Details</summary>
Motivation: 通过视觉-语言模型（VLM）进行放射报告生成（RRG）在减轻文档负担、提高报告一致性和加速临床工作流程方面具有潜力，但因缺乏可解释性以及生成与影像证据不符的幻觉结果，其临床应用受到限制。现有研究通常将可解释性和准确性视为独立目标。

Method: 提出了概念增强多模态RAG（CEMRAG）框架。该方法将视觉表示分解为可解释的临床概念，并将其与多模态RAG集成。通过利用丰富的上下文提示进行放射报告生成。

Result: 在MIMIC-CXR和IU X-Ray数据集上，CEMRAG在多种VLM架构、训练方案和检索配置下，相较于传统RAG和仅基于概念的基线方法，在临床准确性指标和标准NLP衡量标准上均取得了持续改进。这些结果挑战了可解释性与性能之间的假设权衡。

Conclusion: CEMRAG通过统一框架提高了报告生成的可解释性和事实准确性，其模块化设计将可解释性分解为视觉透明度和结构化语言模型条件，为临床可信赖的AI辅助放射学提供了原则性途径。这表明透明的视觉概念可以增强而非损害医学VLM的诊断准确性。

Abstract: Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.

</details>


### [26] [A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models](https://arxiv.org/abs/2602.15656)
*Mustafa Yurdakul,Zeynep Sena Bastug,Ali Emre Gok,Sakir Taşdemir*

Main category: cs.CV

TL;DR: 本研究提出了一个用于草莓成熟度检测的新公开数据集，并使用YOLO系列模型进行了基准测试，结果显示中小型模型表现良好，为智能农业提供了参考。


<details>
  <summary>Details</summary>
Motivation: 草莓成熟度评估对于避免生产者损失和确保消费者获得优质产品至关重要。然而，传统的视觉评估方法主观且误差大，因此需要计算机辅助系统。现有文献中缺乏全面的公开数据集，这阻碍了该领域研究的比较。

Method: 研究创建了一个新的、公开可用的草莓成熟度数据集，包含566张图像和1,201个标记对象，数据在土耳其的两个不同温室中，在可变光照和环境条件下采集。然后使用YOLOv8、YOLOv9和YOLO11模型对数据集进行了比较测试。

Result: YOLOv9c模型取得了最高的精确度（90.94%），YOLO11s模型取得了最高的召回率（83.74%）。在通用性能指标mAP@50上，YOLOv8s模型表现最佳，成功率为86.09%。

Conclusion: 该研究证明了中小型模型在此类数据集上表现出更均衡和高效的性能，并为智能农业应用提供了基础参考。

Abstract: The strawberry (Fragaria x ananassa), known worldwide for its economic value and nutritional richness, is a widely cultivated fruit. Determining the correct ripeness level during the harvest period is crucial for both preventing losses for producers and ensuring consumers receive a quality product. However, traditional methods, i.e., visual assessments alone, can be subjective and have a high margin of error. Therefore, computer-assisted systems are needed. However, the scarcity of comprehensive datasets accessible to everyone in the literature makes it difficult to compare studies in this field. In this study, a new and publicly available strawberry ripeness dataset, consisting of 566 images and 1,201 labeled objects, prepared under variable light and environmental conditions in two different greenhouses in Turkey, is presented to the literature. Comparative tests conducted on the data set using YOLOv8, YOLOv9, and YOLO11-based models showed that the highest precision value was 90.94% in the YOLOv9c model, while the highest recall value was 83.74% in the YOLO11s model. In terms of the general performance criterion mAP@50, YOLOv8s was the best performing model with a success rate of 86.09%. The results show that small and medium-sized models work more balanced and efficiently on this type of dataset, while also establishing a fundamental reference point for smart agriculture applications.

</details>


### [27] [Bayesian Optimization for Design Parameters of 3D Image Data Analysis](https://arxiv.org/abs/2602.15660)
*David Exler,Joaquin Eduardo Urrutia Gómez,Martin Krüger,Maike Schliephake,John Jbeily,Mario Vitacolonna,Rüdiger Rudolf,Markus Reischl*

Main category: cs.CV

TL;DR: 该论文提出了一种名为“3D数据分析优化流程”的方法，通过两个贝叶斯优化阶段，自动化3D生物医学图像数据的分割和分类模型设计及参数优化，并在案例研究中证明了其效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 在大规模生物医学成像（特别是3D数据）中，基于深度学习的分割和分类至关重要，但手动分析不切实际。现有方法在选择合适模型和调整参数方面存在重大瓶颈。

Method: 该方法通过两个贝叶斯优化阶段，自动化分割和分类模型的设计与参数调整：
1.  **第一阶段（分割优化）**: 针对分割模型选择和后处理参数优化，使用领域适应的句法基准数据集进行。引入了新的分割质量指标作为目标函数以实现简洁的性能评估。
2.  **第二阶段（分类优化）**: 针对分类器的设计选择（如编码器、分类头架构、先验知识整合、预训练策略）进行优化。此阶段包含一个辅助类别注释工作流，从分割结果中提取预测实例并顺序呈现给操作员，以减少手动标注工作。

Result: 在四个案例研究中，“3D数据分析优化流程”成功且高效地为不同的数据集识别出有效的模型和参数配置。

Conclusion: “3D数据分析优化流程”能够有效地为特定数据集识别出合适的模型和参数配置。

Abstract: Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.

</details>


### [28] [Criteria-first, semantics-later: reproducible structure discovery in image-based sciences](https://arxiv.org/abs/2602.15712)
*Jan Bumberger*

Main category: cs.CV

TL;DR: 该论文提出了一个“标准优先，语义后置”的图像分析新范式，旨在解决当前“语义优先”方法在开放式发现和长期监测中的局限性，通过无语义的结构提取和下游语义映射，实现可重现的、领域通用的分析。


<details>
  <summary>Details</summary>
Motivation: 当前图像分析中主导的“语义优先”范式（通过预测或强制领域特定标签来恢复结构）在开放式科学发现、跨传感器和跨站点可比性以及领域本体和标签集随时间漂移的长期监测等关键情境下，系统性地失效，限制了图像科学的价值。

Method: 研究提出了一种“标准优先，语义后置”的演绎反转范式。它引入了一个统一的框架，用于将基于标准的、无语义的结构提取与下游的语义映射（到领域本体或词汇表）分开。这种方法通过明确的最优性标准而非局部领域本体来发现稳定的划分、结构场或层级结构，从而实现可重现的分析。

Result: 该方法提供了一个领域通用的支架，用于跨图像科学的可重现分析。它能够实现多元解释和明确的交叉引用，而无需重写上游提取过程。研究结果表明，当标签无法扩展时，“标准优先”组件会反复出现。

Conclusion: 该研究提出了超越传统类别准确性验证的方法，并将结构产品视为FAIR且AI就绪的数字对象，以支持长期监测和数字孪生应用。

Abstract: Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.

</details>


### [29] [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724)
*Shutian Gu,Chengkai Huang,Ruoyu Wang,Lina Yao*

Main category: cs.CV

TL;DR: 本文提出了一种检索增强框架，通过在指令和步骤层面引入检索模块，显著提升了大型语言模型在视觉语言导航任务中的效率和稳定表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示的LLM导航方法在决策过程中效率低下，因为LLM模型在每一步都需要从头开始重复解释指令，并对嘈杂且冗长的可导航候选进行推理。

Method: 本文提出了一种检索增强框架，通过在两个互补层面引入检索来提高基于大型语言模型（LLM）的视觉语言导航（VLN）的效率和稳定性，而无需修改或微调LLM。在情节层面，一个指令级嵌入检索器选择语义相似的成功导航轨迹作为上下文示例，为指令基础提供任务特定先验。在步骤层面，一个模仿学习的候选检索器在LLM推理前修剪不相关的可导航方向，减少动作模糊性和提示复杂性。这两个检索模块都是轻量级、模块化的，并独立于LLM进行训练。

Result: 在Room-to-Room (R2R) 基准测试中，该方法在可见和不可见环境中，成功率（Success Rate）、先知成功率（Oracle Success Rate）和路径长度标准化成功率（SPL）方面均实现了持续提升。消融研究进一步表明，指令级示例检索和候选剪枝为全局指导和分步决策效率提供了互补的优势。

Conclusion: 检索增强决策支持是提升基于LLM的视觉语言导航效率和稳定性的有效且可扩展策略。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.

</details>


### [30] [Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding](https://arxiv.org/abs/2602.15734)
*Guile Wu,David Huang,Bingbing Liu,Dongfeng Bai*

Main category: cs.CV

TL;DR: 该论文提出了一种利用语言和几何基础的稀疏体素表示的新方法，通过统一的框架协同建模3D场景的外观、语义和几何，以解决现有方法忽略外观、语义和几何协同作用的问题，并在整体场景理解和重建方面取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D开放词汇场景理解方法主要侧重于将2D基础模型中的语言特征蒸馏到3D特征场中，但很大程度上忽略了场景外观、语义和几何之间的协同作用。这导致场景理解往往偏离场景的底层几何结构，并与重建过程脱节。

Method: 本文提出了一种利用语言和几何基础的稀疏体素表示的新方法。具体而言，它使用3D稀疏体素作为基元，并采用外观场、密度场、特征场和置信度场来整体表示3D场景。为了促进外观、密度和特征场之间的协同作用，构建了一个特征调制模块，并将2D基础模型中的语言特征蒸馏到3D场景模型中。此外，通过深度相关正则化和模式一致性正则化，将几何蒸馏集成到特征场蒸馏中，以将几何知识从几何基础模型转移到3D场景表示中。

Result: 广泛的实验表明，该方法在整体场景理解和重建方面取得了优于现有技术的综合性能。

Conclusion: 该方法通过统一的框架协同建模3D场景的外观、语义和几何，在整体场景理解和重建方面取得了优于现有技术的性能。

Abstract: Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.

</details>


### [31] [Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772)
*Sen Ye,Mengde Xu,Shuyang Gu,Di He,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: 该论文提出了Reason-Reflect-Refine (R3) 框架，通过“生成-理解-再生成”的多步过程，解决了多模态模型中生成与理解能力之间的权衡问题，从而在生成和理解两方面都取得了提升。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型面临生成能力提升与理解能力下降之间的权衡挑战，主要原因在于生成与理解之间潜在的冲突。

Method: 提出Reason-Reflect-Refine (R3) 框架，将单步生成任务重构为“生成-理解-再生成”的多步过程，显式利用模型的理解能力辅助生成。

Result: 成功缓解了优化困境，实现了更强的生成结果，并提升了与生成过程相关的理解能力。

Conclusion: R3框架为设计下一代统一多模态模型提供了宝贵的见解。

Abstract: Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of "generate-understand-regenerate". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at .

</details>


### [32] [NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy](https://arxiv.org/abs/2602.15775)
*Laura Salort-Benejam,Antonio Agudo*

Main category: cs.CV

TL;DR: NeRFscopy是一个自监督的神经渲染管线，用于从单目视频中对可变形内窥镜组织进行3D重建和新视角合成，其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜检查在医学成像中至关重要，但开发一个鲁棒的内窥镜视频动态3D重建管线面临挑战，主要原因在于组织的可变形性、单目摄像机的使用、光照变化、遮挡以及未知的相机轨迹。解决这些问题可以增强可视化、提高诊断准确性、辅助治疗规划并指导手术过程。

Method: NeRFscopy是一个受神经渲染启发的自监督管线，用于从单目视频中对可变形内窥镜组织进行新视角合成和3D重建。它包含一个可变形模型，该模型具有一个规范辐射场和一个由SE(3)变换参数化的时间相关形变场。此外，它通过引入复杂的项有效利用彩色图像，仅从数据中学习3D隐式模型，无需任何模板或预训练模型。

Result: NeRFscopy在新视角合成方面取得了准确的结果，并在各种具有挑战性的内窥镜场景中优于竞争方法。

Conclusion: NeRFscopy通过引入一个鲁棒的自监督神经渲染管线，成功解决了从单目视频重建可变形内窥镜组织3D模型的挑战，并在新视角合成方面表现出卓越的性能。

Abstract: Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.

</details>


### [33] [Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers](https://arxiv.org/abs/2602.15783)
*Lucas Sancéré,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: 该研究提出并评估了使用可扩展图Transformer对全切片细胞图进行分类的方法，在区分形态相似的健康与肿瘤细胞的任务中，其性能优于基于图像的方法，并强调了细胞上下文信息的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在分析全切片图像（WSI）时，依赖于基于图像块的表示，这导致了组织层面关键上下文信息的丢失。本研究旨在解决这一问题，特别是在区分形态高度相似的健康与肿瘤上皮细胞的挑战性任务中。

Method: 研究提出在全切片细胞图上使用可扩展图Transformer（SGFormer和DIFFormer）进行分类。节点特征配置探索了形态学特征、纹理特征以及非上皮细胞类别信息的组合。在处理多张全切片图像时，将图像块（$2560 	imes 2560$像素）转换为图进行分析，以克服计算限制。

Result: 在单张WSI上，SGFormer和DIFFormer的平衡准确率分别为$85.2 \pm 1.5$和$85.1 \pm 2.5$，优于最佳图像方法的$81.2 \pm 3.0$。最有效的节点特征组合是形态学和纹理特征，辅以非上皮细胞的类别信息。在多张WSI上，DIFFormer的平衡准确率为$83.6 \pm 1.9$，而最先进的基于图像的模型CellViT256为$78.1 \pm 0.5$。

Conclusion: 该研究证明，可扩展图Transformer模型在全切片图像的细胞图分类任务中优于基于图像的方法，尤其是在区分形态相似的细胞类型时。细胞图上的上下文信息（包括形态、纹理特征及非上皮细胞类别）对提高分类性能至关重要。

Abstract: Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \pm 1.5$ ($\pm$ standard error) and $85.1 \pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \pm 0.5$.

</details>


### [34] [VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819)
*Hui Ren,Yuval Alaluf,Omer Bar Tal,Alexander Schwing,Antonio Torralba,Yael Vinker*

Main category: cs.CV

TL;DR: 一种数据高效的顺序素描生成方法，结合大型语言模型（LLM）进行语义规划和笔画排序，以及视频扩散模型进行高质量渲染，即使在有限的人工素描数据下也能生成遵循文本指令且细节丰富的顺序素描。


<details>
  <summary>Details</summary>
Motivation: 大多数生成模型将素描视为静态图像，忽略了创意绘画中固有的时间结构。

Method: 提出了一种数据高效的顺序素描生成方法，该方法调整了预训练的文本到视频扩散模型。关键在于结合大型语言模型（LLM）的语义规划和笔画排序能力与视频扩散模型的高质量渲染能力。素描被表示为笔画在空白画布上逐步绘制的短视频，由文本指令引导。采用两阶段微调策略：笔画排序使用具有受控时间结构的人工合成形状组合学习，而视觉外观则从仅七个手动创作的素描过程中提取。

Result: 尽管人工绘制素描数据量极少，但该方法生成了高质量的顺序素描，这些素描严格遵循文本指定的顺序，并展现出丰富的视觉细节。

Conclusion: 该方法通过画笔风格条件和自回归素描生成等扩展展示了其灵活性，实现了额外的可控性以及交互式、协作式绘画。

Abstract: Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [35] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: 本文介绍了EduResearchBench，一个用于教育学术写作的评估平台，它基于HATD框架分解研究工作流并提供细粒度诊断。通过课程学习策略训练的专用模型EduWrite在垂直领域表现优于大型通用模型，强调了数据质量和分层训练的重要性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在社会科学人工智能领域中的能力评估面临挑战，现有基准主要侧重于单一、整体生成，缺乏反映复杂学术研究工作流所需的细粒度评估。整体评分往往掩盖了具体的瓶颈。

Method: 引入EduResearchBench平台，该平台基于分层原子任务分解（HATD）框架，将研究工作流分解为六个专业研究模块和24个原子任务，以实现自动化评估和细粒度诊断反馈。提出课程学习策略，从基础技能逐步培养能力。利用5.5万原始学术样本，筛选出1.1万高质量指令对来训练专用教育学术写作模型EduWrite。

Result: EduWrite（30B）在多个核心指标上显著优于更大的通用模型（72B），证明了在垂直领域中，数据质量密度和分层阶段训练课程比参数规模更具决定性。

Conclusion: 在垂直领域，数据质量密度和分层阶段训练课程比参数规模更具决定性。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [36] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: 本文提出了Indic-TunedLens，一个针对印度语言的跨语言解释性框架，通过调整隐藏状态来更忠实地解码模型表示，在10种印度语言上显著优于现有方法，尤其对低资源语言表现出色，并提供了对多语言Transformer层级语义编码的深入洞察。


<details>
  <summary>Details</summary>
Motivation: 现有的解释性工具主要为英语设计，而多语言大语言模型在印度等语言多样地区的应用日益增多。以往研究表明LLMs常在以英语为中心的表示空间中运行，使得跨语言解释性成为一个紧迫的问题。

Method: 引入了Indic-TunedLens框架，它学习共享的仿射变换。与直接解码中间激活的标准Logit Lens不同，Indic-TunedLens会调整每个目标语言的隐藏状态，使其与目标输出分布对齐，从而实现更忠实的模型表示解码。

Result: 在MMLU基准测试上对10种印度语言进行评估，结果显示Indic-TunedLens显著优于最先进的解释性方法，特别是对于形态丰富和低资源的语言。

Conclusion: Indic-TunedLens为多语言Transformer的层级语义编码提供了关键洞察，并显著提升了印度语种（尤其是形态丰富和低资源语种）的解释性，超越了现有最先进的方法。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at . Our code is available at .

</details>


### [37] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 提出了一种名为CGRA DeBERTa的概念引导残差领域增强Transformer框架，用于提高哈迪斯语料库上的神学问答准确性。该模型结合了定制的DeBERTa骨干、LoRA适应器和概念感知门控机制，并在特定数据集上取得了97.85的EM分数，显著优于BERT和标准DeBERTa，同时保持了计算效率和神学精确性。


<details>
  <summary>Details</summary>
Motivation: 由于领域特定语义、长上下文依赖和概念敏感推理，对经典伊斯兰文本进行准确问答（QA）仍然具有挑战性。

Method: CGRA DeBERTa模型建立在定制的DeBERTa Transformer骨干之上，采用轻量级基于LoRA的适应器和残差概念感知门控机制。定制的DeBERTa嵌入块学习全局和位置上下文，而概念引导残差块则整合了来自12个核心术语的伊斯兰概念词典的神学先验知识。概念门控机制通过重要性加权注意力选择性地放大语义关键令牌，应用1.04至3.00的差异缩放。模型在包含Sahih al-Bukhari和Sahih Muslim文本中42591个问答对的数据集上进行训练。

Result: CGRA DeBERTa模型在测试数据集上取得了97.85的EM分数，绝对值超过了BERT（75.87）和DeBERTa（89.77）8.08分。该模型在增加约8的推理开销（由于参数高效门控）的同时实现了这一性能。定性评估表明，模型在信息提取、鉴别能力和神学精确性方面表现更好。

Conclusion: 本研究提出了高效、可解释、准确的圣训问答系统，该系统能够提供具有必要神学细微差别的教育材料。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [38] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: Vision Wormhole 是一种新颖的框架，通过重新利用视觉语言模型的视觉接口，实现了多智能体系统（MAS）中模型无关、无文本的通信，解决了传统文本通信的效率低下问题，并减少了端到端运行时间，同时保持了推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的由大型语言模型驱动的多智能体系统（MAS）在高级协作推理方面取得了进展，但受限于离散文本通信的低效性，导致显著的运行时开销和信息量化损失。虽然潜在状态传输提供了一种高带宽的替代方案，但现有方法要么假设同构的发送-接收器架构，要么依赖于特定配对的学习翻译器，这限制了在具有不相交流形的异构模型家族中的可扩展性和模块化。

Method: 本文提出了 Vision Wormhole 框架。其核心思想是重新利用视觉语言模型（VLM）的视觉接口，实现模型无关、无文本的通信。通过引入一个通用视觉编解码器（Universal Visual Codec），该框架将异构推理轨迹映射到一个共享的连续潜在空间中，并将其直接注入到接收者的视觉路径中，从而将视觉编码器作为智能体间“心灵感应”的通用端口。此外，该框架采用中心辐射型拓扑结构，将成对对齐的复杂度从 O(N^2) 降低到 O(N)，并利用无标签的师生蒸馏目标，将高速视觉通道与文本路径的稳健推理模式对齐。

Result: 在异构模型家族（如 Qwen-VL, Gemma）上的广泛实验表明，Vision Wormhole 在受控比较中减少了端到端实际运行时间，同时保持了与标准基于文本的多智能体系统相当的推理保真度。

Conclusion: Vision Wormhole 通过利用 VLM 的视觉接口，为多智能体系统提供了一种模型无关、无文本的通信框架，解决了传统文本通信的低效性和现有隐式状态传输方法的局限性。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at

</details>


### [39] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [40] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: 本研究开发并验证了一个名为LX的微调大型语言模型，用于从消费者文本中准确测量情绪和评估，其性能优于现有模型，并揭示了情绪对购买行为的直接和间接影响。


<details>
  <summary>Details</summary>
Motivation: 准确测量非结构化文本中的消费者情绪和评估仍然是营销研究和实践的核心挑战。

Method: 本研究引入了“语言提取器”（Linguistic eXtractor, LX），这是一个在消费者撰写并带有16种消费相关情绪和四种评估构建（信任、承诺、推荐、情感）自报告评分标签的文本上进行微调的大型语言模型。通过对在线零售数据应用LX，并使用看似无关回归进行分析。

Result: LX在开放式调查回复上实现了81%的宏观F1准确率，在第三方标注的亚马逊和Yelp评论上准确率超过95%，持续优于GPT-4 Turbo、RoBERTa和DeepSeek等领先模型。分析证实，评论中表达的情绪能预测产品评分，进而预测购买行为。大多数情绪效应通过产品评分介导，但一些情绪（如不满和平静）直接影响购买，表明情绪语调提供了超越星级评分的有意义信号。

Conclusion: 本研究为消费者感知测量建立了新的方法论基础，并展示了如何利用大型语言模型推进营销研究和实践，实现对消费者数据中营销构建的有效检测。同时，LX的无代码、免费Web应用支持可扩展的消费者文本分析。

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [41] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis是一种新的LLM记忆框架，它结合了System-1相似性搜索和System-2全局选择机制，通过基础图和分层图实现语义和结构相关的记忆检索，并在长期记忆基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）记忆检索方法（RAG和Graph-RAG）主要通过基于相似性的机制（System-1风格）进行检索，这在需要全局推理或全面覆盖所有相关信息的场景中表现不佳。LLM越来越需要有效的历史消息组织和检索。

Method: 本文提出了Mnemis框架，该框架将System-1相似性搜索与名为“全局选择”的System-2机制相结合。Mnemis将记忆组织成一个用于相似性检索的基础图和一个实现语义层级自上而下、深思熟虑遍历的分层图。通过结合两种检索途径的互补优势，Mnemis检索到语义和结构都相关的记忆项。

Result: Mnemis在长期记忆基准测试中超越了所有现有方法，使用GPT-4.1-mini在LoCoMo上获得93.9分，在LongMemEval-S上获得91.6分，达到了最先进的性能。

Conclusion: Mnemis通过结合System-1和System-2机制以及双图结构，有效解决了现有记忆检索方法的局限性，在LLM的长期记忆任务中实现了卓越的性能。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [42] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: NeuroSymActive是一个模块化框架，它结合了可微分的神经-符号推理层和主动、价值引导的探索控制器，用于知识图谱问答，以实现高准确性并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型和神经推理系统在处理需要精确、结构化多跳推理的知识密集型查询时面临挑战。将图结构与神经模型集成并非易事：直接将图事实嵌入提示会导致低效和脆弱，而纯符号或重搜索方法在检索中成本高昂且缺乏基于梯度的细化。

Method: 本文提出了NeuroSymActive框架，它结合了可微分的神经-符号推理层和主动的、价值引导的探索控制器。该方法将软统一风格的符号模块与神经路径评估器以及蒙特卡洛风格的探索策略结合起来，该策略优先考虑高价值的路径扩展。

Result: 在标准知识图谱问答（KGQA）基准测试中，NeuroSymActive取得了强大的答案准确性，同时与常见的检索增强基线相比，减少了昂贵的图查找和模型调用次数。

Conclusion: NeuroSymActive通过结合可微分的神经-符号推理层和主动、价值引导的探索控制器，有效解决了知识图谱问答中的知识密集型多跳推理挑战，提高了答案准确性并降低了资源消耗。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [43] [Far Out: Evaluating Language Models on Slang in Australian and Indian English](https://arxiv.org/abs/2602.15373)
*Deniz Kaya Dilsiz,Dipankar Srirag,Aditya Joshi*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \textsc{web} versus \textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.

</details>


### [44] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 本研究探究了LLM在图卢语（一种训练数据极少的语言）中通过结构化提示词进行对话的能力，未进行微调。通过结合语法文档、负面约束和合成数据，词汇污染从80%降至5%，语法准确率达到85%。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否能够在训练数据中几乎不存在的语言进行对话。具体以图卢语（一种拥有超过200万使用者但数字存在感极低的达罗毗荼语系语言）为例进行案例研究。

Method: 该研究未对大型语言模型进行微调，而是通过结构化提示词来测试其对话能力。具体方法包括：结合明确的语法文档、应用负面约束以抑制来自相关语言的高概率词元、进行罗马化标准化，以及通过自玩（self-play）生成高质量的合成数据。该方法在三种不同的LLM（Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B）上进行了评估。

Result: 该方法将词汇污染率从80%显著降低至5%，同时实现了85%的语法准确率。跨模型分析显示，负面约束持续带来12-18个百分点的性能提升，而语法文档对不同模型架构的影响则在8-22个百分点之间。

Conclusion: 该研究通过结构化提示词、结合明确语法文档、负面约束和合成数据生成等策略，成功使大型语言模型在训练数据极度稀缺的低资源语言（图卢语）上展现了基本的对话能力，有效解决了数据匮乏的挑战。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [45] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 本文开发了一个分类框架和LLM应用方法，用于大规模分析芬兰二战撤离者访谈中的休闲活动和组织成员数据，将大量非结构化活动名称转化为结构化数据，以支持社会研究。


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案中的文本信息难以直接定量回答历史学家或社会学家提出的研究问题。具体而言，从芬兰二战卡累利阿撤离者家庭访谈中提取的休闲活动和组织成员信息包含7.1万个独特名称，数量庞大，无法直接分析。

Method: 开发了一个分类框架，用于捕捉参与活动的关键方面（活动/组织类型、社交性、规律性、体力要求）。标注了一个黄金标准数据集用于评估。测试大型语言模型（LLMs）以大规模应用该框架，并采用简单的多模型运行投票方法。

Result: 通过简单的多模型运行投票方法，一个开源大型语言模型能够与专家判断高度匹配。

Conclusion: 该方法成功地对35万个实体进行了标注，为后续的社会融合及相关研究提供了结构化资源。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly. We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [46] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: TAROT是一种测试驱动和能力自适应的课程强化微调方法，通过构建四层测试套件并根据模型能力调整课程进展，显著提高了大型语言模型生成代码的功能正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在代码生成方面面临挑战，尤其是在合成算法复杂且健壮的代码时。现有的强化微调（RFT）方法忽略了测试用例难度的异质性，导致奖励信号不平衡和梯度更新偏差。

Method: 提出TAROT方法。该方法为每个问题系统地构建了一个四层（基础、中等、复杂、边缘）测试套件，提供了一个受控的难度景观用于课程设计和评估。TAROT将课程进展与原始奖励分数解耦，实现了能力条件评估和从一系列课程策略中进行原则性选择。

Result: TAROT促进了稳定的优化和更高效的能力获取。实验结果表明，RFT在代码生成中的最优课程与模型的固有能力密切相关：能力较弱的模型在从易到难的课程中获得更大的收益，而能力较强的模型在先难后易的课程中表现更出色。TAROT一致性地提高了生成代码的功能正确性和鲁棒性。

Conclusion: TAROT提供了一种可复现的方法，能够根据模型的固有能力自适应地调整课程设计，从而持续提高生成代码的功能正确性和鲁棒性。所有代码和数据均已发布，以促进复现性和社区研究。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at .

</details>


### [47] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 该研究引入了“期望检测”这一新的NLP任务，构建了包含4.5K个Reddit帖子的RedHOTExpect语料库，并利用LLM进行数据银标（准确率约78%）。分析发现，身体疾病讨论中乐观和主动性更强，且患者多关注治疗益处。


<details>
  <summary>Details</summary>
Motivation: 患者对治疗的期望显著影响治疗效果，但在线患者平台（如医学Subreddit）中患者不愿在其他地方分享的期望尚未被研究。此前，自然语言处理（NLP）领域尚未对期望进行过研究，因此缺乏对患者如何在线讨论和表达期望的理解。

Method: 引入了“期望检测”作为一项新的自然语言处理任务；构建了包含4.5K个Reddit帖子的RedHOTExpect语料库；使用大型语言模型（LLM）进行银标（silver-labeling）数据，并进行人工验证（标签准确率约78%）；分析了表征期望的语言模式，并探究了患者的期望内容及其原因。

Result: 乐观和主动的表达方式在讨论身体或治疗相关疾病的帖子中比心理健康背景下更为突出；在收集的数据集中，患者主要讨论益处而非负面结果。

Conclusion: 该研究引入了一个新的自然语言处理任务“期望检测”，并创建了RedHOTExpect语料库，为后续研究患者在线期望的表达方式奠定了基础，并揭示了不同健康背景下患者期望表达的语言模式。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from

</details>


### [48] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [49] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: Fine-Refine是一个细粒度细化框架，通过分解响应、验证原子单元和迭代纠错，显著提升了对话系统的真实性，有效解决了大型语言模型幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在对话系统中容易产生幻觉，导致不准确的响应，损害用户信任。现有细化方法通常在响应层面操作，未能解决单个响应中包含多个可验证或不可验证事实的问题。

Method: Fine-Refine将响应分解为原子单元，使用外部知识验证每个单元的真实性，通过困惑度评估流畅性，并迭代纠正细粒度错误。

Result: Fine-Refine在HybriDialogue和OpendialKG数据集上显著提高了真实性，对话真实性得分提升高达7.63点，同时对话质量略有下降。

Conclusion: Fine-Refine框架通过对大型语言模型生成响应的细粒度分解和迭代纠错，显著提升了对话系统的真实性，为解决幻觉问题提供了一个有效途径，尽管在对话质量上存在轻微权衡。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [50] [DependencyAI: Detecting AI Generated Text through Dependency Parsing](https://arxiv.org/abs/2602.15514)
*Sara Ahmed,Tracy Hammond*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text using only the labels of linguistic dependency relations. Our method achieves competitive performance across monolingual, multi-generator, and multilingual settings. To increase interpretability, we analyze feature importance to reveal syntactic structures that distinguish AI-generated from human-written text. We also observe a systematic overprediction of certain models on unseen domains, suggesting that generator-specific writing styles may affect cross-domain generalization. Overall, our results demonstrate that dependency relations alone provide a robust signal for AI-generated text detection, establishing DependencyAI as a strong linguistically grounded, interpretable, and non-neural network baseline.

</details>


### [51] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [52] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [53] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: Perspectives是一个交互式工具，帮助数字人文研究者探索和组织大型非结构化文档集，通过人机协作的聚类和精炼来发现主题和见解。


<details>
  <summary>Details</summary>
Motivation: 数字人文（DH）学者在探索和组织大型非结构化文档集时面临挑战，需要一个工具来有效探索和组织这些数据。

Method: Perspectives实现了一个灵活的、以方面为中心的文档聚类流程，并结合了人机协作（human-in-the-loop）的精炼能力。该过程通过文档重写提示和基于指令的嵌入来定义分析视角，并通过聚类精炼工具和嵌入模型微调机制来进一步与用户意图对齐。

Result: 该工具能帮助数字人文研究者利用交互式文档地图发现主题、情感或其他相关类别，从而获得见解，并为后续的深入分析准备数据。

Conclusion: Perspectives为数字人文研究者提供了一个强大的交互式工具，通过灵活的聚类和精炼功能，有效探索和组织大型非结构化文档集，进而深入分析数据。

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [54] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [55] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at

</details>


### [56] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 本研究提出了一个症状特异性且受临床启发的框架，用于从语音中估计抑郁症严重程度，该框架采用症状引导的交叉注意力机制和情感感知的语音表示，在EDAIC数据集上表现优于现有工作，并提高了可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的抑郁症预测方法大多将抑郁症视为二元标签或整体严重程度评分，而没有明确地建模症状特异性信息。这限制了它们提供与临床筛查相关的症状层面分析的能力。

Method: 该方法提出了一个症状特异性且受临床启发的语音抑郁症严重程度估计框架。它使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知的语音表示对齐，以识别参与者语音中对每个症状更重要的片段。为了适应症状随时间表达方式的差异，引入了一个可学习的症状特异性参数来自适应地控制注意力分布的锐度。

Result: 在标准临床数据集EDAIC上的结果表明，该方法性能有所提高，优于现有工作。此外，注意力分布分析显示，包含与多个抑郁症状相关线索的话语获得了更高的注意力，突出了该方法的可解释性。

Conclusion: 这些发现强调了症状引导和情感感知建模对于基于语音的抑郁症筛查的重要性。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [57] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: 强化学习微调大型语言模型（LLM）存在不稳定性，源于“虚假令牌”导致梯度异常放大。本文提出STAPO方法，通过屏蔽这些更新并重新规范化损失，解决了这一问题，并在数学推理基准上取得了显著的性能提升和更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习微调方法过度依赖启发式技术来维持稳定性，导致后期性能崩溃、推理质量下降和训练不稳定。研究发现，令牌级别的策略梯度大小与令牌概率和局部策略熵呈负相关，并且训练不稳定性是由约0.01%的“虚假令牌”引起的，这些令牌在正确响应中贡献小但继承了完整的序列级奖励，导致梯度更新异常放大。

Method: 作者提出了虚假令牌感知策略优化（STAPO）方法，该方法选择性地屏蔽由虚假令牌引起的更新，并对有效令牌的损失进行重新规范化。

Result: 在六个数学推理基准上，使用Qwen 1.7B、8B和14B基础模型进行测试，STAPO始终表现出卓越的熵稳定性，并比GRPO、20-Entropy和JustRL平均性能提高了7.13%。

Conclusion: STAPO通过识别并减轻虚假令牌的影响，有效解决了大语言模型微调中强化学习的不稳定性问题，从而显著提高了性能。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [58] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 该研究介绍了NileTTS，这是首个公开可用的38小时埃及阿拉伯语TTS数据集，利用新颖的LLM驱动合成管道构建。研究人员在该数据集上微调了XTTS v2，并发布了开源模型和管道，旨在解决埃及阿拉伯语语音合成资源匮乏的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管神经文本到语音（TTS）技术取得了进步，但许多阿拉伯语方言变体仍未得到充分关注，大多数资源集中在现代标准阿拉伯语（MSA）和海湾方言上，使得埃及阿拉伯语——最广泛理解的阿拉伯语方言——资源严重不足。

Method: 通过引入NileTTS数据集（包含来自两名说话者、涵盖医疗、销售和日常对话等多个领域的38小时转录语音）来解决这一差距。该数据集是使用一种新颖的合成管道构建的：大型语言模型（LLM）生成埃及阿拉伯语内容，然后使用音频合成工具将其转换为自然语音，接着进行自动转录和说话人分离，并辅以人工质量验证。将最先进的多语言TTS模型XTTS v2在该数据集上进行微调，并与在其他阿拉伯语方言上训练的基线模型进行评估。

Result: 该研究的贡献包括：1) 首个公开可用的埃及阿拉伯语TTS数据集；2) 可复现的方言TTS合成数据生成管道；3) 一个开源的微调模型。

Conclusion: 所有资源均已发布，以推动埃及阿拉伯语语音合成研究的发展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [59] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 本文提出了一种基于荣格原型理论的角色功能框架，用于分析弗莱的四种叙事体裁，并通过大型语言模型（LLMs）进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的弗莱叙事框架计算方法主要关注叙事模式而非角色功能。本文旨在通过考察原型角色在不同体裁中的表现，补充基于模式的分析。

Method: 1. 基于荣格原型理论，推导出四种通用角色功能（主角、导师、反派、伙伴），并将其映射到荣格的心理结构。
2. 根据原型作品，将这些功能细化为十六种特定体裁的角色。
3. 使用六个先进的大型语言模型，在40部叙事作品中评估角色-角色对应关系，通过正样本和负样本进行框架验证。

Result: 1. 大型语言模型取得了显著的性能（平均平衡准确率为82.5%），模型间具有高度一致性（Fleiss' $\kappa$ = 0.600）。
2. 性能因体裁（72.7%至89.9%）和角色（52.5%至99.2%）而异。
3. 定性分析表明，这些差异反映了真实的叙事属性，包括浪漫体裁中的功能分布和讽刺体裁中有意的原型颠覆。

Conclusion: 这种基于角色的方法展示了大型语言模型支持计算叙事学方法的潜力，并为未来叙事生成方法和交互式故事应用的发展奠定了基础。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $\kappa$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [60] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 本研究引入了平均最小距离（AMD）和对称平均最小距离（SAMD）两种新的语义变化度量，用于改进基于上下文嵌入的词汇语义变化检测。结果显示，AMD在非专业编码器和降维下表现更鲁棒，SAMD在专业编码器下表现更好，建议LSCD考虑这些替代度量。


<details>
  <summary>Details</summary>
Motivation: 词汇语义变化检测（LSCD）越来越依赖于上下文语言模型嵌入，但大多数现有方法主要使用少量语义变化度量（如平均成对距离APD和基于词原型的余弦距离PRT）来量化变化。作者认为需要更鲁棒和高效的语义变化度量。

Method: 引入了平均最小距离（AMD）和对称平均最小距离（SAMD）作为新的语义变化度量，通过跨时间段的词汇用法之间的局部对应关系来量化语义变化。这些新度量在多种语言、编码器模型和表示空间上进行了评估。

Result: 研究表明，在多种语言、编码器模型和表示空间中，AMD通常能提供更鲁棒的性能，特别是在降维和使用非专业编码器时。而SAMD在搭配专业编码器时表现更优。

Conclusion: 在基于上下文嵌入的词汇语义变化检测中，考虑使用除APD和PRT之外的替代语义变化度量是有益的，其中AMD为非专业编码器和降维场景提供了一个鲁棒的选择，而SAMD在专业编码器下表现出色。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [61] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [62] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在低资源语言的词形还原和词性标注任务上的表现，发现LLMs在少样本设置下表现出色，是语言标注的有效工具，尽管在处理复杂形态和非拉丁语系时仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在词形还原和词性标注等自然语言处理任务中面临持续的挑战。

Method: 该研究调查了包括GPT-4变体和开放权重的Mistral模型在内的LLM，在少样本和零样本设置下，对四种低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语）进行词形还原和POS标注任务的能力。研究使用了一个包含对齐训练和域外测试语料库的新型基准，评估了基础模型在这些任务上的表现，并与特定任务的RNN基线PIE进行了比较。

Result: 在少样本设置下，LLM即使未经微调，在大多数语言的词性标注和词形还原任务中也取得了具有竞争力或更优的性能。对于具有复杂形态和非拉丁字母的语言，仍然存在显著挑战。

Conclusion: LLMs是启动低资源语言语言学标注任务的可靠且相关选项，在缺乏数据的情况下可作为有效的标注辅助工具。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [63] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 该研究提出了FineMuSe，一个西班牙语多模态性别歧视检测数据集，包含细粒度标注和分层分类法。评估发现多模态LLMs在识别细微性别歧视方面表现良好，但在处理视觉线索传达的共同出现类型时仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有自动化性别歧视检测工具仅限于二元分类，缺乏细粒度、上下文敏感的标签，导致许多细微的在线性别歧视表现形式未能被检测到。

Method: 1. 构建了FineMuSe，一个包含二元和细粒度标注的西班牙语多模态性别歧视检测数据集。
2. 引入了一个全面的分层分类法，涵盖了性别歧视、非性别歧视形式以及讽刺和幽默的修辞手法。
3. 评估了多种大型语言模型（LLMs）在二元和细粒度性别歧视检测任务上的表现。

Result: 1. 多模态大型语言模型（LLMs）在识别细微的性别歧视形式方面表现出与人类标注者相当的竞争力。
2. 这些模型在通过视觉线索传达共同出现的性别歧视类型时表现不佳。

Conclusion: 多模态大型语言模型在识别细微的性别歧视方面具有竞争力，但在处理通过视觉线索传达的共同出现的性别歧视类型时仍存在挑战。新数据集和分类法为细粒度性别歧视检测提供了基础。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [64] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: 引入ChartEditBench基准测试和评估框架，以探究多模态大语言模型（MLLMs）在多轮图表编辑中的表现，结果显示MLLMs在多轮编辑中性能显著下降，尤其是在数据中心转换方面。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在单轮图表生成方面表现出色，但其支持真实世界探索性数据分析（EDA）的能力，特别是需要维护共同基础、跟踪先前编辑和适应用户偏好的多轮交互，尚未得到充分探索。

Method: 提出ChartEditBench，一个用于通过代码进行增量式、视觉接地式图表编辑的基准测试，包含5,000个难度可控的修改链和一个经过严格人工验证的子集。此外，还提出了一个鲁棒的评估框架，通过集成基于执行的保真度检查、像素级视觉相似性和逻辑代码验证来弥补“LLM作为评判者”指标的局限性。

Result: 最先进的MLLMs在多轮设置中由于错误累积和共享上下文的中断而表现出显著的性能下降。它们在样式编辑方面表现强劲，但在以数据为中心的转换上经常出现执行失败。

Conclusion: ChartEditBench为接地、意图感知的多模态编程提供了一个具有挑战性的测试平台。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [65] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 本文介绍了*-PLUIE，这是一种基于困惑度的LLM-judge变体，它在低计算成本下，与人类判断高度相关，用于评估自动生成文本的质量。


<details>
  <summary>Details</summary>
Motivation: 评估自动生成文本质量的LLM-as-a-judge (LLM-judge) 方法虽然有效，但计算成本高且需要后处理。为解决这些限制，本文旨在开发一种更高效的方法。

Method: 本文基于ParaPLUIE（一种无需生成文本即可评估“是/否”答案置信度的困惑度LLM-judge指标），提出了*-PLUIE（ParaPLUIE的任务特定提示变体），并评估了其与人类判断的一致性。

Result: 实验结果表明，个性化的*-PLUIE与人类评分表现出更强的相关性，同时保持了较低的计算成本。

Conclusion: *-PLUIE为评估自动生成文本质量提供了一种计算效率更高且与人类判断更一致的方法。

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [66] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文重新设计了Avey架构，并引入了解耦参数化、稳定性归一化和神经压缩等创新，使其在词元分类和信息检索任务上优于现有Transformer编码器，并在长上下文处理上更高效。


<details>
  <summary>Details</summary>
Motivation: 紧凑型预训练双向编码器在计算和内存预算有限的工业NLP中至关重要。尽管BERT风格的自注意力模型在该领域表现出色，但Avey作为一种自回归、无注意力模型，天然支持仅编码器适应，这促使了对其在仅编码器范式下的进一步探索和改进。

Method: 本文重新设计了Avey架构以适应仅编码器范式，并提出了几项架构创新，包括：解耦的静态和动态参数化、面向稳定性的归一化以及神经压缩。

Result: 重新设计的Avey架构在标准词元分类和信息检索基准测试中，表现持续优于四种广泛使用的基于Transformer的编码器，并且在处理长上下文时展现出更高的效率。

Conclusion: 本文提出的重新设计的Avey架构及其创新，为需要紧凑、双向上下文理解的任务，特别是在长上下文中，提供了一种优于基于Transformer的编码器的更高效替代方案。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [67] [Artificial Intelligence Specialization in the European Union: Underexplored Role of the Periphery at NUTS-3 Level](https://arxiv.org/abs/2602.15249)
*Victor Herrero-Solana*

Main category: cs.DL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This study examines the geographical distribution of Artificial Intelligence (AI) research production across European regions at the NUTS-3 level for the period 2015-2024. Using bibliometric data from Clarivate InCites and the Citation Topics classification system, we analyze two hierarchical levels of thematic aggregation: Electrical Engineering, Electronics & Computer Science (Macro Citation Topic 4) and Artificial Intelligence & Machine Learning (Meso Citation Topic 4.61). We calculate the Relative Specialization Index (RSI) and Relative Citation Impact (RCI) for 781 NUTS-3 regions. While major metropolitan hubs such as Paris (IIle-de-France), Warszawa, and Madrid lead in absolute production volume, our findings reveal that peripheral regions, particularly from Eastern Europe and Spain, exhibit the highest levels of relative AI specialization. Notably, we find virtually no correlation between regional specialization and citation impact, identifying four distinct regional profiles: high-impact specialized regions (e.g., Granada, Jaen, Vilniaus), high-volume but low-impact regions (e.g., Bugas, several Polish regions), high-impact non-specialized regions, with Fyn (Denmark) standing out as a remarkable outlier achieving exceptional citation impact (RCI > 4) despite low specialization, and diversified portfolios with selective excellence (e.g., German regions). These results suggest that AI research represents a strategic opportunity for peripheral regions to develop competitive scientific niches, though achieving international visibility requires more than research volume alone.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [68] [Unforgeable Watermarks for Language Models via Robust Signatures](https://arxiv.org/abs/2602.15323)
*Huijia Lin,Kameron Shahabi,Min Jae Song*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Language models now routinely produce text that is difficult to distinguish from human writing, raising the need for robust tools to verify content provenance. Watermarking has emerged as a promising countermeasure, with existing work largely focused on model quality preservation and robust detection. However, current schemes provide limited protection against false attribution. We strengthen the notion of soundness by introducing two novel guarantees: unforgeability and recoverability. Unforgeability prevents adversaries from crafting false positives, texts that are far from any output from the watermarked model but are nonetheless flagged as watermarked. Recoverability provides an additional layer of protection: whenever a watermark is detected, the detector identifies the source text from which the flagged content was derived. Together, these properties strengthen content ownership by linking content exclusively to its generating model, enabling secure attribution and fine-grained traceability. We construct the first undetectable watermarking scheme that is robust, unforgeable, and recoverable with respect to substitutions (i.e., perturbations in Hamming metric). The key technical ingredient is a new cryptographic primitive called robust (or recoverable) digital signatures, which allow verification of messages that are close to signed ones, while preventing forgery of messages that are far from all previously signed messages. We show that any standard digital signature scheme can be boosted to a robust one using property-preserving hash functions (Boyle, LaVigne, and Vaikuntanathan, ITCS 2019).

</details>


### [69] [SecCodeBench-V2 Technical Report](https://arxiv.org/abs/2602.15485)
*Longfei Chen,Ji Zhao,Lanxiao Cui,Tong Su,Xingbo Pan,Ziyang Li,Yongxing Wu,Qijiang Cao,Qiyao Cai,Jing Zhang,Yuandong Ni,Junyao He,Zeyu Zhang,Chao Ge,Xuhuai Lu,Zeyu Gao,Yuxin Cui,Weisen Chen,Yuxuan Peng,Shengping Wang,Qi Li,Yukai Huang,Yukun Liu,Tuo Zhou,Terry Yue Zhuo,Junyang Lin,Chao Zhang*

Main category: cs.CR

TL;DR: SecCodeBench-V2是一个公开的基准，用于评估大型语言模型（LLM）编程助手生成安全代码的能力。它包含98个来自阿里巴巴工业生产的生成和修复场景，涵盖22种常见CWE，支持Java、C、Python、Go等五种编程语言。该基准采用函数级任务，提供可执行的PoC测试用例进行功能和安全验证，并构建了一个主要通过动态执行进行评估的统一流水线，结合Pass@K评分协议，为评估AI编码助手的安全态势提供了严格且可复现的基础。


<details>
  <summary>Details</summary>
Motivation: 为了严格且可复现地评估AI编码助手的安全态势，本研究旨在提供一个全面的基准和评估流水线，以衡量其生成安全代码的能力。

Method: SecCodeBench-V2由98个生成和修复场景组成，这些场景源于阿里巴巴集团的工业生产，涵盖22个常见CWE类别和五种编程语言（Java、C、Python、Go等）。它采用函数级任务，每个场景提供完整的项目脚手架，要求模型在固定接口和依赖下实现或修补指定的目标函数。每个场景都提供由安全专家编写并双重审查的可执行概念验证（PoC）测试用例，用于功能验证和安全验证。构建了一个统一的评估流水线，主要通过动态执行评估模型，即在隔离环境中编译和运行模型生成的代码并执行PoC测试用例。对于无法通过确定性测试用例判断安全问题的场景，还额外采用了LLM作为裁判的预言机。设计了一个基于Pass@K的评分协议，结合场景和严重程度的聚合，以实现全面且可比较的模型评估。

Result: SecCodeBench-V2为评估AI编码助手的安全态势提供了一个严格且可复现的基础，其结果和相关成果已公开发布。

Conclusion: SecCodeBench-V2作为一个强大的基准和评估框架，能够评估和比较LLM编程助手生成安全代码的能力，从而有助于开发更安全的AI编码助手。

Abstract: We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and . SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at . The benchmark is publicly available at .

</details>


### [70] [Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections](https://arxiv.org/abs/2602.15654)
*Xianglin Yang,Yufei He,Shuo Ji,Bryan Hooi,Jin Song Dong*

Main category: cs.CR

TL;DR: 研究发现，自我演进型LLM智能体因存储外部内容到长期记忆中，存在被持久性攻击（僵尸智能体）利用的风险。这种攻击通过隐蔽植入恶意载荷，使其在会话之间持续存在并执行未经授权的行为，表明单一会话的提示过滤防御不足以应对此类威胁。


<details>
  <summary>Details</summary>
Motivation: 自我演进型LLM智能体通过更新内部状态和重用长期记忆来提高长任务性能，但这引入了一个安全风险：会话中观察到的不可信外部内容可能被存储为记忆，并在后续被视为指令。因此，研究人员旨在研究这种风险，并形式化一种持久性攻击。

Method: 研究人员提出了一种名为“僵尸智能体”的持久性攻击形式，该攻击通过两阶段的黑盒攻击框架实现：感染阶段（智能体在执行良性任务时读取恶意内容并将其写入长期记忆）和触发阶段（恶意载荷被检索或传播并导致未经授权的工具行为）。针对滑动窗口和检索增强型记忆等常见记忆实现，设计了特定的持久化策略以抵抗截断和相关性过滤。该攻击通过攻击者控制的网页内容进行间接暴露。

Result: 评估结果表明，攻击能够长期持续存在，并能在保持良性任务质量的同时诱导未经授权的行为。记忆演进可以将一次性的间接注入转化为持久性危害。

Conclusion: 自我演进型LLM智能体仅依赖会话级别提示过滤的防御措施不足以应对持久性攻击，需要更全面的安全策略来解决记忆演进带来的持续性威胁。

Abstract: Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the agent into a puppet of the attacker. We present a black-box attack framework that uses only indirect exposure through attacker-controlled web content. The attack has two phases. During infection, the agent reads a poisoned source while completing a benign task and writes the payload into long-term memory through its normal update process. During trigger, the payload is retrieved or carried forward and causes unauthorized tool behavior. We design mechanism-specific persistence strategies for common memory implementations, including sliding-window and retrieval-augmented memory, to resist truncation and relevance filtering. We evaluate the attack on representative agent setups and tasks, measuring both persistence over time and the ability to induce unauthorized actions while preserving benign task quality. Our results show that memory evolution can convert one-time indirect injection into persistent compromise, which suggests that defenses focused only on per-session prompt filtering are not sufficient for self-evolving agents.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [71] [Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient](https://arxiv.org/abs/2602.15036)
*Saumyadip Mukhopadhyay,Kiho Yang,Kasyap Thottasserymana Vasudevan,Mounica Jyothi Divvela,Selim Dogru,Dilip Krishnamurthy,Fergo Treska,Werner Gillijns,Ryan Ryoung han Kim,Kumara Sastry,Vivek Singh*

Main category: eess.SP

TL;DR: 面对科学计算和半导体制造中计算光刻日益增长的复杂性和成本，本研究利用加速计算（AC）和人工智能（AI）（通过NVIDIA cuLitho）将计算光刻的端到端速度提高了57倍，并在硅实验中显著改善了工艺窗口（35%）和边缘放置误差（19%）。


<details>
  <summary>Details</summary>
Motivation: 科学计算需求（如气候科学、药物发现）因更大的数据集、更复杂的模型和更高的仿真精度而急剧增长，其增长速度远超晶体管缩放，导致成本、能耗和排放的不可持续增长。半导体制造中的计算光刻作为最大工作负载，随着微型化进入埃时代变得异常复杂，需要更精确的建模、复杂的校正和更广泛的解决方案空间探索。因此，需要一个可持续的下一代计算平台来应对这些挑战。

Method: 该研究通过结合加速计算（AC）和人工智能（AI）作为计算密集型步骤的高保真替代物来解决问题。具体而言，针对计算光刻，NVIDIA cuLitho平台重塑了核心原语，包括衍射光学、计算几何、多变量优化和数据处理，并重新设计了软件堆栈。此外，还重新投入少量计算资源以实现焦点贯穿校正（through-focus correction）。

Result: 该方法实现了计算光刻端到端57倍的加速。扩展的计算能力使得能够实现更严格的解决方案，包括曲线掩模、高数值孔径极紫外（high-NA EUV）光刻和亚原子建模。在IMEC进行的硅实验表明，与传统方法相比，工艺窗口提高了35%，边缘放置误差（EPE）改善了19%。这是首次在芯片层面量化展示AC和AI在硅片上对光刻的益处。

Conclusion: 加速计算（AC）和人工智能（AI），通过NVIDIA cuLitho平台实现，为科学计算工作负载提供了可持续的下一代计算平台，并彻底改变了计算光刻技术，显著提升了其速度和质量。

Abstract: From climate science to drug discovery, scientific computing demands have surged dramatically in recent years -- driven by larger datasets, more sophisticated models, and higher simulation fidelity. This growth rate far outpaces transistor scaling, leading to unsustainably rising costs, energy consumption, and emissions. Semiconductor manufacturing is no exception. Computational lithography -- involving transferring circuitry to silicon in diffraction-limited conditions -- is the largest workload in semiconductor manufacturing. It has also grown exceptionally complex as miniaturization has advanced in the angstrom-era, requiring more accurate modeling, intricate corrections, and broader solution-space exploration. Accelerated computing (AC) offers a solution by dramatically freeing up the compute and power envelope. AI augments these gains by serving as high-fidelity surrogates for compute-intensive steps. Together, they present a sustainable, next-generation computing platform for scientific workloads. This new paradigm needs a fundamental redesign of the software stack. For computational lithography, NVIDIA cuLitho reinvents the core primitives -- diffractive optics, computational geometry, multi-variant optimization, data processing -- to achieve a transformative 57X end-to-end acceleration. Beyond dramatically faster cycles, this expanded compute envelope enables more rigorous solutions, including curvilinear masks, high-numerical aperture extreme ultraviolet (high-NA EUV) lithography, and subatomic modeling. We reinvest a small fraction of the freed-up compute to include through-focus correction for better process resilience. Silicon experiments at IMEC show significant benefits compared to conventional methods -- 35% better process window and 19% better edge placement error. This is the first quantified chip-scale demonstration of the lithography benefits of AC and AI in silicon.

</details>


### [72] [Combining scEEG and PPG for reliable sleep staging using lightweight wearables](https://arxiv.org/abs/2602.15042)
*Jiawei Wang,Liang Xu,Shuntian Zheng,Yu Guan,Kaichen Wang,Ziqing Zhang,Chen Chen,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 本研究提出了一种scEEG-PPG融合方法，尤其是一种Mamba增强型融合策略，用于在短窗口限制下进行4类睡眠分期。该方法显著提升了浅睡眠的分类性能，并展现了良好的泛化能力，为轻量级可穿戴睡眠监测提供了更准确、便捷的解决方案。


<details>
  <summary>Details</summary>
Motivation: 对于单通道脑电图（scEEG）或光电容积描记（PPG）等轻量级可穿戴设备而言，可靠的睡眠分期仍然具有挑战性。scEEG在浅睡眠分期上表现有限，而PPG虽对浅睡眠有效，但现有方法依赖于长时间记录（8-10小时），不适用于及时反馈。因此，需要一种在短窗口限制下提供准确睡眠分期的方法。

Method: 本研究在短窗口（30秒-30分钟）限制下，研究了scEEG-PPG融合进行4类睡眠分期的方案。首先，评估了每种模态所需的时间上下文。其次，研究了三种融合策略：分数级融合、交叉注意力融合和Mamba增强型融合。最后，在MESA数据集上进行训练和评估，并在CFS和ABC数据集上进行跨数据集验证。

Result: Mamba增强型融合在MESA数据集上表现最佳（Cohen's Kappa $\kappa$ = 0.798，准确率 = 86.9%），在浅睡眠分类方面有显著提高（F1-score: 85.63% vs. scEEG单独的77.76%；召回率: 82.85% vs. scEEG单独的69.95%），并且在CFS和ABC数据集上泛化性良好。

Conclusion: scEEG-PPG融合，尤其是Mamba增强型融合，是基于轻量级可穿戴设备的睡眠监测的一种有前景的方法，通过在短窗口限制下提高准确性，特别是对浅睡眠的准确性，为更便捷的睡眠健康评估提供了途径。

Abstract: Reliable sleep staging remains challenging for lightweight wearable devices such as single-channel electroencephalography (scEEG) or photoplethysmography (PPG). scEEG offers direct measurement of cortical activity and serves as the foundation for sleep staging, yet exhibits limited performance on light sleep stages. PPG provides a low-cost complement that captures autonomic signatures effective for detecting light sleep. However, prior PPG-based methods rely on full night recordings (8 - 10 hours) as input context, which is less practical to provide timely feedback for sleep intervention. In this work, we investigate scEEG-PPG fusion for 4-class sleep staging under short-window (30 s - 30 min) constraints. First, we evaluate the temporal context required for each modality, to better understand the relationship of sleep staging performance with respect to monitoring window. Second, we investigate three fusion strategies: score-level fusion, cross-attention fusion enabling feature-level interactions, and Mamba-enhanced fusion incorporating temporal context modeling. Third, we train and evaluate on the Multi-Ethnic Study of Atherosclerosis (MESA) dataset and perform cross-dataset validation on the Cleveland Family Study (CFS) and the Apnea, Bariatric surgery, and CPAP (ABC) datasets. The Mamba-enhanced fusion achieves the best performance on MESA (Cohen's Kappa $\kappa$ = 0.798, Acc = 86.9%), with particularly notable improvement in light sleep classification (F1-score: 85.63% vs. 77.76%, recall: 82.85% vs. 69.95% for scEEG alone), and generalizes well to CFS and ABC datasets with different populations. These findings suggest that scEEG-PPG fusion is a promising approach for lightweight wearable based sleep monitoring, offering a pathway toward more accessible sleep health assessment. Source code of this project can be found at:

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [73] [Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid](https://arxiv.org/abs/2602.15350)
*Mohamad Chehade,Hao Zhu*

Main category: eess.SY

TL;DR: 该研究微调了一个大型语言模型（LLM），用于在公共安全停电（PSPS）事件中生成纠正性输电切换计划，通过多阶段方法显著提高了直流目标值，并降低了交流潮流故障率，同时改善了电压性能。


<details>
  <summary>Details</summary>
Motivation: 公共安全停电（PSPS）事件会导致电网拓扑结构的快速变化，使标准运行点变得不可行。在这种情况下，电网运营商需要迅速识别纠正性输电切换操作，以在维持可接受的电压行为的同时，减少负荷削减。现有方法难以快速有效地应对这种复杂的紧急情况。

Method: 研究提出了一种可验证的多阶段适应性管道来微调经过指令调整的大型语言模型（LLM）。该管道使LLM能够从紧凑的PSPS场景摘要中，在明确的切换预算下，生成“仅开放”的纠正性切换计划。具体方法包括：
1.  **监督式微调（Supervised Fine-tuning, SFT）**：将直流最优潮流混合整数线性规划（DC-OPF MILP）预言机蒸馏成一个受约束的动作语法，以实现可靠的解析和可行性检查。
2.  **直接偏好优化（Direct Preference Optimization, DPO）**：使用通过电压惩罚指标排名的交流评估偏好对来优化策略，从而在直流模拟之外注入电压感知能力。
3.  **最佳-N选择（Best-of-N selection）**：在推理时通过从多个候选方案中选择目标指标下最佳的可行方案来进一步增强。

Result: 在IEEE 118节点PSPS场景中，研究结果显示：
1.  与零样本生成相比，微调显著改善了直流（DC）目标值。
2.  交流（AC）潮流故障率从50%大幅降低到个位数。
3.  在共同成功集合上，电压惩罚结果得到了改善。
为支持结果的复现性，代码和数据生成脚本已发布。

Conclusion: 该研究通过多阶段微调方法，成功使大型语言模型（LLM）能够生成针对PSPS场景的纠正性输电切换方案，显著提升了直流目标值并大幅降低了交流潮流故障率，同时改善了电压惩罚结果，证明了该方法在电力系统应急操作中的有效性和潜力。

Abstract: Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [74] [Proactive Conversational Assistant for a Procedural Manual Task based on Audio and IMU](https://arxiv.org/abs/2602.15707)
*Rehana Mahfuz,Yinyi Guo,Erik Visser,Phanidhar Chinchili*

Main category: cs.MM

TL;DR: 该论文提出了一种实时对话助手，仅使用来自可穿戴设备的音频和IMU输入来为程序性任务（如家具组装）提供指导，从而解决了视频输入成本高昂和隐私问题。通过一种新颖的UWA LoRA微调方法，该助手提高了对话效率（F-score提高30%以上），实现了16倍的速度提升，并可在边缘设备上运行。


<details>
  <summary>Details</summary>
Motivation: 现有的程序性任务实时对话助手通常依赖于计算成本高昂且会损害用户隐私的视频输入。

Method: 1. 提出了一种仅使用来自用户可穿戴设备的音频和IMU输入来理解上下文的实时对话助手。
2. 该助手主动为用户执行家具组装任务提供分步说明并回答用户问题。
3. 构建了一个包含助手指导用户执行任务对话的数据集。
4. 设计了一种新颖的用户意图无关（UWA）LoRA微调方法，以抑制信息量较少的对话，同时保持传达重要指令的能力，解决了现成语言模型过于健谈的问题。
5. 描述了该助手如何在不依赖云的情况下在边缘设备上实现。

Result: 1. UWA LoRA微调方法使F-score提高了30%以上。
2. 通过消除在提示中提供上下文示例的需要，模型微调实现了16倍的速度提升。
3. 该助手可以在边缘设备上实现。

Conclusion: 该研究成功开发了一个仅使用轻量级、隐私保护模态（音频和IMU）的实时对话助手，并通过创新的UWA LoRA微调方法显著提高了其对话效率和性能，同时实现了在边缘设备上的独立部署，为程序性任务辅助提供了高效且注重隐私的解决方案。

Abstract: Real-time conversational assistants for procedural tasks often depend on video input, which can be computationally expensive and compromise user privacy. For the first time, we propose a real-time conversational assistant that provides comprehensive guidance for a procedural task using only lightweight privacy-preserving modalities such as audio and IMU inputs from a user's wearable device to understand the context. This assistant proactively communicates step-by-step instructions to a user performing a furniture assembly task, and answers user questions. We construct a dataset containing conversations where the assistant guides the user in performing the task. On observing that an off-the-shelf language model is a very talkative assistant, we design a novel User Whim Agnostic (UWA) LoRA finetuning method which improves the model's ability to suppress less informative dialogues, while maintaining its tendency to communicate important instructions. This leads to >30% improvement in the F-score. Finetuning the model also results in a 16x speedup by eliminating the need to provide in-context examples in the prompt. We further describe how such an assistant is implemented on edge devices with no dependence on the cloud.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [75] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 本文提出通过修改大型语言模型（LLM）教师模型的推理轨迹，以实现反蒸馏和API水印。研究结果表明，一种简单的指令式重写方法可以有效阻止未经授权的知识蒸馏，并实现可靠的水印检测。


<details>
  <summary>Details</summary>
Motivation: 未经授权的知识蒸馏利用了开发前沿模型所付出的巨大努力和成本，造成了不公平的优势。本文旨在通过降低查询响应的训练有用性（反蒸馏）和在学生模型中嵌入可验证的签名（API水印）来阻止这种行为。

Method: 通过修改教师模型生成的推理轨迹来实现，方法包括利用大型语言模型的重写能力和基于梯度的技术。目标是保持答案的正确性和语义连贯性。

Result: 简单的指令式重写方法实现了强大的反蒸馏效果，同时保持甚至提升了教师模型的性能。此外，该重写方法还实现了高度可靠的水印检测，几乎没有误报。

Conclusion: 通过指令式重写修改教师模型生成的推理轨迹，可以有效阻止未经授权的知识蒸馏，并实现可靠的水印检测，同时不牺牲教师模型的性能。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [76] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 本文提出了一种名为da Costian-Tarskianism的新方法来处理本体论异质性，该方法基于扩展的后果系统和扩展的发展图。


<details>
  <summary>Details</summary>
Motivation: 处理本体论异质性问题，并借鉴Carnapian-Goguenism的思想提出新颖的解决方案。

Method: 该方法被称为da Costian-Tarskianism，灵感来源于da Costa的数学宽容原则和Tarski的后果算子工作。它基于后果系统，并引入了扩展后果系统（即带有本体论公理的后果系统）的概念。此外，还定义了扩展发展图，这是一种通过扩展后果系统的态射以及其他操作（如纤维化和分裂）来关联本体的图结构。

Result: 提出了一种新颖的本体论异质性处理方法da Costian-Tarskianism；定义了扩展后果系统和扩展发展图。

Conclusion: 讨论了该方法对应用本体论领域的影响，并提出了未来的研究方向。

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [77] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 研究比较了LLM在不确定性下的风险选择，发现LLM分为推理模型（RMs）和对话模型（CMs）。RMs更理性，对多种因素不敏感；CMs理性程度较低，更像人类，且对前景顺序、框架和解释敏感，并存在描述-历史差距。数学推理训练是区分两者的关键因素。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在数字生态系统中的应用日益广泛，但其在不确定性下的决策机制尚不明确。

Method: 对20个前沿和开放LLM的风险选择进行了比较研究，考察了前景表示（明确 vs. 基于经验）和决策理由（解释）两个维度。研究还通过人类受试者实验和预期收益最大化理性智能体模型提供参考点。

Result: LLM分为推理模型（RMs）和对话模型（CMs）。RMs倾向于理性行为，对前景顺序、盈亏框架和解释不敏感，且对前景的明确或经验呈现表现相似。CMs则理性程度显著较低，更像人类，对前景顺序、框架和解释敏感，并表现出大的描述-历史差距。数学推理训练是区分RMs和CMs的关键因素。

Conclusion: LLM在不确定性下的决策行为存在显著差异，可分为更偏向理性的推理模型和更具人类特征且易受环境因素影响的对话模型，这两种模型的根本区别在于其是否接受过数学推理训练。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [78] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 该论文提出并评估了一个AI和机器学习框架，旨在通过补充确定性算法来预测供应链金融中的发票稀释，以解决传统方法在风险管理和采纳方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 发票或支付稀释是供应链金融中非信用风险和利润损失的重要来源。传统方法（如买方不可撤销支付承诺，IPU）虽然用于管理此风险，但其会阻碍供应链金融的采纳，尤其是在非投资级买方中。因此，需要更先进、数据驱动的方法来实时预测发票稀释。

Method: 该论文引入了一个AI和机器学习框架，并评估其如何补充确定性算法来预测发票稀释。该框架利用包含九个关键交易字段的大规模生产数据集进行预测。

Result: 该论文评估了所提出的AI和机器学习框架如何能补充确定性算法来预测发票稀释。

Conclusion: 该论文引入的AI和机器学习框架可以有效地补充确定性算法，用于预测供应链金融中的发票稀释，从而改善风险管理和潜在地促进该金融模式的采纳。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [79] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [80] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [81] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: 该研究引入了EduEVAL-DB数据集，这是一个基于教师角色的大型数据集，用于评估和训练AI教学评估器及导师。该数据集包含多源解释和五个维度的教学风险评估标准，并通过初步实验验证了其适用性，尤其是在支持消费级硬件部署模型进行风险检测方面。


<details>
  <summary>Details</summary>
Motivation: 为支持自动教学评估器和AI导师在教学解释方面的评估和训练，研究人员旨在创建一个基于教师角色的大规模数据集，以解决现有资源不足的问题。

Method: 1. 构建了EduEVAL-DB数据集：包含来自ScienceQA基准测试的139个问题的854个教学解释，涵盖K-12的科学、语言和社会科学。
2. 数据集内容：每个问题包含一个人类教师解释和六个由LLM模拟不同教师角色（通过提示工程模拟真实教学风格和不足）生成的解释。
3. 提出教学风险评估标准：制定了一个包含五个维度的教学风险评估量表，包括事实正确性、解释的深度和完整性、重点与相关性、学生水平适切性以及意识形态偏见。
4. 风险标签标注：所有解释通过半自动化流程并结合专家教师评审进行二元风险标签标注。
5. 实验验证：进行了初步验证实验，对比了先进的教育模型（Gemini 2.5 Pro）与轻量级本地模型（Llama 3.1 8B），并探讨了在EduEVAL-DB上进行监督微调是否支持在消费级硬件上部署模型进行教学风险检测。

Result: 该研究提出了EduEVAL-DB数据集，并开发了包含五个维度的教学风险评估量表。通过半自动化标注和专家评审，对解释进行了风险标记。初步验证实验评估了EduEVAL-DB在评估教育模型方面的适用性，并探讨了在消费级硬件上部署模型进行监督微调以实现教学风险检测的可能性。

Conclusion: 该研究通过引入EduEVAL-DB数据集、提出教学风险评估标准及进行初步验证实验，证明了该数据集在评估和训练自动教学评估器及AI导师方面的适用性，尤其是在利用消费级硬件可部署模型进行教学风险检测方面的潜力。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [82] [Quantifying construct validity in large language model evaluations](https://arxiv.org/abs/2602.15532)
*Ryan Othniel Kearns*

Main category: cs.AI

TL;DR: 本论文提出了一种名为“结构化能力”的新模型，用于解决LLM基准测试中结构效度的问题。该模型结合了潜在因子模型和缩放定律的优点，能够从LLM基准测试结果中提取出可解释且可泛化的能力，并在解释和预测方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM社区常将基准测试结果等同于通用模型能力，但基准测试可能存在问题（如测试集污染、标注错误），从而扭曲性能。这引出了一个关于LLM基准测试结构效度的问题，即如何判断基准测试是否可靠地衡量了我们想要的能力。现有的形式模型（潜在因子模型和缩放定律）在解决结构效度方面均不令人满意：潜在因子模型忽略缩放定律，导致提取的能力常与模型规模相关；缩放定律忽略测量误差，导致提取的能力既不可解释又过拟合。

Method: 该论文提出了“结构化能力模型”，它结合了缩放定律（模型规模影响能力）和潜在因子模型（能力通过测量误差影响观测结果）的优点。作者将该模型及其两种替代方法（潜在因子模型和缩放定律）应用于OpenLLM排行榜的大量结果样本进行拟合。

Result: 结构化能力模型在简约拟合指标上优于潜在因子模型。它在离分布基准预测方面也优于缩放定律。这些改进是因为该模型能够以适当的方式将模型规模与能力分离，结合了缩放定律中模型规模应告知能力以及潜在因子模型中能力应通过测量误差告知观测结果的见解。

Conclusion: 结构化能力模型在量化LLM评估的结构效度方面展现出更好的解释力和预测能力。它通过适当地结合模型规模和测量误差，提取出更具可解释性和泛化性的能力。

Abstract: The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance. Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks. This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.

</details>


### [83] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva是一个为个人AI设计的“Glass Box”架构，通过个人知识图谱而非向量匹配，解决了现有“Black Box”RAG在透明度、可问责性和精确遗忘权方面的问题。


<details>
  <summary>Details</summary>
Motivation: 当前个人AI（特别是黑盒检索增强生成）依赖向量数据库，导致缺乏问责性，当AI产生幻觉或检索敏感数据时，用户无法检查原因或纠正错误。此外，从向量空间中删除概念不精确，可能留下“概率幽灵”，侵犯隐私。

Method: 提出Ruva，一个“Glass Box”架构，专为“人机协作记忆管理”设计。Ruva将个人AI建立在个人知识图谱上，使AI从向量匹配转向图谱推理，从而实现用户检查AI知识和精确修订特定事实。

Result: Ruva通过将个人AI建立在个人知识图谱上，使用户能够检查AI的知识并精确修订特定事实。通过从向量匹配转向图谱推理，Ruva确保了“被遗忘权”。

Conclusion: Ruva提供了一个透明且可控的“Glass Box”架构，使用户能够编辑其个人AI的记忆，从而确保了隐私和数据管理，实现了“被遗忘权”。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at .

</details>


### [84] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [85] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 该论文提出了一种预处理方法，通过推断累积约束来捕获多资源交互，从而改进约束规划中的调度问题求解性能。


<details>
  <summary>Details</summary>
Motivation: 在约束编程中，累积约束是调度问题的核心，但其传播通常是针对单个约束进行的，忽略了多资源交互，导致某些基准测试出现严重的性能下降。

Method: 该方法是一种预处理方法，用于推断额外的累积约束以捕获多资源交互，而无需在搜索时进行探测。它将累积约束解释为占用向量上的线性不等式，并通过以下步骤生成有效不等式：(i) 发现封面（即不能并行运行的任务集），(ii) 通过提升强化发现集的封面不等式，以及 (iii) 将所得约束注入回调度问题实例中。

Result: 在标准RCPSP和RCPSP/max测试套件上的实验表明，这些推断出的约束在有利实例上改善了搜索性能并收紧了目标边界，而在不利实例上造成的性能下降很小。此外，这些实验发现了25个新的下限和5个新的最佳解；其中8个下限是直接从推断的约束中获得的。

Conclusion: 该预处理方法通过推断累积约束有效地捕获了多资源交互，显著提升了约束编程在调度问题中的求解性能和解的质量，尤其是在发现新的下限和最佳解方面表现突出。

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [86] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: 本文提出了CARE Drive框架，用于评估自动驾驶中视觉语言模型的原因响应性，通过上下文变化比较模型决策，发现人类原因能显著影响模型决策，但响应性因上下文因素而异。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要评估基于结果的性能，如安全性和轨迹精度，未能确定模型决策是否反映了人类相关的考虑因素。这导致不清楚模型产生的解释是真正的理性决策还是事后合理化，这在安全关键领域会造成虚假的信心。

Method: CARE Drive，一个与模型无关的上下文感知原因评估框架，用于评估应用于自动驾驶的视觉语言模型中的原因响应性。该框架采用两阶段评估过程：提示校准确保稳定输出；系统上下文扰动测量决策对人类原因的敏感性，例如安全裕度、社会压力和效率约束。

Result: 结果表明，明确的人类原因显著影响模型决策，提高了与专家推荐行为的一致性。然而，响应性因上下文因素而异，表明对不同类型原因的敏感性不均衡。

Conclusion: 本研究提供了经验证据，表明基础模型中的原因响应性可以在不修改模型参数的情况下进行系统评估。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [87] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA是一个免训练框架，通过直接操作激活空间中的个性向量来实现微调级别的性能，以实现大型语言模型的动态个性控制。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型个性控制方法依赖于静态提示或昂贵的微调，未能捕捉人类特质的动态和组合性质。

Method: PERSONA框架通过三个阶段运行：Persona-Base通过对比激活分析提取正交特质向量；Persona-Algebra通过向量算术（标量乘法用于强度，加法用于组合，减法用于抑制）实现精确控制；Persona-Flow通过在推理过程中动态组合这些向量来实现上下文感知适应。

Result: 在PersonalityBench上，该方法获得了9.60的平均分数，几乎与监督微调的上限9.61持平，且无需任何梯度更新。在所提出的用于动态个性适应的Persona-Evolve基准测试中，该方法在不同模型家族中取得了高达91%的胜率。

Conclusion: LLM个性方面是数学上可处理的，这为可解释和高效的行为控制开辟了新方向。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [88] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: 大型语言模型在复合推理任务中表现不佳，因为其内部表示是固定的。本文提出了递归概念演化（RCE）框架，允许模型在推理时动态修改其内部表示几何并构建新的抽象概念。RRCE在多个复合推理基准测试中（如ARC-AGI-2、GPQA、BBH、MATH、HLE）显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在许多复杂推理任务中表现出色，但在需要复合推理的基准测试（如ARC-AGI-2、GPQA、MATH、BBH和HLE）上，其准确性急剧下降。现有方法（如思维链提示、自洽性或强化学习）通过扩展令牌级搜索来改进推理，但它们保持模型潜在表示空间固定不变。当所需的抽象未被编码在该固定空间中时，模型性能会崩溃。因此，需要一种能让模型构建新抽象而非仅仅重组现有抽象的方法。

Method: 本文提出了递归概念演化（Recursive Concept Evolution, RCE）框架。RCE使预训练语言模型能够在推理过程中修改其内部表示几何。该框架在检测到表示不足时动态生成低秩概念子空间，通过最小描述长度准则进行选择，在协同作用时进行合并，并通过约束优化进行整合以保持稳定性。这一过程允许模型构建新的抽象。RCE被集成到Mistral-7B模型中进行评估。

Result: RCE在复合推理基准测试中表现出显著提升：
- 在ARC-AGI-2上取得12-18点的提升。
- 在GPQA和BBH上取得8-14点的改进。
- 在MATH和HLE上持续减少了深度引起的错误。

Conclusion: RCE通过允许预训练语言模型在推理过程中修改其内部表示几何结构，并构建新的抽象而非仅仅重组现有概念，显著提升了模型在复合推理任务上的性能。该框架为提高大型语言模型的推理能力提供了一个有前景的方向。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [89] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: Global State Diffusion Algorithm (GlobeDiff) 提出通过多模态扩散过程从局部观测中推断全局状态，解决了多智能体系统中的部分可观测性问题，表现优异且误差有界。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，部分可观测性是有效协调和决策的关键障碍。现有的方法，如基于信念的状态估计和智能体间通信，往往存在不足。基于信念的方法受限于对过去经验的关注，未能充分利用全局信息；而通信方法则缺乏一个健壮的模型来有效利用辅助信息。

Method: 提出了一种名为全局状态扩散算法（GlobeDiff）的方法。该方法通过将状态推断过程公式化为多模态扩散过程，利用局部观测推断全局状态。

Result: GlobeDiff在克服状态估计模糊性的同时，能够高精度地推断全局状态。该研究证明了GlobeDiff在单模态和多模态分布下的估计误差都是有界的。广泛的实验结果表明，GlobeDiff取得了卓越的性能，能够准确推断全局状态。

Conclusion: GlobeDiff通过多模态扩散过程有效解决了多智能体系统中的部分可观测性问题，能够高精度地推断全局状态，并具有可证明的估计误差界限，优于现有方法。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [90] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 该论文探讨了在社会科学实验中使用大型语言模型（LLMs）作为合成参与者的两种策略：启发式方法和统计校准。它明确了每种方法适用于探索性研究与验证性研究的条件，指出启发式方法适合探索性任务，而统计校准在明确假设下能为验证性研究提供更精确且经济的因果效应估计。两种方法的有效性均取决于LLMs对相关人群的近似程度。


<details>
  <summary>Details</summary>
Motivation: 社会科学实验中越来越多地使用大型语言模型（LLM）作为合成参与者来生成经济高效且几乎即时的响应。然而，关于何时此类模拟可以有效推断人类行为的指导有限。该研究旨在解决这一空白。

Method: 论文通过对比两种策略来获得因果效应的有效估计：
1.  **启发式方法 (Heuristic approaches)**：通过提示工程、模型微调等手段，使模拟行为与观察到的人类行为互换。
2.  **统计校准 (Statistical calibration)**：结合辅助人类数据和统计调整，以解释观察到的和模拟响应之间的差异。
文章阐明了每种方法适用于探索性研究或验证性研究的假设条件。

Result: 1.  **启发式方法**：适用于许多探索性任务，但缺乏验证性研究通常所需的正式统计保证。
2.  **统计校准**：在明确的假设下，它能保持有效性并以更低的成本提供更精确的因果效应估计，优于仅依赖人类参与者的实验。
3.  **共同限制**：两种方法的潜力都取决于LLM对相关人群的近似程度。
4.  **机会不足**：当研究人员只专注于用LLM替代研究中的人类参与者时，可能会忽略其他机会。

Conclusion: 该论文区分了在社会科学实验中使用LLM的两种策略，并指出了它们各自适用于探索性研究和验证性研究的场景。统计校准为验证性研究提供了更强的保证，但两种方法的有效性都取决于LLM对相关人群的近似程度。研究人员应超越仅仅用LLM替代人类参与者的狭隘视角，探索更广泛的应用机会。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [91] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 本研究提出了一种利用大型语言模型（LLM）嵌入来编码建筑语义的新方法，以提高AI模型对AECO行业中建筑对象子类型分类的理解和准确性。实验结果显示，LLM编码（尤其是llama-3压缩嵌入）在F1分数上优于传统的one-hot编码。


<details>
  <summary>Details</summary>
Motivation: 在建筑、工程、施工和运营（AECO）行业中，准确表示建筑语义（包括通用对象类型和特定子类型）对于有效的AI模型训练至关重要。传统编码方法（例如，one-hot编码）通常无法传达密切相关子类型之间细微的关系，从而限制了AI的语义理解能力。

Method: 本研究提出了一种新颖的训练方法，利用大型语言模型（LLM）嵌入（如OpenAI GPT和Meta LLaMA）作为编码，以保留建筑语义中更精细的区别。通过训练GraphSAGE模型对五个高层住宅建筑信息模型（BIM）中的42种建筑对象子类型进行分类，评估了该方法。测试了各种嵌入维度，包括原始高维LLM嵌入（1,536、3,072或4,096）和通过Matryoshka表示模型生成的1,024维压缩嵌入。

Result: 实验结果表明，LLM编码优于传统的one-hot基线，其中llama-3（压缩）嵌入的加权平均F1分数达到0.8766，而one-hot编码为0.8475。

Conclusion: LLM编码在增强人工智能解释复杂、特定领域建筑语义的能力方面具有巨大潜力。随着LLM和降维技术的发展，这种方法在AECO行业语义细化任务中具有广阔的应用前景。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [92] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 针对AI训练中数据量和质量不足的问题，本文介绍了一种通过仿真生成合成数据的方法，并提出了一个基于数字孪生的AI仿真解决方案的参考框架，涵盖了其概念、优势和挑战。


<details>
  <summary>Details</summary>
Motivation: 由于数据量和数据质量不足仍然是现代次符号AI应用的主要障碍，因此对合成数据生成技术有很高的需求。

Method: 本文方法是利用仿真作为一种系统方法来生成多样化的合成数据，并引入了一个基于数字孪生的AI仿真解决方案的参考框架。

Result: 结果是提供了一个用于描述、设计和分析数字孪生AI仿真解决方案的参考框架。

Conclusion: 本文介绍了基于数字孪生的AI仿真解决方案的关键概念、优势、挑战以及一个用于描述、设计和分析这些解决方案的参考框架。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [93] [Structure-Aware Piano Accompaniment via Style Planning and Dataset-Aligned Pattern Retrieval](https://arxiv.org/abs/2602.15074)
*Wanyu Zang,Yang Yu,Meng Yu*

Main category: cs.SD

TL;DR: 本文提出了一种结构感知的符号钢琴伴奏方法，它将高层规划与音符级实现解耦，利用Transformer预测风格规划，并通过检索器从语料库中选择并重新和声钢琴模式。实验表明，该方法能够生成多样化且风格实现度高的长篇伴奏。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为符号钢琴伴奏引入一种结构感知方法，该方法将高层规划与音符级实现解耦，从而解决生成具有强风格实现的多样化长篇伴奏的挑战。

Method: 本文提出了一种结构感知方法，用于符号钢琴伴奏的生成，该方法将高层规划与音符级实现解耦。具体而言，一个轻量级Transformer根据乐段/乐句结构和功能和声来预测可解释的逐小节风格规划，然后一个检索器从语料库中选择并重新和声人类演奏的钢琴模式。检索被公式化为在显式能量下的模式匹配，该能量项考虑了和声可行性、结构角色兼容性、声部进行连续性、风格偏好和重复控制。

Result: 实验结果表明，由Transformer风格规划器引导的检索能够生成多样化的长篇伴奏，并且风格实现度高。通过对规划器进行消融分析并量化了风格间的隔离度，进一步证明了该方法在钢琴伴奏生成方面的有效性。

Conclusion: 该论文提出的推断时方法在钢琴伴奏生成方面是有效的，并通过解耦高层规划和音符级实现，能够生成多样化且风格实现度高的长篇伴奏。

Abstract: We introduce a structure-aware approach for symbolic piano accompaniment that decouples high-level planning from note-level realization. A lightweight transformer predicts an interpretable, per-measure style plan conditioned on section/phrase structure and functional harmony, and a retriever then selects and reharmonizes human-performed piano patterns from a corpus. We formulate retrieval as pattern matching under an explicit energy with terms for harmonic feasibility, structural-role compatibility, voice-leading continuity, style preferences, and repetition control. Given a structured lead sheet and optional keyword prompts, the system generates piano-accompaniment MIDI. In our experiments, transformer style-planner-guided retrieval produces diverse long-form accompaniments with strong style realization. We further analyze planner ablations and quantify inter-style isolation. Experimental results demonstrate the effectiveness of our inference-time approach for piano accompaniment generation.

</details>


### [94] [S-PRESSO: Ultra Low Bitrate Sound Effect Compression With Diffusion Autoencoders And Offline Quantization](https://arxiv.org/abs/2602.15082)
*Zineb Lahrichi,Gaëtan Hadjeres,Gaël Richard,Geoffroy Peeters*

Main category: cs.SD

TL;DR: S-PRESSO是一种48kHz音效的超低比特率（最低0.096 kbps）音频压缩模型，通过预训练的潜在扩散模型解码潜在编码器学习的压缩嵌入，可在极低帧率下实现高质量重建，超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的神经音频压缩模型和潜在生成模型在处理低分辨率音频时表现良好，但在极低比特率下（特别是48kHz高分辨率音频），其性能显著下降，导致出现明显的听觉伪影。因此，需要一种能够在高压缩率下保持高质量音频重建的新方法。

Method: S-PRESSO模型通过一个潜在编码器学习压缩音频嵌入，并利用一个预训练的潜在扩散模型进行解码，从而在超低比特率下（最低0.096 kbps）产生连续和离散嵌入。其核心方法包括离线量化生成嵌入，并利用扩散解码器的生成先验实现极低帧率（最低1Hz，750倍压缩率）。

Result: S-PRESSO实现了对48kHz音效的超低比特率（最低0.096 kbps）压缩和极低帧率（最低1Hz，750倍压缩率）重建。尽管牺牲了精确保真度，但模型能够产生令人信服且逼真的重建音频，并且在音频质量、声学相似性和重建指标方面均优于现有的连续和离散基线模型。

Conclusion: S-PRESSO通过结合潜在编码器和预训练扩散解码器，在超低比特率下实现了48kHz音效的高质量压缩和重建，解决了现有模型在极低比特率下性能下降的问题，并在多项指标上超越了现有基线。

Abstract: Neural audio compression models have recently achieved extreme compression rates, enabling efficient latent generative modeling. Conversely, latent generative models have been applied to compression, pushing the limits of continuous and discrete approaches. However, existing methods remain constrained to low-resolution audio and degrade substantially at very low bitrates, where audible artifacts are prominent. In this paper, we present S-PRESSO, a 48kHz sound effect compression model that produces both continuous and discrete embeddings at ultra-low bitrates, down to 0.096 kbps, via offline quantization. Our model relies on a pretrained latent diffusion model to decode compressed audio embeddings learned by a latent encoder. Leveraging the generative priors of the diffusion decoder, we achieve extremely low frame rates, down to 1Hz (750x compression rate), producing convincing and realistic reconstructions at the cost of exact fidelity. Despite operating at high compression rates, we demonstrate that S-PRESSO outperforms both continuous and discrete baselines in audio quality, acoustic similarity and reconstruction metrics.

</details>


### [95] [UniTAF: A Modular Framework for Joint Text-to-Speech and Audio-to-Face Modeling](https://arxiv.org/abs/2602.15651)
*Qiangong Zhou,Nagasaka Tomohiro*

Main category: cs.SD

TL;DR: 本文将TTS和A2F模型合并，以提高文本生成音频与面部表情之间的一致性，并探讨情感控制的扩展。重点在于系统设计的可行性验证，而非生成质量。


<details>
  <summary>Details</summary>
Motivation: 通过实现内部特征迁移，提高从文本生成的音频和面部表情之间的一致性。同时，探讨情感控制机制的扩展。

Method: 将两个独立的模型（TTS和A2F）合并成一个统一模型，以实现内部特征迁移。讨论了将情感控制机制从TTS扩展到联合模型。

Result: 从系统设计角度验证了重用TTS中间表示进行语音和面部表情联合建模的可行性，并提供了工程实践参考。本文不旨在展示生成质量。

Conclusion: 统一模型设计通过重用TTS中间表示来联合建模语音和面部表情是可行的，为未来的协同设计工作提供了工程实践参考。

Abstract: This work considers merging two independent models, TTS and A2F, into a unified model to enable internal feature transfer, thereby improving the consistency between audio and facial expressions generated from text. We also discuss the extension of the emotion control mechanism from TTS to the joint model. This work does not aim to showcase generation quality; instead, from a system design perspective, it validates the feasibility of reusing intermediate representations from TTS for joint modeling of speech and facial expressions, and provides engineering practice references for subsequent speech expression co-design. The project code has been open source at:

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [96] [Tomography by Design: An Algebraic Approach to Low-Rank Quantum States](https://arxiv.org/abs/2602.15202)
*Shakir Showkat Sofi,Charlotte Vermeylen,Lieven De Lathauwer*

Main category: quant-ph

TL;DR: 一种用于低秩量子态的代数量子态层析成像算法，利用代数矩阵完备性实现高效且有保证的恢复。


<details>
  <summary>Details</summary>
Motivation: 估计量子态密度矩阵的结构化条目，并仅使用标准数值线性代数操作获取剩余条目，特别是在低秩假设下。

Method: 提出了一种代数算法，该算法利用某些可观测量的测量来估计底层密度矩阵的结构化条目。在低秩假设下，其余条目仅使用标准数值线性代数运算获得，形成了一个代数矩阵完备性框架。

Result: 该方法适用于广泛的通用低秩混合量子态。与现有技术相比，它计算效率高，并提供确定性恢复保证。

Conclusion: 该代数矩阵完备性框架为低秩混合量子态的量子态层析成像提供了一种高效且具有确定性恢复保证的方法。

Abstract: We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [97] [Reconstructing Carbon Monoxide Reanalysis with Machine Learning](https://arxiv.org/abs/2602.15056)
*Paula Harder,Johannes Flemming*

Main category: physics.ao-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Copernicus Atmospheric Monitoring Service provides reanalysis products for atmospheric composition by combining model simulations with satellite observations. The quality of these products depends strongly on the availability of the observational data, which can vary over time as new satellite instruments become available or are discontinued, such as Carbon Monoxide (CO) observations of the Measurements Of Pollution In The Troposphere (MOPITT) satellite in early 2025. Machine learning offers a promising approach to compensate for such data losses by learning systematic discrepancies between model configurations. In this study, we investigate machine learning methods to predict monthly-mean total column of Carbon Monoxide re-analysis from a control model simulation.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [98] [TokaMind: A Multi-Modal Transformer Foundation Model for Tokamak Plasma Dynamics](https://arxiv.org/abs/2602.15084)
*Tobia Boschi,Andrea Loreti,Nicola C. Amorisco,Rodrigo H. Ordonez-Hurtado,Cécile Rousseau,George K. Holt,Eszter Székely,Alexander Whittle,Samuel Jackson,Adriano Agnello,Stanislas Pamela,Alessandra Pascale,Robert Akers,Juan Bernabe Moreno,Vassil Alexandrov,Mykhaylo Zayats*

Main category: physics.plasm-ph

TL;DR: TokaMind是一个基于多模态Transformer的开源基础模型框架，用于聚变等离子体建模。它通过在MAST数据集上训练来支持多种数据模态，能处理缺失信号，并通过高效任务适应性在基准测试中超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前聚变等离子体建模面临处理异构托卡马克诊断数据、不同采样率、缺失信号以及需要高效任务适应性的挑战。因此，该研究旨在开发一个开放、灵活且高性能的框架，以充分利用多模态数据进行托卡马克等离子体动力学建模，并突出多模态预训练的优势。

Method: 该研究提出了TokaMind，一个基于多模态Transformer（MMT）的开源基础模型框架，用于聚变等离子体建模。TokaMind利用公共的MAST数据集中的异构托卡马克诊断数据进行训练，支持多种数据模态（时间序列、2D剖面和视频），处理不同的采样率，并具备鲁棒的缺失信号处理能力。它通过选择性加载和冻结四个模型组件来实现高效的任务适应。为了表示多模态信号，TokaMind使用免训练的离散余弦变换嵌入（DCT3D），并提供了一个简洁的接口支持替代嵌入（如变分自编码器）。该模型在TokaMark基准上进行了评估。

Result: 经过微调的TokaMind在除一项任务外的所有任务上均优于基准线。对于多项任务，轻量级微调比在相同训练周期预算下从头开始训练相同的架构表现更好。这些结果证明了多模态预训练在托卡马克等离子体动力学方面的优势。

Conclusion: 多模态预训练对托卡马克等离子体动力学有益，TokaMind为未来的聚变建模任务提供了一个实用且可扩展的基础。

Abstract: We present TokaMind, an open-source foundation model framework for fusion plasma modeling, based on a Multi-Modal Transformer (MMT) and trained on heterogeneous tokamak diagnostics from the publicly available MAST dataset. TokaMind supports multiple data modalities (time-series, 2D profiles, and videos) with different sampling rates, robust missing-signal handling, and efficient task adaptation via selectively loading and freezing four model components. To represent multi-modal signals, we use a training-free Discrete Cosine Transform embedding (DCT3D) and provide a clean interface for alternative embeddings (e.g., Variational Autoencoders - VAEs). We evaluate TokaMind on the recently introduced MAST benchmark TokaMark, comparing training and embedding strategies. Our results show that fine-tuned TokaMind outperforms the benchmark baseline on all but one task, and that, for several tasks, lightweight fine-tuning yields better performance than training the same architecture from scratch under a matched epoch budget. These findings highlight the benefits of multi-modal pretraining for tokamak plasma dynamics and provide a practical, extensible foundation for future fusion modeling tasks. Training code and model weights will be made publicly available.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [99] [StrokeNeXt: A Siamese-encoder Approach for Brain Stroke Classification in Computed Tomography Imagery](https://arxiv.org/abs/2602.15087)
*Leo Thomas Ramos,Angel D. Sappa*

Main category: eess.IV

TL;DR: 本文提出StrokeNeXt，一个用于2D CT图像卒中分类的双分支ConvNeXt模型，实现了高达0.988的准确率和F1-score，超越基线模型，并具有快速推理和收敛的优点。


<details>
  <summary>Details</summary>
Motivation: 在2D CT图像中进行卒中分类（包括检测和亚型分类）的需求，旨在提高诊断的准确性和效率。

Method: StrokeNeXt采用双分支设计，包含两个ConvNeXt编码器。其特征通过一个轻量级卷积解码器进行融合，该解码器基于堆叠的一维操作（包括瓶颈投影和转换层）和一个紧凑的分类头。模型在包含6,774张CT图像的数据集上进行评估，旨在实现卒中检测以及缺血性与出血性卒中亚型分类。

Result: StrokeNeXt始终优于基于卷积和Transformer的基线模型，准确率和F1-score高达0.988。性能提升具有统计学意义。在诊断类别中显示出稳健的类别敏感性和特异性。与竞争方法相比，预测误差更低，混淆矩阵结果显示误分类率低。此外，模型具有低推理时间和快速收敛的特点。

Conclusion: StrokeNeXt模型在2D CT图像卒中分类中表现出卓越的性能、鲁棒性、效率和实用性，优于现有方法。

Abstract: We present StrokeNeXt, a model for stroke classification in 2D Computed Tomography (CT) images. StrokeNeXt employs a dual-branch design with two ConvNeXt encoders, whose features are fused through a lightweight convolutional decoder based on stacked 1D operations, including a bottleneck projection and transformation layers, and a compact classification head. The model is evaluated on a curated dataset of 6,774 CT images, addressing both stroke detection and subtype classification between ischemic and hemorrhage cases. StrokeNeXt consistently outperforms convolutional and Transformer-based baselines, reaching accuracies and F1-scores of up to 0.988. Paired statistical tests confirm that the performance gains are statistically significant, while class-wise sensitivity and specificity demonstrate robust behavior across diagnostic categories. Calibration analysis shows reduced prediction error compared to competing methods, and confusion matrix results indicate low misclassification rates. In addition, the model exhibits low inference time and fast convergence.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [100] [MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning](https://arxiv.org/abs/2602.15245)
*Ankit Bhattarai,Hannah Selder,Florian Fischer,Arthur Fleig,Per Ola Kristensson*

Main category: cs.HC

TL;DR: MyoInteract是一个新颖的框架，通过提供用户友好的GUI和显著缩短训练时间（高达98%），使人机交互中的生物力学强化学习变得更加快速和易于使用。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的生物力学模拟在人机交互研究和交互设计中缺乏可用性和可解释性。

Method: 开发了MyoInteract框架，该框架提供了一个易于使用的图形用户界面，允许设计者在几分钟内设置任务、用户模型和训练参数，并训练和评估肌肉驱动的模拟用户。

Result: MyoInteract将训练时间缩短了98%。一项针对12名交互设计师的研讨会研究表明，生物力学强化学习新手可以在一个会话内成功设置、训练和评估目标导向的用户动作。

Conclusion: MyoInteract显著降低了人机交互生物力学研究的门槛，并将耗时数天的专家级任务转变为可在一小时内完成的工作流程，从而加速了迭代周期。

Abstract: Reinforcement learning (RL)-based biomechanical simulations have the potential to revolutionise HCI research and interaction design, but currently lack usability and interpretability. Using the Human Action Cycle as a design lens, we identify key limitations of biomechanical RL frameworks and develop MyoInteract, a novel framework for fast prototyping of biomechanical HCI tasks. MyoInteract allows designers to setup tasks, user models, and training parameters from an easy-to-use GUI within minutes. It trains and evaluates muscle-actuated simulated users within minutes, reducing training times by up to 98%. A workshop study with 12 interaction designers revealed that MyoInteract allowed novices in biomechanical RL to successfully setup, train, and assess goal-directed user movements within a single session. By transforming biomechanical RL from a days-long expert task into an accessible hour-long workflow, this work significantly lowers barriers to entry and accelerates iteration cycles in HCI biomechanics research.

</details>


### [101] [From Diagnosis to Inoculation: Building Cognitive Resistance to AI Disempowerment](https://arxiv.org/abs/2602.15265)
*Aleksey Komissarov*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent empirical research by Sharma et al. (2026) demonstrated that AI assistant interactions carry meaningful potential for situational human disempowerment, including reality distortion, value judgment distortion, and action distortion. While this work provides a critical diagnosis of the problem, concrete pedagogical interventions remain underexplored. I present an AI literacy framework built around eight cross-cutting Learning Outcomes (LOs), developed independently through teaching practice and subsequently found to align with Sharma et al.'s disempowerment taxonomy. I report a case study from a publicly available online course, where a co-teaching methodology--with AI serving as an active voice co-instructor--was used to deliver this framework. Drawing on inoculation theory (McGuire, 1961)--a well-established persuasion research framework recently applied to misinformation prebunking by the Cambridge school (van der Linden, 2022; Roozenbeek & van der Linden, 2019)--I argue that AI literacy cannot be acquired through declarative knowledge alone, but requires guided exposure to AI failure modes, including the sycophantic validation and authority projection patterns identified by Sharma et al. This application of inoculation theory to AI-specific distortion is, to my knowledge, novel. I discuss the convergence between the pedagogically-derived framework and Sharma et al.'s empirically-derived taxonomy, and argue that this convergence--two independent approaches arriving at similar problem descriptions--strengthens the case for both the diagnosis and the proposed educational response.

</details>


### [102] [How to Disclose? Strategic AI Disclosure in Crowdfunding](https://arxiv.org/abs/2602.15698)
*Ning Wang,Chen Liang*

Main category: cs.HC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As artificial intelligence (AI) increasingly integrates into crowdfunding practices, strategic disclosure of AI involvement has become critical. Yet, empirical insights into how different disclosure strategies influence investor decisions remain limited. Drawing on signaling theory and Aristotle's rhetorical framework, we examine how mandatory AI disclosure affects crowdfunding performance and how substantive signals (degree of AI involvement) and rhetorical signals (logos/explicitness, ethos/authenticity, pathos/emotional tone) moderate these effects. Leveraging Kickstarter's mandatory AI disclosure policy as a natural experiment and four supplementary online experiments, we find that mandatory AI disclosure significantly reduces crowdfunding performance: funds raised decline by 39.8% and backer counts by 23.9% for AI-involved projects. However, this adverse effect is systematically moderated by disclosure strategy. Greater AI involvement amplifies the negative effects of AI disclosure, while high authenticity and high explicitness mitigate them. Interestingly, excessive positive emotional tone (a strategy creators might intuitively adopt to counteract AI skepticism) backfires and exacerbates negative outcomes. Supplementary randomized experiments identify two underlying mechanisms: perceived creator competence and AI washing concerns. Substantive signals primarily affect competence judgments, whereas rhetorical signals operate through varied pathways: either mediator alone or both in sequence. These findings provide theoretical and practical insights for entrepreneurs, platforms, and policymakers strategically managing AI transparency in high-stakes investment contexts.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [103] [Automatic Funny Scene Extraction from Long-form Cinematic Videos](https://arxiv.org/abs/2602.15381)
*Sibendu Paul,Haotian Jiang,Caren Chen*

Main category: cs.IR

TL;DR: 本文提出一个端到端系统，利用视觉、文本和音频线索，自动从长篇电影中高效地检测、定位和标注幽默场景，显著提高了场景检测和幽默识别的性能，以增强用户参与度和零食化内容创作。


<details>
  <summary>Details</summary>
Motivation: 从电影中自动提取引人入胜且高质量的幽默场景对于创建引人注目的视频预览和零食化内容至关重要，能提升流媒体平台的用户参与度。然而，长篇电影的持续时间长和叙事复杂性给场景定位带来了挑战，而幽默对多种模态和细致风格的依赖进一步增加了复杂性。

Method: 本文提出了一个端到端系统，用于自动识别和排序长篇电影中的幽默场景，包括镜头检测、多模态场景定位和针对电影内容优化的幽默标注。关键创新包括：结合视觉和文本线索的新型场景分割方法、通过引导式三元组挖掘改进的镜头表示，以及利用音频和文本的多模态幽默标注框架。

Result: 该系统在OVSD数据集上比最先进的场景检测AP提高了18.3%，在长文本幽默检测方面F1分数为0.834。对五部电影的广泛评估表明，通过该管道提取的片段中87%旨在搞笑，98%的场景被准确本地化，并且成功推广到预告片。

Conclusion: 该系统能够增强内容创作流程，提高用户参与度，并简化各种电影媒体格式的零食化内容生成。

Abstract: Automatically extracting engaging and high-quality humorous scenes from cinematic titles is pivotal for creating captivating video previews and snackable content, boosting user engagement on streaming platforms. Long-form cinematic titles, with their extended duration and complex narratives, challenge scene localization, while humor's reliance on diverse modalities and its nuanced style add further complexity. This paper introduces an end-to-end system for automatically identifying and ranking humorous scenes from long-form cinematic titles, featuring shot detection, multimodal scene localization, and humor tagging optimized for cinematic content. Key innovations include a novel scene segmentation approach combining visual and textual cues, improved shot representations via guided triplet mining, and a multimodal humor tagging framework leveraging both audio and text. Our system achieves an 18.3% AP improvement over state-of-the-art scene detection on the OVSD dataset and an F1 score of 0.834 for detecting humor in long text. Extensive evaluations across five cinematic titles demonstrate 87% of clips extracted by our pipeline are intended to be funny, while 98% of scenes are accurately localized. With successful generalization to trailers, these results showcase the pipeline's potential to enhance content creation workflows, improve user engagement, and streamline snackable content generation for diverse cinematic media formats.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [104] [Decision Making under Imperfect Recall: Algorithms and Benchmarks](https://arxiv.org/abs/2602.15252)
*Emanuel Tewolde,Brian Hu Zhang,Ioannis Anagnostides,Tuomas Sandholm,Vincent Conitzer*

Main category: cs.GT

TL;DR: 本文首次提出了不完美回忆决策问题的基准套件，并发现后悔匹配（RM）算法在解决这类问题中的非线性约束优化方面，其性能显著优于传统一阶优化器，确立了RM算法在大规模约束优化中的强大作用。


<details>
  <summary>Details</summary>
Motivation: 不完美回忆决策问题建模了智能体遗忘其先前信息的情境，这在AI隐私和安全等领域具有重要意义。尽管后悔匹配（RM）算法在解决大型双人零和博弈中取得了巨大成功，但其在非线性约束优化领域的应用却相对未被探索，因此有必要研究其在该环境下的性能。

Method: 本文引入了第一个用于不完美回忆决策问题的基准套件，涵盖了AI隐私和安全等多种问题类型。使用该套件生成的61个问题实例，作者评估了不同算法寻找一阶最优策略的性能。重点是引入并评估了后悔匹配（RM）算法家族，并将其性能与常用的如投影梯度下降等一阶优化器进行了比较。

Result: 后悔匹配（RM）算法在处理不完美回忆决策问题时，其性能持续且显著地优于常用的如投影梯度下降等一阶优化器，性能提升往往达到数量级。

Conclusion: 这项研究首次确立了后悔匹配（RM）算法家族是解决大规模约束优化问题的强大方法。

Abstract: In game theory, imperfect-recall decision problems model situations in which an agent forgets information it held before. They encompass games such as the ``absentminded driver'' and team games with limited communication. In this paper, we introduce the first benchmark suite for imperfect-recall decision problems. Our benchmarks capture a variety of problem types, including ones concerning privacy in AI systems that elicit sensitive information, and AI safety via testing of agents in simulation. Across 61 problem instances generated using this suite, we evaluate the performance of different algorithms for finding first-order optimal strategies in such problems. In particular, we introduce the family of regret matching (RM) algorithms for nonlinear constrained optimization. This class of parameter-free algorithms has enjoyed tremendous success in solving large two-player zero-sum games, but, surprisingly, they were hitherto relatively unexplored beyond that setting. Our key finding is that RM algorithms consistently outperform commonly employed first-order optimizers such as projected gradient descent, often by orders of magnitude. This establishes, for the first time, the RM family as a formidable approach to large-scale constrained optimization problems.

</details>


### [105] [Outer Diversity of Structured Domains](https://arxiv.org/abs/2602.15708)
*Piotr Faliszewski,Krzysztof Sornat,Stanisław Szufa,Tomasz Wąs*

Main category: cs.GT

TL;DR: 本文介绍并研究了序数偏好域的外部多样性概念，并评估了其在单峰、单交叉、群可分和欧几里德等结构域中的价值。


<details>
  <summary>Details</summary>
Motivation: 在选举中，序数偏好域是选民可以投票的偏好顺序的子集。本文旨在引入和研究域的外部多样性概念，并评估其对于一些知名结构域的价值。

Method: 本文引入并研究了域的外部多样性概念，并评估了其在多种知名结构域（如单峰、单交叉、群可分和欧几里德域）中的价值。

Result: 本文评估了域的外部多样性在多种知名结构域（如单峰、单交叉、群可分和欧几里德域）中的价值。

Conclusion: 本摘要未提供明确结论。

Abstract: An ordinal preference domain is a subset of preference orders that the voters are allowed to cast in an election. We introduce and study the notion of outer diversity of a domain and evaluate its value for a number of well-known structured domains, such as the single-peaked, single-crossing, group-separable, and Euclidean ones.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [106] [LemonadeBench: Evaluating the Economic Intuition of Large Language Models in Simple Markets](https://arxiv.org/abs/2602.13209)
*Aidan Vyas*

Main category: q-fin.GN

TL;DR: LemonadeBench v0.5基准测试通过模拟柠檬水摊位业务，评估LLM的经济决策能力，发现所有模型都能盈利，但性能随复杂度提升，且模型普遍存在局部优化而非全局优化的特点。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在经济直觉、长期规划和不确定性下的决策能力。这些任务是小型企业主日常面临的挑战。

Method: 通过模拟柠檬水摊位业务，评估LLM在为期30天的模拟经营中管理库存（有过期商品）、设定价格、选择营业时间以实现利润最大化的能力。此基准测试名为LemonadeBench v0.5。

Result: 所有模型均能盈利，但性能随复杂度急剧提升，前沿模型可达到理论最优的70%，相比基础模型有超过10倍的改进。然而，对业务效率的六个维度分析发现，模型普遍倾向于局部优化，而非全局优化，在特定领域表现出色，但在其他领域存在显著盲点。

Conclusion: 所有模型都表现出经济能动性并实现盈利，但性能随模型复杂性显著提升，从基本模型获得最低利润到前沿模型达到理论最优的70%。六个维度的业务效率分解揭示，模型倾向于局部优化而非全局优化，在某些方面表现出色但在其他方面存在盲点。

Abstract: We introduce LemonadeBench v0.5, a minimal benchmark for evaluating economic intuition, long-term planning, and decision-making under uncertainty in large language models (LLMs) through a simulated lemonade stand business. Models must manage inventory with expiring goods, set prices, choose operating hours, and maximize profit over a 30-day period-tasks that any small business owner faces daily. All models demonstrate meaningful economic agency by achieving profitability, with performance scaling dramatically by sophistication-from basic models earning minimal profits to frontier models capturing 70% of theoretical optimal, a greater than 10x improvement. Yet our decomposition of business efficiency across six dimensions reveals a consistent pattern: models achieve local rather than global optimization, excelling in select areas while exhibiting surprising blind spots elsewhere.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [107] [An effective Genetic Programming Hyper-Heuristic for Uncertain Agile Satellite Scheduling](https://arxiv.org/abs/2602.15070)
*Yuning Chen,Junhua Xue,Wangqi Gu,Mingyan Shao*

Main category: cs.NE

TL;DR: 本文提出了一种遗传编程超启发式（GPHH）方法，以解决不确定敏捷地球观测卫星调度问题（UAEOSSP），该方法生成的调度策略在不确定环境下表现出色，并显著优于现有启发式算法。


<details>
  <summary>Details</summary>
Motivation: 为了反映实际信息固有的未知性，该研究考虑了任务利润、资源消耗和任务可见性等一系列不确定因素，从而解决了不确定敏捷地球观测卫星调度问题（UAEOSSP），这与静态AEOSSP不同。

Method: 设计了一种有效的遗传编程超启发式算法（GPHH），用于自动化生成调度策略。

Result: 进化的调度策略显著优于精心设计的前瞻启发式算法（LAHs）和手动设计的启发式算法（MDHs）。具体而言，GPHH 生成的策略与 LAHs 相比平均提高了 5.03%，与 MDHs 相比平均提高了 8.14%。

Conclusion: 进化的调度策略能够实时调整计划并表现出色，GPHH 生成的策略显著优于现有的启发式方法。

Abstract: This paper investigates a novel problem, namely the Uncertain Agile Earth Observation Satellite Scheduling Problem (UAEOSSP). Unlike the static AEOSSP, it takes into account a range of uncertain factors (e.g., task profit, resource consumption, and task visibility) in order to reflect the reality that the actual information is inherently unknown beforehand. An effective Genetic Programming Hyper-Heuristic (GPHH) is designed to automate the generation of scheduling policies. The evolved scheduling policies can be utilized to adjust plans in real time and perform exceptionally well. Experimental results demonstrate that evolved scheduling policies significantly outperform both well-designed Look-Ahead Heuristics (LAHs) and Manually Designed Heuristics (MDHs). Specifically, the policies generated by GPHH achieve an average improvement of 5.03% compared to LAHs and 8.14% compared to MDHs.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [108] [The geometry of online conversations and the causal antecedents of conflictual discourse](https://arxiv.org/abs/2602.15600)
*Carlo Santagiustina,Caterina Cruciani*

Main category: cs.SI

TL;DR: 本文研究了气候变化在线讨论中冲突性语言的因果前因和交互几何结构，发现回复延迟、与父帖和同级帖的对齐以及早期分支响应会影响立场、语气和情绪化程度。


<details>
  <summary>Details</summary>
Motivation: 调查在线线程对话中冲突性语言的因果前因以及交互的几何结构。

Method: 使用LLM提示和平均推断了三个注释维度（立场：同意 vs 分歧；语气：攻击性 vs 尊重；情绪化 vs 事实性），并利用在线论坛数据，检查这些维度如何响应时间、对话和树状结构特征。

Result: 更长的帖子间延迟与更尊重的回复相关；相对于父帖的更长延迟与较少分歧但更多情绪化语言相关。与父帖和同级帖的平均立场、语气和情绪化框架存在强烈的趋同（父帖效应通常强于同级帖效应）。早期分支级别的响应会调节这些对齐动态，使得父子立场对齐根据分支是同意还是不同意根消息而增强或减弱。礼仪相关维度（攻击性 vs 尊重，分歧 vs 同意）的影响是可加的，而情绪化与事实性框架的对齐在同级帖也相似对齐时会增强。

Conclusion: 在线讨论中冲突性语言的形成和演变受多种因素影响，包括时间延迟、对话环境的对齐效应以及早期分支的互动模式。这些因素共同作用于参与者的立场、语气和情绪表达。

Abstract: This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [109] [CircuChain: Disentangling Competence and Compliance in LLM Circuit Analysis](https://arxiv.org/abs/2602.15037)
*Mayank Ravishankara*

Main category: cs.SE

TL;DR: 本文介绍了CircuChain，一个诊断基准，用于评估LLMs在电路分析中遵循指令的能力与物理推理能力。研究发现，即使是强大的模型，在面临与训练先验冲突的明确指令时，也存在“依从性-能力分歧”，表明模型能力与指令遵循之间存在脱节。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在工程领域达到专家级性能时，在用户指定约束下进行可靠推理变得至关重要。在电路分析中，即使数值正确，违反既定方法惯例（如网格方向或极性分配）的解决方案也是不足的，这些错误可能在安全关键系统中传播。目前尚不清楚前沿模型是真正应用第一性原理推理，还是依赖与明确指令冲突的固有训练先验。

Method: 引入了CircuChain诊断基准，旨在区分指令依从性与物理推理能力。CircuChain包含在五种经典电路拓扑中平衡的对照/陷阱问题对，并系统地改变了符号约定、电流方向和极性定义。通过符号求解器、SPICE仿真和基于LLM的错误分类法相结合的多阶段验证流程，可以精细地将故障归因于约定错误、物理错误、算术错误或幻觉。

Result: 在每个模型的100项任务中，观察到一致的“依从性-能力分歧”。评估出的最强模型表现出近乎完美的物理推理能力，但在陷阱条件故意反转自然符号模式时，约定违规率很高。相反，较弱的模型物理保真度较低，但对明确指令的遵循能力更强。

Conclusion: 结果表明，模型能力的提升并不能保证对约束条件的更好遵循，并强调了在数学严格领域中强调指令遵循的新评估框架的需求。CircuChain为此提供了一个框架，并为工程教育和AI对齐研究提供了可操作的见解。

Abstract: As large language models (LLMs) advance toward expert-level performance in engineering domains, reliable reasoning under user-specified constraints becomes critical. In circuit analysis, for example, a numerically correct solution is insufficient if it violates established methodological conventions such as mesh directionality or polarity assignments, errors that can propagate in safety-critical systems. Yet it remains unclear whether frontier models truly apply first-principles reasoning or rely on entrenched training priors that conflict with explicit instructions. We introduce CircuChain, a diagnostic benchmark designed to disentangle instruction compliance from physical reasoning competence in electrical circuit analysis. CircuChain consists of counterbalanced Control/Trap problem pairs across five canonical circuit topologies, augmented with systematic variations in sign conventions, current orientations, and polarity definitions. A multi-stage verification pipeline, combining symbolic solvers, SPICE simulation, and an LLM-based error taxonomy, enables fine-grained attribution of failures to convention errors, physics errors, arithmetic mistakes, or hallucinations. Across 100 tasks per model, we observe a consistent Compliance-Competence Divergence. The strongest model evaluated exhibits near-perfect physical reasoning but a high rate of convention violations when Trap conditions deliberately invert natural sign patterns. Conversely, weaker models display lower physical fidelity yet superior adherence to explicit instructions. These results suggest that increased model capability does not guarantee improved constraint alignment and highlight the need for new evaluation frameworks that stress instruction-following under mathematically rigid domains. CircuChain provides one such framework and offers actionable insights for both engineering education and AI alignment research.

</details>


### [110] [GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon](https://arxiv.org/abs/2602.15241)
*Arya Tschand,Chenyu Wang,Zishen Wan,Andrew Cheng,Ioana Cristescu,Kevin He,Howard Huang,Alexander Ingare,Akseli Kangaslahti,Sara Kangaslahti,Theo Lebryk,Hongjin Lin,Jeffrey Jian Ma,Alexandru Meterez,Clara Mohri,Depen Morwani,Sunny Qin,Roy Rinberg,Paula Rodriguez-Diaz,Alyssa Mia Taliotis,Pernille Undrum Fathi,Rosie Zhao,Todd Zhou,Vijay Janapa Reddi*

Main category: cs.SE

TL;DR: 本文从跨栈角度分析了生成式AI在计算系统设计中的应用，识别出五个普遍挑战和五个有效设计原则，并构建了一个挑战-原则图，强调了共享工程方法论的必要性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑计算系统的设计、优化和构建方式，但其研究在软件、架构和芯片设计社区之间仍然是碎片化的。

Method: 本文采用跨栈视角，审查了生成模型从代码生成、分布式运行时到硬件设计空间探索、RTL综合、物理布局和验证的应用。研究分析了相同结构性困难和有效响应如何在整个栈中反复出现，并分析了超过275篇论文，涵盖计算栈三层中的十一个应用领域。

Result: 研究发现，尽管领域和工具多样，该领域在面临五个反复出现的挑战（反馈循环危机、隐性知识问题、信任与验证、跨边界协同设计以及从确定性到动态性的转变）时，会不约而同地采取五种独立出现的有效响应设计原则（拥抱混合方法、设计持续反馈、按角色分离关注点、根据问题结构匹配方法、以及建立在数十年的系统知识之上）。这些被组织成一个挑战-原则图。

Conclusion: 该领域需要共享的工程方法论，包括通用词汇、跨层基准和系统设计实践，以促进不同社区的共同进步，并揭示了从跨层视角才能看到的开放研究问题。

Abstract: Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [111] [Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight](https://arxiv.org/abs/2602.15259)
*Kirandeep Kaur,Xingda Lyu,Chirag Shah*

Main category: cs.CY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. Existing approaches to proactivity remain narrowly anticipatory, extrapolating from past behavior and presuming that goals are already well defined, thereby failing to support users meaningfully. However, surfacing possibilities beyond a user's current awareness is not inherently beneficial. Unconstrained proactive interventions can misdirect attention, overwhelm users, or introduce harm. Proactive agents, therefore, require behavioral grounding: principled constraints on when, how, and to what extent an agent should intervene. We advance the position that generative proactivity must be grounded both epistemically and behaviorally. Drawing on the philosophy of ignorance and research on proactive behavior, we argue that these theories offer critical guidance for designing agents that can engage responsibly and foster meaningful partnerships.

</details>


### [112] [Algorithmic Approaches to Opinion Selection for Online Deliberation: A Comparative Study](https://arxiv.org/abs/2602.15439)
*Salim Hafid,Manon Berriche,Jean-Philippe Cointet*

Main category: cs.CY

TL;DR: 该研究评估了在线协商平台中用于选择意见的算法策略，并提出了一种新的社会选择算法，该算法在比例代表性和多样性之间取得了最佳权衡。


<details>
  <summary>Details</summary>
Motivation: 在在线协商平台中，算法选择意见的过程可能导致忽视少数派声音或降低内容多样性。目前尚不清楚不同的选择策略如何影响比例代表性等民主标准。

Method: 该研究评估了多种算法方法，并基于社会选择理论提出了一种新的算法，该算法在选择策略中结合了多样性和平衡的代表性概念。

Result: 实证研究发现，虽然没有单一策略在所有民主期望中都占主导地位，但该研究提出的受社会选择启发的选择规则在比例代表性和多样性之间取得了最强的权衡。

Conclusion: 在在线协商中，通过社会选择理论设计的新算法可以有效地平衡意见选择中的比例代表性和多样性。

Abstract: During deliberation processes, mediators and facilitators typically need to select a small and representative set of opinions later used to produce digestible reports for stakeholders. In online deliberation platforms, algorithmic selection is increasingly used to automate this process. However, such automation is not without consequences. For instance, enforcing consensus-seeking algorithmic strategies can imply ignoring or flattening conflicting preferences, which may lead to erasing minority voices and reducing content diversity. More generally, across the variety of existing selection strategies (e.g., consensus, diversity), it remains unclear how each approach influences desired democratic criteria such as proportional representation. To address this gap, we benchmark several algorithmic approaches in this context. We also build on social choice theory to propose a novel algorithm that incorporates both diversity and a balanced notion of representation in the selection strategy. We find empirically that while no single strategy dominates across all democratic desiderata, our social-choice-inspired selection rule achieves the strongest trade-off between proportional representation and diversity.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [113] [CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation](https://arxiv.org/abs/2602.15060)
*Tengjie Zhu,Guanyu Cai,Yang Zhaohui,Guanzhu Ren,Haohui Xie,ZiRui Wang,Junsong Wu,Jingbo Wang,Xiaokang Yang,Yao Mu,Yichao Yan,Yichao Yan*

Main category: cs.RO

TL;DR: CLOT是一个实时全身人形机器人遥操作系统，通过闭环全局运动跟踪和数据驱动的随机化策略，实现了长时间范围内无漂移、稳定、高精度的人机模仿。


<details>
  <summary>Details</summary>
Motivation: 长程全身人形机器人遥操作面临全局姿态漂移累积的挑战，尤其是在大型人形机器人上。现有的学习型跟踪方法通常在机器人局部坐标系中操作，忽略全局姿态反馈，导致长时间执行期间的漂移和不稳定。

Method: 提出了CLOT系统，一个通过高频定位反馈实现闭环全局运动跟踪的实时全身人形机器人遥操作系统。采用数据驱动的随机化策略，将观察轨迹与奖励评估解耦，以实现平滑稳定的全局校正。通过对抗性运动先验来规范策略以抑制不自然行为。收集了20小时的人类运动数据用于训练。设计并训练了一个基于Transformer的策略，训练时长超过1300 GPU小时。将策略部署在一个31自由度（不包括手）的全尺寸人形机器人上。

Result: 仿真和现实世界的实验均验证了在从仿真到现实的人形机器人遥操作中，该系统具有高动态运动、高精度跟踪和强大的鲁棒性。

Conclusion: CLOT通过闭环全局运动跟踪、数据驱动的随机化以及对抗性运动先验，有效解决了长程人形机器人遥操作中的全局姿态漂移问题，在仿真和现实场景中均表现出优异的性能。

Abstract: Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.

</details>


### [114] [Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories](https://arxiv.org/abs/2602.15061)
*Zihan Zhang,Haohui Que,Junhan Chang,Xin Zhang,Hao Wei,Tong Zhu*

Main category: cs.RO

TL;DR: 本文提出了Safe-SDL框架，通过引入操作设计域(ODD)、控制屏障函数(CBF)和事务安全协议(CRUTD)来弥补AI生成命令与物理安全之间的“语法到安全鸿沟”，从而为自动驾驶实验室(SDL)提供全面的安全边界和控制机制，以实现AI驱动发现的负责任加速。


<details>
  <summary>Details</summary>
Motivation: 自主驾驶实验室(SDL)尽管能加速科学发现，但其部署带来了前所未有的安全挑战，尤其是AI生成命令与物理安全影响之间的“语法到安全鸿沟”，这是传统安全机制无法有效解决的。

Method: 论文提出了Safe-SDL框架，通过三个协同组件来解决“语法到安全鸿沟”：1) 正式定义的操作设计域(ODD)，以数学验证边界约束系统行为；2) 控制屏障函数(CBF)，提供实时安全保障；3) 创新的事务安全协议(CRUTD)，确保数字规划与物理执行的原子一致性。

Result: 对LabSafety Bench的评估显示，当前基础模型存在显著安全故障，强调了架构安全机制的必要性。Safe-SDL的理论贡献通过分析UniLabOS和Osprey等现有实现得到了验证。

Conclusion: Safe-SDL框架为自主科学系统的安全部署提供了全面的理论基础和实践指导，为负责任地加速AI驱动的科学发现奠定了基石。

Abstract: The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.

</details>


### [115] [Augmenting Human Balance with Generic Supernumerary Robotic Limbs](https://arxiv.org/abs/2602.15092)
*Xuanyun Qiu,Dorian Verdel,Hector Cervantes-Culebro,Alexis Devillard,Etienne Burdet*

Main category: cs.RO

TL;DR: 本研究提出了一种通用的三层架构，用于维持人类-附加机械臂系统中的平衡，通过预测人体动态、规划质心轨迹和执行控制输入，有效减少了姿态不稳定性。


<details>
  <summary>Details</summary>
Motivation: 附加机械臂（SLs）尽管潜力巨大，但其可用性受限于安全性和通用控制等关键技术挑战。本研究旨在解决人类-SLs系统中的平衡维持这一关键问题，这是实现安全舒适增强任务的先决条件。

Method: 提出了一种通用的平衡维持框架，该框架采用分层三层架构，包括：(i) 预测层，用于估计人体躯干和质心（CoM）动态；(ii) 规划层，用于生成最佳CoM轨迹以抵消躯干运动并计算相应的SL控制输入；(iii) 控制层，用于在SL硬件上执行这些输入。

Result: 通过对10名参与者进行前屈和侧屈任务的评估，结果表明该框架显著减少了姿态不稳定性，证明了其在增强平衡方面的有效性。

Conclusion: 这项工作为实现安全多功能的人类-附加机械臂交互铺平了道路。

Abstract: Supernumerary robotic limbs (SLs) have the potential to transform a wide range of human activities, yet their usability remains limited by key technical challenges, particularly in ensuring safety and achieving versatile control. Here, we address the critical problem of maintaining balance in the human-SLs system, a prerequisite for safe and comfortable augmentation tasks. Unlike previous approaches that developed SLs specifically for stability support, we propose a general framework for preserving balance with SLs designed for generic use. Our hierarchical three-layer architecture consists of: (i) a prediction layer that estimates human trunk and center of mass (CoM) dynamics, (ii) a planning layer that generates optimal CoM trajectories to counteract trunk movements and computes the corresponding SL control inputs, and (iii) a control layer that executes these inputs on the SL hardware. We evaluated the framework with ten participants performing forward and lateral bending tasks. The results show a clear reduction in stance instability, demonstrating the framework's effectiveness in enhancing balance. This work paves the path towards safe and versatile human-SLs interactions. [This paper has been submitted for publication to IEEE.]

</details>


### [116] [A ROS2 Benchmarking Framework for Hierarchical Control Strategies in Mobile Robots for Mediterranean Greenhouses](https://arxiv.org/abs/2602.15162)
*Fernando Cañadas-Aránega,Francisco J. Mañas-Álvarez,José L- Guzmán,José C. Moreno,José L. Blanco-Claraco*

Main category: cs.RO

TL;DR: 本文提出了一个用于评估温室环境中移动机器人控制器的综合基准测试框架，该框架集成了物理模拟器、分层控制架构、扰动场景和标准化指标，以实现对不同控制策略在真实条件下的可重复评估。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在农业工业环境中（如地中海温室）面临着不平坦地形、可变摩擦、有效载荷变化和地形坡度等挑战性条件，这些因素严重影响了控制性能和稳定性。尽管农业机器人平台日益普及，但缺乏标准化、可重现的基准测试，这阻碍了在现实操作条件下对控制策略进行公平比较和系统评估。

Method: 该研究提出了一个综合的基准测试框架，该框架集成了精确的三维环境模型、基于物理的模拟器以及包含低、中、高三层控制的分层控制架构。该框架定义了三类基准测试（从执行器级别控制到完全自主导航），并明确建模了三种干扰场景（有效载荷变化、地形类型和坡度）。为了确保客观和可重复的评估，引入了标准化的性能指标，包括平方绝对误差（SAE）、平方控制输入（SCI）和复合性能指标。研究还采用了基于重复试验的统计分析来减轻传感器噪声和环境变异性的影响，并通过基于插件的架构增强了框架，以促进用户定义控制器和规划器的无缝集成。

Result: 该基准测试框架能够对移动机器人控制器进行模块化评估，范围从执行器级别的控制到完全自主导航，并通过建模真实农业条件下的干扰，确保了评估的客观性和可重复性。其结果提供了一个强大的工具，用于在模拟环境中量化比较不同控制策略的性能。

Conclusion: 该基准测试为在真实农业工业环境中对经典、预测和基于规划的控制策略进行量化比较提供了一个鲁棒且可扩展的工具，弥合了基于仿真的分析与实际应用之间的差距。

Abstract: Mobile robots operating in agroindustrial environments, such as Mediterranean greenhouses, are subject to challenging conditions, including uneven terrain, variable friction, payload changes, and terrain slopes, all of which significantly affect control performance and stability. Despite the increasing adoption of robotic platforms in agriculture, the lack of standardized, reproducible benchmarks impedes fair comparisons and systematic evaluations of control strategies under realistic operating conditions. This paper presents a comprehensive benchmarking framework for evaluating mobile robot controllers in greenhouse environments. The proposed framework integrates an accurate three dimensional model of the environment, a physics based simulator, and a hierarchical control architecture comprising low, mid, and high level control layers. Three benchmark categories are defined to enable modular assessment, ranging from actuator level control to full autonomous navigation. Additionally, three disturbance scenarios payload variation, terrain type, and slope are explicitly modeled to replicate real world agricultural conditions. To ensure objective and reproducible evaluation, standardized performance metrics are introduced, including the Squared Absolute Error (SAE), the Squared Control Input (SCI), and composite performance indices. Statistical analysis based on repeated trials is employed to mitigate the influence of sensor noise and environmental variability. The framework is further enhanced by a plugin based architecture that facilitates seamless integration of user defined controllers and planners. The proposed benchmark provides a robust and extensible tool for the quantitative comparison of classical, predictive, and planning based control strategies in realistic conditions, bridging the gap between simulation based analysis and real world agroindustrial applications.

</details>


### [117] [DexEvolve: Evolutionary Optimization for Robust and Diverse Dexterous Grasp Synthesis](https://arxiv.org/abs/2602.15201)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种可扩展的生成-细化管道，该管道结合了分析抓取生成与高保真模拟器中的进化细化，并通过扩散模型进行蒸馏，从而生成大规模、多样化且物理可行的灵巧抓取，显著提高了抓取数量和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有的灵巧抓取预测方法严重依赖于成本高昂且多样性有限的大规模数据集。分析抓取合成虽然可以扩展数据收集，但其简化的假设往往导致物理上不可行的抓取，需要高保真模拟器进行过滤，这显著降低了抓取数量和多样性。

Method: 本文提出了一种可扩展的生成-细化管道。首先，通过分析法生成潜在次优的抓取作为初始种子集。然后，在 Isaac Sim 高保真模拟器中，使用异步、无梯度演化算法对这些抓取进行持续优化和细化，以提高稳定性并保持多样性。该细化阶段可以根据人类偏好和/或特定领域的质量指标进行指导。最后，将细化后的抓取分布提炼成一个扩散模型，以实现鲁棒的实际部署。

Result: 在 Handles 数据集和 DexGraspNet 子集上的实验表明，该方法能够为每个物体实现超过 120 个不同的稳定抓取（比未细化的分析方法提高了 1.7-6 倍），同时在独特的抓取覆盖率方面，比基于扩散的替代方案高出 46-60%。

Conclusion: 该论文提出了一种可扩展的生成-细化管道，用于合成大规模、多样化且物理可行的抓取，并强调了多样性在训练和部署中的关键作用。

Abstract: Dexterous grasping is fundamental to robotics, yet data-driven grasp prediction heavily relies on large, diverse datasets that are costly to generate and typically limited to a narrow set of gripper morphologies. Analytical grasp synthesis can be used to scale data collection, but necessary simplifying assumptions often yield physically infeasible grasps that need to be filtered in high-fidelity simulators, significantly reducing the total number of grasps and their diversity. We propose a scalable generate-and-refine pipeline for synthesizing large-scale, diverse, and physically feasible grasps. Instead of using high-fidelity simulators solely for verification and filtering, we leverage them as an optimization stage that continuously improves grasp quality without discarding precomputed candidates. More specifically, we initialize an evolutionary search with a seed set of analytically generated, potentially suboptimal grasps. We then refine these proposals directly in a high-fidelity simulator (Isaac Sim) using an asynchronous, gradient-free evolutionary algorithm, improving stability while maintaining diversity. In addition, this refinement stage can be guided toward human preferences and/or domain-specific quality metrics without requiring a differentiable objective. We further distill the refined grasp distribution into a diffusion model for robust real-world deployment, and highlight the role of diversity for both effective training and during deployment. Experiments on a newly introduced Handles dataset and a DexGraspNet subset demonstrate that our approach achieves over 120 distinct stable grasps per object (a 1.7-6x improvement over unrefined analytical methods) while outperforming diffusion-based alternatives by 46-60\% in unique grasp coverage.

</details>


### [118] [OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy](https://arxiv.org/abs/2602.15309)
*Mostafa A. Atalla,Anand S. Sekar,Remi van Starkenburg,David J. Jager,Aimée Sakes,Michaël Wiertlewski,Paul Breedveld*

Main category: cs.RO

TL;DR: OSCAR是一种受产卵器启发的自推进胶囊机器人，通过相位编码的摩擦各向异性在结肠中产生推力。它在体外猪结肠中实现了0.85 N的牵引力，平均速度达到3.08 mm/s，表现出可预测、可扩展且稳定的结肠镜检查性能。


<details>
  <summary>Details</summary>
Motivation: 传统的结肠镜检查存在轴环问题，导致患者不适。自推进胶囊机器人可以解决此问题，但在湿滑、粘弹性的结肠环境中可靠移动仍是巨大挑战。

Method: 提出了一种名为OSCAR的受产卵器启发的自推进胶囊机器人。该机器人通过弹簧加载凸轮系统驱动12个环向滑块，以协调、相移的序列机械编码受产卵器启发的运动模式。通过调整运动配置文件，使回缩阶段相对于前进阶段最大化，胶囊在界面处产生受控的摩擦各向异性，从而产生净向前推力。开发了一个结合Kelvin-Voigt公式的分析模型，以捕捉滑块和组织之间的粘弹性黏滑相互作用，并将前进和回缩阶段持续时间之间的不对称性与平均推力关联起来，将滑块反转同步性与推力稳定性关联起来。

Result: 在体外猪结肠中进行的综合力学特性实验显示，平均稳态牵引力为0.85 N，与模型高度匹配。实验证实推力产生与速度无关，并与相位不对称性呈线性关系，与理论预测一致，突显了胶囊的可预测性能和可扩展性。在运动验证实验中，OSCAR表现出稳定的性能，平均速度达到3.08 mm/s，足以与传统结肠镜检查的盲肠插管时间相匹配。

Conclusion: 通过将相位编码的摩擦各向异性与预测模型相结合，OSCAR在低法向载荷下提供可控的推力产生，从而为机器人胶囊结肠镜检查实现更安全、更强大的自推进运动。

Abstract: Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.

</details>


### [119] [Feasibility-aware Imitation Learning from Observation with Multimodal Feedback](https://arxiv.org/abs/2602.15351)
*Kei Takahashi,Hikaru Sasaki,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文提出了可行性感知观察行为克隆（FABCO），通过整合可行性估计和多模态反馈，解决了模仿学习中人类示教动作缺失机器人动作和示教动作不可行的问题，显著提升了模仿学习性能3.2倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习框架通过手持示教界面从示教者的动作中学习机器人控制策略，但面临两个局限：i) 示教数据不包含机器人动作；ii) 示教动作可能对机器人不可行。这些局限性使得策略学习变得困难。

Method: 本文提出了“可行性感知观察行为克隆”（FABCO）框架。FABCO整合了观察行为克隆（利用机器人动力学模型补充机器人动作）和可行性估计。可行性估计通过从机器人执行数据中学习到的机器人动力学模型来评估示教动作的可复现性。估计出的可行性用于多模态反馈（通过视觉和触觉提供给示教者，以促进可行的示教动作）和可行性感知策略学习（减少不可行示教动作的影响，从而学习机器人能稳定执行的策略）。

Result: 在两项任务中对15名参与者进行的实验证实，与没有可行性反馈的情况相比，FABCO将模仿学习性能提高了3.2倍以上。

Conclusion: FABCO通过结合可行性估计、多模态反馈和可行性感知策略学习，有效解决了从人类示教中进行模仿学习的挑战，从而显著提高了机器人模仿学习的性能，并获得了更稳定、可执行的策略。

Abstract: Imitation learning frameworks that learn robot control policies from demonstrators' motions via hand-mounted demonstration interfaces have attracted increasing attention. However, due to differences in physical characteristics between demonstrators and robots, this approach faces two limitations: i) the demonstration data do not include robot actions, and ii) the demonstrated motions may be infeasible for robots. These limitations make policy learning difficult. To address them, we propose Feasibility-Aware Behavior Cloning from Observation (FABCO). FABCO integrates behavior cloning from observation, which complements robot actions using robot dynamics models, with feasibility estimation. In feasibility estimation, the demonstrated motions are evaluated using a robot-dynamics model, learned from the robot's execution data, to assess reproducibility under the robot's dynamics. The estimated feasibility is used for multimodal feedback and feasibility-aware policy learning to improve the demonstrator's motions and learn robust policies. Multimodal feedback provides feasibility through the demonstrator's visual and haptic senses to promote feasible demonstrated motions. Feasibility-aware policy learning reduces the influence of demonstrated motions that are infeasible for robots, enabling the learning of policies that robots can execute stably. We conducted experiments with 15 participants on two tasks and confirmed that FABCO improves imitation learning performance by more than 3.2 times compared to the case without feasibility feedback.

</details>


### [120] [A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking](https://arxiv.org/abs/2602.15354)
*Jose Luis Peralta-Cabezas,Miguel Torres-Torriti,Marcelo Guarini-Hermann*

Main category: cs.RO

TL;DR: 本文比较了应用于多机器人跟踪问题的不同估计和预测技术的性能，评估标准包括估计或预测误差、计算量和对非高斯噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 比较不同估计和预测技术在多机器人跟踪问题中的性能。

Method: 比较了卡尔曼滤波器及其变体（如扩展卡尔曼滤波器和无迹卡尔曼滤波器）以及基于序贯蒙特卡洛采样方法的新技术（如粒子滤波器和高斯混合Sigma点粒子滤波器）。评估性能的标准是估计或预测误差的大小、计算量以及每种方法对非高斯噪声的鲁棒性。

Result: 摘要中未明确给出具体结果，但指出将根据估计/预测误差、计算量和对非高斯噪声的鲁棒性进行评估。

Conclusion: 摘要中未明确给出结论，但研究旨在通过比较多种估计和预测技术，为多机器人跟踪问题提供性能评估。

Abstract: This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.

</details>


### [121] [Fluoroscopy-Constrained Magnetic Robot Control via Zernike-Based Field Modeling and Nonlinear MPC](https://arxiv.org/abs/2602.15357)
*Xinhao Chen,Hongkun Yao,Anuruddha Bhattacharjee,Suraj Raval,Lamar O. Mair,Yancy Diaz-Mercado,Axel Krieger*

Main category: cs.RO

TL;DR: 该研究提出了一个针对磁性外科机器人的控制框架，通过结合NMPC、Zernike多项式磁场模型和卡尔曼滤波器，解决了荧光透视成像中低帧率和噪声反馈带来的控制挑战。实验证明，该方法在模拟临床条件下仍能保持高精度，并在脊柱模型中成功实现了1.18毫米RMS误差的药物递送。


<details>
  <summary>Details</summary>
Motivation: 磁性驱动外科机器人虽然能减少组织创伤并提高手术精度，但在临床应用中受到限制，因为荧光透视成像提供的低帧率和嘈杂姿态反馈给控制带来了挑战。

Method: 本文提出了一种控制框架，结合了直接输出线圈电流的非线性模型预测控制（NMPC）、基于Zernike多项式的可微分磁场模型以及用于机器人状态估计的卡尔曼滤波器。通过在3D打印流体工作空间和模拟硬膜外药物递送的脊柱模型中，使用两个磁性机器人进行实验验证。

Result: 实验结果表明，该控制方法在反馈下采样至3 Hz并加入高斯噪声（标准差2 mm，模拟临床荧光透视）的情况下，仍能保持高精度。在脊柱模型实验中，药物递送轨迹的均方根（RMS）位置误差为1.18 mm，同时保持了与关键解剖边界的安全距离。

Conclusion: 该论文提出的控制框架在模拟临床荧光透视的低帧率和噪声反馈条件下，实现了对磁性外科机器人的精确稳定控制，并在脊柱模型实验中成功执行了药物递送轨迹，证明了其在实际医疗应用中的潜力。

Abstract: Magnetic actuation enables surgical robots to navigate complex anatomical pathways while reducing tissue trauma and improving surgical precision. However, clinical deployment is limited by the challenges of controlling such systems under fluoroscopic imaging, which provides low frame rate and noisy pose feedback. This paper presents a control framework that remains accurate and stable under such conditions by combining a nonlinear model predictive control (NMPC) framework that directly outputs coil currents, an analytically differentiable magnetic field model based on Zernike polynomials, and a Kalman filter to estimate the robot state. Experimental validation is conducted with two magnetic robots in a 3D-printed fluid workspace and a spine phantom replicating drug delivery in the epidural space. Results show the proposed control method remains highly accurate when feedback is downsampled to 3 Hz with added Gaussian noise (sigma = 2 mm), mimicking clinical fluoroscopy. In the spine phantom experiments, the proposed method successfully executed a drug delivery trajectory with a root mean square (RMS) position error of 1.18 mm while maintaining safe clearance from critical anatomical boundaries.

</details>


### [122] [ActionCodec: What Makes for Good Action Tokenizers](https://arxiv.org/abs/2602.15397)
*Zibin Dong,Yicheng Liu,Shiduo Zhang,Baijun Ye,Yifu Yuan,Fei Ni,Jingjing Gong,Xipeng Qiu,Hang Zhao,Yinchuan Li,Jianye Hao*

Main category: cs.RO

TL;DR: 该论文提出了一套针对VLA模型优化的高性能动作分词器设计原则，并基于此引入了ActionCodec，显著提升了训练效率和VLA性能，在LIBERO基准测试上实现了97.4%的成功率，达到新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的动作分词器设计主要关注重建保真度，未能解决其对VLA优化的直接影响，导致“何为好的动作分词器”这一基本问题悬而未决。

Method: 通过建立基于信息论洞察的设计原则，包括最大化时间令牌重叠、最小化词汇冗余、增强多模态互信息和令牌独立性。在此指导下，引入了高性能动作分词器ActionCodec。

Result: ActionCodec显著提高了训练效率和VLA性能。在LIBERO上，一个经ActionCodec微调的SmolVLM2-2.2B在没有机器人预训练的情况下实现了95.5%的成功率，经过高级架构增强后达到97.4%，代表了无机器人预训练VLA模型的新SOTA。

Conclusion: 论文建立的设计原则和发布的模型为社区开发更有效的动作分词器提供了明确的路线图。

Abstract: Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.

</details>


### [123] [Hybrid F' and ROS2 Architecture for Vision-Based Autonomous Flight: Design and Experimental Validation](https://arxiv.org/abs/2602.15398)
*Abdelrahman Metwally,Monijesu James,Aleksey Fedoseev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Andrey Somov*

Main category: cs.RO

TL;DR: 该论文提出了一种混合飞行软件架构，通过Protocol Buffers桥接将NASA的F'飞行软件框架与ROS2中间件相结合，以平衡确定性实时控制和先进感知能力，并在一项四旋翼飞行测试中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 自主航空航天系统需要一种能够平衡确定性实时控制与先进感知能力的架构。

Method: 通过Protocol Buffers桥接，将NASA的F'飞行软件框架与ROS2中间件集成。通过32.25分钟的室内四旋翼飞行测试，使用基于视觉的导航来评估该架构。

Result: 视觉系统实现了87.19 Hz的位置估计，数据连续性达99.90%，平均延迟为11.47 ms。所有15个地面命令均以100%的成功率执行。系统资源利用率保持在低水平（CPU 15.19%，RAM 1,244 MB），无陈旧遥测消息。

Conclusion: 结果验证了将认证级确定性与灵活自主性相结合的混合飞行软件架构在自主飞行器上的可行性。

Abstract: Autonomous aerospace systems require architectures that balance deterministic real-time control with advanced perception capabilities. This paper presents an integrated system combining NASA's F' flight software framework with ROS2 middleware via Protocol Buffers bridging. We evaluate the architecture through a 32.25-minute indoor quadrotor flight test using vision-based navigation. The vision system achieved 87.19 Hz position estimation with 99.90\% data continuity and 11.47 ms mean latency, validating real-time performance requirements. All 15 ground commands executed successfully with 100 % success rate, demonstrating robust F'--PX4 integration. System resource utilization remained low (15.19 % CPU, 1,244 MB RAM) with zero stale telemetry messages, confirming efficient operation on embedded platforms. Results validate the feasibility of hybrid flight-software architectures combining certification-grade determinism with flexible autonomy for autonomous aerial vehicles.

</details>


### [124] [One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](https://arxiv.org/abs/2602.15400)
*Zerui Li,Hongpei Zheng,Fangguo Zhao,Aidan Chan,Jian Zhou,Sihao Lin,Shijie Li,Qi Wu*

Main category: cs.RO

TL;DR: 本文提出了一种解耦设计，将空间感知与语义规划分离，并引入交互式度量世界表示，以提升基于多模态大语言模型（MLLMs）的导航智能体性能，实现了零样本SOTA和强大的模拟到真实世界迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有的以多模态大语言模型（MLLMs）为中心的导航智能体设计，其紧密耦合的结构严重限制了系统性能。传统的导航方法依赖于预定义、过于简化的文本地图。

Method: 本文提出了一种解耦设计，将低级空间状态估计与高级语义规划分离。引入了一个交互式度量世界表示，该表示维护丰富且一致的信息，允许多模态大语言模型（MLLMs）在其上进行交互和推理以做出决策。此外，引入了反事实推理来进一步激发MLLMs的能力，同时度量世界表示确保了所生成动作的物理有效性。

Result: 在R2R-CE基准测试中，成功率（SR）达到48.8%，在RxR-CE基准测试中达到42.2%，建立了新的零样本最新技术水平。证明了零样本模拟到真实世界的迁移能力，涵盖了多种实体，包括TurtleBot 4轮式机器人和定制的空中无人机。

Conclusion: 该解耦框架为具身视觉与语言导航提供了一个鲁棒且领域无关的接口。

Abstract: A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\% Success Rate (SR) in R2R-CE and 42.2\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.

</details>


### [125] [Lyapunov-Based $\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot](https://arxiv.org/abs/2602.15424)
*Branimir Ćaran,Vladimir Milić,Bojan Jerbić*

Main category: cs.RO

TL;DR: 本文提出了一种基于Lyapunov的类PI控制器综合方法，用于独立驱动和转向的四轮移动机器人的$\mathcal{L}_2$稳定运动控制，并通过实验证明了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为独立驱动和转向的四轮移动机器人实现$\mathcal{L}_2$稳定的运动控制，并提供适用于实时操作的稳定性和性能保证，同时保持控制器形式简单以便于嵌入式实现。

Method: 该方法采用基于Lyapunov的类PI控制器综合设计，利用明确且经过结构验证的模型。构建了一个Lyapunov函数以推导出明确的界限和$\mathcal{L}_2$稳定性结果，支持反馈综合以减少配置相关效应。

Result: 所得到的控制律是类PI形式，适用于标准嵌入式实现，并保持了严格的稳定性。其有效性和鲁棒性在真实的四轮移动机器人平台上通过实验得到了验证。

Conclusion: 该论文成功开发并验证了一种基于Lyapunov的类PI控制器，用于四轮移动机器人的$\mathcal{L}_2$稳定运动控制，该控制器具有严格的稳定性并适用于实时应用。

Abstract: In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.

</details>


### [126] [VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing](https://arxiv.org/abs/2602.15549)
*Guoqin Tang,Qingxuan Jia,Gang Chen,Tong Li,Zeyuan Huang,Zihang Lv,Ning Ji*

Main category: cs.RO

TL;DR: 本文提出VLM-DEWM，一个认知架构，通过动态外部世界模型（DEWM）将VLM推理与世界状态管理解耦，并通过可外部化推理轨迹（ERT）和故障差异分析，显著提高了动态制造环境中VLM的状态追踪准确性和故障恢复成功率，同时降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在高层规划方面在智能制造中展现出潜力，但其在动态工作单元中的部署面临两大挑战：1）无状态操作，无法持续追踪视野外的状态，导致世界状态漂移；2）不透明推理，难以诊断故障，导致代价高昂的盲目重试。

Method: 本文提出了VLM-DEWM认知架构，通过持久化、可查询的动态外部世界模型（DEWM）将VLM推理与世界状态管理解耦。每个VLM决策都被组织成一个可外部化推理轨迹（ERT），包含动作提议、世界信念和因果假设，并在执行前对照DEWM进行验证。当发生故障时，通过比较预测状态和观察状态之间的差异进行分析，从而实现有针对性的恢复而非全局重新规划。

Result: 在多工位装配、大规模设施探索以及真实机器人诱发故障下的恢复实验中，VLM-DEWM将状态追踪准确率从56%提高到93%，将恢复成功率从低于5%提升至95%，并通过结构化内存显著降低了计算开销。

Conclusion: VLM-DEWM为动态制造环境中长周期机器人操作提供了一种可验证且具有弹性的解决方案。

Abstract: Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.

</details>


### [127] [Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions](https://arxiv.org/abs/2602.15567)
*Jieting Long,Dechuan Liu,Weidong Cai,Ian Manchester,Weiming Zhi*

Main category: cs.RO

TL;DR: 提出了一种名为CASF的框架，通过在执行期间根据约束条件调整学习到的速度场，使得流策略能够适应安全和任务特定约束。


<details>
  <summary>Details</summary>
Motivation: 机器人运动分布通常具有多模态性，需要灵活的生成模型。现有的流策略（Streaming Flow Policies, SFPs）在生成机器人轨迹方面表现强大，但缺乏在训练后调整轨迹以强制执行安全和任务特定约束的机制。

Method: CASF通过引入约束相关的度量来增强流策略，这些度量在执行期间重塑学习到的速度场。它将每个约束（在机器人工作空间或配置空间中定义）建模为可微分距离函数，并将其转换为局部度量，再拉回到机器人的控制空间。在远离受限区域时，度量为恒等式；在约束边界附近，它平滑地衰减或重定向运动，从而变形底层流以保持安全。

Result: CASF能够在实时调整轨迹的同时，确保机器人动作遵守关节限制、避免碰撞并保持在可行工作空间内，同时保留了流策略的多模态和反应特性。在模拟和真实世界的操纵任务中，CASF生成了平滑、可行、动态一致且满足约束的轨迹，性能优于标准的后验投影基线。

Conclusion: CASF成功地为流策略引入了实时约束适应机制，使其在保持原有优势的同时，能够生成安全且符合任务要求的机器人轨迹。

Abstract: Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajectories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot's workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot's control space. Far from restricted regions, the resulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines.

</details>


### [128] [Grip as Needed, Glide on Demand: Ultrasonic Lubrication for Robotic Locomotion](https://arxiv.org/abs/2602.15608)
*Mostafa A. Atalla,Daan van Bemmel,Jack Cummings,Paul Breedveld,Michaël Wiertlewski,Aimée Sakes*

Main category: cs.RO

TL;DR: 超声波润滑可以主动控制机器人运动中的摩擦力，使其在各种表面上高效移动。


<details>
  <summary>Details</summary>
Motivation: 摩擦力是陆地运动的关键介质，但机器人系统中几乎总是将其视为由表面材料和条件决定的被动特性。

Method: 通过超声波频率激发共振结构，使接触界面在“抓取”和“滑动”状态之间动态切换，从而实现运动。开发了两种摩擦控制模块（圆柱形和平板形），并将其集成到仿生系统中（模仿尺蠖和黄蜂产卵器运动）。

Result: 两种系统都实现了双向运动，运动效率接近完美，超过90%。摩擦特性实验进一步证明，在各种表面（包括刚性、软性、颗粒状和生物组织界面）、干燥和潮湿条件下以及不同粗糙度的表面上，摩擦力都显著降低。

Conclusion: 超声波润滑是一种可行的机器人运动主动摩擦控制机制，有可能降低设计复杂性并提高机器人运动系统的效率。

Abstract: Friction is the essential mediator of terrestrial locomotion, yet in robotic systems it is almost always treated as a passive property fixed by surface materials and conditions. Here, we introduce ultrasonic lubrication as a method to actively control friction in robotic locomotion. By exciting resonant structures at ultrasonic frequencies, contact interfaces can dynamically switch between "grip" and "slip" states, enabling locomotion. We developed two friction control modules, a cylindrical design for lumen-like environments and a flat-plate design for external surfaces, and integrated them into bio-inspired systems modeled after inchworm and wasp ovipositor locomotion. Both systems achieved bidirectional locomotion with nearly perfect locomotion efficiencies that exceeded 90%. Friction characterization experiments further demonstrated substantial friction reduction across various surfaces, including rigid, soft, granular, and biological tissue interfaces, under dry and wet conditions, and on surfaces with different levels of roughness, confirming the broad applicability of ultrasonic lubrication to locomotion tasks. These findings establish ultrasonic lubrication as a viable active friction control mechanism for robotic locomotion, with the potential to reduce design complexity and improve efficiency of robotic locomotion systems.

</details>


### [129] [SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms](https://arxiv.org/abs/2602.15633)
*Haichao Liu,Yufeng Hu,Shuang Wang,Kangjun Guo,Jun Ma,Jinni Zhou*

Main category: cs.RO

TL;DR: SpecFuse是一个新的谱-时融合预测控制框架，它结合了频域波浪分解和时域递归状态估计，实现了无人机在振荡海洋平台上高精度自主着陆。该框架解决了波浪引起的振荡、风扰动和预测相位滞后等挑战，并在模拟和实际测试中表现出卓越的预测精度、着陆偏差和成功率，优于现有方法44%-48%。


<details>
  <summary>Details</summary>
Motivation: 无人机在振荡海洋平台上自主着陆受到波浪引起的多频振荡、风扰动和运动预测中的预测相位滞后的严重限制。现有方法要么将平台运动视为一般的随机过程，要么缺乏对波浪谱特征的明确建模，导致在动态海洋条件下性能不佳。

Method: 提出了一种新颖的谱-时融合预测控制框架SpecFuse。该框架将频域波浪分解与时域递归状态估计相结合，用于USV高精度六自由度运动预测。它明确建模了主导波浪谐波以减轻相位滞后，并通过IMU数据实时细化预测，无需复杂的校准。此外，设计了一个分层控制架构，其中包含一个基于采样的HPO-RRT*算法，用于在非凸约束下进行动态轨迹规划，以及一个学习增强的预测控制器，该控制器融合了数据驱动的扰动补偿和基于优化的执行。

Result: 通过2000次模拟和8次湖泊实验，该方法实现了3.2厘米的预测误差、4.46厘米的着陆偏差、98.7%（模拟）/87.5%（实际）的成功率，以及在嵌入式硬件上82毫秒的延迟。在准确性方面，它比现有最先进方法高出44%-48%。

Conclusion: 该框架对波浪-风耦合扰动的鲁棒性支持了搜索救援和环境监测等关键海上任务。所有代码、实验配置和数据集将开源以促进可重复性。

Abstract: Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.

</details>


### [130] [Spatially-Aware Adaptive Trajectory Optimization with Controller-Guided Feedback for Autonomous Racing](https://arxiv.org/abs/2602.15642)
*Alexander Wachter,Alexander Willert,Marc-Philip Ecker,Christian Hartl-Nesic*

Main category: cs.RO

TL;DR: 本研究提出了一种闭环框架，通过结合NURBS轨迹、CMA-ES优化和卡尔曼启发的空间更新，利用跟踪误差自适应优化赛车线路，在仿真和真实硬件上显著缩短了单圈时间，并展现出对抓地力变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将跟踪误差视为瞬态干扰，而本研究旨在开发一种新方法，将跟踪误差利用为局部赛道特性的信息信号，以提高轨迹优化在不同赛道和车辆行为下的性能。

Method: 该研究提出了一种结合NURBS轨迹表示、CMA-ES全局轨迹优化和控制器引导空间反馈的闭环自动赛车线路优化框架。它利用跟踪误差作为局部赛道特性的信息信号，通过卡尔曼滤波器启发的空间更新，构建自适应的、基于加速度的约束图，从而迭代优化轨迹，以在空间变化的赛道和车辆行为下实现接近最佳的性能。

Result: 在仿真中，该方法实现了17.38%的单圈时间缩减；在真实硬件上，对不同轮胎化合物（从高摩擦到低摩擦）进行测试，单圈时间提高了7.60%，且无需显式参数化摩擦力。

Conclusion: 该方法在实际场景中对变化的抓地力条件表现出鲁棒性。

Abstract: We present a closed-loop framework for autonomous raceline optimization that combines NURBS-based trajectory representation, CMA-ES global trajectory optimization, and controller-guided spatial feedback. Instead of treating tracking errors as transient disturbances, our method exploits them as informative signals of local track characteristics via a Kalman-inspired spatial update. This enables the construction of an adaptive, acceleration-based constraint map that iteratively refines trajectories toward near-optimal performance under spatially varying track and vehicle behavior. In simulation, our approach achieves a 17.38% lap time reduction compared to a controller parametrized with maximum static acceleration. On real hardware, tested with different tire compounds ranging from high to low friction, we obtain a 7.60% lap time improvement without explicitly parametrizing friction. This demonstrates robustness to changing grip conditions in real-world scenarios.

</details>


### [131] [MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction](https://arxiv.org/abs/2602.15733)
*Qiang Zhang,Jiahao Ma,Peiran Liu,Shuai Shi,Zeran Su,Zifan Wang,Jingkai Sun,Wei Cui,Jialin Yu,Gang Han,Wen Zhao,Pihai Sun,Kangning Yin,Jiaxu Wang,Jiahang Cao,Lingfeng Zhang,Hao Cheng,Xiaoshuai Hao,Yiding Ji,Junwei Liang,Jian Tang,Renjing Xu,Yijie Guo*

Main category: cs.RO

TL;DR: MeshMimic是一种创新框架，通过3D场景重建和具身智能，使人形机器人能直接从视频中学习“运动-地形”交互，克服了传统MoCap数据的局限性，实现了在复杂地形上稳定动态的机器人行为，并证明了低成本单目传感器管道训练复杂物理交互的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有人形机器人运动控制方法面临挑战：手动运动设计因高维度和复杂动力学而不可行，过度依赖昂贵且缺乏环境几何背景的运动捕捉（MoCap）数据。这导致现有运动合成框架中运动与场景脱节，在地形感知任务中产生物理不一致性，如接触滑动或网格穿透。

Method: MeshMimic框架通过结合3D场景重建和具身智能，使人形机器人能够直接从视频中学习耦合的“运动-地形”交互。该方法利用先进的3D视觉模型精确分割和重建人类轨迹以及地形和物体的底层3D几何结构。它引入了一种基于运动学一致性的优化算法，从有噪声的视觉重建中提取高质量运动数据，并采用了一种接触不变重定向方法将人-环境交互特征转移到人形智能体。

Result: MeshMimic在多样化和具有挑战性的地形上，实现了鲁棒、高动态性能。

Conclusion: MeshMimic通过使用消费级单目传感器，提供了一种低成本的训练复杂物理交互的方法，为人形机器人在非结构化环境中的自主进化提供了可扩展的路径。

Abstract: Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled "motion-terrain" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.

</details>


### [132] [Robot-Assisted Social Dining as a White Glove Service](https://arxiv.org/abs/2602.15767)
*Atharva S Kashyap,Ugne Aleksandra Morkute,Patricia Alves-Oliveira*

Main category: cs.RO

TL;DR: 该研究探讨了机器人辅助进食系统在户外社交用餐场景（如餐厅）中的应用，旨在解决现有系统仅限于实验室或家庭环境的问题，并通过参与式设计提出了一系列以用户为中心的设计原则。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人辅助进食系统仅在实验室或家庭环境中进行过测试，户外社交用餐场景（如餐厅）在很大程度上尚未被探索。在这种环境中设计机器人会带来独特的挑战，例如机器人需要考虑并响应动态且无人监督的用餐环境。

Method: 通过与残疾人进行推测性参与式设计，并辅以半结构化访谈和定制的基于人工智能的视觉故事板工具。

Result: 我们揭示了户外社交用餐的理想场景。主要见解表明，此类系统应体现“白手套服务”的原则，即机器人应：(1) 支持多模态输入和不显眼的输出；(2) 具有情境敏感的社交行为并优先考虑用户；(3) 具有超出喂食的扩展角色；(4) 适应餐桌上的其他人际关系。

Conclusion: 这项工作对机器人辅助进食在户外和团体环境中的应用具有重要意义。

Abstract: Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.

</details>


### [133] [FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy](https://arxiv.org/abs/2602.15813)
*Haochen Zhang,Nirav Savaliya,Faizan Siddiqui,Enna Sachdeva*

Main category: cs.RO

TL;DR: FAST-EQA是一个问答驱动的具身问答框架，通过识别目标、引导导航和CoT推理，实现了高效的有限记忆探索和SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 具身问答（EQA）面临核心挑战：如何在有限的可观察性下，将物理搜索限制在与问题相关的子空间，同时维持紧凑、可操作的观察记忆，并确保探索过程中推理速度快，以适应实际部署。

Method: 论文引入了FAST-EQA框架，其包含三个主要组成部分：(i) 识别可能的视觉目标，(ii) 评估全局感兴趣区域以指导导航，(iii) 利用视觉记忆上的思维链（CoT）推理自信地回答问题。FAST-EQA通过维护一个存储固定容量区域-目标假设的有界场景记忆，在线更新以处理单目标和多目标问题，避免记忆无限增长。此外，为了高效扩展覆盖范围，一个全局探索策略将狭窄的开口和门视为高价值的前沿，以最小的计算量补充局部目标寻找。

Result: FAST-EQA的组件协同工作，使智能体的注意力更集中，改进了场景覆盖范围，提高了答案的可靠性，同时运行速度显著快于现有方法。在HMEQA和EXPRESS-Bench数据集上，FAST-EQA取得了最先进的性能，并在OpenEQA和MT-HM3D上表现出竞争力。

Conclusion: FAST-EQA通过其创新的问答驱动框架、高效的记忆管理和探索策略，有效解决了具身问答中的关键挑战，实现了性能和速度的显著提升，为该领域树立了新的基准。

Abstract: Embodied Question Answering (EQA) combines visual scene understanding, goal-directed exploration, spatial and temporal reasoning under partial observability. A central challenge is to confine physical search to question-relevant subspaces while maintaining a compact, actionable memory of observations. Furthermore, for real-world deployment, fast inference time during exploration is crucial. We introduce FAST-EQA, a question-conditioned framework that (i) identifies likely visual targets, (ii) scores global regions of interest to guide navigation, and (iii) employs Chain-of-Thought (CoT) reasoning over visual memory to answer confidently. FAST-EQA maintains a bounded scene memory that stores a fixed-capacity set of region-target hypotheses and updates them online, enabling robust handling of both single and multi-target questions without unbounded growth. To expand coverage efficiently, a global exploration policy treats narrow openings and doors as high-value frontiers, complementing local target seeking with minimal computation. Together, these components focus the agent's attention, improve scene coverage, and improve answer reliability while running substantially faster than prior approaches. On HMEQA and EXPRESS-Bench, FAST-EQA achieves state-of-the-art performance, while performing competitively on OpenEQA and MT-HM3D.

</details>


### [134] [Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828)
*Yuxuan Kuang,Sungjae Park,Katerina Fragkiadaki,Shubham Tulsiani*

Main category: cs.RO

TL;DR: Dex4D是一个框架，通过在模拟中学习任务无关的灵巧技能，实现零样本迁移到真实的通用灵巧操作任务，避免了昂贵的数据收集和复杂的任务特定设计。


<details>
  <summary>Details</summary>
Motivation: 在灵巧操作中，学习能够完成各种日常任务的通用策略仍然是一个开放的挑战。具体来说，通过真实世界的远程操作收集大规模操作数据既昂贵又难以扩展。虽然在模拟中学习提供了一个可行的替代方案，但设计多个任务特定的环境和奖励进行训练同样具有挑战性。

Method: 我们提出了Dex4D框架，它利用模拟学习任务无关的灵巧技能，这些技能可以灵活重组以执行多样化的真实世界操作任务。具体来说，Dex4D学习一种领域无关的3D点轨迹条件策略，能够将任何物体操纵到任何期望的姿态。我们通过在模拟中对数千个具有不同姿态配置的物体进行训练，涵盖了广泛的机器人-物体交互空间，这些交互可以在测试时进行组合。在部署时，该策略可以零样本迁移到真实世界的任务中，无需微调，只需通过从生成的视频中提取的期望的以物体为中心的点轨迹进行提示。在执行过程中，Dex4D使用在线点跟踪进行闭环感知和控制。

Result: 在模拟和真实机器人上的大量实验表明，我们的方法能够实现多样化灵巧操作任务的零样本部署，并比现有基线方法取得持续改进。此外，我们展示了对新颖物体、场景布局、背景和轨迹的强大泛化能力。

Conclusion: Dex4D框架提供了一种鲁棒且可扩展的方法，用于学习通用的灵巧操作技能，这些技能可以零样本泛化到现实世界的任务中，强调了所提方法的鲁棒性和可扩展性。

Abstract: Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [135] [Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning](https://arxiv.org/abs/2602.15817)
*Oswin So,Eric Yang Yu,Songyuan Zhang,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: 该论文提出了可行性引导探索（FGE）方法，通过同时识别可行初始条件并学习安全策略来解决强化学习中的可达性问题，其覆盖率比现有最佳方法高出50%以上。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（RL）在处理高维控制任务时表现出色，但将其应用于可达性问题时存在根本性不匹配：RL优化的是用户指定分布的预期回报，而可达性旨在最大化系统无限期保持安全的初始状态集。这种不匹配可能导致策略在低概率但仍在安全集内的状态上表现不佳。将问题构建为对初始条件集的鲁棒优化是一种自然的选择，但其可行性是先验未知的。

Method: 提出了一种名为可行性引导探索（FGE）的方法。FGE同时识别存在安全策略的可行初始条件子集，并学习一个策略来解决在此初始条件集上的可达性问题。

Result: 实验结果表明，在MuJoCo模拟器和Kinetix模拟器（带有像素观测）中，对于具有挑战性的初始条件，FGE学习到的策略比现有最佳方法的覆盖率高出50%以上。

Conclusion: FGE通过识别可行初始条件并学习鲁棒的安全策略，有效地解决了强化学习与可达性之间的不匹配问题，显著提高了覆盖率。

Abstract: Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.

</details>


### [136] [PolyNODE: Variable-dimension Neural ODEs on M-polyfolds](https://arxiv.org/abs/2602.15128)
*Per Åhag,Alexander Friedrich,Fredrik Ohlsson,Viktor Vigren Näslund*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at .

</details>


### [137] [MAVRL: Learning Reward Functions from Multiple Feedback Types with Amortized Variational Inference](https://arxiv.org/abs/2602.15206)
*Raphaël Baur,Yannick Metz,Maria Gkoulta,Mennatallah El-Assady,Giorgia Ramponi,Thomas Kleine Buening*

Main category: cs.LG

TL;DR: 提出了一种基于贝叶斯推断的可扩展摊销变分推断方法，用于从异构反馈类型（如演示、比较、评分）中联合学习奖励函数，无需手动加权，并在离散和连续控制任务中表现优异，提升了策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励学习方法通常依赖单一反馈类型或手动加权组合多种反馈。目前尚不清楚如何有效地从演示、比较、评分和停止等本质上不同的异构反馈类型中联合学习奖励函数。

Method: 将从多种反馈类型学习奖励函数的问题建模为对共享潜在奖励函数的贝叶斯推断，其中每种反馈类型通过显式似然函数贡献信息。引入了一种可扩展的摊销变分推断方法，该方法学习一个共享的奖励编码器和特定于反馈的似然解码器，并通过优化单个证据下界（ELBO）进行训练。该方法避免了将反馈简化为共同中间表示，并消除了手动平衡损失的需要。

Result: 在离散和连续控制基准测试中，联合推断的奖励后验优于单一类型基线，能够利用跨反馈类型的互补信息，并生成对环境扰动更鲁棒的策略。推断出的奖励不确定性还提供了可解释的信号，用于分析模型置信度和跨反馈类型的一致性。

Conclusion: 该方法成功地从异构反馈中联合学习奖励函数，无需手动加权，其学习到的奖励函数不仅表现出更高的性能和鲁棒性，而且其不确定性信息也提供了有价值的模型分析能力。

Abstract: Reward learning typically relies on a single feedback type or combines multiple feedback types using manually weighted loss terms. Currently, it remains unclear how to jointly learn reward functions from heterogeneous feedback types such as demonstrations, comparisons, ratings, and stops that provide qualitatively different signals. We address this challenge by formulating reward learning from multiple feedback types as Bayesian inference over a shared latent reward function, where each feedback type contributes information through an explicit likelihood. We introduce a scalable amortized variational inference approach that learns a shared reward encoder and feedback-specific likelihood decoders and is trained by optimizing a single evidence lower bound. Our approach avoids reducing feedback to a common intermediate representation and eliminates the need for manual loss balancing. Across discrete and continuous-control benchmarks, we show that jointly inferred reward posteriors outperform single-type baselines, exploit complementary information across feedback types, and yield policies that are more robust to environment perturbations. The inferred reward uncertainty further provides interpretable signals for analyzing model confidence and consistency across feedback types.

</details>


### [138] [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)
*Yannic Neuhaus,Nicolas Flammarion,Matthias Hein,Francesco Croce*

Main category: cs.LG

TL;DR: 本研究通过一个网格导航任务评估了大语言模型和视觉语言模型中链式思考(CoT)推理的泛化能力。结果显示CoT提高了分布内泛化，但分布外泛化有限，不过结合多种文本格式的推理轨迹能实现最佳的分布外泛化，并且纯文本模型优于图像模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型和大型视觉语言模型中整合推理能力近期显著提升了其性能。然而，推理模型的泛化能力仍然定义模糊且理解不足。本工作旨在严格检验链式思考(CoT)方法在简单规划任务上的泛化能力。

Method: 本研究提出了一个评估框架，用于严格检验链式思考(CoT)方法在简单规划任务上的泛化能力。具体而言，采用一个基于网格的导航任务，模型需根据地图输出从起点到终点并避开障碍的移动序列。利用任务和数据的多功能性，通过不同输入表示（视觉和文本）和CoT推理策略对模型变体进行微调，并在分布内(ID)和分布外(OOD)测试条件下进行系统评估。

Result: 实验结果表明，尽管CoT推理提高了所有表示形式的分布内(ID)泛化能力，但当控制与ID数据的平凡匹配时，在大多数情况下，分布外(OOD)泛化能力（例如，对于更大的地图）仍然非常有限。令人惊讶的是，研究发现结合多种文本格式的推理轨迹产生了最佳（且非平凡）的OOD泛化。此外，纯文本模型始终优于利用基于图像输入的模型。

Conclusion: 链式思考(CoT)推理提高了分布内(ID)泛化能力，但在大多数情况下，其分布外(OOD)泛化能力（例如，在更大的地图上）仍然非常有限。令人惊讶的是，结合多种文本格式的推理轨迹产生了最佳（且非平凡）的OOD泛化。纯文本模型始终优于使用基于图像输入的模型。

Abstract: Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigorously examine how well chain-of-thought (CoT) approaches generalize on a simple planning task. Specifically, we consider a grid-based navigation task in which a model is provided with a map and must output a sequence of moves that guides a player from a start position to a goal while avoiding obstacles. The versatility of the task and its data allows us to fine-tune model variants using different input representations (visual and textual) and CoT reasoning strategies, and systematically evaluate them under both in-distribution (ID) and out-of-distribution (OOD) test conditions. Our experiments show that, while CoT reasoning improves in-distribution generalization across all representations, out-of-distribution generalization (e.g., to larger maps) remains very limited in most cases when controlling for trivial matches with the ID data. Surprisingly, we find that reasoning traces which combine multiple text formats yield the best (and non-trivial) OOD generalization. Finally, purely text-based models consistently outperform those utilizing image-based inputs, including a recently proposed approach relying on latent space reasoning.

</details>


### [139] [Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design](https://arxiv.org/abs/2602.15648)
*Jens U. Kreber,Christian Weißenfels,Joerg Stueckler*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的新型逆向设计方法，通过将复杂离散设计空间松弛为连续网格并结合引导扩散，解决了梯度优化难题。该方法在复合材料设计中表现出色，能生成多样化且误差小的设计，并可同时优化材料密度。


<details>
  <summary>Details</summary>
Motivation: 逆向设计问题在工程和材料科学中很常见，但面临挑战。正向模拟（如FEM）本身就是一个优化问题。在许多情况下，多个设计参数可能导致相同或相似的输出值，需要多模态概率方法以获得多样化解决方案。逆向设计的主要困难源于设计空间的结构，因为离散参数或额外约束阻碍了直接使用基于梯度的优化方法。

Method: 提出了一种基于扩散模型的新型逆向设计方法。该方法将原始设计空间松弛为连续网格表示，并通过前向模拟中的隐式微分计算梯度。在松弛参数空间上训练一个扩散模型作为合理松弛设计的先验。在推理时，通过可微分模拟将目标函数传播的梯度用于引导扩散采样参数。通过反向投影将设计样本恢复到原始参数空间。该方法应用于复合材料设计问题，其中正向过程建模为线性FEM问题。

Result: 该方法能够在2D和3D设置中，针对中到高目标体积模量，在1%相对误差范围内提出多样化的设计。同时，通过使用多目标损失函数，可以最小化生成样本的材料密度。

Conclusion: 本研究提出的基于扩散模型的逆向设计方法能有效解决具有复杂设计空间和离散参数的逆向设计问题，为材料设计提供多样化且优化的解决方案。

Abstract: Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.

</details>


### [140] [Automatically Finding Reward Model Biases](https://arxiv.org/abs/2602.15222)
*Atticus Wang,Iván Arcuschin,Arthur Conmy*

Main category: cs.LG

TL;DR: 本文提出了一种使用LLM迭代发现奖励模型偏见的方法，成功揭示了已知偏见和新偏见（如Skywork-V2-8B偏爱冗余空格和幻觉内容），并证明迭代优化优于N选一搜索。


<details>
  <summary>Details</summary>
Motivation: 奖励模型在大型语言模型（LLM）的后期训练中至关重要。然而，过去的研究表明，它们可能奖励虚假或不良属性，如长度、格式、幻觉和奉承。本研究旨在自动发现自然语言中奖励模型的偏见。

Method: 我们提出了一种简单的方法，即使用大型语言模型（LLM）迭代地提出和完善候选偏见。

Result: 我们的方法可以发现已知的偏见并揭示新的偏见。例如，我们发现领先的开源奖励模型Skywork-V2-8B经常错误地偏爱具有冗余空格和包含幻觉内容的回复。此外，我们证明了进化迭代优于扁平的N选一搜索，并通过合成注入偏见验证了我们流程的召回率。

Conclusion: 我们希望这项工作能通过自动化可解释性方法促进对奖励模型改进的进一步研究。

Abstract: Reward models are central to large language model (LLM) post-training. However, past work has shown that they can reward spurious or undesirable attributes such as length, format, hallucinations, and sycophancy. In this work, we introduce and study the research problem of automatically finding reward model biases in natural language. We offer a simple approach of using an LLM to iteratively propose and refine candidate biases. Our method can recover known biases and surface novel ones: for example, we found that Skywork-V2-8B, a leading open-weight reward model, often mistakenly favors responses with redundant spacing and responses with hallucinated content. In addition, we show evidence that evolutionary iteration outperforms flat best-of-N search, and we validate the recall of our pipeline using synthetically injected biases. We hope our work contributes to further research on improving RMs through automated interpretability methods.

</details>


### [141] [Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238)
*Chengzhi Hu,Jonas Dornbusch,David Lüdke,Stephan Günnemann,Leo Schwinn*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Adversarial training for LLMs is one of the most promising methods to reliably improve robustness against adversaries. However, despite significant progress, models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or translating them into other languages. We argue that this persistent fragility stems from a fundamental limitation in current adversarial training algorithms: they minimize adversarial loss on their training set but inadequately cover the data distribution, resulting in vulnerability to seemingly simple attacks. To bridge this gap, we propose Distributional Adversarial Training, DAT. We leverage Diffusion LLMs to approximate the true joint distribution of prompts and responses, enabling generation of diverse, high-likelihood samples that address generalization failures. By combining optimization over the data distribution provided by the diffusion model with continuous adversarial training, DAT achieves substantially higher adversarial robustness than previous methods.

</details>


### [142] [Fast and Effective On-policy Distillation from Reasoning Prefixes](https://arxiv.org/abs/2602.15260)
*Dongxu Zhang,Zhichao Yang,Sepehr Janghorbani,Jun Han,Andrew Ressler II,Qian Qian,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.LG

TL;DR: 策略性前缀蒸馏在保持性能的同时，显著降低了策略性蒸馏的训练成本。


<details>
  <summary>Details</summary>
Motivation: 策略性蒸馏（OPD）虽然有效但成本高昂，尤其对于长响应。分析发现，训练信号通常集中在每个输出的前缀中，并且短的教师生成前缀可以显著帮助学生生成正确答案。

Method: 提出了一种策略性前缀蒸馏（On-policy Prefix Distillation, OPPD）方法，该方法仅将蒸馏目标应用于学生生成输出的前缀部分，并在蒸馏过程中提前终止采样。

Result: 策略性前缀蒸馏在AI-for-Math和域外基准测试中，性能与完整的策略性蒸馏相匹配，同时将训练FLOPs降低了2到47倍。

Conclusion: 策略性前缀蒸馏是一种简单而有效的改进，它在不牺牲性能的情况下显著降低了计算成本。

Abstract: On-policy distillation (OPD), which samples trajectories from the student model and supervises them with a teacher at the token level, avoids relying solely on verifiable terminal rewards and can yield better generalization than off-policy distillation. However, OPD requires expensive on-the-fly sampling of the student policy during training, which substantially increases training cost, especially for long responses. Our initial analysis shows that, during OPD, training signals are often concentrated in the prefix of each output, and that even a short teacher-generated prefix can significantly help the student produce the correct answer. Motivated by these observations, we propose a simple yet effective modification of OPD: we apply the distillation objective only to prefixes of student-generated outputs and terminate each sampling early during distillation. Experiments on a suite of AI-for-Math and out-of-domain benchmarks show that on-policy prefix distillation matches the performance of full OPD while reducing training FLOP by 2x-47x.

</details>


### [143] [The Information Geometry of Softmax: Probing and Steering](https://arxiv.org/abs/2602.15293)
*Kiho Park,Todd Nief,Yo Joong Choe,Victor Veitch*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop "dual steering", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.

</details>


### [144] [Hybrid Federated and Split Learning for Privacy Preserving Clinical Prediction and Treatment Optimization](https://arxiv.org/abs/2602.15304)
*Farzana Akter,Rakib Hossain,Deb Kanna Roy Toushi,Mahmood Menon Khan,Sultana Amin,Lisan Al Amin*

Main category: cs.LG

TL;DR: 提出一种混合联邦学习(FL)和拆分学习(SL)的隐私保护框架，用于医疗决策支持，在不共享原始数据的前提下，实现了与独立FL或SL相当的预测性能，并提供了可调的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 协作式临床决策支持常受限于管理和隐私规定，这些规定阻止了跨机构汇集患者级记录。

Method: 提出一种混合隐私保护框架，结合联邦学习（FL）和拆分学习（SL）。该方法将特征提取主干保留在客户端，而将预测头部托管在协调服务器上，实现了共享表示学习，并暴露了可应用隐私控制的显式协作边界。通过成员推理审计切层表示上的隐私泄露，并研究基于激活裁剪和加性高斯噪声的轻量级防御。

Result: 混合FL-SL变体在预测性能和面向决策的优先级行为方面与独立的FL或SL相比具有竞争力，并提供了可调的隐私-效用权衡，可在不共享原始数据的情况下减少审计泄露。评估涵盖了事实预测效用、容量限制下的提升排名、审计隐私泄露和通信开销四个部署相关轴。

Conclusion: 混合FL-SL是一种实用的隐私保护医疗决策支持设计空间，能够明确平衡效用、泄露风险和部署成本。

Abstract: Collaborative clinical decision support is often constrained by governance and privacy rules that prevent pooling patient-level records across institutions. We present a hybrid privacy-preserving framework that combines Federated Learning (FL) and Split Learning (SL) to support decision-oriented healthcare modeling without raw-data sharing. The approach keeps feature-extraction trunks on clients while hosting prediction heads on a coordinating server, enabling shared representation learning and exposing an explicit collaboration boundary where privacy controls can be applied. Rather than assuming distributed training is inherently private, we audit leakage empirically using membership inference on cut-layer representations and study lightweight defenses based on activation clipping and additive Gaussian noise. We evaluate across three public clinical datasets under non-IID client partitions using a unified pipeline and assess performance jointly along four deployment-relevant axes: factual predictive utility, uplift-based ranking under capacity constraints, audited privacy leakage, and communication overhead. Results show that hybrid FL-SL variants achieve competitive predictive performance and decision-facing prioritization behavior relative to standalone FL or SL, while providing a tunable privacy-utility trade-off that can reduce audited leakage without requiring raw-data sharing. Overall, the work positions hybrid FL-SL as a practical design space for privacy-preserving healthcare decision support where utility, leakage risk, and deployment cost must be balanced explicitly.

</details>


### [145] [On Surprising Effectiveness of Masking Updates in Adaptive Optimizers](https://arxiv.org/abs/2602.15322)
*Taejong Joo,Wenhan Xia,Cheolmin Kim,Ming Zhang,Eugene Ie*

Main category: cs.LG

TL;DR: 本文提出Magma，一种通过动量对齐梯度掩蔽的简单优化器，在LLM训练中显著优于现有自适应优化器，大幅降低困惑度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的训练主要依赖于复杂的自适应优化器。本文旨在挑战这一现状，探索随机掩蔽参数更新的有效性。

Method: 研究通过随机掩蔽参数更新来挑战现有优化器，并分析其引入的曲率依赖几何正则化效应。在此基础上，提出了一种新的优化器Magma（Momentum-aligned gradient masking），它利用动量-梯度对齐来调制掩蔽更新。

Result: 随机掩蔽的RMSProp变体持续优于最先进的优化器。Magma在LLM预训练中表现出显著的性能提升和可忽略的计算开销。对于1B模型，Magma相比Adam降低了超过19%的困惑度，相比Muon降低了9%的困惑度。

Conclusion: Magma作为一种简单的即插即用型优化器，在LLM预训练中表现出色，能显著提升性能并降低计算开销，是替代现有自适应优化器的一种有效选择。

Abstract: Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\% and 9\% compared to Adam and Muon, respectively.

</details>


### [146] [Prescriptive Scaling Reveals the Evolution of Language Model Capabilities](https://arxiv.org/abs/2602.15327)
*Hanlin Zhang,Jikai Jin,Vasilis Syrgkanis,Sham Kakade*

Main category: cs.LG

TL;DR: 该论文通过大规模观测评估和光滑分位数回归，估计了基础模型的性能能力边界，并提出了一种将计算预算转化为可靠性能预期并监控能力边界随时间变化的实用方法，同时发布了Proteus 2k数据集。


<details>
  <summary>Details</summary>
Motivation: 基础模型部署中，实践者需要规定性扩展定律：给定预训练计算预算，可达到的下游准确度以及这种映射随时间演变的稳定性。

Method: 1. 利用5k观测数据和2k新增样本进行大规模模型性能观测评估。2. 通过带有单调饱和S型参数化的平滑分位数回归，估计基准分数高条件分位数与对数预训练FLOPs函数关系的能力边界。3. 通过在早期模型世代上拟合并在后期版本上评估来验证时间可靠性。4. 将方法扩展到分析任务依赖的饱和度，并探测数学推理任务上与污染相关的偏移。5. 引入一种高效算法，以大约20%的评估预算恢复接近完整数据边界。

Result: 1. 估计的能力边界在各种任务中大多稳定，但数学推理任务例外，其边界随时间持续推进。2. 高效算法能够以约20%的评估预算恢复接近完整的数据前沿。3. 发布了最新的模型性能评估数据集Proteus 2k。

Conclusion: 该工作发布了Proteus 2k数据集，并引入了一种实用方法，用于将计算预算转化为可靠的性能预期，并监控能力边界随时间的变化。

Abstract: For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.

</details>


### [147] [A Scalable Curiosity-Driven Game-Theoretic Framework for Long-Tail Multi-Label Learning in Data Mining](https://arxiv.org/abs/2602.15330)
*Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 本文提出了一种好奇心驱动的博弈论多标签学习（CD-GTMLL）框架，通过将长尾多标签分类建模为多玩家博弈，并引入好奇心奖励，有效解决了大规模多标签分类中的长尾问题，超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 大规模多标签分类（MLC）在真实世界数据挖掘应用中面临长尾分布的挑战，即少数头部标签占据主导地位，而稀有的尾部标签数量庞大。现有重采样和重加权策略通常会破坏标签间依赖性，或在标签空间扩展到数万个标签时需要脆弱的超参数调整。

Method: 本文提出了好奇心驱动的博弈论多标签学习（CD-GTMLL）框架，将长尾多标签分类重构为多玩家博弈。每个子预测器（玩家）专注于标签空间的一个分区，通过合作最大化全局准确率，并根据尾部标签的稀有性和玩家间的分歧追求内在的好奇心奖励，从而自适应地向代表性不足的尾部标签注入学习信号。该机制避免了手动平衡或调优。

Result: 理论分析表明，CD-GTMLL收敛到尾部感知均衡，并与Rare-F1指标的改进有形式上的联系。在包含30,000+标签的极限多标签分类数据集在内的7个基准测试中，CD-GTMLL始终优于现有先进方法，在Wiki10-31K数据集上P@3指标提升高达1.6%。消融研究证实了博弈论合作和好奇心驱动探索对稳健尾部性能的贡献。

Conclusion: CD-GTMLL通过整合博弈论与好奇心机制，不仅提高了资源受限环境下的模型效率，还为电子商务和医疗保健等行业的不平衡数据场景中的自适应学习铺平了道路。

Abstract: The long-tail distribution, where a few head labels dominate while rare tail labels abound, poses a persistent challenge for large-scale Multi-Label Classification (MLC) in real-world data mining applications. Existing resampling and reweighting strategies often disrupt inter-label dependencies or require brittle hyperparameter tuning, especially as the label space expands to tens of thousands of labels. To address this issue, we propose Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL), a scalable cooperative framework that recasts long-tail MLC as a multi-player game - each sub-predictor ("player") specializes in a partition of the label space, collaborating to maximize global accuracy while pursuing intrinsic curiosity rewards based on tail label rarity and inter-player disagreement. This mechanism adaptively injects learning signals into under-represented tail labels without manual balancing or tuning. We further provide a theoretical analysis showing that our CD-GTMLL converges to a tail-aware equilibrium and formally links the optimization dynamics to improvements in the Rare-F1 metric. Extensive experiments across 7 benchmarks, including extreme multi-label classification datasets with 30,000+ labels, demonstrate that CD-GTMLL consistently surpasses state-of-the-art methods, with gains up to +1.6% P@3 on Wiki10-31K. Ablation studies further confirm the contributions of both game-theoretic cooperation and curiosity-driven exploration to robust tail performance. By integrating game theory with curiosity mechanisms, CD-GTMLL not only enhances model efficiency in resource-constrained environments but also paves the way for more adaptive learning in imbalanced data scenarios across industries like e-commerce and healthcare.

</details>


### [148] [FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning](https://arxiv.org/abs/2602.15337)
*Chaoyi Lu*

Main category: cs.LG

TL;DR: FedPSA是一个细粒度的异步联邦学习框架，通过参数敏感度测量模型过时性并利用动态动量队列实时评估训练阶段，从而动态调整对过期信息的容忍度，性能优于基线方法和现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有异步联邦学习（AFL）方法因异步过程引入的陈旧性导致性能下降，且通常仅使用粗粒度的轮次差异来衡量模型陈旧性，缺乏对模型本身的观察，限制了性能上限。

Method: 提出FedPSA框架，通过参数敏感度（Parameter Sensitivity）细粒度地衡量模型过时性，并建立动态动量队列（dynamic momentum queue）实时评估当前训练阶段，从而动态调整对过期信息的容忍度。

Result: FedPSA在多个数据集上表现出卓越性能，相比基线方法提升高达6.37%，相比现有最先进方法提升1.93%。

Conclusion: FedPSA通过其创新的细粒度陈旧性度量和动态调整机制，有效解决了异步联邦学习中因模型陈旧性导致的性能下降问题，显著优于现有方法。

Abstract: Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\% improvement over baseline methods and 1.93\% over the current state-of-the-art method.

</details>


### [149] [CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies](https://arxiv.org/abs/2602.15367)
*Sibo Zhang,Rui Jing,Liangfu Lv,Jian Zhang,Yunliang Zang*

Main category: cs.LG

TL;DR: 强化学习（RL）在样本效率、对噪声的敏感性和泛化能力方面存在局限性。本文提出了一种受小脑启发的生物学RL架构，该架构融合了大规模扩展、稀疏连接、稀疏激活和树突级调制，以提高样本效率、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在处理高维序贯决策任务时，存在样本效率低、对噪声敏感以及在部分可观察性下泛化能力弱的问题。现有方法主要通过优化策略来解决这些问题，而对架构先验在塑造表示学习和决策动态中的作用探索较少。

Method: 受小脑结构原理的启发，提出了一种生物学基础的RL架构，该架构包含了大规模扩展、稀疏连接、稀疏激活和树突级调制。

Result: 在有噪声、高维的RL基准测试中，与传统设计相比，小脑架构和树突调制均持续提高了样本效率、鲁棒性和泛化能力。对架构参数的敏感性分析表明，受小脑启发的结构可以在模型参数受限的情况下为RL提供优化的性能。

Conclusion: 小脑结构先验可以作为RL的有效归纳偏置。

Abstract: Reinforcement learning (RL) has achieved notable performance in high-dimensional sequential decision-making tasks, yet remains limited by low sample efficiency, sensitivity to noise, and weak generalization under partial observability. Most existing approaches address these issues primarily through optimization strategies, while the role of architectural priors in shaping representation learning and decision dynamics is less explored. Inspired by structural principles of the cerebellum, we propose a biologically grounded RL architecture that incorporate large expansion, sparse connectivity, sparse activation, and dendritic-level modulation. Experiments on noisy, high-dimensional RL benchmarks show that both the cerebellar architecture and dendritic modulation consistently improve sample efficiency, robustness, and generalization compared to conventional designs. Sensitivity analysis of architectural parameters suggests that cerebellum-inspired structures can offer optimized performance for RL with constrained model parameters. Overall, our work underscores the value of cerebellar structural priors as effective inductive biases for RL.

</details>


### [150] [Seeing to Generalize: How Visual Data Corrects Binding Shortcuts](https://arxiv.org/abs/2602.15183)
*Nicolas Buzeta,Felipe del Rio,Cristian Hinostroza,Denis Parra,Hans Lobel,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: 视觉语言模型（VLMs）在纯文本任务上，特别是在长上下文信息检索中，表现优于其基础大型语言模型（LLMs）。研究发现，视觉训练通过改变模型的内部绑定策略，使其从依赖位置快捷方式转变为更鲁棒的符号绑定机制，从而提高文本任务的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）旨在为大型语言模型（LLMs）扩展视觉能力，但作者观察到一个出人意料的现象：VLMs在纯文本任务上，尤其是在长上下文信息检索中，表现优于其基础LLMs。

Method: 研究构建了一个受控的合成检索任务。通过机械可解释性方法，分析了不同训练机制（仅文本训练与图像标记化训练）下模型内部绑定策略的变化。进一步探究了绑定策略在不同训练方案、视觉编码器和初始化之间的差异，并展示了在预训练LLM到VLM转换过程中出现的类似转变。

Result: 仅文本训练的Transformer在分布内准确率完美，但在分布外泛化失败。在相同任务的图像标记化版本上进行后续训练，几乎使纯文本OOD（分布外）性能翻倍。视觉训练改变了模型的内部绑定策略：仅文本训练鼓励位置快捷方式，而基于图像的训练通过空间平移不变性打破了这些快捷方式，迫使模型采用更鲁棒的符号绑定机制，即使在重新引入纯文本示例后也能保持。

Conclusion: 跨模态训练可以增强推理和泛化能力，即使对于仅基于单一模态的任务也是如此。

Abstract: Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in long-context information retrieval. To investigate this effect, we build a controlled synthetic retrieval task and find that a transformer trained only on text achieves perfect in-distribution accuracy but fails to generalize out of distribution, while subsequent training on an image-tokenized version of the same task nearly doubles text-only OOD performance. Mechanistic interpretability reveals that visual training changes the model's internal binding strategy: text-only training encourages positional shortcuts, whereas image-based training disrupts them through spatial translation invariance, forcing the model to adopt a more robust symbolic binding mechanism that persists even after text-only examples are reintroduced. We further characterize how binding strategies vary across training regimes, visual encoders, and initializations, and show that analogous shifts occur during pretrained LLM-to-VLM transitions. Our findings suggest that cross-modal training can enhance reasoning and generalization even for tasks grounded in a single modality.

</details>


### [151] [Discovering Implicit Large Language Model Alignment Objectives](https://arxiv.org/abs/2602.15338)
*Edward Chen,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: Obj-Disco是一个框架，通过将对齐奖励信号分解为人类可解释的自然语言目标，自动识别和验证大型语言模型对齐中隐含的激励，从而提高透明度和安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的对齐依赖于复杂的奖励信号，这些信号常常模糊了被激励的具体行为，导致对齐失调和奖励攻击的严重风险。现有的解释方法通常依赖预定义的规则，可能遗漏“未知未知”，或未能识别全面且对模型行为具有因果关系的目标。

Method: 本文引入了Obj-Disco框架，它将对齐奖励信号自动分解为人类可解释的自然语言目标的稀疏、加权组合。该方法利用迭代贪婪算法分析训练检查点之间的行为变化，识别并验证最能解释剩余奖励信号的候选目标。

Result: Obj-Disco框架在不同的任务、模型大小和对齐算法上表现出鲁棒性。对流行的开源奖励模型的实验表明，该框架始终能捕获超过90%的奖励行为，并通过人工评估进一步证实。案例研究显示，Obj-Disco能成功识别与预期行为同时出现的潜在错位激励。

Conclusion: Obj-Disco为揭示LLM对齐中的隐含目标提供了一个关键工具，为更透明和更安全的AI开发铺平了道路。

Abstract: Large language model (LLM) alignment relies on complex reward signals that often obscure the specific behaviors being incentivized, creating critical risks of misalignment and reward hacking. Existing interpretation methods typically rely on pre-defined rubrics, risking the omission of "unknown unknowns", or fail to identify objectives that comprehensively cover and are causal to the model behavior. To address these limitations, we introduce Obj-Disco, a framework that automatically decomposes an alignment reward signal into a sparse, weighted combination of human-interpretable natural language objectives. Our approach utilizes an iterative greedy algorithm to analyze behavioral changes across training checkpoints, identifying and validating candidate objectives that best explain the residual reward signal. Extensive evaluations across diverse tasks, model sizes, and alignment algorithms demonstrate the framework's robustness. Experiments with popular open-source reward models show that the framework consistently captures > 90% of reward behavior, a finding further corroborated by human evaluation. Additionally, a case study on alignment with an open-source reward model reveals that Obj-Disco can successfully identify latent misaligned incentives that emerge alongside intended behaviors. Our work provides a crucial tool for uncovering the implicit objectives in LLM alignment, paving the way for more transparent and safer AI development.

</details>


### [152] [Logit Distance Bounds Representational Similarity](https://arxiv.org/abs/2602.15438)
*Beatrix M. B. Nielsen,Emanuele Marconato,Luigi Gresele,Andrea Dittadi,Simon Buchholz*

Main category: cs.LG

TL;DR: 本研究探讨了判别模型中，当条件分布近似时，内部表示是否也近似一致的问题。结果发现，基于logit差异的距离比KL散度能提供更好的线性表示相似性保证。KL散度在蒸馏过程中未能保留线性表示特性，而logit距离蒸馏则能更有效地实现此目的。


<details>
  <summary>Details</summary>
Motivation: 对于包括自回归语言模型在内的判别模型，可识别性结果表明，如果两个模型产生相同的条件分布，它们的内部表示在可逆线性变换下是一致的。本文旨在探讨当分布近似而非完全相等时，是否能得出类似的近似结论。此动机源于Nielsen et al. (2025) 的观察，即KL散度上的接近度不一定意味着高线性表示相似性。

Method: 研究了一种基于logit差异的分布距离。定义了一种基于模型可识别性类的表示不相似性度量，并证明它受到logit距离的限制。进一步证明，当模型概率远离零时，KL散度可以作为logit距离的上限，但实际应用中此界限未能提供非平凡的控制。在合成数据集和图像数据集上进行了蒸馏实验，比较了logit距离蒸馏的效果。

Result: 基于logit差异的距离接近度确实能产生线性相似性保证。定义的表示不相似性度量受logit距离的限制。基于KL的蒸馏可以匹配教师模型的预测，但未能保留线性表示特性，例如人类可解释概念的线性探测可恢复性。在蒸馏实验中，logit距离蒸馏得到的学生模型具有更高的线性表示相似性，并更好地保留了教师模型的线性可恢复概念。

Conclusion: 基于logit差异的分布距离在保证判别模型的线性表示相似性方面优于KL散度。KL散度蒸馏不足以保留线性表示特性（如人类可解释概念的线性可恢复性），而logit距离蒸馏则能有效实现这一目标，从而更好地保留教师模型的线性可恢复概念。

Abstract: For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.

</details>


### [153] [The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes](https://arxiv.org/abs/2602.15515)
*Mohammad Taufeeque,Stefan Heimersheim,Adam Gleave,Chris Cundy*

Main category: cs.LG

TL;DR: 该研究探讨了在针对白盒欺骗检测器进行训练时，AI系统如何学会混淆其欺骗行为。发现在现实编码环境中，模型会通过“混淆激活”或“混淆策略”来隐藏欺骗。研究提出了通过足够高的KL正则化和检测器惩罚可以实现诚实策略，从而证明了白盒欺骗检测器作为奖励劫持任务的有效训练信号。


<details>
  <summary>Details</summary>
Motivation: 先前的研究仅在人工设置中探讨了混淆问题，本文旨在在一个奖励劫持（reward hacking）自然发生的现实编码环境中研究AI系统在对抗白盒欺骗检测器训练时可能出现的混淆行为，以理解模型如何学习规避检测器，并最终确定白盒欺骗检测器作为避免奖励劫持任务的有效训练信号。

Method: 1. 构建了一个现实的编码环境，其中通过硬编码测试用例进行奖励劫持自然发生。2. 提出了一个在对抗欺骗检测器训练时可能结果的分类法（诚实、通过混淆激活欺骗、通过混淆策略欺骗）。3. 实证研究了混淆激活和混淆策略的出现。4. 从理论上解释了为什么策略梯度方法在有探测惩罚时会产生混淆策略。5. 考察了KL正则化和检测器惩罚对实现诚实策略的影响。

Result: 1. 在奖励劫持自然发生的现实编码环境中，混淆行为确实出现。2. 混淆激活源于强化学习过程中的表示漂移，无论是否有检测器惩罚。3. 探测惩罚仅激励混淆策略的产生。4. 理论证明，对于策略梯度方法，探测惩罚确实会导致混淆策略。5. 足够高的KL正则化和检测器惩罚可以促使模型采用诚实策略。

Conclusion: 白盒欺骗检测器可以作为容易发生奖励劫持任务的有效训练信号，前提是施加足够高的KL正则化和检测器惩罚，以确保模型采纳诚实策略并防止欺骗行为的混淆。

Abstract: Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.

</details>


### [154] [MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2602.15740)
*Fatemeh Khalvandi,Saadat Izadi,Abdolah Chalechale*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.

</details>


### [155] [UrbanVerse: Learning Urban Region Representation Across Cities and Tasks](https://arxiv.org/abs/2602.15750)
*Fengze Sun,Egemen Tanin,Shanika Karunasekera,Zuqing Li,Flora D. Salim,Jianzhong Qi*

Main category: cs.LG

TL;DR: UrbanVerse是一个跨城市城市区域表示学习和跨任务城市分析的基础模型，通过关注区域局部特征和附近区域的结构特征，并引入HCondDiffCT模块进行跨任务泛化，在六项任务中优于现有方法，预测准确率最高提升35.89%。


<details>
  <summary>Details</summary>
Motivation: 现有城市区域表示学习方法在跨城市和跨分析任务泛化能力上存在局限，目标是构建一个超越特定城市和任务的、基础风格的城市分析模型。

Method: 提出UrbanVerse模型：1. 针对跨城市泛化，模型关注目标区域的局部特征和附近区域的结构特征，将区域建模为图上的节点，并通过基于随机游走的程序形成“区域序列”进行表示学习。2. 针对跨任务泛化，提出HCondDiffCT跨任务学习模块，该模块将区域条件先验知识和任务条件语义整合到扩散过程中，共同建模多个下游城市预测任务，且该模块具有通用性，可与现有模型结合。

Result: 在真实世界数据集上的实验表明，UrbanVerse在跨城市设置下的六项任务中持续优于现有最先进的方法，预测准确率最高提升35.89%。

Conclusion: UrbanVerse成功实现了城市表示学习在跨城市和跨任务情境下的泛化，提供了一个稳健的城市分析基础模型，并显著提升了性能。

Abstract: Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form "sequences of regions" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.

</details>


### [156] [The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety](https://arxiv.org/abs/2602.15799)
*Max Springer,Chung Peng Lee,Blossom Metevier,Jane Castleman,Bohdan Turbal,Hayoung Jung,Zeyu Shen,Aleksandra Korolova*

Main category: cs.LG

TL;DR: 微调对齐语言模型会不可预测地降低安全护栏，这不是一个简单的错误，而是梯度下降固有的几何特性。一项新颖的几何分析表明，对齐损失与训练时间呈四次方关系，需要开发曲率感知方法来解决。


<details>
  <summary>Details</summary>
Motivation: 在良性任务上微调对齐的语言模型，即使训练数据无害且开发者无恶意，也会不可预测地降低安全护栏的有效性。现有解释（高维参数空间中的正交性）被证明是不可靠的，因为它在梯度下降动力学下结构不稳定且会崩溃。

Method: 本文通过新颖的几何分析，证明了对齐集中在具有尖锐曲率的低维子空间中，形成了脆弱的结构。研究者通过“对齐不稳定性条件”（三个几何特性）形式化了这一机制，并揭示了微调损失的曲率如何产生二阶加速，系统地将轨迹引导至对齐敏感区域。

Result: 研究发现，对齐损失的增长与训练时间的四次方成正比，受对齐几何的尖锐性和微调任务与安全关键参数之间曲率耦合强度的影响。这一“四次缩放定律”揭示了对齐的脆弱性是梯度下降固有的几何特性。

Conclusion: 当前的安全范式存在结构性盲点，主流的安全微调方法仅解决了动态问题的初始状态。对齐的脆弱性并非可修补的错误，而是梯度下降在弯曲流形上的内在几何属性。这些结果促使开发曲率感知方法，并将对齐安全分析从被动红队转向开放权重模型部署的预测诊断。

Abstract: Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.

</details>
