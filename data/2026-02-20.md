<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 33]
- [cs.CL](#cs.CL) [Total: 54]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.HC](#cs.HC) [Total: 4]
- [nlin.AO](#nlin.AO) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.LG](#cs.LG) [Total: 24]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.LO](#cs.LO) [Total: 1]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.RO](#cs.RO) [Total: 38]
- [cs.MM](#cs.MM) [Total: 1]
- [stat.AP](#stat.AP) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Egocentric Bias in Vision-Language Models](https://arxiv.org/abs/2602.15892)
*Maijunxian Wang,Yijiang Li,Bingyang Wang,Tianwei Zhao,Ran Ji,Qingying Gao,Emmy Liu,Hokin Deng,Dezhi Luo*

Main category: cs.CV

TL;DR: 该论文引入了FlipSet，一个用于评估视觉语言模型（VLMs）二级视觉视角采纳（L2 VPT）能力的诊断基准。研究发现VLMs存在系统性的自我中心偏见和组合性缺陷，表明它们缺乏将社会意识与空间操作结合的机制。


<details>
  <summary>Details</summary>
Motivation: 视觉视角采纳是社会认知的基础。该研究旨在诊断视觉语言模型在二级视觉视角采纳方面的能力。

Method: 研究引入了FlipSet，这是一个诊断性基准，要求模型模拟从另一个智能体的视角对2D字符串进行180度旋转，以隔离空间转换与3D场景复杂性。评估了103个VLM，并进行了对照实验以揭示组合性缺陷。

Result: 绝大多数VLM表现低于偶然水平，并显示出系统性的自我中心偏见（约四分之三的错误是重现摄像机视角）。对照实验表明，模型在单独的心理理论准确性和高于偶然水平的心理旋转方面表现良好，但在需要整合时会灾难性地失败。

Conclusion: 当前的VLM缺乏将社会意识与空间操作结合所需的机制，这表明基于模型的空间推理存在根本性局限。FlipSet为诊断多模态系统中的视角采纳能力提供了一个认知基础的测试平台。

Abstract: Visual perspective taking--inferring how the world appears from another's viewpoint--is foundational to social cognition. We introduce FlipSet, a diagnostic benchmark for Level-2 visual perspective taking (L2 VPT) in vision-language models. The task requires simulating 180-degree rotations of 2D character strings from another agent's perspective, isolating spatial transformation from 3D scene complexity. Evaluating 103 VLMs reveals systematic egocentric bias: the vast majority perform below chance, with roughly three-quarters of errors reproducing the camera viewpoint. Control experiments expose a compositional deficit--models achieve high theory-of-mind accuracy and above-chance mental rotation in isolation, yet fail catastrophically when integration is required. This dissociation indicates that current VLMs lack the mechanisms needed to bind social awareness to spatial operations, suggesting fundamental limitations in model-based spatial reasoning. FlipSet provides a cognitively grounded testbed for diagnosing perspective-taking capabilities in multimodal systems.

</details>


### [2] [Detecting Deepfakes with Multivariate Soft Blending and CLIP-based Image-Text Alignment](https://arxiv.org/abs/2602.15903)
*Jingwei Li,Jiaxin Tong,Pengfei Wu*

Main category: cs.CV

TL;DR: 提出MSBA-CLIP框架，利用CLIP的多模态对齐能力和多变量软混合增强(MSBA)策略，通过混合多种伪造方法生成图像并结合多变量伪造强度估计(MFIE)模块，解决了现有深度伪造检测方法泛化能力差的问题。实验证明该方法在域内和跨域检测上均达到最先进水平，显著提高了准确性和AUC。


<details>
  <summary>Details</summary>
Motivation: 随着高度逼真的人脸伪造技术激增，对鲁棒的检测方法的需求日益增加。然而，现有方法由于不同伪造技术生成的样本之间存在显著的分布差异，导致准确性有限和泛化能力差。

Method: 提出了一种新颖的MSBA-CLIP框架。该方法利用CLIP的多模态对齐能力来捕获细微的伪造痕迹。引入了多变量软混合增强(MSBA)策略，通过将来自多种方法的伪造图像以随机权重混合来合成图像，以迫使模型学习可泛化的模式。此外，还设计了一个专门的多变量伪造强度估计(MFIE)模块，明确指导模型学习与不同伪造模式和强度相关的特征。

Result: 广泛的实验证明了该方法达到了最先进的性能。在域内测试中，该方法相比最佳基线，准确率和AUC分别提高了3.32%和4.02%。在跨五个数据集的跨域评估中，平均AUC增益达到3.27%。消融研究证实了所提出两种组件的有效性。

Conclusion: 尽管依赖大型视觉语言模型会带来更高的计算成本，但这项工作在实现更具泛化性和鲁棒性的深度伪造检测方面迈出了重要一步。

Abstract: The proliferation of highly realistic facial forgeries necessitates robust detection methods. However, existing approaches often suffer from limited accuracy and poor generalization due to significant distribution shifts among samples generated by diverse forgery techniques. To address these challenges, we propose a novel Multivariate and Soft Blending Augmentation with CLIP-guided Forgery Intensity Estimation (MSBA-CLIP) framework. Our method leverages the multimodal alignment capabilities of CLIP to capture subtle forgery traces. We introduce a Multivariate and Soft Blending Augmentation (MSBA) strategy that synthesizes images by blending forgeries from multiple methods with random weights, forcing the model to learn generalizable patterns. Furthermore, a dedicated Multivariate Forgery Intensity Estimation (MFIE) module is designed to explicitly guide the model in learning features related to varied forgery modes and intensities. Extensive experiments demonstrate state-of-the-art performance. On in-domain tests, our method improves Accuracy and AUC by 3.32\% and 4.02\%, respectively, over the best baseline. In cross-domain evaluations across five datasets, it achieves an average AUC gain of 3.27\%. Ablation studies confirm the efficacy of both proposed components. While the reliance on a large vision-language model entails higher computational cost, our work presents a significant step towards more generalizable and robust deepfake detection.

</details>


### [3] [A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving](https://arxiv.org/abs/2602.15904)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: 本文对自动驾驶中激光雷达超分辨率方法进行了首次全面综述，旨在解决高分辨率传感器昂贵而低分辨率传感器点云稀疏的问题。文章将现有方法分为四类，建立了基本概念，讨论了当前趋势，并指出了未来的研究方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 高分辨率激光雷达传感器价格昂贵，而经济实惠的低分辨率传感器产生的点云稀疏，缺失关键细节。激光雷达超分辨率技术旨在通过深度学习增强稀疏点云，弥合不同传感器类型之间的差距，实现实际部署中的跨传感器兼容性。然而，在此之前，尚未有针对自动驾驶领域激光雷达超分辨率方法的系统性综述。

Method: 本文对自动驾驶中的激光雷达超分辨率方法进行了首次全面综述。文章将现有方法分为四大类：基于CNN的架构、基于模型的深度展开、隐式表示方法以及基于Transformer和Mamba的方法。同时，文章建立了基本概念，包括数据表示、问题 формуulation、基准数据集和评估指标。

Result: 文章对现有方法进行了分类，并总结了当前趋势，包括采用距离图像表示以提高处理效率、极端模型压缩以及开发分辨率灵活的架构。最近的研究优先考虑实时推理和跨传感器泛化以实现实际部署。

Conclusion: 文章最后指出了推进激光雷达超分辨率技术所面临的开放挑战和未来的研究方向。

Abstract: LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while affordable low-resolution sensors produce sparse point clouds that miss critical details. LiDAR super-resolution addresses this challenge by using deep learning to enhance sparse point clouds, bridging the gap between different sensor types and enabling cross-sensor compatibility in real-world deployments. This paper presents the first comprehensive survey of LiDAR super-resolution methods for autonomous driving. Despite the importance of practical deployment, no systematic review has been conducted until now. We organize existing approaches into four categories: CNN-based architectures, model-based deep unrolling, implicit representation methods, and Transformer and Mamba-based approaches. We establish fundamental concepts including data representations, problem formulation, benchmark datasets and evaluation metrics. Current trends include the adoption of range image representation for efficient processing, extreme model compression and the development of resolution-flexible architectures. Recent research prioritizes real-time inference and cross-sensor generalization for practical deployment. We conclude by identifying open challenges and future research directions for advancing LiDAR super-resolution technology.

</details>


### [4] [EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery](https://arxiv.org/abs/2602.15918)
*Zelin Xu,Yupu Zhang,Saugat Adhikari,Saiful Islam,Tingsong Xiao,Zibo Liu,Shigang Chen,Da Yan,Zhe Jiang*

Main category: cs.CV

TL;DR: EarthSpatialBench是一个全面的基准测试，用于评估多模态大语言模型（MLLMs）在地球图像上的空间推理能力，填补了现有基准在量化距离/方向推理、系统拓扑关系和复杂对象几何方面存在的空白。


<details>
  <summary>Details</summary>
Motivation: 由于其对于具身AI和其他需要与物理世界精确交互的智能系统的重要性，对多模态大语言模型（MLLMs）中的空间推理进行基准测试受到了计算机视觉领域日益增长的关注。然而，地球图像上的空间推理相对滞后，因为它独特地涉及到将对象定位在地理参考图像中，并利用视觉线索和矢量几何坐标（如2D边界框、多段线和多边形）对距离、方向和拓扑关系进行定量推理。现有地球图像基准主要关注2D空间定位、图像标注和粗略空间关系，缺乏对定量方向和距离推理、系统拓扑关系以及超出边界框的复杂对象几何的支持。

Method: 我们提出了EarthSpatialBench，这是一个用于评估MLLMs在地球图像上空间推理的综合基准测试。该基准包含超过32.5万个问答对，涵盖：1）关于空间距离和方向的定性和定量推理；2）系统拓扑关系；3）单对象查询、对象对查询和组合聚合组查询；4）通过文本描述、视觉叠加和明确几何坐标（包括2D边界框、多段线和多边形）表达的对象引用。

Result: 我们对开源和专有模型进行了广泛实验，以识别MLLMs在空间推理方面的局限性。

Conclusion: EarthSpatialBench基准测试有助于识别多模态大语言模型在地球图像空间推理方面的局限性，为未来研究提供了有价值的工具。

Abstract: Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively reasoning about distances, directions, and topological relations using both visual cues and vector geometry coordinates (e.g., 2D bounding boxes, polylines, and polygons). Existing benchmarks for Earth imagery primarily focus on 2D spatial grounding, image captioning, and coarse spatial relations (e.g., simple directional or proximity cues). They lack support for quantitative direction and distance reasoning, systematic topological relations, and complex object geometries beyond bounding boxes. To fill this gap, we propose \textbf{EarthSpatialBench}, a comprehensive benchmark for evaluating spatial reasoning in MLLMs on Earth imagery. The benchmark contains over 325K question-answer pairs spanning: (1) qualitative and quantitative reasoning about spatial distance and direction; (2) systematic topological relations; (3) single-object queries, object-pair queries, and compositional aggregate group queries; and (4) object references expressed via textual descriptions, visual overlays, and explicit geometry coordinates, including 2D bounding boxes, polylines, and polygons. We conducted extensive experiments on both open-source and proprietary models to identify limitations in the spatial reasoning of MLLMs.

</details>


### [5] [A Study on Real-time Object Detection using Deep Learning](https://arxiv.org/abs/2602.15926)
*Ankita Bose,Jayasravani Bhumireddy,Naveen N*

Main category: cs.CV

TL;DR: 该论文详细探讨了深度学习算法如何增强实时目标识别，涵盖了现有模型、数据集和应用研究，并通过比较研究提供见解，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 实时目标检测在人机交互、安全监控、导航、交通监测、交通系统、工业自动化、医疗保健、增强现实和虚拟现实、环境监测和活动识别等多个领域具有重要的应用，通过深度学习算法可以提供更准确、高效的解决方案。

Method: 详细阐述了深度学习算法如何增强实时目标识别，提供了不同的目标检测模型、开放基准数据集以及在各种应用中使用目标检测模型的研究信息。此外，还进行了受控研究以比较各种策略。

Result: 呈现了关于深度学习算法增强实时目标识别的详细信息，包括各种目标检测模型（如Faster R-CNN, Mask R-CNN, Cascade R-CNN, YOLO, SSD, RetinaNet等）、开放基准数据集和应用研究，并通过比较研究获得了一些启发性发现。

Conclusion: 提供了进一步研究相关深度学习方法和目标识别的挑战和方法建议。

Abstract: Object detection has compelling applications over a range of domains, including human-computer interfaces, security and video surveillance, navigation and road traffic monitoring, transportation systems, industrial automation healthcare, the world of Augmented Reality (AR) and Virtual Reality (VR), environment monitoring and activity identification. Applications of real time object detection in all these areas provide dynamic analysis of the visual information that helps in immediate decision making. Furthermore, advanced deep learning algorithms leverage the progress in the field of object detection providing more accurate and efficient solutions. There are some outstanding deep learning algorithms for object detection which includes, Faster R CNN(Region-based Convolutional Neural Network),Mask R-CNN, Cascade R-CNN, YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), RetinaNet etc. This article goes into great detail on how deep learning algorithms are used to enhance real time object recognition. It provides information on the different object detection models available, open benchmark datasets, and studies on the use of object detection models in a range of applications. Additionally, controlled studies are provided to compare various strategies and produce some illuminating findings. Last but not least, a number of encouraging challenges and approaches are offered as suggestions for further investigation in both relevant deep learning approaches and object recognition.

</details>


### [6] [Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families](https://arxiv.org/abs/2602.15950)
*Yuval Levental*

Main category: cs.CV

TL;DR: 本研究揭示了视觉语言模型（VLMs）在定位缺乏文本标识的二元网格中的填充单元格时存在的根本局限性，并发现它们在处理文本符号图像时表现出远优于处理非文本视觉元素（如填充方块）的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 揭示视觉语言模型（VLMs）在识别缺乏文本标识的二元网格中的填充单元格时的基本局限性，并证明VLMs的空间推理似乎严重依赖高保真文本识别而非原生视觉通路。

Method: 生成15个15x15的二元网格，密度不同（10.7%-41.8%的填充单元格）。将每个网格渲染成两种图像类型：文本符号（.和#）和无网格线的填充方块。然后，要求三款前沿VLM（Claude Opus、ChatGPT 5.2和Gemini 3 Thinking）进行转录。所有条件均通过相同的视觉编码器处理。

Result: 在文本符号条件下，Claude和ChatGPT实现了约91%的单元格准确率和84%的F1分数，Gemini实现了84%的准确率和63%的F1分数。在填充方块条件下，所有模型性能均大幅下降，准确率降至60-73%，F1分数降至29-39%。文本与方块条件下的F1分数差距在34至54点之间。各模型在方块条件下表现出不同的失败模式：Claude系统性漏计，ChatGPT大量过计，Gemini模板幻觉。

Conclusion: 视觉语言模型（VLMs）对非文本视觉元素的空间定位能力严重下降，表明它们在空间推理中似乎更依赖高保真文本识别通路，而非其固有的视觉通路。这暴露出它们在处理非文本空间任务时存在根本性缺陷。

Abstract: We present a simple experiment that exposes a fundamental limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% filled cells) and render each as two image types -- text symbols (. and #) and filled squares without gridlines -- then ask three frontier VLMs (Claude Opus, ChatGPT 5.2, and Gemini 3 Thinking) to transcribe them. In the text-symbol condition, Claude and ChatGPT achieve approximately 91% cell accuracy and 84% F1, while Gemini achieves 84% accuracy and 63% F1. In the filled-squares condition, all three models collapse to 60-73% accuracy and 29-39% F1. Critically, all conditions pass through the same visual encoder -- the text symbols are images, not tokenized text. The text-vs-squares F1 gap ranges from 34 to 54 points across models, demonstrating that VLMs behave as if they possess a high-fidelity text-recognition pathway for spatial reasoning that dramatically outperforms their native visual pathway. Each model exhibits a distinct failure mode in the squares condition -- systematic under-counting (Claude), massive over-counting (ChatGPT), and template hallucination (Gemini) -- but all share the same underlying deficit: severely degraded spatial localization for non-textual visual elements.

</details>


### [7] [Position-Aware Scene-Appearance Disentanglement for Bidirectional Photoacoustic Microscopy Registration](https://arxiv.org/abs/2602.15959)
*Yiwen Wang,Jiahao Qin*

Main category: cs.CV

TL;DR: 本文提出GPEReg-Net，一个利用场景外观解耦和全局位置编码的深度学习框架，用于解决高速OR-PAM双向扫描引起的域偏移和几何错位问题，显著提高了图像配准的准确性和时间一致性，超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 高速光分辨光声显微（OR-PAM）的双向栅格扫描技术虽然能使成像速度翻倍，但会引入前向和后向扫描线之间耦合的域偏移和几何错位。现有配准方法受限于亮度恒定假设，配准质量有限；而最近的生成方法通过复杂架构解决域偏移问题，但缺乏跨帧的时间感知能力。

Method: 本文提出了GPEReg-Net，一个场景外观解耦框架，通过自适应实例归一化（AdaIN）将领域不变场景特征与领域特定外观代码分离，实现直接的图像到图像配准而无需显式形变场估计。同时引入了全局位置编码（GPE）模块，结合可学习位置嵌入、正弦编码和跨帧注意力，利用相邻帧的上下文信息提高时间连贯性。

Result: 在OR-PAM-Reg-4K基准（432个测试样本）上，GPEReg-Net在NCC方面达到0.953，SSIM达到0.932，PSNR达到34.49dB。与现有最佳技术相比，SSIM提高了3.8%，PSNR提高了1.99dB，同时保持了有竞争力的NCC。

Conclusion: GPEReg-Net通过场景外观解耦和全局位置编码，显著提高了OR-PAM图像配准的准确性和时间一致性，在多个指标上超越了现有技术。

Abstract: High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional raster scanning doubles imaging speed but introduces coupled domain shift and geometric misalignment between forward and backward scan lines. Existing registration methods, constrained by brightness constancy assumptions, achieve limited alignment quality, while recent generative approaches address domain shift through complex architectures that lack temporal awareness across frames. We propose GPEReg-Net, a scene-appearance disentanglement framework that separates domain-invariant scene features from domain-specific appearance codes via Adaptive Instance Normalization (AdaIN), enabling direct image-to-image registration without explicit deformation field estimation. To exploit temporal structure in sequential acquisitions, we introduce a Global Position Encoding (GPE) module that combines learnable position embeddings with sinusoidal encoding and cross-frame attention, allowing the network to leverage context from neighboring frames for improved temporal coherence. On the OR-PAM-Reg-4K benchmark (432 test samples), GPEReg-Net achieves NCC of 0.953, SSIM of 0.932, and PSNR of 34.49dB, surpassing the state-of-the-art by 3.8% in SSIM and 1.99dB in PSNR while maintaining competitive NCC. Code is available at .

</details>


### [8] [Non-Contact Physiological Monitoring in Pediatric Intensive Care Units via Adaptive Masking and Self-Supervised Learning](https://arxiv.org/abs/2602.15967)
*Mohamed Khalil Ben Salah,Philippe Jouvet,Rita Noumeir*

Main category: cs.CV

TL;DR: 该论文提出了一种基于VisionMamba、自适应掩蔽和教师-学生蒸馏的自监督预训练框架，旨在改善儿科重症监护室（PICU）中的远程光电容积描记（rPPG）心率监测。该框架在标准掩蔽自编码器基础上将平均绝对误差（MAE）降低了42%，并比PhysFormer高出31%，最终MAE达到3.2 bpm。


<details>
  <summary>Details</summary>
Motivation: 儿科重症监护室（PICU）中持续的生命体征监测对于早期发现临床恶化和有效的临床决策至关重要。然而，脉搏血氧仪等接触式传感器可能导致皮肤刺激、增加感染风险并引起患者不适。远程光电容积描记（rPPG）提供了一种使用面部视频监测心率的非接触式替代方案，但由于运动伪影、遮挡、可变光照以及实验室与临床数据之间的领域偏移，在PICU中仍未得到充分利用。

Method: 本研究引入了一个基于渐进式课程策略的自监督预训练框架，用于PICU环境中的rPPG估计。该方法利用VisionMamba架构并集成了一个自适应掩蔽机制，其中一个轻量级基于Mamba的控制器分配时空重要性分数以指导概率性补丁采样。这种策略动态地增加了重建难度，同时保留了生理相关性。为解决标记临床数据不足的问题，研究采用了教师-学生蒸馏设置。一个在公共数据集上训练的监督专家模型向学生模型提供潜在的生理指导。课程分为三个阶段：干净的公共视频、合成遮挡场景和来自500名儿科患者的未标记视频。

Result: 该框架相对于标准掩蔽自编码器，平均绝对误差（MAE）降低了42%，并比PhysFormer高出31%，最终MAE达到3.2 bpm。该模型在没有明确区域兴趣提取的情况下，持续关注富含脉搏的区域，并在临床遮挡和噪声下表现出鲁棒性。

Conclusion: 所提出的自监督预训练框架显著改善了在充满挑战的PICU环境中的rPPG估计，提供了一种能够适应临床复杂性的强大非接触式心率监测解决方案，优于现有方法并解决了数据稀缺和环境鲁棒性等关键限制。

Abstract: Continuous monitoring of vital signs in Pediatric Intensive Care Units (PICUs) is essential for early detection of clinical deterioration and effective clinical decision-making. However, contact-based sensors such as pulse oximeters may cause skin irritation, increase infection risk, and lead to patient discomfort. Remote photoplethysmography (rPPG) offers a contactless alternative to monitor heart rate using facial video, but remains underutilized in PICUs due to motion artifacts, occlusions, variable lighting, and domain shifts between laboratory and clinical data. We introduce a self-supervised pretraining framework for rPPG estimation in the PICU setting, based on a progressive curriculum strategy. The approach leverages the VisionMamba architecture and integrates an adaptive masking mechanism, where a lightweight Mamba-based controller assigns spatiotemporal importance scores to guide probabilistic patch sampling. This strategy dynamically increases reconstruction difficulty while preserving physiological relevance. To address the lack of labeled clinical data, we adopt a teacher-student distillation setup. A supervised expert model, trained on public datasets, provides latent physiological guidance to the student. The curriculum progresses through three stages: clean public videos, synthetic occlusion scenarios, and unlabeled videos from 500 pediatric patients. Our framework achieves a 42% reduction in mean absolute error relative to standard masked autoencoders and outperforms PhysFormer by 31%, reaching a final MAE of 3.2 bpm. Without explicit region-of-interest extraction, the model consistently attends to pulse-rich areas and demonstrates robustness under clinical occlusions and noise.

</details>


### [9] [LAND: A Longitudinal Analysis of Neuromorphic Datasets](https://arxiv.org/abs/2602.15973)
*Gregory Cohen,Alexandre Marcireau*

Main category: cs.CV

TL;DR: 这篇综述探讨了神经形态工程中的数据问题，包括对更多数据的需求、现有数据集的发现、理解和使用困难、缺乏标准化，以及合成数据集的兴起。它还引入了元数据集的概念，作为减少对更多数据需求和消除潜在偏差的一种方式。


<details>
  <summary>Details</summary>
Motivation: 神经形态工程存在数据问题，尽管神经形态数据集数量激增，但许多研究仍指出需要更多甚至更大的数据集。这部分是由于现代深度学习方法所需的数据量巨大，也源于现有神经形态数据集的现状及其在查找、理解目的和确定底层任务性质方面的困难，以及下载和使用这些数据集的实际困难。

Method: 本综述首先概述了423个现有神经形态数据集，然后探讨了这些数据集的任务性质和底层数据结构。它分析了数据集的规模、缺乏标准化以及访问实际数据的困难。本综述还探讨了通过模拟或视频转事件方法创建的合成数据集的优势和潜在缺陷，并引入了从现有数据集创建元数据集的概念。

Result: 分析显示了现有数据集因其规模、缺乏标准化以及难以访问实际数据而带来的困难。研究还强调了个体数据集规模的增长以及处理数据所涉及的复杂性。更重要的是，合成数据集（通过模拟或视频转事件方法创建）的数量正在增加，并讨论了模拟数据在测试现有算法和应用方面的益处以及探索神经形态技术新应用时可能存在的陷阱。

Conclusion: 本综述提出，从现有数据集中创建元数据集是一种减少对更多数据需求并消除因同时定义数据集和任务而产生的潜在偏差的方法，以应对神经形态工程中的数据挑战。

Abstract: Neuromorphic engineering has a data problem. Despite the meteoric rise in the number of neuromorphic datasets published over the past ten years, the conclusion of a significant portion of neuromorphic research papers still states that there is a need for yet more data and even larger datasets. Whilst this need is driven in part by the sheer volume of data required by modern deep learning approaches, it is also fuelled by the current state of the available neuromorphic datasets and the difficulties in finding them, understanding their purpose, and determining the nature of their underlying task. This is further compounded by practical difficulties in downloading and using these datasets. This review starts by capturing a snapshot of the existing neuromorphic datasets, covering over 423 datasets, and then explores the nature of their tasks and the underlying structure of the presented data. Analysing these datasets shows the difficulties arising from their size, the lack of standardisation, and difficulties in accessing the actual data. This paper also highlights the growth in the size of individual datasets and the complexities involved in working with the data. However, a more important concern is the rise of synthetic datasets, created by either simulation or video-to-events methods. This review explores the benefits of simulated data for testing existing algorithms and applications, highlighting the potential pitfalls for exploring new applications of neuromorphic technologies. This review also introduces the concepts of meta-datasets, created from existing datasets, as a way of both reducing the need for more data, and to remove potential bias arising from defining both the dataset and the task.

</details>


### [10] [SAM 3D Body: Robust Full-Body Human Mesh Recovery](https://arxiv.org/abs/2602.15989)
*Xitong Yang,Devansh Kukreja,Don Pinkus,Anushka Sagar,Taosha Fan,Jinhyung Park,Soyong Shin,Jinkun Cao,Jiawei Liu,Nicolas Ugrinovic,Matt Feiszli,Jitendra Malik,Piotr Dollar,Kris Kitani*

Main category: cs.CV

TL;DR: SAM 3D Body (3DB)是一个可提示的单图像全身3D人体网格恢复(HMR)模型，它利用新的参数化网格表示Momentum Human Rig (MHR)，在各种野外条件下表现出最先进的性能、强大的泛化能力和一致的准确性。它支持辅助提示，并通过多阶段注释管道和高效数据引擎进行训练，开源。评估结果显示其在泛化能力和性能上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单图像全身3D人体网格恢复(HMR)方面可能存在泛化能力和在多样化野外条件下的准确性问题，需要一个能同时估计身体、脚和手的姿态，并具有强大泛化能力和一致准确性的模型。

Method: 1. 引入SAM 3D Body (3DB)模型，用于单图像全身3D人体网格恢复。
2. 采用新的参数化网格表示Momentum Human Rig (MHR)，该表示解耦了骨骼结构和表面形状。
3. 模型采用编码器-解码器架构，并支持2D关键点和掩码等辅助提示，以实现用户引导的推理。
4. 通过多阶段注释管道（结合手动关键点注释、可微分优化、多视图几何和密集关键点检测）获取高质量注释。
5. 利用数据引擎高效选择和处理数据，确保数据多样性（包括不寻常的姿势和罕见的成像条件）。

Result: 1. SAM 3D Body (3DB)在单图像全身3D人体网格恢复中表现出最先进的性能、强大的泛化能力和在多样化野外条件下的一致准确性。
2. 该模型能估计身体、脚和手的姿态。
3. 在定性用户偏好研究和传统定量分析中，与现有方法相比，展示出卓越的泛化能力和显著改进。

Conclusion: SAM 3D Body (3DB)及其核心表示Momentum Human Rig (MHR)为单图像全身3D人体网格恢复提供了一个高效且性能优越的解决方案。这些模型具有强大的泛化能力和准确性，并且已经开源，为该领域未来的研究和应用奠定了基础。

Abstract: We introduce SAM 3D Body (3DB), a promptable model for single-image full-body 3D human mesh recovery (HMR) that demonstrates state-of-the-art performance, with strong generalization and consistent accuracy in diverse in-the-wild conditions. 3DB estimates the human pose of the body, feet, and hands. It is the first model to use a new parametric mesh representation, Momentum Human Rig (MHR), which decouples skeletal structure and surface shape. 3DB employs an encoder-decoder architecture and supports auxiliary prompts, including 2D keypoints and masks, enabling user-guided inference similar to the SAM family of models. We derive high-quality annotations from a multi-stage annotation pipeline that uses various combinations of manual keypoint annotation, differentiable optimization, multi-view geometry, and dense keypoint detection. Our data engine efficiently selects and processes data to ensure data diversity, collecting unusual poses and rare imaging conditions. We present a new evaluation dataset organized by pose and appearance categories, enabling nuanced analysis of model behavior. Our experiments demonstrate superior generalization and substantial improvements over prior methods in both qualitative user preference studies and traditional quantitative analysis. Both 3DB and MHR are open-source.

</details>


### [11] [MedProbCLIP: Probabilistic Adaptation of Vision-Language Foundation Model for Reliable Radiograph-Report Retrieval](https://arxiv.org/abs/2602.16019)
*Ahmad Elallaf,Yu Zhang,Yuktha Priya Masupalli,Jeong Yang,Young Lee,Zechun Cao,Gongbo Liang*

Main category: cs.CV

TL;DR: MedProbCLIP是一个概率视觉-语言学习框架，通过高斯嵌入和概率对比目标提升胸部X射线和放射学报告的表示学习及检索，解决了确定性模型在生物医学应用中可靠性不足的问题，并在MIMIC-CXR数据集上取得了优于基线模型的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言基础模型在生物医学应用中，其确定性嵌入在可靠性方面表现不足，无法满足高风险生物医学应用的需求。

Method: MedProbCLIP将图像和文本表示建模为高斯嵌入，采用概率对比目标来捕获不确定性和多对多对应关系。它通过变分信息瓶颈（VIB）减少过度自信的预测，并在训练过程中使用多视图X射线编码和多节报告编码提供细粒度监督，但在推理时仅需单张X射线和单份报告。

Result: 在MIMIC-CXR数据集上，MedProbCLIP在检索和零样本分类方面均优于包括CLIP、CXR-CLIP和PCME++在内的确定性及概率基线模型。此外，它在校准、风险覆盖行为、选择性检索可靠性以及对临床相关损坏的鲁棒性方面表现出色。

Conclusion: MedProbCLIP通过引入概率视觉-语言建模，显著提升了放射学图像-文本检索系统的可信度和安全性。

Abstract: Vision-language foundation models have emerged as powerful general-purpose representation learners with strong potential for multimodal understanding, but their deterministic embeddings often fail to provide the reliability required for high-stakes biomedical applications. This work introduces MedProbCLIP, a probabilistic vision-language learning framework for chest X-ray and radiology report representation learning and bidirectional retrieval. MedProbCLIP models image and text representations as Gaussian embeddings through a probabilistic contrastive objective that explicitly captures uncertainty and many-to-many correspondences between radiographs and clinical narratives. A variational information bottleneck mitigates overconfident predictions, while MedProbCLIP employs multi-view radiograph encoding and multi-section report encoding during training to provide fine-grained supervision for clinically aligned correspondence, yet requires only a single radiograph and a single report at inference. Evaluated on the MIMIC-CXR dataset, MedProbCLIP outperforms deterministic and probabilistic baselines, including CLIP, CXR-CLIP, and PCME++, in both retrieval and zero-shot classification. Beyond accuracy, MedProbCLIP demonstrates superior calibration, risk-coverage behavior, selective retrieval reliability, and robustness to clinically relevant corruptions, underscoring the value of probabilistic vision-language modeling for improving the trustworthiness and safety of radiology image-text retrieval systems.

</details>


### [12] [OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis](https://arxiv.org/abs/2602.16110)
*Tianwei Lin,Zhongwei Qiu,Wenqiao Zhang,Jiang Liu,Yihan Xie,Mingjian Gao,Zhenxuan Fan,Zhaocheng Li,Sijing Li,Zhongle Xie,Peng LU,Yueting Zhuang,Yingda Xia,Ling Zhang,Beng Chin Ooi*

Main category: cs.CV

TL;DR: OmniCT是一个统一的切片-体素LVLM，用于CT场景，通过空间一致性增强和器官级语义增强，解决了现有LVLM在CT切片和体素理解上的局限性，并在广泛的临床任务中显著优于现有方法，建立了医学影像理解的新范式。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLM在CT切片与体素理解上存在碎片化：切片驱动的LVLM泛化能力强但缺乏跨切片空间一致性，而体素驱动的LVLMs能捕获体素语义但粒度粗糙且与切片输入兼容性差。这种统一建模范式的缺失是医学LVLM临床转化的主要瓶颈。

Method: OmniCT通过三方面贡献实现：(i) 空间一致性增强（SCE）：结合体素切片组合和三轴位置嵌入来引入体素一致性，并采用MoE混合投影实现高效切片-体素适应。(ii) 器官级语义增强（OSE）：通过分割和ROI定位明确对齐解剖区域，强调病灶和器官级别的语义。(iii) MedEval-CT：构建了最大的切片-体素CT数据集和混合基准，集成了全面的指标用于统一评估。

Result: OmniCT在各种临床任务中始终以显著优势超越现有方法，并同时满足微观细节敏感性和宏观空间推理的需求。

Conclusion: OmniCT为跨模态医学影像理解建立了一种新范式，解决了现有LVLM在CT解释中的不足。

Abstract: Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both slice-driven local features (e.g., sub-centimeter nodules, lesion boundaries) and volume-driven spatial representations (e.g., tumor infiltration, inter-organ anatomical relations). However, existing Large Vision-Language Models (LVLMs) remain fragmented in CT slice versus volumetric understanding: slice-driven LVLMs show strong generalization but lack cross-slice spatial consistency, while volume-driven LVLMs explicitly capture volumetric semantics but suffer from coarse granularity and poor compatibility with slice inputs. The absence of a unified modeling paradigm constitutes a major bottleneck for the clinical translation of medical LVLMs. We present OmniCT, a powerful unified slice-volume LVLM for CT scenarios, which makes three contributions: (i) Spatial Consistency Enhancement (SCE): volumetric slice composition combined with tri-axial positional embedding that introduces volumetric consistency, and an MoE hybrid projection enables efficient slice-volume adaptation; (ii) Organ-level Semantic Enhancement (OSE): segmentation and ROI localization explicitly align anatomical regions, emphasizing lesion- and organ-level semantics; (iii) MedEval-CT: the largest slice-volume CT dataset and hybrid benchmark integrates comprehensive metrics for unified evaluation. OmniCT consistently outperforms existing methods with a substantial margin across diverse clinical tasks and satisfies both micro-level detail sensitivity and macro-level spatial reasoning. More importantly, it establishes a new paradigm for cross-modal medical imaging understanding.

</details>


### [13] [CHAI: CacHe Attention Inference for text2video](https://arxiv.org/abs/2602.16132)
*Joel Mathew Cherian,Ashutosh Muralidhara Bharadwaj,Vima Gupta,Anand Padmanabha Iyer*

Main category: cs.CV

TL;DR: CHAI利用跨推理缓存和缓存注意力机制，通过在语义相关提示之间重用缓存的潜在变量，显著加速文本到视频扩散模型的推理过程，同时保持视频质量，甚至可以在少数去噪步骤下生成高质量视频。


<details>
  <summary>Details</summary>
Motivation: 文本到视频扩散模型由于3D潜在变量的顺序去噪而速度缓慢。现有加速方法要么需要昂贵的模型再训练，要么使用启发式跳步但难以在减少去噪步数时保持视频质量。

Method: 论文提出了CHAI，它利用跨推理缓存来减少延迟并保持视频质量。核心是引入了缓存注意力（Cache Attention），这是一种有效的方法，用于关注跨推理潜在变量中的共享对象/场景。这种选择性注意力机制能够有效重用语义相关提示之间的缓存潜在变量，从而实现高缓存命中率。

Result: 通过缓存注意力，可以在少至8个去噪步骤下生成高质量视频。当集成到整体系统中时，CHAI比基线OpenSora 1.2快1.65倍至3.35倍，同时保持了视频质量。

Conclusion: CHAI通过引入跨推理缓存和缓存注意力机制，成功解决了文本到视频扩散模型推理速度慢的问题，实现了显著的加速并保持了视频生成质量。

Abstract: Text-to-video diffusion models deliver impressive results but remain slow because of the sequential denoising of 3D latents. Existing approaches to speed up inference either require expensive model retraining or use heuristic-based step skipping, which struggles to maintain video quality as the number of denoising steps decreases. Our work, CHAI, aims to use cross-inference caching to reduce latency while maintaining video quality. We introduce Cache Attention as an effective method for attending to shared objects/scenes across cross-inference latents. This selective attention mechanism enables effective reuse of cached latents across semantically related prompts, yielding high cache hit rates. We show that it is possible to generate high-quality videos using Cache Attention with as few as 8 denoising steps. When integrated into the overall system, CHAI is 1.65x - 3.35x faster than baseline OpenSora 1.2 while maintaining video quality.

</details>


### [14] [IRIS: Intent Resolution via Inference-time Saccades for Open-Ended VQA in Large Vision-Language Models](https://arxiv.org/abs/2602.16138)
*Parsa Madinei,Srijita Karmakar,Russell Cohen Hoffing,Felix Gervitz,Miguel P. Eckstein*

Main category: cs.CV

TL;DR: IRIS是一种无需训练的新方法，通过实时眼动追踪数据解决开放式VQA中的歧义，显著提升了歧义问题上的准确率（从35.2%到77.2%），并提供了新的数据集、协议和评估工具。


<details>
  <summary>Details</summary>
Motivation: 解决开放式视觉问答（VQA）中的歧义问题，尤其是大型视觉语言模型（VLMs）在处理歧义问题时存在的挑战。该研究旨在利用实时用户意图（通过眼动追踪）来提高VQA的准确性。

Method: 该研究引入了IRIS，一种无需训练的方法，利用实时眼动追踪数据（特别是参与者开始口头提问时最近的注视点）来解决开放式VQA中的歧义。研究团队进行了一项包含500对独特图像-问题的用户研究，并在最先进的视觉语言模型（VLMs）上进行了评估。

Result: 在歧义问题上，利用IRIS方法的响应准确率提高了两倍多（从35.2%增至77.2%），同时在无歧义查询上保持了性能。实验表明，在参与者开始口头提问时最接近的注视点对于大型VLMs的消歧最有信息量。该方法在不同架构的最先进VLMs上都显示出一致的改进。此外，研究还发布了一个新的基准数据集、一个新颖的实时交互协议和一个评估套件。

Conclusion: IRIS通过实时眼动追踪有效解决了VQA中的歧义问题，显著提升了大型视觉语言模型在歧义问题上的表现，并表明凝视数据对于VQA消歧的价值。他们还发布了新的基准数据集、实时交互协议和评估套件。

Abstract: We introduce IRIS (Intent Resolution via Inference-time Saccades), a novel training-free approach that uses eye-tracking data in real-time to resolve ambiguity in open-ended VQA. Through a comprehensive user study with 500 unique image-question pairs, we demonstrate that fixations closest to the time participants start verbally asking their questions are the most informative for disambiguation in Large VLMs, more than doubling the accuracy of responses on ambiguous questions (from 35.2% to 77.2%) while maintaining performance on unambiguous queries. We evaluate our approach across state-of-the-art VLMs, showing consistent improvements when gaze data is incorporated in ambiguous image-question pairs, regardless of architectural differences. We release a new benchmark dataset to use eye movement data for disambiguated VQA, a novel real-time interactive protocol, and an evaluation suite.

</details>


### [15] [Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing](https://arxiv.org/abs/2602.16149)
*Huichan Seo,Minki Hong,Sieun Choi,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 本研究揭示了图像到图像（I2I）编辑中存在人口统计学偏差，发现身份保留失败普遍且不均衡，并由社会先验塑造。研究提出了两种失败模式：软擦除和刻板印象替换，并通过受控基准测试和评估证实了这些问题。最后，发现提示级身份约束可在不更新模型的情况下显著改善少数群体的身份保留。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）生成中的人口统计学偏差已得到充分研究，但在指令引导的图像到图像（I2I）编辑中，与人口统计学相关的失败模式仍未得到充分探索。本研究旨在探讨在开放权重I2I编辑器中，相同的编辑指令是否会导致不同人口统计学主体产生系统性差异的结果。

Method: 通过创建受控基准测试，该研究生成并编辑了基于种族、性别和年龄条件的肖像，并使用诊断提示集。评估方法包括视觉语言模型（VLM）评分和人工评估，以识别两种失败模式：软擦除（编辑被削弱或忽略）和刻板印象替换（引入未请求的刻板印象属性）。此外，还测试了在提示级别添加身份约束的效果。

Result: 分析表明，身份保留失败普遍存在，且在不同人口统计学群体中表现出不均衡，这些失败受到隐含社会先验（包括职业驱动的性别推断）的影响。此外，研究发现，在不更新模型的情况下，提示级别的身份约束可以显著减少少数群体的图像人口统计学变化，而对多数群体的肖像影响不大，这揭示了当前编辑器中存在不对称的身份先验。

Conclusion: 身份保留是I2I编辑中一个核心且存在人口统计学不均衡的失败模式，这激发了开发人口统计学鲁棒的编辑系统的需求。

Abstract: Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-guided image-to-image (I2I) editing remain underexplored. We examine whether identical edit instructions yield systematically different outcomes across subject demographics in open-weight I2I editors. We formalize two failure modes: Soft Erasure, where edits are silently weakened or ignored in the output image, and Stereotype Replacement, where edits introduce unrequested, stereotype-consistent attributes. We introduce a controlled benchmark that probes demographic-conditioned behavior by generating and editing portraits conditioned on race, gender, and age using a diagnostic prompt set, and evaluate multiple editors with vision-language model (VLM) scoring and human evaluation. Our analysis shows that identity preservation failures are pervasive, demographically uneven, and shaped by implicit social priors, including occupation-driven gender inference. Finally, we demonstrate that a prompt-level identity constraint, without model updates, can substantially reduce demographic change for minority groups while leaving majority-group portraits largely unchanged, revealing asymmetric identity priors in current editors. Together, our findings establish identity preservation as a central and demographically uneven failure mode in I2I editing and motivate demographic-robust editing systems. Project page:

</details>


### [16] [EasyControlEdge: A Foundation-Model Fine-Tuning for Edge Detection](https://arxiv.org/abs/2602.16238)
*Hiroki Nakamura,Hiroto Iino,Masashi Okada,Tadahiro Taniguchi*

Main category: cs.CV

TL;DR: EasyControlEdge 提出一种将图像生成基础模型应用于边缘检测的方法，通过利用其预训练先验和迭代细化能力，实现清晰、数据高效的边缘检测，并通过引入边缘导向目标和无条件动态指导，在有限数据和高清晰度要求下取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 在真实世界的边缘检测中（例如，平面图墙壁、卫星道路/建筑物和医疗器官边界），清晰度和数据效率至关重要。然而，使用有限的训练样本生成清晰的原始边缘图仍然具有挑战性。尽管图像生成基础模型在许多下游任务中表现良好，但其在数据高效传输和用于高频细节保留的迭代细化方面的预训练先验能力，在边缘检测领域尚未得到充分利用。

Method: EasyControlEdge 通过对图像生成基础模型进行边缘专业化改造来实现。具体方法包括：引入一个带有高效像素空间损失的边缘导向目标函数，以更好地使基础模型适应边缘检测任务；在推理阶段，引入基于无条件动态的指导，使得单一模型能够通过指导尺度控制边缘密度。

Result: 在BSDS500、NYUDv2、BIPED和CubiCasa数据集上的实验表明，EasyControlEdge 与最先进的方法相比，取得了持续的性能提升，尤其在无需后处理的清晰度评估和有限训练数据的情况下，表现出显著优势。

Conclusion: EasyControlEdge 成功地将图像生成基础模型应用于边缘检测，实现了清晰且数据高效的边缘检测，尤其在无需后处理的清晰度评估和有限训练数据场景下，优于现有方法。

Abstract: We propose EasyControlEdge, adapting an image-generation foundation model to edge detection. In real-world edge detection (e.g., floor-plan walls, satellite roads/buildings, and medical organ boundaries), crispness and data efficiency are crucial, yet producing crisp raw edge maps with limited training samples remains challenging. Although image-generation foundation models perform well on many downstream tasks, their pretrained priors for data-efficient transfer and iterative refinement for high-frequency detail preservation remain underexploited for edge detection. To enable crisp and data-efficient edge detection using these capabilities, we introduce an edge-specialized adaptation of image-generation foundation models. To better specialize the foundation model for edge detection, we incorporate an edge-oriented objective with an efficient pixel-space loss. At inference, we introduce guidance based on unconditional dynamics, enabling a single model to control the edge density through a guidance scale. Experiments on BSDS500, NYUDv2, BIPED, and CubiCasa compare against state-of-the-art methods and show consistent gains, particularly under no-post-processing crispness evaluation and with limited training data.

</details>


### [17] [AFFMAE: Scalable and Efficient Vision Pretraining for Desktop Graphics Cards](https://arxiv.org/abs/2602.16249)
*David Smerkous,Zian Wang,Behzad Najafian*

Main category: cs.CV

TL;DR: AFFMAE是一种新的分层预训练框架，通过自适应、非网格token合并，解决了MAE在高分辨率图像上与分层架构结合时的计算和内存效率问题，实现了与ViT-MAE相似的性能，但FLOPs和内存使用大幅减少，训练速度更快。


<details>
  <summary>Details</summary>
Motivation: 自监督预训练虽然在计算机视觉领域取得了巨大进步，但高分辨率训练通常需要服务器规模的基础设施，限制了许多研究实验室开发领域基础模型。现有的掩码自编码器（MAE）通过仅编码可见token来减少计算，但将其与分层下采样架构结合时，由于密集的网格先验和掩码感知设计妥协，结构上仍存在挑战。

Method: 引入了AFFMAE，一个基于自适应、非网格token合并的掩码友好型分层预训练框架。它通过丢弃被掩码的token并仅在可见token上执行动态合并，消除了密集网格假设，同时保留了分层可扩展性。为解决此问题，开发了数值稳定的混合精度Flash风格的簇注意力核，并通过深度监督缓解了稀疏阶段的表示崩溃。

Result: 在等参数量下，AFFMAE在高分辨率电子显微镜分割任务上匹配了ViT-MAE的性能，同时将FLOPs降低了高达7倍，内存使用量减半，并在单个RTX 5090上实现了更快的训练。

Conclusion: AFFMAE提供了一种在资源受限环境下进行高分辨率图像分层自监督预训练的有效方法，使其在保持性能的同时，大幅降低了计算和内存需求，从而加速了研究和开发。

Abstract: Self-supervised pretraining has transformed computer vision by enabling data-efficient fine-tuning, yet high-resolution training typically requires server-scale infrastructure, limiting in-domain foundation model development for many research laboratories. Masked Autoencoders (MAE) reduce computation by encoding only visible tokens, but combining MAE with hierarchical downsampling architectures remains structurally challenging due to dense grid priors and mask-aware design compromises. We introduce AFFMAE, a masking-friendly hierarchical pretraining framework built on adaptive, off-grid token merging. By discarding masked tokens and performing dynamic merging exclusively over visible tokens, AFFMAE removes dense-grid assumptions while preserving hierarchical scalability. We developed numerically stable mixed-precision Flash-style cluster attention kernels, and mitigate sparse-stage representation collapse via deep supervision. On high-resolution electron microscopy segmentation, AFFMAE matches ViT-MAE performance at equal parameter count while reducing FLOPs by up to 7x, halving memory usage, and achieving faster training on a single RTX 5090. Code available at .

</details>


### [18] [Breaking the Sub-Millimeter Barrier: Eyeframe Acquisition from Color Images](https://arxiv.org/abs/2602.16281)
*Manel Guzmán,Antonio Agudo*

Main category: cs.CV

TL;DR: 本文提出了一种基于计算机视觉和多视图信息的新方法，用于眼框镜片追踪。该方法通过图像采集、眼框分割、深度估计和多视图处理，从静态彩色图像中实现精确测量，取代了传统机械追踪器，提高了眼镜师的工作效率。


<details>
  <summary>Details</summary>
Motivation: 传统的眼框镜片追踪方法依赖机械工具，需要精确的定位和校准，耗时且需要额外设备，导致眼镜师的工作流程效率低下。

Method: 本文提出了一种基于人工智能视觉的新方法，利用多视图信息。该算法使用InVision系统捕获的图像，完整的流程包括图像采集、眼框分割以将眼框从背景中分离、深度估计以获取3D空间信息，以及将分割后的RGB图像与深度数据整合进行精确眼框轮廓测量的多视图处理。

Result: 该方法从静态彩色图像中提供了与现有解决方案相媲美的测量结果，同时消除了对专业追踪设备的需求，并降低了光学技术人员的工作流程复杂性。

Conclusion: 该研究通过基于人工智能视觉和多视图信息的方法，成功解决了传统眼框镜片追踪效率低下的问题，提供了一种更高效、更简化的解决方案，减少了对专业设备的需求。

Abstract: Eyeframe lens tracing is an important process in the optical industry that requires sub-millimeter precision to ensure proper lens fitting and optimal vision correction. Traditional frame tracers rely on mechanical tools that need precise positioning and calibration, which are time-consuming and require additional equipment, creating an inefficient workflow for opticians. This work presents a novel approach based on artificial vision that utilizes multi-view information. The proposed algorithm operates on images captured from an InVision system. The full pipeline includes image acquisition, frame segmentation to isolate the eyeframe from background, depth estimation to obtain 3D spatial information, and multi-view processing that integrates segmented RGB images with depth data for precise frame contour measurement. To this end, different configurations and variants are proposed and analyzed on real data, providing competitive measurements from still color images with respect to other solutions, while eliminating the need for specialized tracing equipment and reducing workflow complexity for optical technicians.

</details>


### [19] [A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks](https://arxiv.org/abs/2602.16322)
*Santiago C. Vilabella,Pablo Pérez-Núñez,Beatriz Remeseiro*

Main category: cs.CV

TL;DR: 本研究提出通过自监督学习增强特征提取器，在未标记数据上训练，以减少对标记数据的依赖，并在目标检测等复杂任务中超越现有SOTA模型，提高特征表示的可靠性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型复杂性和规模的增长，用于训练深度学习模型的标记数据变得稀缺且成本高昂，尤其在目标检测等复杂任务中，数据标注需要大量时间和资源。

Method: 采用自监督学习策略，在未标记数据上训练模型以增强特征提取器。

Result: 所提出的模型在未标记数据上训练后，性能优于当前最先进的ImageNet预训练特征提取器，尤其在目标检测任务中表现突出。此外，该方法促使模型关注对象最相关的方面，从而获得了更好的特征表示，增强了模型的可靠性和鲁棒性。

Conclusion: 通过增强特征提取器并利用自监督学习策略，可以显著缓解标记数据稀缺的挑战，使模型在更少的标记数据下学习更有效的表示，并提升模型的可靠性和鲁棒性。

Abstract: In the fast-evolving field of artificial intelligence, where models are increasingly growing in complexity and size, the availability of labeled data for training deep learning models has become a significant challenge. Addressing complex problems like object detection demands considerable time and resources for data labeling to achieve meaningful results. For companies developing such applications, this entails extensive investment in highly skilled personnel or costly outsourcing. This research work aims to demonstrate that enhancing feature extractors can substantially alleviate this challenge, enabling models to learn more effective representations with less labeled data. Utilizing a self-supervised learning strategy, we present a model trained on unlabeled data that outperforms state-of-the-art feature extractors pre-trained on ImageNet and particularly designed for object detection tasks. Moreover, the results demonstrate that our approach encourages the model to focus on the most relevant aspects of an object, thus achieving better feature representations and, therefore, reinforcing its reliability and robustness.

</details>


### [20] [SCAR: Satellite Imagery-Based Calibration for Aerial Recordings](https://arxiv.org/abs/2602.16349)
*Henry Hölzemann,Michael Schleiss*

Main category: cs.CV

TL;DR: SCAR是一种利用地理参考卫星图像对航空视觉惯性系统进行长期自动校准细化的方法，它在现场部署条件下优于现有基线并显著减少误差。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于专门的校准操作或手动测量地面控制点，这对于长期现场部署效率低下。需要在现场部署条件下检测和纠正校准退化。

Method: SCAR通过将航空图像与从公开可用的正射影像和高程模型中导出的2D-3D对应关系对齐来估计内参和外参。它利用外部地理空间数据。

Result: SCAR在两年内进行的六次大规模航空活动中进行了评估，始终优于现有基线（Kalibr、COLMAP、VINS-Mono），大幅降低了中值重投影误差，并将这些校准增益转化为显著更低的视觉定位旋转误差和更高的姿态精度。

Conclusion: SCAR在长期航空操作中提供准确、稳健和可重复的校准，无需人工干预。

Abstract: We introduce SCAR, a method for long-term auto-calibration refinement of aerial visual-inertial systems that exploits georeferenced satellite imagery as a persistent global reference. SCAR estimates both intrinsic and extrinsic parameters by aligning aerial images with 2D--3D correspondences derived from publicly available orthophotos and elevation models. In contrast to existing approaches that rely on dedicated calibration maneuvers or manually surveyed ground control points, our method leverages external geospatial data to detect and correct calibration degradation under field deployment conditions. We evaluate our approach on six large-scale aerial campaigns conducted over two years under diverse seasonal and environmental conditions. Across all sequences, SCAR consistently outperforms established baselines (Kalibr, COLMAP, VINS-Mono), reducing median reprojection error by a large margin, and translating these calibration gains into substantially lower visual localization rotation errors and higher pose accuracy. These results demonstrate that SCAR provides accurate, robust, and reproducible calibration over long-term aerial operations without the need for manual intervention.

</details>


### [21] [Parameter-Free Adaptive Multi-Scale Channel-Spatial Attention Aggregation framework for 3D Indoor Semantic Scene Completion Toward Assisting Visually Impaired](https://arxiv.org/abs/2602.16385)
*Qi He,XiangXiang Wang,Jingtao Zhang,Yongbin Yu,Hongxiang Chu,Manping Fan,JingYe Cai,Zhenglin Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为自适应多尺度注意力聚合（AMAA）的框架，该框架基于MonoScene管道，旨在通过并行通道-空间注意力聚合和分层自适应特征门控策略，解决单目3D语义场景补全中体素特征可靠性和跨尺度信息传播的问题。AMAA在NYUv2基准测试中展示了优于MonoScene的性能提升，并可在嵌入式硬件上稳定运行，为视障用户的室内辅助系统提供了可靠且可部署的感知框架。


<details>
  <summary>Details</summary>
Motivation: 现有的单目语义场景补全（SSC）方法在2D-3D投影和多尺度融合过程中，缺乏对体素特征可靠性和跨尺度信息传播的明确建模和规范，导致投影扩散和特征纠缠，从而限制了结构连贯性。这对于为视障用户提供安全关键场景理解的室内辅助感知至关重要。

Method: 该论文提出了一种自适应多尺度注意力聚合（AMAA）框架，该框架构建在MonoScene管道之上。AMAA专注于单目SSC框架内的面向可靠性的特征调节。具体来说，通过并行的通道-空间注意力聚合，在语义和空间维度上联合校准提升的体素特征；同时，通过分层的自适应特征门控策略稳定多尺度编码器-解码器融合，该策略调节跨尺度的信息注入。

Result: 在NYUv2基准测试中，与MonoScene相比，AMAA取得了持续改进，而没有显著增加系统复杂性。AMAA实现了27.25%的SSC mIoU（+0.31）和43.10%的SC IoU（+0.59）。此外，在NVIDIA Jetson平台上的系统级部署验证了完整的AMAA框架可以在嵌入式硬件上稳定执行。

Conclusion: AMAA提高了单目语义场景补全的质量，并为针对视障用户的室内辅助系统提供了一个可靠且可部署的感知框架。

Abstract: In indoor assistive perception for visually impaired users, 3D Semantic Scene Completion (SSC) is expected to provide structurally coherent and semantically consistent occupancy under strictly monocular vision for safety-critical scene understanding. However, existing monocular SSC approaches often lack explicit modeling of voxel-feature reliability and regulated cross-scale information propagation during 2D-3D projection and multi-scale fusion, making them vulnerable to projection diffusion and feature entanglement and thus limiting structural address these challenges, this paper presents an Adaptive Multi-scale Attention Aggregation (AMAA) framework built upon the MonoScene pipeline. Rather than introducing a heavier backbone, AMAA focuses on reliability-oriented feature regulation within a monocular SSC framework. Specifically, lifted voxel features are jointly calibrated in semantic and spatial dimensions through parallel channel-spatial attention aggregation, while multi-scale encoder-decoder fusion is stabilized via a hierarchical adaptive feature-gating strategy that regulates information injection across on the NYUv2 benchmark demonstrate consistent improvements over MonoScene without significantly increasing system complexity: AMAA achieves 27.25% SSC mIoU (+0.31) and 43.10% SC IoU (+0.59). In addition, system-level deployment on an NVIDIA Jetson platform verifies that the complete AMAA framework can be executed stably on embedded hardware. Overall, AMAA improves monocular SSC quality and provides a reliable and deployable perception framework for indoor assistive systems targeting visually impaired users.

</details>


### [22] [ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding](https://arxiv.org/abs/2602.16412)
*Daichi Yashima,Shuhei Kurita,Yusuke Oda,Komei Sugiura*

Main category: cs.CV

TL;DR: ReMoRa是一个视频多模态大语言模型，它通过处理压缩表示（关键帧和运动表示）来解决长视频理解的挑战，实现了高效且有效的长视频处理。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在广泛任务中取得了显著成功，但长视频理解仍然是一个重大挑战。处理完整的RGB帧在计算上是不可行的且高度冗余的，因为自注意力机制的复杂度与序列长度呈平方关系。

Method: 本文提出了ReMoRa，一个直接操作视频压缩表示的视频多模态大语言模型。它保留稀疏的RGB关键帧用于外观信息，并编码时间动态为运动表示，作为光流的紧凑替代品。为了改进基于块的运动的噪声和低保真度，模型引入了一个模块来去噪并生成细粒度的运动表示。此外，ReMoRa以与序列长度呈线性关系的方式压缩这些特征。

Result: ReMoRa在多个具有挑战性的长视频理解基准测试中（包括LongVideoBench、NExT-QA和MLVU）表现优于基线方法。

Conclusion: ReMoRa通过有效处理压缩视频表示，证明了其在长视频理解方面的有效性。

Abstract: While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames is computationally intractable and highly redundant, as self-attention have quadratic complexity with sequence length. In this paper, we propose ReMoRa, a video MLLM that processes videos by operating directly on their compressed representations. A sparse set of RGB keyframes is retained for appearance, while temporal dynamics are encoded as a motion representation, removing the need for sequential RGB frames. These motion representations act as a compact proxy for optical flow, capturing temporal dynamics without full frame decoding. To refine the noise and low fidelity of block-based motions, we introduce a module to denoise and generate a fine-grained motion representation. Furthermore, our model compresses these features in a way that scales linearly with sequence length. We demonstrate the effectiveness of ReMoRa through extensive experiments across a comprehensive suite of long-video understanding benchmarks. ReMoRa outperformed baseline methods on multiple challenging benchmarks, including LongVideoBench, NExT-QA, and MLVU.

</details>


### [23] [Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing](https://arxiv.org/abs/2602.16455)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLMs）在图表解析等视觉感知任务中表现不佳，常出现数据遗漏、错位和幻觉。受人类“视觉锚点”策略启发，本文提出**视觉自我修正（VSR）**范式，使模型能生成、可视化并自我修正像素级定位。该范式通过**ChartVSR**应用于图表解析，分解为修正和解码两阶段，以实现准确的数据点定位和结构化数据解析。此外，还构建了更具挑战性的**ChartP-Bench**基准。VSR被提出作为一种通用的视觉反馈机制。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLMs）在文本推理和自我修正方面表现出色，但对于以视觉感知为核心的复杂任务（如图表解析）效果不佳。当前模型在处理视觉密集型图表时，常出现数据遗漏、错位和幻觉等错误。

Method: 1. 提出**视觉自我修正（Visual Self-Refine, VSR）**范式，其灵感来源于人类阅读复杂图表时使用手指作为“视觉锚点”的策略。
2. VSR的核心思想是使模型能够生成像素级定位输出，将其可视化，然后将这些可视化结果反馈给模型本身，使其能够直观地检查并纠正潜在的视觉感知错误。
3. 通过提出**ChartVSR**将VSR范式应用于图表解析领域。
4. ChartVSR将解析过程分解为两个阶段：
    *   **修正阶段（Refine Stage）**：迭代使用视觉反馈确保所有数据点的像素级定位准确性。
    *   **解码阶段（Decode Stage）**：使用这些经过验证的定位作为精确的视觉锚点来解析最终的结构化数据。
5. 构建了一个新的、极具挑战性的图表解析基准**ChartP-Bench**，以解决现有基准的局限性。

Result: ChartVSR通过VSR范式实现了对图表解析任务的改进，能够克服现有模型在处理视觉密集型图表时的数据遗漏、错位和幻觉问题。新构建的ChartP-Bench为图表解析提供了一个更具挑战性的评估工具。

Conclusion: VSR作为一种通用的视觉反馈机制，为增强一系列以视觉为中心任务的准确性提供了一个有前景的新方向。该研究强调了通过视觉自我修正来提升LVLMs在复杂视觉感知任务中的表现。

Abstract: While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often struggle with visually dense charts, leading to errors like data omission, misalignment, and hallucination. Inspired by the human strategy of using a finger as a ``visual anchor'' to ensure accuracy when reading complex charts, we propose a new paradigm named Visual Self-Refine (VSR). The core idea of VSR is to enable a model to generate pixel-level localization outputs, visualize them, and then feed these visualizations back to itself, allowing it to intuitively inspect and correct its own potential visual perception errors. We instantiate the VSR paradigm in the domain of Chart Parsing by proposing ChartVSR. This model decomposes the parsing process into two stages: a Refine Stage, where it iteratively uses visual feedback to ensure the accuracy of all data points' Pixel-level Localizations, and a Decode Stage, where it uses these verified localizations as precise visual anchors to parse the final structured data. To address the limitations of existing benchmarks, we also construct ChartP-Bench, a new and highly challenging benchmark for chart parsing. Our work also highlights VSR as a general-purpose visual feedback mechanism, offering a promising new direction for enhancing accuracy on a wide range of vision-centric tasks.

</details>


### [24] [Benchmarking Adversarial Robustness and Adversarial Training Strategies for Object Detection](https://arxiv.org/abs/2602.16494)
*Alexis Winter,Jean-Vincent Martini,Romaric Audigier,Angelique Loesch,Bertrand Luvison*

Main category: cs.CV

TL;DR: 目标检测模型容易受到对抗性攻击，但缺乏标准化评估。本文提出了一个统一的基准框架来公平比较攻击，并调查了攻击在不同架构间的可迁移性以及最有效的对抗性训练策略。研究发现，现代攻击对基于Transformer的架构缺乏可迁移性，且最鲁棒的对抗性训练策略是利用混合高扰动攻击的数据集。


<details>
  <summary>Details</summary>
Motivation: 自动化系统中的目标检测模型易受对抗性攻击，构成严重安全风险。目前针对这些模型的防御进展落后于分类任务，且缺乏标准化评估，导致难以彻底比较攻击或防御方法。

Method: 提出了一个统一的数字、非补丁式攻击基准框架，引入特定指标以区分定位和分类错误，并使用多种感知指标评估攻击成本。利用此基准对最先进的攻击和多种检测器进行了广泛实验。

Result: 现代对抗性攻击对目标检测模型表现出对基于Transformer的架构显著缺乏可迁移性。最鲁棒的对抗性训练策略是利用由不同目标（如空间和语义）的高扰动攻击混合组成的数据集，这优于单一攻击训练。

Conclusion: 本文通过提出统一的基准框架解决了目标检测模型对抗性攻击评估标准缺失的问题。研究得出结论，当前攻击对Vision Transformer架构的迁移性不佳，并且多样化的混合高扰动攻击是实现鲁棒对抗性训练的最佳方法。

Abstract: Object detection models are critical components of automated systems, such as autonomous vehicles and perception-based robots, but their sensitivity to adversarial attacks poses a serious security risk. Progress in defending these models lags behind classification, hindered by a lack of standardized evaluation. It is nearly impossible to thoroughly compare attack or defense methods, as existing work uses different datasets, inconsistent efficiency metrics, and varied measures of perturbation cost. This paper addresses this gap by investigating three key questions: (1) How can we create a fair benchmark to impartially compare attacks? (2) How well do modern attacks transfer across different architectures, especially from Convolutional Neural Networks to Vision Transformers? (3) What is the most effective adversarial training strategy for robust defense? To answer these, we first propose a unified benchmark framework focused on digital, non-patch-based attacks. This framework introduces specific metrics to disentangle localization and classification errors and evaluates attack cost using multiple perceptual metrics. Using this benchmark, we conduct extensive experiments on state-of-the-art attacks and a wide range of detectors. Our findings reveal two major conclusions: first, modern adversarial attacks against object detection models show a significant lack of transferability to transformer-based architectures. Second, we demonstrate that the most robust adversarial training strategy leverages a dataset composed of a mix of high-perturbation attacks with different objectives (e.g., spatial and semantic), which outperforms training on any single attack.

</details>


### [25] [DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images](https://arxiv.org/abs/2602.16502)
*Zeng Tao,Ying Jiang,Yunuo Chen,Tianyi Xie,Huamin Wang,Yingnian Wu,Yin Yang,Abishek Sampath Kumar,Kenji Tashiro,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 该论文提出了DressWild，一个新颖的前馈管道，能够从单张野外图像重建符合物理规律的2D缝纫图案和相应的3D服装。它利用视觉-语言模型和基于Transformer的编码器解决现有方法在处理多样姿态和视角方面的局限性，并提供高效可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈方法在处理多样姿态和视角的服装图案生成方面存在困难，而基于优化的方法计算成本高昂且难以扩展。服装建模和制造应用需要可编辑、可分离和可模拟的服装。

Method: 提出DressWild，一个前馈管道，从单张野外图像重建符合物理规律的2D缝纫图案和相应的3D服装。该方法利用视觉-语言模型（VLMs）在图像层面规范化姿态变化，然后提取姿态感知、3D信息的服装特征。这些特征通过基于Transformer的编码器融合，并用于预测缝纫图案参数。这些参数可直接应用于物理模拟、纹理合成和多层虚拟试穿。

Result: 该方法能够从野外图像中鲁棒地恢复多样化的缝纫图案和相应的3D服装，无需多视角输入或迭代优化。

Conclusion: DressWild为逼真的服装模拟和动画提供了一个高效且可扩展的解决方案。

Abstract: Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.

</details>


### [26] [Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding](https://arxiv.org/abs/2602.16545)
*Kaiting Liu,Hazel Doughty*

Main category: cs.CV

TL;DR: 提出“类别拆分”任务，通过零样本编辑和低样本微调，在不牺牲整体性能的情况下，高效地将视频分类器中的粗糙类别细化为更精细的子类别。


<details>
  <summary>Details</summary>
Motivation: 现有的视频识别模型通常在固定且粗糙的分类体系上训练，难以适应任务和定义的变化，无法识别新兴的细微区别。重新收集标注和再训练的成本高昂，因此需要一种更经济高效的方法来细化现有类别。

Method: 本文提出了一种零样本编辑方法，该方法利用视频分类器潜在的组合结构，无需额外数据即可揭示细粒度区别。在此基础上，结合低样本微调（low-shot fine-tuning），并通过零样本初始化优化微调过程。

Result: 在新的视频类别拆分基准测试中，该方法显著优于视觉-语言基线，在新的拆分类别上提高了准确性，同时没有牺牲其他类别的性能。

Conclusion: 该研究引入了“类别拆分”的新任务，提出了一种零样本编辑方法，并通过低样本微调进一步优化，有效地在不牺牲其他类别性能的情况下，提高了视频分类模型对细粒度类别的识别精度。这为视频分类模型适应新任务和定义提供了高效且可扩展的解决方案。

Abstract: Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce category splitting, a new task where an existing classifier is edited to refine a coarse category into finer subcategories, while preserving accuracy elsewhere. We propose a zero-shot editing method that leverages the latent compositional structure of video classifiers to expose fine-grained distinctions without additional data. We further show that low-shot fine-tuning, while simple, is highly effective and benefits from our zero-shot initialization. Experiments on our new video benchmarks for category splitting demonstrate that our method substantially outperforms vision-language baselines, improving accuracy on the newly split categories without sacrificing performance on the rest. Project page: .

</details>


### [27] [Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face](https://arxiv.org/abs/2602.16569)
*Nicolò Di Domenico,Annalisa Franco,Matteo Ferrara,Davide Maltoni*

Main category: cs.CV

TL;DR: 本文提出了一种基于Arc2Face的新型人脸变形技术，该技术是一种身份条件人脸基础模型，能够从紧凑的身份表示中合成逼真的人脸图像，并实现了与最先进的基于landmark的技术相当的变形攻击潜力。


<details>
  <summary>Details</summary>
Motivation: 人脸变形攻击被广泛认为是电子身份证件中人脸识别系统面临的最具挑战性的威胁之一，这些攻击利用了许多国家护照注册程序中的关键漏洞，即面部图像通常在没有监督的活体捕获过程下获取。

Method: 本文提出了一种基于Arc2Face（一种身份条件人脸基础模型，能够从紧凑的身份表示中合成逼真的人脸图像）的新型人脸变形技术。

Result: 实验结果表明，所提出的深度学习方法在两个大规模隔离人脸变形攻击检测数据集以及两个源自FEI和ONOT的新型变形人脸数据集上，实现了与基于landmark技术相当的变形攻击潜力，而后者传统上被认为是最具挑战性的方法。

Conclusion: 这些发现证实了所提出的方法在变形生成过程中有效保留和管理身份信息的能力。

Abstract: Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.

</details>


### [28] [A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification](https://arxiv.org/abs/2602.16590)
*Qi You,Yitai Cheng,Zichao Zeng,James Haworth*

Main category: cs.CV

TL;DR: CLIP-MHAdapter通过在补丁tokens上应用多头自注意力机制，提高了街景图像属性分类中细粒度属性的捕捉能力，在低计算成本下达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 街景图像属性分类对自动驾驶、城市分析和高清地图构建至关重要，但计算成本高昂。现有基于CLIP的适应方法主要依赖全局图像嵌入，难以捕捉复杂街景中必需的细粒度、局部属性。

Method: 提出CLIP-MHAdapter，一种轻量级CLIP适应范例的变体。它通过在补丁（patch）tokens上附加一个带有多头自注意力机制的瓶颈MLP来建模补丁间的依赖关系，以捕捉细粒度属性。

Result: CLIP-MHAdapter仅用约140万可训练参数，在Global StreetScapes数据集的八项属性分类任务上实现了卓越或具有竞争力的准确性，取得了新的最先进结果，同时保持了较低的计算成本。

Conclusion: CLIP-MHAdapter通过引入多头自注意力机制处理补丁tokens，有效解决了现有CLIP适应方法在街景图像属性分类中细粒度属性捕捉不足的问题，在保持计算效率的同时显著提升了性能。

Abstract: Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at .

</details>


### [29] [Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge](https://arxiv.org/abs/2602.16664)
*Jiaming Liu,Felix Petersen,Yunhe Gao,Yabin Zhang,Hyojin Kim,Akshay S. Chaudhari,Yu Sun,Stefano Ermon,Sergios Gatidis*

Main category: cs.CV

TL;DR: 本文提出了自监督语义桥（SSB）框架，它将外部语义先验集成到扩散桥模型中，从而在无需跨域监督的情况下实现空间上忠实的图像到图像翻译。SSB通过利用自监督视觉编码器学习对外观变化不变但捕获几何结构的表示，形成一个共享的潜在空间来条件化扩散桥。在具有挑战性的医学图像合成任务中，SSB在域内和域外设置下均优于现有方法，并可轻松扩展到高质量的文本引导编辑。


<details>
  <summary>Details</summary>
Motivation: 对抗性扩散方法在训练过程中需要目标域对抗性损失，这限制了其对未见数据的泛化能力。扩散反演方法由于不完善的反演到噪声潜在表示，通常会产生低保真度的翻译结果。

Method: 我们提出了自监督语义桥（SSB），一个将外部语义先验集成到扩散桥模型中的通用框架。其核心思想是利用自监督视觉编码器学习对外观变化不变但捕获几何结构的表示，从而形成一个共享的潜在空间来条件化扩散桥。

Result: 广泛的实验表明，SSB在具有挑战性的医学图像合成任务中，无论是在域内还是域外设置下，都优于强大的现有方法，并且可以轻松扩展到高质量的文本引导编辑。

Conclusion: SSB通过集成自监督语义先验，提供了一个多功能的框架，实现了空间上忠实的无配对图像到图像翻译，有效解决了现有对抗性扩散和扩散反演方法的关键局限性。

Abstract: Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-inversion methods often produce low-fidelity translations due to imperfect inversion into noise-latent representations. In this work, we propose the Self-Supervised Semantic Bridge (SSB), a versatile framework that integrates external semantic priors into diffusion bridge models to enable spatially faithful translation without cross-domain supervision. Our key idea is to leverage self-supervised visual encoders to learn representations that are invariant to appearance changes but capture geometric structure, forming a shared latent space that conditions the diffusion bridges. Extensive experiments show that SSB outperforms strong prior methods for challenging medical image synthesis in both in-domain and out-of-domain settings, and extends easily to high-quality text-guided editing.

</details>


### [30] [PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction](https://arxiv.org/abs/2602.16669)
*Bo Lang,Nirav Savaliya,Zhihao Zheng,Jinglun Feng,Zheng-Hang Yeh,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: 提出了一种用于一致在线高清矢量化地图构建的端到端框架，通过地图实例跟踪和短期预测，解决了现有查询方法的时间不一致和不稳定性问题，并实现了优于SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于查询的高清地图构建方法常采用随机查询初始化和隐式时间建模，导致全局地图构建过程中出现时间不一致和不稳定性。

Method: 提出了一种端到端框架，用于一致在线高清矢量化地图构建。该框架包括：1. 语义感知查询生成器：利用空间对齐的语义掩码初始化查询，捕捉场景级上下文。2. 历史栅格化地图记忆模块：存储每个跟踪实例的细粒度实例级地图，提供显式历史先验。3. 历史地图引导模块：将栅格化地图信息整合到轨迹查询中，提高时间连续性。4. 短期未来引导模块：基于存储的历史轨迹预测地图实例的即时运动，利用预测的未来位置作为提示，避免不合理的预测并保持时间一致性。

Result: 在nuScenes和Argoverse2数据集上的大量实验表明，所提出的方法在效率良好的情况下，优于最先进（SOTA）的方法。

Conclusion: 通过结合地图实例跟踪和短期预测，该端到端框架成功解决了在线高清矢量化地图构建中的时间一致性问题，并展现出卓越的性能和效率。

Abstract: High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.

</details>


### [31] [VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection](https://arxiv.org/abs/2602.16681)
*Yingyuan Yang,Tian Lan,Yifei Gao,Yimeng Lu,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.CV

TL;DR: VETime是一个统一时间序列和视觉模态的TSAD框架，通过精细的视觉-时间对齐和动态融合，解决了现有模型在点异常和上下文异常检测中的局限性，并在零样本场景中表现出卓越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测（TSAD）基础模型面临一个根本性权衡：一维时间模型提供精细的点定位但缺乏全局上下文，而二维视觉模型捕捉全局模式但由于缺乏时间对齐和粗粒度点检测而存在信息瓶颈。

Method: VETime引入了可逆图像转换（Reversible Image Conversion）和补丁级时间对齐（Patch-Level Temporal Alignment）模块，以建立共享的视觉-时间线，同时设计了异常窗口对比学习（Anomaly Window Contrastive Learning）机制和任务自适应多模态融合（Task-Adaptive Multi-Modal Fusion）来整合两种模态的互补优势。

Result: VETime在零样本场景中显著优于现有最先进模型，实现了更高的定位精度和比当前基于视觉方法更低的计算开销。

Conclusion: VETime通过统一时间序列和视觉模态，有效解决了现有TSAD模型在细粒度定位和全局上下文理解之间的困境，实现了更好的性能和效率。

Abstract: Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual perspective, while 2D vision-based models capture global patterns but suffer from information bottlenecks due to a lack of temporal alignment and coarse-grained pointwise detection. To resolve this dilemma, we propose VETime, the first TSAD framework that unifies temporal and visual modalities through fine-grained visual-temporal alignment and dynamic fusion. VETime introduces a Reversible Image Conversion and a Patch-Level Temporal Alignment module to establish a shared visual-temporal timeline, preserving discriminative details while maintaining temporal sensitivity. Furthermore, we design an Anomaly Window Contrastive Learning mechanism and a Task-Adaptive Multi-Modal Fusion to adaptively integrate the complementary perceptual strengths of both modalities. Extensive experiments demonstrate that VETime significantly outperforms state-of-the-art models in zero-shot scenarios, achieving superior localization precision with lower computational overhead than current vision-based approaches. Code available at: .

</details>


### [32] [Are Object-Centric Representations Better At Compositional Generalization?](https://arxiv.org/abs/2602.16689)
*Ferdinand Kapl,Amir Mohammad Karimi Mamaghan,Maximilian Seitzer,Karl Henrik Johansson,Carsten Marr,Stefan Bauer,Andrea Dittadi*

Main category: cs.CV

TL;DR: 本研究通过视觉问答基准评估了有无对象中心偏置的视觉编码器在视觉丰富场景下的组合泛化能力。结果表明，在更具挑战性的泛化设置、有限的下游计算或数据量约束下，以对象为中心的表示方法表现出更优的泛化能力和更高的样本效率。


<details>
  <summary>Details</summary>
Motivation: 组合泛化是人类认知的基础，也是机器学习面临的关键挑战。以对象为中心的表示常被认为支持这种泛化，但在视觉丰富的场景中，缺乏系统的证据支持。

Method: 研究团队引入了一个跨三个受控视觉世界（CLEVRTex、Super-CLEVR和MOVi-C）的视觉问答基准，以衡量有无对象中心偏置的视觉编码器对物体属性的未见组合的泛化能力。为确保公平比较，研究者控制了训练数据多样性、样本量、表示大小、下游模型容量和计算资源。实验使用了DINOv2和SigLIP2作为基础视觉编码器及其对象中心对应模型。

Result: (1) 在更困难的组合泛化设置中，以对象为中心的方法表现更优；(2) 原始的密集表示仅在较容易的设置中超越对象中心表示，且通常需要更多的下游计算资源；(3) 以对象为中心的模型样本效率更高，用更少的图像就能实现更强的泛化，而密集编码器只有在数据和多样性充足时才能赶上或超越它们。

Conclusion: 当数据集大小、训练数据多样性或下游计算资源受限时，以对象为中心的表示能提供更强的组合泛化能力。

Abstract: Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual Question Answering benchmark across three controlled visual worlds (CLEVRTex, Super-CLEVR, and MOVi-C) to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for training data diversity, sample size, representation size, downstream model capacity, and compute. We use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their OC counterparts. Our key findings reveal that (1) OC approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of dataset size, training data diversity, or downstream compute is constrained.

</details>


### [33] [Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning](https://arxiv.org/abs/2602.16702)
*Mingjia Shi,Yinhan He,Yaochen Zhu,Jundong Li*

Main category: cs.CV

TL;DR: 提出了一种名为Saliency-Aware Principle (SAP) 的模型无关、无需训练的方法，用于视觉语言模型 (VLMs) 的推理。SAP通过在高层推理原则上操作，实现更稳定的控制和视觉证据的重新咨询，并支持多路径推理，有效减少了对象幻觉，提高了推理的稳定性和降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型 (VLMs) 在推理时面临挑战。主要问题是视觉输入通常只在生成开始时提供一次，导致推理逐渐由文本主导，并使早期视觉基础错误累积。此外，推理过程中对视觉基础的指导通常粗糙且嘈杂，难以在长文本上进行引导。

Method: 提出了一种名为Saliency-Aware Principle (SAP) 的选择方法。SAP在高层推理原则而非token级别的轨迹上操作，这使得在嘈杂反馈下能够稳定控制离散生成，并允许后续推理步骤在需要重新建立基础时重新咨询视觉证据。此外，SAP支持多路径推理，从而能够并行探索不同的推理行为。SAP是模型无关且无需数据的，不需要额外的训练。

Result: 经验结果表明，SAP在可比较的token生成预算下，实现了具有竞争力的性能，尤其是在减少对象幻觉方面。与CoT风格的长序列推理相比，SAP产生了更稳定的推理和更低的响应延迟。

Conclusion: SAP提供了一种有效且无需训练的解决方案，用于解决视觉语言模型在推理过程中视觉基础丢失和错误累积的问题。通过在高层原则上操作并支持视觉证据的重新咨询及多路径推理，SAP显著提高了VLMs的性能，特别是在减少幻觉、提高稳定性和降低延迟方面。

Abstract: Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominated and allowing early visual grounding errors to accumulate. Moreover, vanilla guidance for visual grounding during inference is often coarse and noisy, making it difficult to steer reasoning over long texts. To address these challenges, we propose \emph{Saliency-Aware Principle} (SAP) selection. SAP operates on high-level reasoning principles rather than token-level trajectories, which enable stable control over discrete generation under noisy feedback while allowing later reasoning steps to re-consult visual evidence when renewed grounding is required. In addition, SAP supports multi-route inference, enabling parallel exploration of diverse reasoning behaviors. SAP is model-agnostic and data-free, requiring no additional training. Empirical results show that SAP achieves competitive performance, especially in reducing object hallucination, under comparable token-generation budgets while yielding more stable reasoning and lower response latency than CoT-style long sequential reasoning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [34] [Language Model Representations for Efficient Few-Shot Tabular Classification](https://arxiv.org/abs/2602.15844)
*Inwon Kang,Parikshit Ram,Yi Zhou,Horst Samulowitz,Oshani Seneviratne*

Main category: cs.CL

TL;DR: TaRL是一种利用预训练大型语言模型（LLMs）语义嵌入进行少样本表格分类的轻量级范式。通过去除嵌入的共同分量和校准softmax温度，TaRL在数据量较少（k≤32）的语义丰富表格中取得了与最先进模型相当的性能，证明了重用现有LLM基础设施进行Web表格理解的可行性。


<details>
  <summary>Details</summary>
Motivation: Web包含大量结构和语义异构的表格数据，难以统一利用。大型语言模型（LLMs）已成为Web基础设施的重要组成部分。因此，研究旨在于探讨是否能利用现有的LLMs对Web原生表格（如产品目录、知识库导出、科学数据集）中的结构化数据进行分类，从而避免使用专门模型或大量再训练。

Method: 该研究提出了一种名为TaRL（Table Representation with Language Model）的轻量级范式，用于少样本表格分类，直接利用单个表格行的语义嵌入。研究首先指出直接应用这些嵌入的表现不如专门的表格模型，然后提出通过两种关键技术释放其潜力：1) 移除所有嵌入中的共同分量；2) 校准softmax温度。此外，一个简单的元学习器，通过手工特征训练，用于预测合适的温度。

Result: 直接应用语义嵌入的表现不如专门的表格模型。然而，通过移除所有嵌入中的共同分量和校准softmax温度这两项关键技术，TaRL在语义丰富表格的低数据量（k≤32）场景下，达到了与现有最先进模型相当的性能。

Conclusion: 研究结果表明，重用现有LLM基础设施进行高效的语义驱动Web表格理解是可行的，为Web表格理解提供了一个新的途径。

Abstract: The Web is a rich source of structured data in the form of tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the structure and semantics of these tables makes it challenging to build a unified method that can effectively leverage the information they contain. Meanwhile, Large language models (LLMs) are becoming an increasingly integral component of web infrastructure for tasks like semantic search. This raises a crucial question: can we leverage these already-deployed LLMs to classify structured data in web-native tables (e.g., product catalogs, knowledge base exports, scientific data portals), avoiding the need for specialized models or extensive retraining? This work investigates a lightweight paradigm, $\textbf{Ta}$ble $\textbf{R}$epresentation with $\textbf{L}$anguage Model~($\textbf{TaRL}$), for few-shot tabular classification that directly utilizes semantic embeddings of individual table rows. We first show that naive application of these embeddings underperforms compared to specialized tabular models. We then demonstrate that their potentials can be unlocked with two key techniques: removing the common component from all embeddings and calibrating the softmax temperature. We show that a simple meta-learner, trained on handcrafted features, can learn to predict an appropriate temperature. This approach achieves performance comparable to state-of-the-art models in low-data regimes ($k \leq 32$) of semantically-rich tables. Our findings demonstrate the viability of reusing existing LLM infrastructure for efficient semantics-driven pathway to reuse existing LLM infrastructure for Web table understanding.

</details>


### [35] [Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models](https://arxiv.org/abs/2602.15847)
*Pranav Bhandari,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: LLM中人格特质的引导向量存在几何依赖性，引导一个特质会连带影响其他特质，表明特质并非完全独立可控。


<details>
  <summary>Details</summary>
Motivation: 现有LLM人格引导方法隐式假设特质可以独立控制。本研究旨在通过分析大五人格引导方向之间的几何关系，检验这一假设是否成立。

Method: 研究了从LLaMA-3-8B和Mistral-8B两种模型家族中提取的引导向量，并应用了一系列几何条件方案，包括无约束方向、软正交化和硬正交化。

Result: 人格引导方向表现出显著的几何依赖性：引导一个特质会持续引起其他特质的变化，即使在明确移除线性重叠后也是如此。尽管硬正交化强制实现了几何独立性，但未能消除跨特质的行为效应，并可能降低引导强度。

Conclusion: LLM中的人格特质占据了一个轻微耦合的子空间，限制了完全独立的特质控制。

Abstract: Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by analysing the geometric relationships between Big Five personality steering directions. We study steering vectors extracted from two model families (LLaMA-3-8B and Mistral-8B) and apply a range of geometric conditioning schemes, from unconstrained directions to soft and hard orthonormalisation. Our results show that personality steering directions exhibit substantial geometric dependence: steering one trait consistently induces changes in others, even when linear overlap is explicitly removed. While hard orthonormalisation enforces geometric independence, it does not eliminate cross-trait behavioural effects and can reduce steering strength. These findings suggest that personality traits in LLMs occupy a slightly coupled subspace, limiting fully independent trait control.

</details>


### [36] [Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling](https://arxiv.org/abs/2602.15848)
*Andrius Matšenas,Anet Lello,Tõnis Lees,Hans Peep,Kim Lilii Tamm*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）可以作为传统问卷式人格评估的替代方案，并显示出中等程度的聚合效度，用户认为其准确性与传统方法相当。


<details>
  <summary>Details</summary>
Motivation: 验证大型语言模型（LLM）作为问卷式人格评估的一种动态替代方案。

Method: 采用被试内实验（N=33），比较了从引导式LLM对话中得出的大五人格分数与黄金标准IPIP-50问卷的结果，并测量了用户感知到的准确性。

Result: 结果显示中等程度的聚合效度（r=0.38-0.58）；尽责性、开放性和神经质分数在两种方法间统计学上等效。宜人性和外向性显示出显著差异，表明需要进行特质特定的校准。值得注意的是，参与者认为LLM生成的人格画像与传统问卷结果的准确性相当。

Conclusion: 对话式人工智能为传统心理测量学提供了一种有前景的新方法。

Abstract: This study validates Large Language Models (LLMs) as a dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we compared Big Five personality scores derived from guided LLM conversations against the gold-standard IPIP-50 questionnaire, while also measuring user-perceived accuracy. Results indicate moderate convergent validity (r=0.38-0.58), with Conscientiousness, Openness, and Neuroticism scores statistically equivalent between methods. Agreeableness and Extraversion showed significant differences, suggesting trait-specific calibration is needed. Notably, participants rated LLM-generated profiles as equally accurate as traditional questionnaire results. These findings suggest conversational AI offers a promising new approach to traditional psychometrics.

</details>


### [37] [Preference Optimization for Review Question Generation Improves Writing Quality](https://arxiv.org/abs/2602.15849)
*Karun Sharma,Vidushee Vats,Shengzhi Li,Yuxiang Wang,Zhongtian Sun,Prayag Tiwari*

Main category: cs.CL

TL;DR: 本研究开发了IntelliReward奖励模型和IntelliAsk问题生成模型，显著提升了LLM在同行评审中生成深度、基于证据和有基础的审稿问题的能力，并在推理和写作任务上取得了 measurable 的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的审稿问题生成方法通常产生肤浅的问题，超过50%的查询token来源于论文的第一页，未能生成实质性、基于证据的问题。

Method: 开发了IntelliReward，一个基于冻结自回归LLM构建的奖励模型，其最终50个token状态上带有可训练的多头Transformer。利用Decoupled Clip和动态采样策略优化（DAPO）结合IntelliReward，训练了IntelliAsk模型，以生成符合人类标准、基于证据且有深度的审稿问题。

Result: IntelliReward在预测专家级人类偏好方面优于基于API的SFT基线。IntelliAsk在推理和写作基准上表现出显著改进，表明审稿问题质量与更广泛的能力相关。与Qwen3-32B基线模型相比，IntelliAsk在MuSR（68.3 vs 64.7 Acc）等推理任务和WritingBench（8.31 vs 8.07）等复杂写作评估上均有可衡量的性能提升。

Conclusion: IntelliReward和IntelliAsk的发布为评估LLM生成的审稿问题在基础性、努力程度和证据方面的表现提供了自动基准。

Abstract: Peer review relies on substantive, evidence-based questions, yet existing LLM-based approaches often generate surface-level queries, drawing over 50\% of their question tokens from a paper's first page. To bridge this gap, we develop IntelliReward, a novel reward model built from a frozen autoregressive LLM with trainable multi-head transformers over the final 50 token states, which outperforms API-based SFT baselines in predicting expert-level human preferences. By applying Decoupled Clip and Dynamic Sampling Policy Optimization (DAPO) with IntelliReward, we train IntelliAsk, a question-generation model aligned with human standards of effort, evidence, and grounding. We find consistent improvements on reasoning and writing benchmarks, suggesting reviewer-question quality correlates with broader capabilities. Compared to the Qwen3-32B base model, IntelliAsk shows measurable gains across diverse benchmarks, specifically improving performance on reasoning tasks like MuSR (68.3 vs 64.7 Acc) and complex writing evaluations such as WritingBench (8.31 vs 8.07). We release our implementation, expert preference annotations, and the IntelliReward model to provide an automatic evaluation benchmark for grounding, effort, and evidence in LLM-generated review questions.

</details>


### [38] [Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey](https://arxiv.org/abs/2602.15851)
*David Y. Liu,Aditya Joshi,Paul Dawson*

Main category: cs.CL

TL;DR: 该调查探讨了大型语言模型（LLMs）在叙事应用中的潜力，提出了一个分类法，并分析了当前NLP叙事研究的模式和趋势。它强调了LLMs在连接NLP与抽象叙事概念方面的作用，并讨论了现有挑战和未来研究方向，建议通过定义和改进基于理论的指标来推动进展。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动故事生成和理解任务中展现出叙事理论应用的巨大潜力，因此有必要调查自然语言处理（NLP）研究如何与叙事学领域结合，并为当前的研究工作提供一个分类法和背景基础。

Method: 本研究通过调查NLP研究与叙事学领域的结合方式，提出了一个反映叙事学既定区别的分类法。我们发现了在叙事数据集与任务、叙事理论与NLP管道以及提示与微调方法学趋势方面的模式。

Result: 我们发现叙事数据集与任务、叙事理论与NLP管道以及提示与微调方法学趋势中存在模式。大型语言模型能够轻松地将NLP管道与抽象叙事概念连接起来，并提供了跨学科合作的机会。然而，在实现叙事相关任务的统一定义或基准方面仍存在挑战，导致模型比较困难。

Conclusion: 虽然在叙事任务的统一基准方面存在挑战，但未来的进展将受益于专注于以下方面的工作：定义和改进个体叙事属性的理论基础指标以逐步提高模型性能；进行大规模、理论驱动的文学/社会/文化分析；以及创建可用于验证或完善叙事理论的实验。这项工作通过概述当前的研究努力和更广泛的叙事学领域，为NLP中更系统、理论信息更丰富的叙事研究奠定了基础。

Abstract: Applications of narrative theories using large language models (LLMs) deliver promising use-cases in automatic story generation and understanding tasks. Our survey examines how natural language processing (NLP) research engages with fields of narrative studies, and proposes a taxonomy for ongoing efforts that reflect established distinctions in narratology. We discover patterns in the following: narrative datasets and tasks, narrative theories and NLP pipeline and methodological trends in prompting and fine-tuning. We highlight how LLMs enable easy connections of NLP pipelines with abstract narrative concepts and opportunities for interdisciplinary collaboration. Challenges remain in attempts to work towards any unified definition or benchmark of narrative related tasks, making model comparison difficult. For future directions, instead of the pursuit of a single, generalised benchmark for 'narrative quality', we believe that progress benefits more from efforts that focus on the following: defining and improving theory-based metrics for individual narrative attributes to incrementally improve model performance; conducting large-scale, theory-driven literary/social/cultural analysis; and creating experiments where outputs can be used to validate or refine narrative theories. This work provides a contextual foundation for more systematic and theoretically informed narrative research in NLP by providing an overview to ongoing research efforts and the broader narrative studies landscape.

</details>


### [39] [Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints](https://arxiv.org/abs/2602.15852)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.CL

TL;DR: 本研究关注在时间泄漏约束下构建安全可部署的临床自然语言处理（NLP）系统所需的设计选择，通过引入轻量级审计流程来识别并抑制易泄漏信号，从而实现更保守、更校准的预测，强调部署就绪的临床NLP系统应优先考虑时间有效性、校准和行为鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 临床NLP模型在出院计划支持方面显示出潜力，但基于笔记的模型特别容易受到时间和词汇泄漏的影响，导致表现虚高，在实际部署中存在风险，可能扰乱临床工作流程并危及患者安全。

Method: 本研究提出了一种轻量级审计流程，将可解释性整合到模型开发过程中，以在最终训练前识别并抑制易泄漏的信号。以择期脊柱手术后次日出院预测为例进行了案例研究。

Result: 审计后的模型表现出更保守、校准更好的概率估计，并减少了对出院相关词汇线索的依赖。

Conclusion: 部署就绪的临床NLP系统应优先考虑时间有效性、校准和行为鲁棒性，而非乐观的性能表现。

Abstract: Clinical natural language processing (NLP) models have shown promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However, note-based models are particularly vulnerable to temporal and lexical leakage, where documentation artifacts encode future clinical decisions and inflate apparent predictive performance. Such behavior poses substantial risks for real-world deployment, where overconfident or temporally invalid predictions can disrupt clinical workflows and compromise patient safety. This study focuses on system-level design choices required to build safe and deployable clinical NLP under temporal leakage constraints. We present a lightweight auditing pipeline that integrates interpretability into the model development process to identify and suppress leakage-prone signals prior to final training. Using next-day discharge prediction after elective spine surgery as a case study, we evaluate how auditing affects predictive behavior, calibration, and safety-relevant trade-offs. Results show that audited models exhibit more conservative and better-calibrated probability estimates, with reduced reliance on discharge-related lexical cues. These findings emphasize that deployment-ready clinical NLP systems should prioritize temporal validity, calibration, and behavioral robustness over optimistic performance.

</details>


### [40] [A Lightweight Explainable Guardrail for Prompt Safety](https://arxiv.org/abs/2602.15853)
*Md Asiful Islam,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级可解释护栏（LEG）方法，用于不安全提示的分类。LEG采用多任务学习架构，联合学习提示分类器和解释分类器，其中解释分类器标记解释安全/不安全整体决策的提示词。LEG使用抵消大型语言模型确认偏见的新颖策略生成的合成数据进行可解释性训练。LEG的训练过程使用一种新颖的损失函数，该函数捕获全局解释信号，并结合了交叉熵和焦点损失与基于不确定性的加权。LEG在提示分类和可解释性方面均取得了与现有技术相当或更优的性能，无论是在域内还是域外，并且模型尺寸远小于当前方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在不安全提示分类中缺乏可解释性或模型尺寸过大，因此需要一种轻量级且具有解释能力的方法来分类不安全提示，同时保持高性能。

Method: 提出了一种轻量级可解释护栏（LEG）方法。LEG使用多任务学习架构，共同训练一个提示分类器和一个解释分类器。解释分类器负责标记解释整体安全/不安全决策的提示词。LEG通过合成数据进行可解释性训练，这些合成数据通过一种新颖的策略生成，旨在抵消大型语言模型（LLMs）的确认偏见。LEG的训练过程采用了一种新颖的损失函数，该函数能够捕获全局解释信号，并结合了交叉熵损失、焦点损失以及基于不确定性的加权。

Result: LEG在提示分类和可解释性方面均取得了与现有技术（state-of-the-art）相当或更优的性能，无论是在域内还是域外，并在三个数据集上进行了验证。尽管LEG的模型尺寸远小于当前方法，但依然达到了这一性能。

Conclusion: LEG是一种有效、轻量级且可解释的不安全提示分类方法。它在模型尺寸显著减小的情况下，依然在提示分类和可解释性方面达到了或超越了现有技术的性能。

Abstract: We propose a lightweight explainable guardrail (LEG) method for the classification of unsafe prompts. LEG uses a multi-task learning architecture to jointly learn a prompt classifier and an explanation classifier, where the latter labels prompt words that explain the safe/unsafe overall decision. LEG is trained using synthetic data for explainability, which is generated using a novel strategy that counteracts the confirmation biases of LLMs. Lastly, LEG's training process uses a novel loss that captures global explanation signals and combines cross-entropy and focal losses with uncertainty-based weighting. LEG obtains equivalent or better performance than the state-of-the-art for both prompt classification and explainability, both in-domain and out-of-domain on three datasets, despite the fact that its model size is considerably smaller than current approaches. If accepted, we will release all models and the annotated dataset publicly.

</details>


### [41] [Rethinking Soft Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective](https://arxiv.org/abs/2602.15856)
*Yunhao Liu,Zian Jia,Xinyu Gao,Kanjun Xu,Yun Xiong*

Main category: cs.CL

TL;DR: 针对RAG中过度上下文长度和冗余检索导致的可扩展性问题，本文提出SeleCom，一个选择器式软压缩框架。SeleCom通过将编码器重新定义为查询条件下的信息选择器，解决了现有完全压缩方法的局限性。实验证明，SeleCom显著优于现有软压缩方法，性能与非压缩基线相当或更优，并大幅降低了计算和延迟。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）的可扩展性受到过长上下文和冗余检索的限制。现有的软上下文压缩方法由于依赖于自动编码器式的“完全压缩”（full-compression），强制编码器压缩所有文档信息，无论其与输入查询的相关性，导致其性能通常不如非压缩RAG。本研究发现“完全压缩”存在两个基本限制：(I) 不可行性，它与LLM的下游生成行为冲突；(II) 非必要性，它是不必要的，并稀释了与任务相关的信息密度。

Method: 引入SeleCom，一个基于选择器的RAG软压缩框架，将编码器重新定义为查询条件下的信息选择器。该选择器是仅解码器（decoder-only）模型，并通过一个大规模、多样化且难度分级的合成问答数据集，结合课程学习进行训练。

Result: SeleCom在广泛的实验中显著优于现有的软压缩方法，并达到了与非压缩基线相当或更优的性能。同时，它将计算和延迟降低了33.8%~84.6%。

Conclusion: SeleCom通过重新定义编码器为查询条件下的信息选择器，有效解决了RAG中软上下文压缩的局限性，显著优于现有方法，并在性能和效率上超越了非压缩基线。

Abstract: Retrieval-Augmented Generation (RAG) effectively grounds Large Language Models (LLMs) with external knowledge and is widely applied to Web-related tasks. However, its scalability is hindered by excessive context length and redundant retrievals. Recent research on soft context compression aims to address this by encoding long documents into compact embeddings, yet they often underperform non-compressed RAG due to their reliance on auto-encoder-like full-compression that forces the encoder to compress all document information regardless of relevance to the input query. In this work, we conduct an analysis on this paradigm and reveal two fundamental limitations: (I) Infeasibility, full-compression conflicts with the LLM's downstream generation behavior; and (II) Non-necessity: full-compression is unnecessary and dilutes task-relevant information density. Motivated by these insights, we introduce SeleCom, a selector-based soft compression framework for RAG that redefines the encoder's role as query-conditioned information selector. The selector is decoder-only and is trained with a massive, diverse and difficulty-graded synthetic QA dataset with curriculum learning. Extensive experiments show that SeleCom significantly outperforms existing soft compression approaches and achieves competitive or superior performance to non-compression baselines, while reducing computation and latency by 33.8%~84.6%.

</details>


### [42] [CAST: Achieving Stable LLM-based Text Analysis for Data Analytics](https://arxiv.org/abs/2602.15861)
*Jinxiang Xie,Zihao Li,Wei He,Rui Ding,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: 针对大型语言模型在表格数据分析中输出稳定性不足的问题，研究提出了CAST框架，通过算法提示和先思考后发言的机制约束模型推理过程，显著提高了总结和标记任务的稳定性，同时保持或提升了输出质量。


<details>
  <summary>Details</summary>
Motivation: 表格数据的文本分析依赖于总结（用于语料库级别主题提取）和标记（用于行级别标注）两项核心操作。然而，大型语言模型（LLM）在执行这些任务时存在一个关键局限性，即其输出稳定性无法满足数据分析所需的高标准。

Method: 引入了CAST（Consistency via Algorithmic Prompting and Stable Thinking）框架，通过约束模型的潜在推理路径来增强输出稳定性。CAST结合了：(i) 算法提示（Algorithmic Prompting），用于在有效推理转换上施加程序性支架；(ii) 先思考后发言（Thinking-before-Speaking），用于在最终生成前强制执行明确的中间承诺。此外，该研究还引入了CAST-S和CAST-T稳定性指标，分别用于项目符号式总结和标签任务，并验证了它们与人类判断的一致性。

Result: 在多个LLM骨干的公共基准测试中进行的实验表明，CAST在所有基线模型中始终表现出最佳稳定性，将稳定性分数提高了高达16.2%，同时保持或提升了输出质量。

Conclusion: CAST框架通过有效提升大型语言模型在表格数据分析任务中的输出稳定性，使其更适用于对稳定性要求严格的数据分析应用。

Abstract: Text analysis of tabular data relies on two core operations: \emph{summarization} for corpus-level theme extraction and \emph{tagging} for row-level labeling. A critical limitation of employing large language models (LLMs) for these tasks is their inability to meet the high standards of output stability demanded by data analytics. To address this challenge, we introduce \textbf{CAST} (\textbf{C}onsistency via \textbf{A}lgorithmic Prompting and \textbf{S}table \textbf{T}hinking), a framework that enhances output stability by constraining the model's latent reasoning path. CAST combines (i) Algorithmic Prompting to impose a procedural scaffold over valid reasoning transitions and (ii) Thinking-before-Speaking to enforce explicit intermediate commitments before final generation. To measure progress, we introduce \textbf{CAST-S} and \textbf{CAST-T}, stability metrics for bulleted summarization and tagging, and validate their alignment with human judgments. Experiments across publicly available benchmarks on multiple LLM backbones show that CAST consistently achieves the best stability among all baselines, improving Stability Score by up to 16.2\%, while maintaining or improving output quality.

</details>


### [43] [Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation](https://arxiv.org/abs/2602.15862)
*Guoshan Liu,Bin Zhu,Yian Li,Jingjing Chen,Chong-Wah Ngo,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 针对MLMMs从食物图像生成菜谱时存在的语义错误，本文提出一个两阶段（SFT+RFT）语义基础框架，通过动作/食材预测与验证，并结合SCSR模块，显著提高了语义准确性，在Recipe1M上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLMMs）能够根据食物图像生成菜谱，但其输出常包含语义不正确的动作或食材，即使在词汇得分（如BLEU、ROUGE）较高的情况下也是如此。

Method: 该方法提出了一个语义基础框架，通过预测和验证动作和食材作为内部上下文来生成指令。它采用两阶段流水线：首先通过监督微调（SFT），利用动作推理数据集和食材语料库建立基础准确性；然后通过强化微调（RFT），使用频率感知奖励来改进长尾动作预测和食材泛化。此外，还引入了一个语义置信度评分与校正（SCSR）模块来过滤和纠正预测结果。

Result: 在Recipe1M数据集上的实验表明，该方法取得了最先进的性能，并显著提高了语义准确性。

Conclusion: 该框架通过结合SFT、RFT和SCSR模块，有效解决了从食物图像生成菜谱时出现的语义错误，显著提高了语义准确性，并取得了最先进的性能。

Abstract: Recent advances in Multimodal Large Language Models (MLMMs) have enabled recipe generation from food images, yet outputs often contain semantically incorrect actions or ingredients despite high lexical scores (e.g., BLEU, ROUGE). To address this gap, we propose a semantically grounded framework that predicts and validates actions and ingredients as internal context for instruction generation. Our two-stage pipeline combines supervised fine-tuning (SFT) with reinforcement fine-tuning (RFT): SFT builds foundational accuracy using an Action-Reasoning dataset and ingredient corpus, while RFT employs frequency-aware rewards to improve long-tail action prediction and ingredient generalization. A Semantic Confidence Scoring and Rectification (SCSR) module further filters and corrects predictions. Experiments on Recipe1M show state-of-the-art performance and markedly improved semantic fidelity.

</details>


### [44] [Not the Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning](https://arxiv.org/abs/2602.15863)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: LLM自生成少样本示例提高推理能力的优势主要来源于问题创建过程本身，而非生成的示例；集成提示（LLM在单一提示中创建并解决问题）表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM通过自生成少样本示例能提高推理性能，但其潜在机制尚不明确，难以有效应用。本文旨在探究这种性能提升是否源于生成的示例本身，还是创建过程。

Method: 通过在五种主流LLM架构上，系统评估了三种上下文学习提示策略：（1）零样本提示；（2）集成提示（LLM在单一提示中创建并解决问题）；（3）解耦提示（自生成示例被重用为上下文示例，但排除其创建上下文）。此外，还进行了注意力分析。

Result: 集成提示显著优于零样本和解耦提示。解耦提示仅比零样本提示略有提升。注意力分析显示，集成提示和解耦提示之间存在显著的注意力模式差异。

Conclusion: 自生成提示的优势来源于问题创建过程，而非生成的示例本身，这为设计更有效的提示策略提供了有价值的见解。

Abstract: Recent studies have shown that Large Language Models (LLMs) can improve their reasoning performance through self-generated few-shot examples, achieving results comparable to manually curated in-context examples. However, the underlying mechanism behind these gains remains unclear, making it hard to decide when and how to apply the technique effectively. In this work, we argue that the key benefit arises not from the generated examples themselves but from the act of creating them. To validate this, on reasoning-intensive tasks across diverse LLM architectures, we systematically evaluate three prompting strategies for in-context learning: (1) Zero-shot prompting; (2) Integrated prompting, where LLMs create and solve problems within a single, unified prompt; and (3) Decoupled prompting, where self-generated examples are reused as in-context examples, but the context of their creation itself is excluded. We conduct experiments across five widely used model architectures, demonstrating that Integrated prompting consistently outperforms both Zero-shot and Decoupled prompting. In contrast, Decoupled prompting offers only marginal gains over Zero-shot. Further, for a more in-depth analysis, we conduct an attention analysis and observe significant differences in attention patterns between Integrated and Decoupled prompting. These findings suggest that the advantage of self-generation prompting comes from the process of problem creation, not the examples themselves, providing valuable insights for designing more effective prompting strategies.

</details>


### [45] [Playing With AI: How Do State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game Zork?](https://arxiv.org/abs/2602.15867)
*Berry Gerrits*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在文本冒险游戏Zork中解决问题和推理的能力受限，平均完成度不到10%，即使提供详细指令或启用“扩展思考”也无改善。这些模型在元认知能力和问题解决方面存在显著局限，表现为重复失败行动、策略不一致以及无法从历史记录中学习。


<details>
  <summary>Details</summary>
Motivation: 评估当代大型语言模型（LLMs）在文本冒险游戏Zork中的问题解决和推理能力。

Method: 通过在Zork游戏中测试领先的专有模型（ChatGPT、Claude和Gemini），在最小和详细指令下进行，以游戏得分作为主要衡量标准，并对模型的推理过程进行定性分析。

Result: 所有测试模型的平均完成度均低于10%，表现最好的模型（Claude Opus 4.5）也仅获得约350分中的75分。提供详细游戏指令或启用“扩展思考”未能改善表现。定性分析揭示了根本性局限：重复失败行动、策略不一致以及未能从历史记录中学习。

Conclusion: 目前的LLMs在文本游戏领域的元认知和问题解决能力方面存在显著局限，这引发了对其推理能力本质和程度的质疑。

Abstract: In this positioning paper, we evaluate the problem-solving and reasoning capabilities of contemporary Large Language Models (LLMs) through their performance in Zork, the seminal text-based adventure game first released in 1977. The game's dialogue-based structure provides a controlled environment for assessing how LLM-based chatbots interpret natural language descriptions and generate appropriate action sequences to succeed in the game. We test the performance of leading proprietary models - ChatGPT, Claude, and Gemini - under both minimal and detailed instructions, measuring game progress through achieved scores as the primary metric. Our results reveal that all tested models achieve less than 10% completion on average, with even the best-performing model (Claude Opus 4.5) reaching only approximately 75 out of 350 possible points. Notably, providing detailed game instructions offers no improvement, nor does enabling ''extended thinking''. Qualitative analysis of the models' reasoning processes reveals fundamental limitations: repeated unsuccessful actions suggesting an inability to reflect on one's own thinking, inconsistent persistence of strategies, and failure to learn from previous attempts despite access to conversation history. These findings suggest substantial limitations in current LLMs' metacognitive abilities and problem-solving capabilities within the domain of text-based games, raising questions about the nature and extent of their reasoning capabilities.

</details>


### [46] [KD4MT: A Survey of Knowledge Distillation for Machine Translation](https://arxiv.org/abs/2602.15845)
*Ona de Gibert,Joseph Attieh,Timothee Mickus,Yves Scherrer,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 本调查综合分析了105篇关于机器翻译中知识蒸馏（KD4MT）的论文，探讨了其作为知识迁移机制的作用。研究识别了领域趋势、研究空白和评估实践的缺失，并提供了实用指南及潜在风险，最后讨论了大型语言模型（LLMs）对KD4MT的重塑作用。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏（KD）在自然语言处理（NLP）中作为大型模型压缩工具受到广泛关注，但在机器翻译（MT）中，KD还被视为一种通用的知识迁移机制，影响监督、翻译质量和效率。本研究旨在综合分析KD在MT领域的应用（KD4MT），以应对该领域的挑战并梳理其发展。

Method: 该研究通过对105篇论文（截至2025年10月1日）进行综合分析，系统地审视了机器翻译中的知识蒸馏（KD4MT）。研究方法包括向非专家介绍MT和KD、概述标准KD方法、根据方法论贡献和实际应用对KD4MT文献进行分类，并进行定性和定量分析。此外，研究还提供了选择KD方法的实用指南，并探讨了相关风险。

Result: 分析结果揭示了该领域的共同趋势、关键研究空白，以及MT中KD方法缺乏统一评估实践的问题。研究还提供了在具体情境中选择KD方法的实用指南，并指出了应用KD于MT可能带来的潜在风险，例如幻觉增加和偏见放大。

Conclusion: 本调查通过提供公开可用的数据库和关键术语词汇表，支持KD4MT领域的进一步研究，并讨论了大型语言模型（LLMs）如何重塑该领域。

Abstract: Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this narrative: in MT, KD also functions as a general-purpose knowledge transfer mechanism that shapes supervision and translation quality as well as efficiency. This survey synthesizes KD for MT (KD4MT) across 105 papers (through October 1, 2025). We begin by introducing both MT and KD for non-experts, followed by an overview of the standard KD approaches relevant to MT applications. Subsequently, we categorize advances in the KD4MT literature based on (i) their methodological contributions and (ii) their practical applications. Our qualitative and quantitative analyses identify common trends in the field and highlight key research gaps as well as the absence of unified evaluation practice for KD methods in MT. We further provide practical guidelines for selecting a KD method in concrete settings and highlight potential risks associated with the application of KD to MT such as increased hallucination and bias amplification. Finally, we discuss the role of LLMs in re-shaping the KD4MT field. To support further research, we complement our survey with a publicly available database summarizing the main characteristics of the surveyed KD methods and a glossary of key terms.

</details>


### [47] [Large Language Models for Assisting American College Applications](https://arxiv.org/abs/2602.15850)
*Zhengliang Liu,Weihang You,Peng Shu,Junhao Chen,Yi Pan,Hanqi Jiang,Yiwei Li,Zhaojun Ding,Chao Cao,Xinliang Li,Yifan Zhou,Ruidong Zhang,Shaochen Xu,Wei Ruan,Huaqin Zhao,Dajiang Zhu,Tianming Liu*

Main category: cs.CL

TL;DR: EZCollegeApp是一个由大型语言模型驱动的系统，旨在通过结构化申请表格、基于权威招生文件提供答案以及保持人工完全控制来帮助高中生完成美国大学申请。


<details>
  <summary>Details</summary>
Motivation: 美国大学申请过程复杂，存在政策碎片化、表格重复且有条件、问题模糊不清等问题，学生需要跨参考多个来源进行申请。

Method: EZCollegeApp采用映射优先范式，将表格理解与答案生成分离，通过整合官方招生网站的文档摄取、检索增强问答和人机协作聊天机器人界面来提供建议，而不进行自动提交。

Result: 论文描述了系统架构、数据管道、内部表示、安全和隐私措施，并通过自动化测试和人工质量评估进行了评估。源代码已在GitHub上发布。

Conclusion: EZCollegeApp旨在简化高中生的大学申请流程，并通过发布源代码以扩大其影响力。

Abstract: American college applications require students to navigate fragmented admissions policies, repetitive and conditional forms, and ambiguous questions that often demand cross-referencing multiple sources. We present EZCollegeApp, a large language model (LLM)-powered system that assists high-school students by structuring application forms, grounding suggested answers in authoritative admissions documents, and maintaining full human control over final responses. The system introduces a mapping-first paradigm that separates form understanding from answer generation, enabling consistent reasoning across heterogeneous application portals. EZCollegeApp integrates document ingestion from official admissions websites, retrieval-augmented question answering, and a human-in-the-loop chatbot interface that presents suggestions alongside application fields without automated submission. We describe the system architecture, data pipeline, internal representations, security and privacy measures, and evaluation through automated testing and human quality assessment. Our source code is released on GitHub ( ) to facilitate the broader impact of this work.

</details>


### [48] [Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion](https://arxiv.org/abs/2602.15895)
*Pengcheng Zhou,Haochen Li,Zhiqiang Nie,JiaLe Chen,Qing Gong,Weizhen Zhang,Chun Yu*

Main category: cs.CL

TL;DR: CogitoRAG是一个受人类认知记忆启发的RAG框架，它通过提取和演化语义要旨，构建多维知识图谱，并通过查询分解、实体扩散和CogniRank算法进行检索，显著提高了复杂知识集成和推理能力，优于现有RAG方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG框架中离散的文本表示导致语义完整性丢失和检索偏差，从而影响LLMs的幻觉缓解效果。本研究旨在通过模拟人类认知记忆机制来解决这一问题。

Method: CogitoRAG在离线阶段将非结构化语料库提炼为要旨记忆语料库，并构建集成实体、关系事实和记忆节点的多维知识图谱。在线阶段，通过查询分解模块处理复杂查询；实体扩散模块利用结构相关性和实体频率奖励机制在图谱上执行联想检索；最后，CogniRank算法融合扩散得分和语义相似度精确重排候选段落，以“段落-记忆配对”格式为生成器提供高密度信息支持。

Result: 在五个主流QA基准测试和GraphBench上的多任务生成实验结果表明，CogitoRAG显著优于SOTA RAG方法，在复杂知识集成和推理方面展现出卓越的能力。

Conclusion: CogitoRAG通过模拟人类认知记忆过程，在复杂知识集成和推理方面表现出优越的性能，显著优于现有RAG方法，有效解决了传统RAG中语义完整性丢失和检索偏差问题。

Abstract: Retrieval-Augmented Generation (RAG) effectively mitigates hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations. Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human cognitive memory processes. The core of this framework lies in the extraction and evolution of the Semantic Gist. During the offline indexing stage, CogitoRAG first deduces unstructured corpora into gist memory corpora, which are then transformed into a multi-dimensional knowledge graph integrating entities, relational facts, and memory nodes. In the online retrieval stage, the framework handles complex queries via Query Decomposition Module that breaks them into comprehensive sub-queries, mimicking the cognitive decomposition humans employ for complex information. Subsequently, Entity Diffusion Module performs associative retrieval across the graph, guided by structural relevance and an entity-frequency reward mechanism. Furthermore, we propose the CogniRank algorithm, which precisely reranks candidate passages by fusing diffusion-derived scores with semantic similarity. The final evidence is delivered to the generator in a passage-memory pairing format, providing high-density information support. Experimental results across five mainstream QA benchmarks and multi-task generation on GraphBench demonstrate that CogitoRAG significantly outperforms state-of-the-art RAG methods, showcasing superior capabilities in complex knowledge integration and reasoning.

</details>


### [49] [Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A Systematically Integrated Approach](https://arxiv.org/abs/2602.15857)
*Yi Liu*

Main category: cs.CL

TL;DR: 本文提出了CRAF框架，通过结合传统方法和大型语言模型，解决了多源异构公共意见分析的挑战。该框架包含跨平台注意力、自适应融合、联合优化和多模态提取等创新点，并在理论分析和实验中证明了其在主题聚类和情感分析上的优越性能，以及强大的跨平台适应性和对标注数据需求的显著降低。


<details>
  <summary>Details</summary>
Motivation: 由于结构差异、语义变化和平台特定偏差，从多个异构来源分析公众舆论面临重大挑战。

Method: 本文提出了一种新颖的协作推理和自适应融合（CRAF）框架，通过结构化的多阶段推理机制系统地整合了基于传统特征的方法和大型语言模型。其核心方法包括：1) 跨平台协作注意力模块，用于对齐语义表示同时保留源特定特征；2) 分层自适应融合机制，根据数据质量和任务需求动态加权特征；3) 联合优化策略，通过共享潜在空间同时学习主题表示和情感分布；4) 新颖的多模态提取能力，通过集成OCR、ASR和视觉情感分析来处理抖音和快手等平台的视频内容。

Result: 理论分析表明，与独立源建模相比，CRAF实现了更紧密的泛化界限，减少了O(sqrt(d log K / m))。在三个多平台数据集（Weibo-12, CrossPlatform-15, NewsForum-8）上的综合实验表明，CRAF的平均主题聚类ARI达到0.76（比最佳基线提高了4.1%），情感分析F1-score达到0.84（提高了3.8%）。该框架表现出强大的跨平台适应性，将新平台所需的标注数据量减少了75%。

Conclusion: CRAF框架通过集成传统方法和大型语言模型，在多源公共意见分析中表现出卓越的性能和跨平台适应性，显著降低了新平台对标注数据的需求。

Abstract: The analysis of public opinion from multiple heterogeneous sources presents significant challenges due to structural differences, semantic variations, and platform-specific biases. This paper introduces a novel Collaborative Reasoning and Adaptive Fusion (CRAF) framework that systematically integrates traditional feature-based methods with large language models (LLMs) through a structured multi-stage reasoning mechanism. Our approach features four key innovations: (1) a cross-platform collaborative attention module that aligns semantic representations while preserving source-specific characteristics, (2) a hierarchical adaptive fusion mechanism that dynamically weights features based on both data quality and task requirements, (3) a joint optimization strategy that simultaneously learns topic representations and sentiment distributions through shared latent spaces, and (4) a novel multimodal extraction capability that processes video content from platforms like Douyin and Kuaishou by integrating OCR, ASR, and visual sentiment analysis. Theoretical analysis demonstrates that CRAF achieves a tighter generalization bound with a reduction of O(sqrt(d log K / m)) compared to independent source modeling, where d is feature dimensionality, K is the number of sources, and m is sample size. Comprehensive experiments on three multi-platform datasets (Weibo-12, CrossPlatform-15, NewsForum-8) show that CRAF achieves an average topic clustering ARI of 0.76 (4.1% improvement over best baseline) and sentiment analysis F1-score of 0.84 (3.8% improvement). The framework exhibits strong cross-platform adaptability, reducing the labeled data requirement for new platforms by 75%.

</details>


### [50] [Reranker Optimization via Geodesic Distances on k-NN Manifolds](https://arxiv.org/abs/2602.15860)
*Wen G. Gong*

Main category: cs.CL

TL;DR: Maniscope是一种RAG的几何重排方法，利用k-NN流形上的测地线距离，结合全局余弦相似度和局部流形几何。它在性能上优于HNSW基线，并以显著低于交叉编码器和LLM重排器的延迟提供竞争力，是实时RAG部署的实用选择。


<details>
  <summary>Details</summary>
Motivation: 当前的RAG神经重排方法（如交叉编码器或大型语言模型）需要大量的计算资源，并且每个查询的延迟高达3-5秒，这限制了它们在实时应用中的部署。

Method: Maniscope是一种几何重排方法，通过在检索到的文档候选集上构建k-最近邻（k-NN）流形来计算测地线距离。它结合了全局余弦相似性和局部流形几何，以捕获平面欧几里德度量无法捕获的语义结构。该方法的复杂度为O(N D + M^2 D + M k log k)，其中M远小于N。

Result: 1.  在8个BEIR基准数据集上进行评估，Maniscope在三个最难的数据集（NFCorpus、TREC-COVID、AorB）上优于基于HNSW图的基线，NDCG@3分别提高了7.0%、1.6%和2.8%。
2.  Maniscope比HNSW基线快3.2倍（平均4.7毫秒 vs 14.8毫秒）。
3.  与交叉编码器重排器相比，Maniscope在10-45倍更低的延迟下实现了2%以内的精度差距。
4.  在TREC-COVID数据集上，LLM-Reranker相比Maniscope仅提供0.5%的NDCG@3提升，但延迟高出840倍。
5.  该方法能够实现低于10毫秒的延迟。

Conclusion: Maniscope通过结合性能和显著降低的延迟，为实时RAG部署提供了一个实用且高效的替代方案，解决了现有神经重排方法的计算密集型和高延迟问题。

Abstract: Current neural reranking approaches for retrieval-augmented generation (RAG) rely on cross-encoders or large language models (LLMs), requiring substantial computational resources and exhibiting latencies of 3-5 seconds per query. We propose Maniscope, a geometric reranking method that computes geodesic distances on k-nearest neighbor (k-NN) manifolds constructed over retrieved document candidates. This approach combines global cosine similarity with local manifold geometry to capture semantic structure that flat Euclidean metrics miss. Evaluating on eight BEIR benchmark datasets (1,233 queries), Maniscope outperforms HNSW graph-based baseline on the three hardest datasets (NFCorpus: +7.0%, TREC-COVID: +1.6%, AorB: +2.8% NDCG@3) while being 3.2x faster (4.7 ms vs 14.8 ms average). Compared to cross-encoder rerankers, Maniscope achieves within 2% accuracy at 10-45x lower latency. On TREC-COVID, LLM-Reranker provides only +0.5% NDCG@3 improvement over Maniscope at 840x higher latency, positioning Maniscope as a practical alternative for real-time RAG deployment. The method requires O(N D + M^2 D + M k log k) complexity where M << N , enabling sub-10 ms latency. We plan to release Maniscope as open-source software.

</details>


### [51] [Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model Reasoning](https://arxiv.org/abs/2602.15868)
*Magnus Boman*

Main category: cs.CL

TL;DR: 该论文提出了一种使用多磁带图灵机模型来形式化大型语言模型（LLM）交互的方法，以定位故障模式并解释分词问题和思维链提示等现象，为错误分析提供了一种严谨的替代方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在看似简单的任务上表现出故障模式。

Method: 使用确定性多磁带图灵机形式化LLM的交互，其中每个磁带代表一个不同的组件：输入字符、标记、词汇表、模型参数、激活、概率分布和输出文本。

Result: 该模型能够将故障模式精确地定位到特定的管道阶段，揭示例如分词如何掩盖计数任务所需的字符级结构。该模型还阐明了思维链提示等技术为何通过将计算外部化到输出磁带上而有所帮助，同时揭示了它们的根本局限性。

Conclusion: 这种方法为几何隐喻提供了一种严谨、可证伪的替代方案，并通过原理性的错误分析补充了经验性的缩放定律。

Abstract: Large language models (LLMs) exhibit failure modes on seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi-tape Turing machine, where each tape represents a distinct component: input characters, tokens, vocabulary, model parameters, activations, probability distributions, and output text. The model enables precise localisation of failure modes to specific pipeline stages, revealing, e.g., how tokenisation obscures character-level structure needed for counting tasks. The model clarifies why techniques like chain-of-thought prompting help, by externalising computation on the output tape, while also revealing their fundamental limitations. This approach provides a rigorous, falsifiable alternative to geometric metaphors and complements empirical scaling laws with principled error analysis.

</details>


### [52] [Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of De-identification Approaches](https://arxiv.org/abs/2602.15869)
*Noopur Zambare,Kiana Aghakasiri,Carissa Lin,Carrie Ye,J. Ross Mitchell,Mohamed Abdalla*

Main category: cs.CL

TL;DR: 本研究评估了不同规模的语言模型在临床去识别任务上的表现。结果显示，小型模型具有与大型模型相当的性能，成本更低，并且经过微调后能在多文化（多种语言、性别）数据上超越大型模型。研究引入了BERT-MultiCulture-DEID以增强多文化鲁棒性，并量化了去识别任务中的效率-泛化性权衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床去识别方面表现出色，但以往研究未能检验其在格式、文化和性别之间的泛化能力。本研究旨在解决LLMs在临床去识别任务中跨格式、文化和性别的泛化性问题，并探索更实用、高效的解决方案。

Method: 本研究系统地评估了针对临床去识别任务的微调Transformer模型（BERT、ClinicalBERT、ModernBERT）、小型大型语言模型（LLMs，Llama 1-8B、Qwen 1.5-7B）和大型LLMs（Llama-70B、Qwen-72B）。研究展示了小型模型可以通过有限数据进行微调，以在识别来自普通话、印地语、西班牙语、法语、孟加拉语和英语地区变体以及性别名字的标识符方面超越大型模型。为了提高多文化环境中的鲁棒性，研究引入并公开发布了BERT-MultiCulture-DEID，这是一套基于BERT、ClinicalBERT和ModernBERT的去识别模型，这些模型在MIMIC数据集上使用多语言变体标识符进行了微调。

Result: 小型模型在性能上与大型模型相当，同时显著降低了推理成本，使其更具部署实用性。通过有限数据微调的小型模型，在识别来自普通话、印地语、西班牙语、法语、孟加拉语和英语地区变体以及性别名字的标识符方面，能够超越大型模型。研究引入了BERT-MultiCulture-DEID以提高多文化环境中的鲁棒性。本研究首次全面量化了去识别化中效率-泛化性的权衡。

Conclusion: 本研究首次全面量化了去识别化中效率-泛化性的权衡，并为公平高效的临床去识别化提供了实用的途径。

Abstract: Large language models (LLMs) have shown strong performance on clinical de-identification, the task of identifying sensitive identifiers to protect privacy. However, previous work has not examined their generalizability between formats, cultures, and genders. In this work, we systematically evaluate fine-tuned transformer models (BERT, ClinicalBERT, ModernBERT), small LLMs (Llama 1-8B, Qwen 1.5-7B), and large LLMs (Llama-70B, Qwen-72B) at de-identification. We show that smaller models achieve comparable performance while substantially reducing inference cost, making them more practical for deployment. Moreover, we demonstrate that smaller models can be fine-tuned with limited data to outperform larger models in de-identifying identifiers drawn from Mandarin, Hindi, Spanish, French, Bengali, and regional variations of English, in addition to gendered names. To improve robustness in multi-cultural contexts, we introduce and publicly release BERT-MultiCulture-DEID, a set of de-identification models based on BERT, ClinicalBERT, and ModernBERT, fine-tuned on MIMIC with identifiers from multiple language variants. Our findings provide the first comprehensive quantification of the efficiency-generalizability trade-off in de-identification and establish practical pathways for fair and efficient clinical de-identification. Details on accessing the models are available at:

</details>


### [53] [VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering](https://arxiv.org/abs/2602.15870)
*Shuhui Qu*

Main category: cs.CL

TL;DR: VDLM是一种可变扩散语言模型，通过在潜在空间中迭代细化语义规划，并使用轨迹感知优化对规划器进行后训练，从而在多步推理中实现可逆修改，并在各种推理、数学和代码任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型从左到右解码，具有不可逆的承诺，限制了多步推理期间的修改。

Method: 提出VDLM，一个模块化的可变扩散语言模型，将语义规划与文本渲染分离。VDLM在语义变量嵌入上应用LLaDA风格的掩码扩散，以在潜在空间中实现迭代细化。然后，使用嵌入空间奖励和值通过轨迹感知优化对规划器进行后训练，避免在RL循环内部进行文本解码。使用Vec2Text渲染器将规划的嵌入转换回文本，并引入嵌入扰动以增强规划器噪声下的解码鲁棒性。

Result: VDLM在预训练中具有竞争力，并在长篇生成任务上取得了显著的后训练改进，优于其他基线，涵盖了通用推理、数学和代码领域的九个基准。

Conclusion: 这些结果强调了嵌入空间后训练和鲁棒的潜在到文本渲染对于扩散语言建模的有效性。

Abstract: Autoregressive language models decode left-to-right with irreversible commitments, limiting revision during multi-step reasoning. We propose \textbf{VDLM}, a modular variable diffusion language model that separates semantic planning from text rendering. VDLM applies LLaDA-style masked diffusion over semantic variable embeddings to enable iterative refinement in latent space, then post-trains the planner with trajectory-aware optimization using embedding-space rewards and values, avoiding text decoding inside the RL loop. To convert planned embeddings back to text, we use a \textbf{Vec2Text} renderer and introduce \textbf{embedding perturbations} to robustify decoding under planner noise. Across nine benchmarks spanning general reasoning, math, and code, VDLM is competitive in pre-training and yields substantial post-training improvements on long-form generation tasks, outperforming other baselines. These results highlight the effectiveness of embedding-space post-training and robust latent-to-text rendering for diffusion language modeling.

</details>


### [54] [DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and Splitting](https://arxiv.org/abs/2602.15958)
*Md Mofijul Islam,Md Sirajus Salekin,Nivedha Balakrishnan,Vincil C. Bishop III,Niharika Jain,Spencer Romo,Bob Strahan,Boyi Xie,Diego A. Socolinsky*

Main category: cs.CL

TL;DR: 该论文介绍了首个全面的文档包拆分基准数据集DocSplit及其评估指标，以评估大型语言模型在处理复杂多页文档包方面的能力。实验发现现有模型在处理这些任务时存在显著的性能差距。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉文档理解取得了进展，但在实际应用中，将异构、多页文档包拆分为独立的文档单元这一基础任务仍未得到充分解决。

Method: 1. 提出了首个全面的基准数据集DocSplit和新颖的评估指标，用于评估大型语言模型的文档包拆分能力。2. DocSplit包含五个不同复杂程度的数据集，涵盖多种文档类型、布局和多模态设置。3. 正式定义了DocSplit任务，要求模型识别文档边界、分类文档类型并保持正确的页面顺序。4. 该基准解决了实际挑战，包括乱序页面、交错文档和缺乏明确分隔符的文档。5. 在这些数据集上进行了广泛实验，评估了多模态LLM。

Result: 实验揭示了当前多模态大型语言模型在处理复杂文档拆分任务方面存在显著的性能差距。

Conclusion: DocSplit基准数据集和提出的新颖评估指标为推进文档理解能力提供了一个系统框架，这对于法律、金融、医疗保健及其他文档密集型领域至关重要。研究者发布了数据集以促进未来的文档包处理研究。

Abstract: Document understanding in real-world applications often requires processing heterogeneous, multi-page document packets containing multiple documents stitched together. Despite recent advances in visual document understanding, the fundamental task of document packet splitting, which involves separating a document packet into individual units, remains largely unaddressed. We present the first comprehensive benchmark dataset, DocSplit, along with novel evaluation metrics for assessing the document packet splitting capabilities of large language models. DocSplit comprises five datasets of varying complexity, covering diverse document types, layouts, and multimodal settings. We formalize the DocSplit task, which requires models to identify document boundaries, classify document types, and maintain correct page ordering within a document packet. The benchmark addresses real-world challenges, including out-of-order pages, interleaved documents, and documents lacking clear demarcations. We conduct extensive experiments evaluating multimodal LLMs on our datasets, revealing significant performance gaps in current models' ability to handle complex document splitting tasks. The DocSplit benchmark datasets and proposed novel evaluation metrics provide a systematic framework for advancing document understanding capabilities essential for legal, financial, healthcare, and other document-intensive domains. We release the datasets to facilitate future research in document packet processing.

</details>


### [55] [CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated Content](https://arxiv.org/abs/2602.15871)
*Diletta Abbonato*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The proliferation of large language models (LLMs) in academic workflows has introduced unprecedented challenges to bibliographic integrity, particularly through reference hallucination -- the generation of plausible but non-existent citations. Recent investigations have documented the presence of AI-hallucinated citations even in papers accepted at premier machine learning conferences such as NeurIPS and ICLR, underscoring the urgency of automated verification mechanisms. This paper presents "CheckIfExist", an open-source web-based tool designed to provide immediate verification of bibliographic references through multi-source validation against CrossRef, Semantic Scholar, and OpenAlex scholarly databases. While existing reference management tools offer bibliographic organization capabilities, they do not provide real-time validation of citation authenticity. Commercial hallucination detection services, though increasingly available, often impose restrictive usage limits on free tiers or require substantial subscription fees. The proposed tool fills this gap by employing a cascading validation architecture with string similarity algorithms to compute multi-dimensional match confidence scores, delivering instant feedback on reference authenticity. The system supports both single-reference verification and batch processing of BibTeX entries through a unified interface, returning validated APA citations and exportable BibTeX records within seconds.

</details>


### [56] [P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA](https://arxiv.org/abs/2602.15874)
*Xingda Lyu,Gongfu Lyu,Zitai Yan,Yuxin Jiang*

Main category: cs.CL

TL;DR: 本研究提出了一种混合RAG变体P-RAG，它结合了LLM内的参数化知识和检索到的证据，并利用CoT提示和LoRA微调。P-RAG在生物医学和通用问答数据集上显著优于标准RAG，特别是在多跳推理方面。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)的能力受限于其对静态训练数据的依赖。检索增强生成(RAG)通过在推理过程中检索外部知识来解决这一限制，但其性能仍高度依赖于知识库的质量。本研究旨在探索RAG的潜在改进。

Method: 研究评估了三种RAG变体：Standard RAG、DA-RAG和本文提出的Prompt-Enhanced Parametric RAG (P-RAG)。P-RAG是一种混合架构，它将参数化知识与LLM内部和检索到的证据相结合，并由思维链(CoT)提示和低秩适应(LoRA)微调指导。模型采用通过LoRA微调的LLaMA-3.2-1B-Instruct，并在通用和生物医学数据集（PubMedQA和2WikiMultihopQA）上进行评估。

Result: 在PubMedQA上，P-RAG的F1分数达到93.33%，相比Standard RAG的82.86%提高了10.47个百分点。在2WikiMultihopQA上，P-RAG的总分达到33.44%，几乎是Standard RAG (17.83%)的两倍，在Compare子集上达到44.03%。CoT提示显著改善了多跳推理，但在单跳查询上结果不一。

Conclusion: P-RAG在生物医学问答中展现出准确、可扩展和上下文自适应的潜力。主要贡献包括：(1) 使用LoRA对LLaMA-3.2-1B-Instruct进行生物医学问答的微调，(2) 引入结合CoT提示的P-RAG，以及(3) 在PubMedQA和2WikiMultihopQA上取得了最先进的结果。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Generation (RAG) addresses this constraint by retrieving external knowledge during inference, though it still depends heavily on knowledge base quality. To explore potential improvements, we evaluated three RAG variants-Standard RAG, DA-RAG, and our proposed Prompt-Enhanced Parametric RAG (P-RAG), a hybrid architecture that integrates parametric knowledge within the LLM and retrieved evidence, guided by Chain-of-Thought (CoT) prompting and Low-Rank Adaptation (LoRA) fine-tuning-on both general and biomedical datasets. Using LLaMA-3.2-1B-Instruct fine-tuned via LoRA, we evaluate on PubMedQA and 2WikiMultihopQA. P-RAG outperforms Standard RAG on PubMedQA by 10.47 percentage points in F1 (93.33% vs. 82.86%; 12.64% relative). On 2WikiMultihopQA, P-RAG nearly doubles the overall score vs. Standard RAG (33.44% vs. 17.83%) and achieves 44.03% on the Compare subset (with 42.74% Bridge, 21.84% Inference, 8.60% Compose). CoT prompting substantially improves multi-hop reasoning but yields mixed results for simpler, single-hop queries. These findings underscore P-RAG's potential for accurate, scalable, and contextually adaptive biomedical question answering. Our contributions include: (1) LoRA-based fine-tuning of LLaMA-3.2-1B-Instruct for biomedical QA, (2) introduction of P-RAG with Chain-of-Thought prompting, and (3) state-of-the-art results on PubMedQA and 2WikiMultihopQA.

</details>


### [57] [Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity](https://arxiv.org/abs/2602.15894)
*Haihui Pan,Yuzhong Hong,Shaoke Lv,Junwei Bao,Hongfei Jiang,Yang Song*

Main category: cs.CL

TL;DR: 本文提出了QEMPO方法，通过最大化输出熵并确保质量，有效提升了大型语言模型输出的多样性，同时保持或超越了RLHF的性能。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型（LLM）的对齐方法在提高输出质量的同时，降低了输出多样性。现有提升多样性的方法又往往以牺牲性能为代价。

Method: 作者首先从理论上将对齐任务分解为质量和多样性两个分布。在此基础上，提出了一种名为质量约束熵最大化策略优化（QEMPO）的方法，旨在确保输出质量的同时最大化策略的输出熵。QEMPO可以通过添加不同的约束获得不同的策略，并提出了在线和离线训练方法来优化这些策略。

Result: 实验证明，QEMPO在提高输出多样性的同时，取得了与RLHF相当甚至更优的性能。

Conclusion: QEMPO能够有效解决LLM输出多样性与质量之间的权衡问题，在保证输出质量的前提下显著提升了多样性。

Abstract: Recent research indicates that while alignment methods significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come at the cost of reduced performance. In this work, we first theoretically demonstrate that the alignment task can be decomposed into two distributions: quality and diversity. To enhance the diversity of LLM outputs while ensuring quality, we propose the Quality-constrained Entropy Maximization Policy Optimization (QEMPO). QEMPO aims to maximize the output entropy of the policy while ensuring output quality. By adding different constraints to QEMPO, we obtain different policies. To optimize policies, we propose both online and offline training methods. Experiments validate that QEMPO achieves performance comparable to or even better than RLHF while improving output diversity.

</details>


### [58] [Every Little Helps: Building Knowledge Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens](https://arxiv.org/abs/2602.15896)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Wen Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: TOFU是一个用于多模态知识图谱推理（MMKGR）的基于token的基础模型，通过将结构、视觉和文本信息离散化为token并采用分层融合架构，实现了在不同MMKG上的强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数多模态知识图谱推理（MMKGR）方法是为直推式设置设计的，难以泛化到新的知识图谱。最近的知识图谱基础模型（KGFMs）虽然改善了跨知识图谱的迁移能力，但主要利用结构模式，忽略了丰富的多模态信号。

Method: TOFU模型将结构、视觉和文本信息离散化为特定模态的token，然后采用一个带有“消息混合机制”（mixture-of-message mechanisms）的分层融合架构来处理这些token，以获得可迁移的特征用于MMKGR。

Result: 在17个直推式、归纳式和完全归纳式多模态知识图谱（MMKGs）上的实验结果表明，TOFU持续优于强大的KGFM和MMKGR基线模型，并在未见过的MMKGs上表现出强大的性能。

Conclusion: TOFU提出了一种针对多模态知识图谱推理（MMKGR）的通用解决方案，通过有效利用多模态信息并展示出强大的迁移能力，解决了现有方法在泛化性和多模态利用方面的不足。

Abstract: Multi-modal knowledge graph reasoning (MMKGR) aims to predict the missing links by exploiting both graph structure information and multi-modal entity contents. Most existing works are designed for a transductive setting, which learns dataset-specific embeddings and struggles to generalize to new KGs. Recent knowledge graph foundation models (KGFMs) improve cross-KG transfer, but they mainly exploit structural patterns and ignore rich multi-modal signals. We address these gaps by proposing a token-based foundation model (TOFU) for MMKGR, which exhibits strong generalization across different MMKGs. TOFU discretizes structural, visual, and textual information into modality-specific tokens. TOFU then employs a hierarchical fusion architecture with mixture-of-message mechanisms, aiming to process these tokens and obtain transferable features for MMKGR. Experimental results on 17 transductive, inductive, and fully-inductive MMKGs show that TOFU consistently outperforms strong KGFM and MMKGR baselines, delivering strong performance on unseen MMKGs.

</details>


### [59] [Mitigating Gradient Inversion Risks in Language Models via Token Obfuscation](https://arxiv.org/abs/2602.15897)
*Xinguo Feng,Zhongkui Ma,Zihan Wang,Alsharif Abuadbba,Guangdong Bai*

Main category: cs.CL

TL;DR: GHOST是一种新颖的令牌级混淆机制，通过解耦梯度、嵌入和令牌空间之间的连接来有效防御梯度反演攻击（GIAs），在保护隐私的同时保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 协同学习在训练和微调大规模语言模型方面具有显著优势，但被证明容易受到梯度反演攻击（GIAs），攻击者可以从共享梯度中重建私有训练数据。现有防御措施（如噪声注入或梯度剪枝）通过扰动梯度来干扰GIAs，但由于梯度、嵌入和令牌空间之间语义相似性的保留而效果不佳。

Method: 本文提出了一种名为GHOST（gradient shield with obfuscated tokens）的令牌级混淆机制。GHOST通过解耦梯度、嵌入和令牌空间之间的固有连接来中和GIA攻击。其核心思想是利用语义不同但嵌入邻近的令牌作为原始令牌的“影子替代品”，从而在令牌空间实现语义断开，同时在嵌入和梯度空间保持连接。GHOST包含两个步骤：搜索步骤（使用多准则搜索过程识别语义不同的候选令牌）和选择步骤（选择最佳影子令牌，以最小化对训练关键特征的干扰，同时保持与原始令牌产生的内部输出的对齐）。

Result: 在多种模型架构（从BERT到Llama）和数据集上进行评估，GHOST在保护隐私（恢复率低至1%）和保持效用（分类F1高达0.92，困惑度为5.45）方面表现出显著效果，适用于分类和生成任务，并能有效防御最先进的GIA和自适应攻击场景。

Conclusion: GHOST在保护隐私和保持模型效用方面均表现出卓越的有效性，能够防御SOTA的GIA攻击和自适应攻击场景。

Abstract: Training and fine-tuning large-scale language models largely benefit from collaborative learning, but the approach has been proven vulnerable to gradient inversion attacks (GIAs), which allow adversaries to reconstruct private training data from shared gradients. Existing defenses mainly employ gradient perturbation techniques, e.g., noise injection or gradient pruning, to disrupt GIAs' direct mapping from gradient space to token space. However, these methods often fall short due to the retention of semantics similarity across gradient, embedding, and token spaces. In this work, we propose a novel defense mechanism named GHOST (gradient shield with obfuscated tokens), a token-level obfuscation mechanism that neutralizes GIAs by decoupling the inherent connections across gradient, embedding, and token spaces. GHOST is built upon an important insight: due to the large scale of the token space, there exist semantically distinct yet embedding-proximate tokens that can serve as the shadow substitutes of the original tokens, which enables a semantic disconnection in the token space while preserving the connection in the embedding and gradient spaces. GHOST comprises a searching step, which identifies semantically distinct candidate tokens using a multi-criteria searching process, and a selection step, which selects optimal shadow tokens to ensure minimal disruption to features critical for training by preserving alignment with the internal outputs produced by original tokens. Evaluation across diverse model architectures (from BERT to Llama) and datasets demonstrates the remarkable effectiveness of GHOST in protecting privacy (as low as 1% in recovery rate) and preserving utility (up to 0.92 in classification F1 and 5.45 in perplexity), in both classification and generation tasks against state-of-the-art GIAs and adaptive attack scenarios.

</details>


### [60] [MultiCube-RAG for Multi-hop Question Answering](https://arxiv.org/abs/2602.15898)
*Jimeng Shi,Wei Hu,Runchu Tian,Bowen Jin,Wonbin Kweon,SeongKu Kang,Yunfan Kang,Dingqi Ye,Sizhe Zhou,Shaowen Wang,Jiawei Han*

Main category: cs.CL

TL;DR: 该论文提出MultiCube-RAG，一种无训练的、基于本体的立方体结构方法，用于多跳问答。该方法通过多维正交结构建模信息并将复杂查询分解为子查询，从而提高了响应准确性、效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法难以准确捕捉多跳问答中的结构语义，导致性能不佳。基于图的RAG方法噪音大、计算成本高。大多数方法依赖单步检索，忽略多跳推理。基于训练的方法收敛不稳定且计算开销大。

Method: 该论文提出MultiCube-RAG，一种无训练方法，它设计了一种具有多个正交维度的本体化立方体结构来建模结构化的主题、属性和关系。该方法包含多个立方体用于多步推理和检索，每个立方体专门建模一类主题。它将复杂的多跳查询分解为沿立方体维度的简单子查询，并按顺序解决每个子查询。

Result: 在四个多跳问答数据集上的实验表明，MultiCube-RAG的响应准确率比各种基线的平均性能提高了8.9%。此外，该方法在效率和内在可解释性方面也表现出色。

Conclusion: MultiCube-RAG通过其基于本体的立方体结构和多步推理方法，提供了一种准确、高效且可解释的解决方案，有效解决了现有方法在多跳问答中的局限性。

Abstract: Multi-hop question answering (QA) necessitates multi-step reasoning and retrieval across interconnected subjects, attributes, and relations. Existing retrieval-augmented generation (RAG) methods struggle to capture these structural semantics accurately, resulting in suboptimal performance. Graph-based RAGs structure such information in graphs, but the resulting graphs are often noisy and computationally expensive. Moreover, most methods rely on single-step retrieval, neglecting the need for multi-hop reasoning processes. Recent training-based approaches attempt to incentivize the large language models (LLMs) for iterative reasoning and retrieval, but their training processes are prone to unstable convergence and high computational overhead. To address these limitations, we devise an ontology-based cube structure with multiple and orthogonal dimensions to model structural subjects, attributes, and relations. Built on the cube structure, we propose MultiCube-RAG, a training-free method consisting of multiple cubes for multi-step reasoning and retrieval. Each cube specializes in modeling a class of subjects, so that MultiCube-RAG flexibly selects the most suitable cubes to acquire the relevant knowledge precisely. To enhance the query-based reasoning and retrieval, our method decomposes a complex multi-hop query into a set of simple subqueries along cube dimensions and conquers each of them sequentially. Experiments on four multi-hop QA datasets show that MultiCube-RAG improves response accuracy by 8.9% over the average performance of various baselines. Notably, we also demonstrate that our method performs with greater efficiency and inherent explainability.

</details>


### [61] [A Curious Class of Adpositional Multiword Expressions in Korean](https://arxiv.org/abs/2602.16023)
*Junghyun Min,Na-Rae Han,Jena D. Hwang,Nathan Schneider*

Main category: cs.CL

TL;DR: 本论文研究了韩语后置动词结构（PVCs），提出了一套标注指南，旨在将其整合到跨语言框架中。


<details>
  <summary>Details</summary>
Motivation: 韩语多词短语在PARSEME等跨语言标注框架中代表性不足，特别是韩语多词介词缺乏系统分析、标注资源和现有框架的整合。

Method: 本文使用韩语维基百科数据，调查和分析了几种PVC表达，并将其与结构相似的非多词短语和轻动词结构进行对比。在此分析的基础上，提出了标注指南。

Result: 通过对韩语维基百科中PVCs的调查分析，并与非多词短语和轻动词结构进行对比，最终提出了一套标注指南。

Conclusion: 所提出的标注指南旨在支持未来韩语多词介词的研究工作，并促进与跨语言框架的对齐。

Abstract: Multiword expressions (MWEs) have been widely studied in cross-lingual annotation frameworks such as PARSEME. However, Korean MWEs remain underrepresented in these efforts. In particular, Korean multiword adpositions lack systematic analysis, annotated resources, and integration into existing multilingual frameworks. In this paper, we study a class of Korean functional multiword expressions: postpositional verb-based constructions (PVCs). Using data from Korean Wikipedia, we survey and analyze several PVC expressions and contrast them with non-MWEs and light verb constructions (LVCs) with similar structure. Building on this analysis, we propose annotation guidelines designed to support future work in Korean multiword adpositions and facilitate alignment with cross-lingual frameworks.

</details>


### [62] [CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill](https://arxiv.org/abs/2602.16054)
*Bradley McDanel,Steven Li,Harshit Khaitan*

Main category: cs.CL

TL;DR: 该论文提出了一种名为跨层注意力聚合（CLAA）的新型token排序方法，通过聚合不同层级的注意力分数，有效解决了长上下文LLM推理中预填充阶段的计算瓶颈，并将首次生成时间（TTFT）最多缩短了39%。


<details>
  <summary>Details</summary>
Motivation: 长上下文大型语言模型（LLM）推理中的预填充阶段是一个计算瓶颈。现有的token排序启发式方法通过选择性地处理语义相关token子集来加速推理，但这些方法存在token重要性估计不稳定的问题，其估计值在不同层之间波动较大，且难以独立评估token排序质量。

Method: 引入了一个“答案引导预言机”（Answer-Informed Oracle），通过测量从生成的答案到提示词的注意力来定义token重要性的真值。该预言机揭示了现有启发式方法在不同层之间存在高方差。针对此问题，提出了一种名为跨层注意力聚合（CLAA）的简单修复方案，该方案通过聚合所有层级的注意力分数，而非依赖单一层，来稳定token重要性估计。

Result: 跨层注意力聚合（CLAA）方法弥补了与预言机上限的差距，与完全KV缓存基线相比，首次生成时间（TTFT）最多减少了39%。

Conclusion: 通过跨层聚合注意力分数（CLAA），可以有效解决现有token排序启发式方法中token重要性估计不稳定的问题，显著提高长上下文LLM推理预填充阶段的效率。

Abstract: The prefill stage in long-context LLM inference remains a computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively processing a subset of semantically relevant tokens. However, existing methods suffer from unstable token importance estimation, often varying between layers. Evaluating token-ranking quality independently from heuristic-specific architectures is challenging. To address this, we introduce an Answer-Informed Oracle, which defines ground-truth token importance by measuring attention from generated answers back to the prompt. This oracle reveals that existing heuristics exhibit high variance across layers: rankings can degrade sharply at specific layers, a failure mode invisible to end-to-end benchmarks. The diagnosis suggests a simple fix: aggregate scores across layers rather than relying on any single one. We implement this as Cross-Layer Attention Aggregation (CLAA), which closes the gap to the oracle upper bound and reduces Time-to-First-Token (TTFT) by up to 39\% compared to the Full KV Cache baseline.

</details>


### [63] [Surgical Activation Steering via Generative Causal Mediation](https://arxiv.org/abs/2602.16080)
*Aruna Sankaranarayanan,Amir Zur,Atticus Geiger,Dylan Hadfield-Menell*

Main category: cs.CL

TL;DR: 本文介绍了生成因果中介（GCM），一种选择模型组件（例如注意力头）以控制语言模型中长篇响应行为的方法，并在拒绝、奉承和风格迁移任务上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决在语言模型中进行干预以控制在长篇响应中广泛分布的行为的难题。

Method: GCM首先构建对比输入和响应的数据集，然后量化单个模型组件如何中介对比概念，并选择最强的中介进行引导。

Result: GCM成功定位了长篇响应中表达的概念，并且在使用稀疏的注意力头进行引导时，始终优于基于相关性探针的基线方法。

Conclusion: GCM为定位和控制语言模型的长篇响应提供了一种有效方法。

Abstract: Where should we intervene in a language model (LM) to control behaviors that are diffused across many tokens of a long-form response? We introduce Generative Causal Mediation (GCM), a procedure for selecting model components, e.g., attention heads, to steer a binary concept (e.g., talk in verse vs. talk in prose) from contrastive long-form responses. In GCM, we first construct a dataset of contrasting inputs and responses. Then, we quantify how individual model components mediate the contrastive concept and select the strongest mediators for steering. We evaluate GCM on three tasks--refusal, sycophancy, and style transfer--across three language models. GCM successfully localizes concepts expressed in long-form responses and consistently outperforms correlational probe-based baselines when steering with a sparse set of attention heads. Together, these results demonstrate that GCM provides an effective approach for localizing and controlling the long-form responses of LMs.

</details>


### [64] [Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs](https://arxiv.org/abs/2602.16085)
*Sean Trott,Samuel Taylor,Cameron Jones,James A. Michaelov,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 本研究评估了41个开源语言模型在错误信念任务中的心理状态推理能力。发现34%的模型对隐含知识状态敏感，但没有模型能完全解释人类效应。大型语言模型显示出更高的敏感性和预测力。研究还发现，当知识状态通过非事实动词提示时，人类和语言模型都更容易归因错误信念，这表明语言的分布统计可以解释这种人类偏见。结论是开源语言模型对于检验人类认知理论和评估语言模型能力有重要价值。


<details>
  <summary>Details</summary>
Motivation: 语言模型中的心理状态推理研究有助于阐明人类社会认知理论（例如，心理状态推理部分源于语言接触的理论）以及我们对语言模型本身的理解。然而，许多已发表的关于语言模型的工作依赖于相对较小的闭源语言模型样本，这限制了我们严格检验心理学理论和评估语言模型能力的能力。

Method: 通过评估41个（来自不同模型家族的）开源模型的心理状态推理行为，复制并扩展了已发表的关于错误信念任务的研究。还使用语言模型行为生成并检验了一个关于人类认知的新假设。

Result: 34%的受测试语言模型对隐含知识状态表现出敏感性；然而，与之前的工作一致，没有一个模型能完全“解释”人类效应。较大的语言模型显示出更高的敏感性，并且也表现出更高的心理测量预测能力。此外，研究发现人类和语言模型都偏向于在知识状态通过非事实动词（“John thinks...”）提示时，比通过间接方式（“John looks in the...”）提示时，更容易归因错误信念。与知识状态的主要效应（人类敏感性超过语言模型）不同，人类知识提示效应的幅度恰好落在语言模型效应大小的分布范围内，这表明语言的分布统计可以在原则上解释后者，但不能解释前者。

Conclusion: 这些结果表明，使用更大样本的开源语言模型对于检验人类认知理论和评估语言模型能力具有重要价值。

Abstract: Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on LMs relies on a relatively small sample of closed-source LMs, limiting our ability to rigorously test psychological theories and evaluate LM capacities. Here, we replicate and extend published work on the false belief task by assessing LM mental state reasoning behavior across 41 open-weight models (from distinct model families). We find sensitivity to implied knowledge states in 34% of the LMs tested; however, consistent with prior work, none fully ``explain away'' the effect in humans. Larger LMs show increased sensitivity and also exhibit higher psychometric predictive power. Finally, we use LM behavior to generate and test a novel hypothesis about human cognition: both humans and LMs show a bias towards attributing false beliefs when knowledge states are cued using a non-factive verb (``John thinks...'') than when cued indirectly (``John looks in the...''). Unlike the primary effect of knowledge states, where human sensitivity exceeds that of LMs, the magnitude of the human knowledge cue effect falls squarely within the distribution of LM effect sizes-suggesting that distributional statistics of language can in principle account for the latter but not the former in humans. These results demonstrate the value of using larger samples of open-weight LMs to test theories of human cognition and evaluate LM capacities.

</details>


### [65] [Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities](https://arxiv.org/abs/2602.16093)
*Shankar Padmanabhan,Mustafa Omer Gul,Tanya Goyal*

Main category: cs.CL

TL;DR: DiSC是一种基于上下文蒸馏的持续知识适应方法，通过从训练示例的不同部分推导学生和教师分布并最小化共享token之间的KL散度，在学习新知识和缓解遗忘之间实现了最佳权衡。


<details>
  <summary>Details</summary>
Motivation: 预训练LLM在后训练后具备了指令遵循和推理等能力，但其知识有截止日期，需要持续适应。现有解决方案无法同时学习新知识并缓解对先前学习能力的遗忘。

Method: 提出Distillation via Split Contexts (DiSC)，这是一种基于上下文蒸馏的持续知识适应方法。DiSC通过对训练示例的不同部分进行条件化，推导学生和教师分布，并最小化共享token之间的KL散度，从而无需训练期间的显式生成步骤即可高效应用上下文蒸馏。

Result: 在四个后训练模型和两个适应域上进行了实验。与之前的微调和蒸馏方法相比，DiSC在学习新知识和缓解遗忘（如指令遵循、推理和事实知识）之间始终报告最佳权衡。

Conclusion: DiSC在持续知识适应方面表现出色，有效解决了学习新知识和缓解遗忘之间的冲突，取得了最佳的权衡效果。

Abstract: Post-training endows pretrained LLMs with a variety of desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions cannot simultaneously learn new knowledge from an adaptation document corpora and mitigate the forgetting of earlier learned capabilities. To address this, we introduce Distillation via Split Contexts (DiSC), a simple context-distillation based approach for continual knowledge adaptation. \methodname~derives student and teacher distributions by conditioning on distinct segments of the training example and minimizes the KL divergence between the shared tokens. This allows us to efficiently apply context-distillation without requiring explicit generation steps during training. We run experiments on four post-trained models and two adaptation domains. Compared to prior finetuning and distillation methods for continual adaptation, DiSC consistently reports the best trade-off between learning new knowledge and mitigating forgetting of previously learned skills like instruction-following, reasoning, and factual knowledge.

</details>


### [66] [Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis](https://arxiv.org/abs/2602.16144)
*Rong Fu,Wenxin Zhang,Ziming Wang,Chunlei Meng,Jiaxuan Lu,Jiekai Wu,Kangan Qian,Hao Zhang,Simon Fong*

Main category: cs.CL

TL;DR: 本文提出了Missing-by-Design (MBD)，一个可撤销多模态情感分析的统一框架，它通过结合结构化表示学习和可认证的参数修改流程，实现了选择性撤销特定数据模态，以满足隐私合规和用户自主性的需求。


<details>
  <summary>Details</summary>
Motivation: 随着多模态系统处理的敏感个人数据越来越多，选择性撤销特定数据模态的能力已成为隐私合规和用户自主性的关键要求。在隐私敏感应用中，用户或监管机构可能要求删除特定模态的信息，因此可撤销性至关重要。

Method: MBD是一个统一的可撤销多模态情感分析框架，它结合了结构化表示学习和可认证的参数修改流程。它学习属性感知嵌入，并采用基于生成器的重建来恢复缺失通道。对于删除请求，该框架应用显著性驱动的候选选择和校准的高斯更新来生成机器可验证的模态删除证书。

Result: 在基准数据集上的实验表明，MBD在不完整输入下仍能实现强大的预测性能，并提供了实用的隐私-效用权衡。

Conclusion: MBD将外科式遗忘定位为全面再训练的有效替代方案。

Abstract: As multimodal systems increasingly process sensitive personal data, the ability to selectively revoke specific data modalities has become a critical requirement for privacy compliance and user autonomy. We present Missing-by-Design (MBD), a unified framework for revocable multimodal sentiment analysis that combines structured representation learning with a certifiable parameter-modification pipeline. Revocability is critical in privacy-sensitive applications where users or regulators may request removal of modality-specific information. MBD learns property-aware embeddings and employs generator-based reconstruction to recover missing channels while preserving task-relevant signals. For deletion requests, the framework applies saliency-driven candidate selection and a calibrated Gaussian update to produce a machine-verifiable Modality Deletion Certificate. Experiments on benchmark datasets show that MBD achieves strong predictive performance under incomplete inputs and delivers a practical privacy-utility trade-off, positioning surgical unlearning as an efficient alternative to full retraining.

</details>


### [67] [Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution](https://arxiv.org/abs/2602.16154)
*Nithin Sivakumaran,Shoubin Yu,Hyunji Lee,Yue Zhang,Ali Payani,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: REMUL是一种多方强化学习方法，通过让听者模型执行说话者生成的推理链条来提升大型语言模型CoT推理的忠实性和准确性，同时解决忠实性与性能的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链（CoT）推理未能忠实反映大型语言模型（LLM）的真实计算过程，限制了其解释LLM答案生成方式的效用。此外，在推理中优化忠实性和可解释性往往会降低任务性能。

Method: 提出REMUL（Reasoning Execution by Multiple Listeners），一种多方强化学习方法。REMUL基于“其他方能理解的推理轨迹更忠实”的假设。说话者模型生成推理轨迹，截断后传递给一组听者模型“执行”以得出答案。说话者因生成对听者清晰的推理而获得奖励，并通过掩码监督微调进行额外的正确性正则化，以解决忠实性与性能的权衡。

Result: 在多个推理基准（BIG-Bench Extra Hard, MuSR, ZebraLogicBench, FOLIO）上，REMUL持续且显著地提高了忠实性的三项指标（提示归因、早期回答曲线下面积AOC和错误注入AOC），同时提高了准确性。分析发现这些提升在不同训练域中具有鲁棒性，可转化为可读性提升，并与更短、更直接的CoT相关。

Conclusion: REMUL成功解决了CoT推理的忠实性与性能之间的权衡，并通过多方交互学习显著提高了大型语言模型的推理忠实性和任务准确性，同时使推理过程更清晰、更直接。

Abstract: Chain-of-thought (CoT) reasoning sometimes fails to faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often degrades task performance. To address this tradeoff and improve CoT faithfulness, we propose Reasoning Execution by Multiple Listeners (REMUL), a multi-party reinforcement learning approach. REMUL builds on the hypothesis that reasoning traces which other parties can follow will be more faithful. A speaker model generates a reasoning trace, which is truncated and passed to a pool of listener models who "execute" the trace, continuing the trace to an answer. Speakers are rewarded for producing reasoning that is clear to listeners, with additional correctness regularization via masked supervised finetuning to counter the tradeoff between faithfulness and performance. On multiple reasoning benchmarks (BIG-Bench Extra Hard, MuSR, ZebraLogicBench, and FOLIO), REMUL consistently and substantially improves three measures of faithfulness -- hint attribution, early answering area over the curve (AOC), and mistake injection AOC -- while also improving accuracy. Our analysis finds that these gains are robust across training domains, translate to legibility gains, and are associated with shorter and more direct CoTs.

</details>


### [68] [LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers](https://arxiv.org/abs/2602.16162)
*Peiqi Sui*

Main category: cs.CL

TL;DR: 大型语言模型在创意写作中缺乏不确定性，导致其内容平庸。本研究量化了人类与模型输出之间的“不确定性差距”，发现人类写作的不确定性显著高于模型，且对齐模型加剧了这一差距。要实现人类水平的创造力，需开发新的以不确定性为导向的对齐范式。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在创意写作中的表现（常被认为是平庸和陈词滥调）存在一个关键且未被充分研究的局限性，即不确定性。文学理论认为不确定性是创意表达的必要条件，而当前的对齐策略却使模型避免不确定性输出，以确保事实性和减少幻觉，这种矛盾促使本研究进行。

Method: 通过对28个大型语言模型在高质量故事数据集上进行受控的信息论分析，量化人类创作故事和模型生成续写之间的“不确定性差距”。

Result: 人类写作始终表现出比模型输出显著更高的不确定性。指令微调和推理模型相比其基础模型加剧了这一趋势。此外，这种差距在创意写作中比在功能领域更为明显，并与写作质量密切相关。

Conclusion: 要达到人类水平的创造力，需要新的、能区分破坏性幻觉和文学丰富性所需建设性模糊的、以不确定性为导向的对齐范式。

Abstract: We argue that uncertainty is a key and understudied limitation of LLMs' performance in creative writing, which is often characterized as trite and cliché-ridden. Literary theory identifies uncertainty as a necessary condition for creative expression, while current alignment strategies steer models away from uncertain outputs to ensure factuality and reduce hallucination. We formalize this tension by quantifying the "uncertainty gap" between human-authored stories and model-generated continuations. Through a controlled information-theoretic analysis of 28 LLMs on high-quality storytelling datasets, we demonstrate that human writing consistently exhibits significantly higher uncertainty than model outputs. We find that instruction-tuned and reasoning models exacerbate this trend compared to their base counterparts; furthermore, the gap is more pronounced in creative writing than in functional domains, and strongly correlates to writing quality. Achieving human-level creativity requires new uncertainty-aware alignment paradigms that can distinguish between destructive hallucinations and the constructive ambiguity required for literary richness.

</details>


### [69] [Beyond Learning: A Training-Free Alternative to Model Adaptation](https://arxiv.org/abs/2602.16189)
*Namkyung Yoon,Kyeonghyun Yoo,Wooyong Jung,Sanghong Kim,Hwangnam Kim*

Main category: cs.CL

TL;DR: 通过激活分析识别语言模型中的局部任务模块，并将其移植到目标模型，以实现性能的即时提升，无需额外训练，并提出模型移植这一新研究领域。


<details>
  <summary>Details</summary>
Motivation: 语言模型有时会表现不如旧版本，而现有克服挑战的方法资源密集。研究需要一种能够实现即时行动的替代方案，并假设每个语言模型内部都包含适合特定功能的局部模块。

Method: 1. 通过激活分析，识别在推理负载下显示一致局部激活变化的模块。
2. 将针对特定任务适当激活的内部模块移植到目标模型中，以实现即时、可测量的功能改变，无需额外训练或微调。
3. 通过量化移植强度与性能提升之间的关系，在两种语言模型上实验验证移植技术的有效性。

Result: 1. 在跨代设置中，移植激活选择的模块显著改善了表现不佳的模型，性能最高达到目标基线的两倍，基于差距的恢复率超过100%。
2. 在基础模型与其指令微调对应模型之间的移植实验中，移植使表现不佳的模型性能向更强的基线靠拢，最佳情况下达到目标基线的约2.33倍，基于差距的恢复率达到100%。
3. 这些结果表明，通过植入语言模型中高度局部化的模块，可以实现有意义的能力迁移。

Conclusion: 这项工作为语言模型中的任务局部化模块化提供了经验证据，并提出了一个新的研究领域：模型移植。

Abstract: Despite the continuous research and evolution of language models, they sometimes underperform previous versions. Existing approaches to overcome these challenges are resource-intensive, highlighting the need for alternatives that enable immediate action. We assume that each language model has a local module inside that is suitable for a specific function. First, this work identifies a set of modules showing consistent and local activation changes under an inference workload through activation-based analysis. Subsequently, we transplant an internal module that is properly activated for a specific task into the target model, leading to immediate and measurable functional changes without additional training or fine-tuning. To experimentally demonstrate the effectiveness of the transplant technique, we quantify the relationship between transplant strength and performance improvement under different conditions for two language models. In the cross-generation setting, we find that transplanting activation-selected modules can substantially improve the underperforming model, reaching up to twice the target baseline and achieving gap-based recovery above 100%. Moreover, in transplant experiments between a base model and its instruction-tuned counterpart, transplantation improves the underperforming model toward the stronger baseline, yielding up to about 2.33 times the target baseline with gap-based recovery reaching up to 100% in the best case. These results show that meaningful capacity transfer can be realized through the implantation of highly localized modules implied by language models. Overall, this work provides empirical evidence for task-localized modularity in language models and presents a new research area: model transplantation.

</details>


### [70] [The Validity of Coreference-based Evaluations of Natural Language Understanding](https://arxiv.org/abs/2602.16200)
*Ian Porada*

Main category: cs.CL

TL;DR: 该论文通过扩展现有评估实践并考虑评估结果的收敛性或冲突性，重新审视了共指消解评估的结论。研究发现，尽管当前语言模型在标准基准测试上表现强劲，但由于测量有效性问题，其结论往往不可泛化，并且对评估条件敏感。


<details>
  <summary>Details</summary>
Motivation: 现有共指消解评估的设计因测量有效性问题（如定义争议和收敛有效性）导致非泛化性结论。本文旨在通过扩展评估实践，更深入理解共指消解评估的结论。

Method: 首先，分析了标准共指消解评估，指出了其设计中存在的测量有效性问题。其次，提出并实现了一种新颖的评估方法，专注于测试系统推断事件相对合理性的能力，这是解决共指消解的关键方面。

Result: 当代语言模型在标准基准测试上表现出强大的性能，在特定领域和共指消解类型上优于早期基线系统。然而，它们对评估条件仍然敏感，当评估上下文略有修改时，往往无法像人类一样进行泛化。

Conclusion: 研究结果阐明了当前NLP范式的优势（如在广泛使用的评估中提高了准确性）和局限性（包括测量有效性方面的弱点）。这为未来开发更好的评估方法和更具泛化性的系统指明了方向。

Abstract: In this thesis, I refine our understanding as to what conclusions we can reach from coreference-based evaluations by expanding existing evaluation practices and considering the extent to which evaluation results are either converging or conflicting. First, I analyze standard coreference evaluations and show that their design often leads to non-generalizable conclusions due to issues of measurement validity - including contestedness (multiple, competing definitions of coreference) and convergent validity (evaluation results that rank models differently across benchmarks). Second, I propose and implement a novel evaluation focused on testing systems' ability to infer the relative plausibility of events, a key aspect of resolving coreference. Through this extended evaluation, I find that contemporary language models demonstrate strong performance on standard benchmarks - improving over earlier baseline systems within certain domains and types of coreference - but remain sensitive to the evaluation conditions: they often fail to generalize in ways one would expect a human to be capable of when evaluation contexts are slightly modified. Taken together, these findings clarify both the strengths, such as improved accuracy over baselines on widely used evaluations, and the limitations of the current NLP paradigm, including weaknesses in measurement validity, and suggest directions for future work in developing better evaluation methods and more genuinely generalizable systems.

</details>


### [71] [Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications](https://arxiv.org/abs/2602.16201)
*Sanket Badhe,Deep Shah,Nehal Kathrotia*

Main category: cs.CL

TL;DR: 本论文提供了一个统一的框架，用于理解大型语言模型（LLMs）中长尾知识的定义、丢失、评估和体现，并探讨了相关开放性挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在低频、特定领域、文化和时间性知识方面表现出持续的失败，但这些失败的特征尚不明确。

Method: 本文开发了一个结构化的长尾知识分类法和分析方法，综合了技术和社会技术视角。引入了一个结构化的分析框架，该框架综合了先前工作在四个互补轴上的内容：长尾知识的定义方式、在训练和推理过程中丢失或扭曲的机制、为缓解这些失败而提出的技术干预措施，以及这些失败对公平性、问责制、透明度和用户信任的影响。此外，还审查了现有评估实践如何掩盖尾部行为并使罕见但重要的失败的问责制复杂化。

Result: 本文提出了一个统一的概念框架，用于理解长尾知识在部署的语言模型系统中如何被定义、丢失、评估和体现。并指出了与隐私、可持续性和治理相关的开放挑战，这些挑战限制了长尾知识的表示。

Conclusion: 本文提供了一个统一的概念框架，用于理解大型语言模型中长尾知识的定义、丢失、评估和体现，并强调了未来研究和实践中的开放性挑战。

Abstract: Large language models (LLMs) are trained on web-scale corpora that exhibit steep power-law distributions, in which the distribution of knowledge is highly long-tailed, with most appearing infrequently. While scaling has improved average-case performance, persistent failures on low-frequency, domain-specific, cultural, and temporal knowledge remain poorly characterized. This paper develops a structured taxonomy and analysis of long-Tail Knowledge in large language models, synthesizing prior work across technical and sociotechnical perspectives. We introduce a structured analytical framework that synthesizes prior work across four complementary axes: how long-Tail Knowledge is defined, the mechanisms by which it is lost or distorted during training and inference, the technical interventions proposed to mitigate these failures, and the implications of these failures for fairness, accountability, transparency, and user trust. We further examine how existing evaluation practices obscure tail behavior and complicate accountability for rare but consequential failures. The paper concludes by identifying open challenges related to privacy, sustainability, and governance that constrain long-Tail Knowledge representation. Taken together, this paper provides a unifying conceptual framework for understanding how long-Tail Knowledge is defined, lost, evaluated, and manifested in deployed language model systems.

</details>


### [72] [Are LLMs Ready to Replace Bangla Annotators?](https://arxiv.org/abs/2602.16241)
*Md. Najib Hasan,Touseef Hasan,Souvika Sarkar*

Main category: cs.CL

TL;DR: LLMs作为自动标注器在低资源敏感任务中存在偏见和不稳定，且模型规模增大不一定能提高标注质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为自动标注器在数据集创建中日益普及，但其在低资源和身份敏感环境下的无偏可靠性尚不明确。特别是在孟加拉语仇恨言论这类人类标注都存在挑战且标注偏见可能导致严重后果的任务中，LLMs的表现需要深入研究。

Method: 研究人员对17个大型语言模型（LLMs）作为孟加拉语仇恨言论的零样本标注器进行了系统性基准测试，并使用了统一的评估框架来分析它们的行为。

Result: 分析揭示了标注器偏见和模型判断中的显著不稳定性。出乎意料的是，模型规模的增加并未能保证标注质量的提高；相反，规模较小、更符合任务的模型反而比大型模型表现出更一致的行为。

Conclusion: 这些结果强调了当前LLMs在低资源语言敏感标注任务中的重要局限性，并强调了在部署前进行仔细评估的必要性。

Abstract: Large Language Models (LLMs) are increasingly used as automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of LLMs as zero-shot annotators for Bangla hate speech, a task where even human agreement is challenging, and annotator bias can have serious downstream consequences. We conduct a systematic benchmark of 17 LLMs using a unified evaluation framework. Our analysis uncovers annotator bias and substantial instability in model judgments. Surprisingly, increased model scale does not guarantee improved annotation quality--smaller, more task-aligned models frequently exhibit more consistent behavior than their larger counterparts. These results highlight important limitations of current LLMs for sensitive annotation tasks in low-resource languages and underscore the need for careful evaluation before deployment.

</details>


### [73] [Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation](https://arxiv.org/abs/2602.16290)
*Jonathan Mutal,Perla Al Almaoui,Simon Hengchen,Pierrette Bouillon*

Main category: cs.CL

TL;DR: Aladdin-FTI是一个用于生成和翻译摩洛哥、埃及、巴勒斯坦、叙利亚和沙特方言的阿拉伯方言系统，并支持这些方言、现代标准阿拉伯语和英语之间的双向翻译，以解决阿拉伯语方言在NLP中代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 由于非标准化和高变异性，阿拉伯方言在自然语言处理(NLP)研究中长期代表性不足。大型语言模型(LLMs)等最新进展为将阿拉伯语建模为多中心语言而非单一系统提供了解决这一差距的途径。

Method: 本文介绍了Aladdin-FTI，这是一个为AMIYA共享任务提交的系统。该系统旨在生成和翻译阿拉伯方言(DA)。具体而言，该模型支持摩洛哥、埃及、巴勒斯坦、叙利亚和沙特方言的文本生成，以及这些方言、现代标准阿拉伯语(MSA)和英语之间的双向翻译。

Result: Aladdin-FTI系统支持摩洛哥、埃及、巴勒斯坦、叙利亚和沙特方言的文本生成，以及这些方言、现代标准阿拉伯语(MSA)和英语之间的双向翻译。代码和训练模型已公开提供。

Conclusion: Aladdin-FTI通过提供一个跨多种方言、现代标准阿拉伯语和英语的生成和翻译模型，解决了阿拉伯语方言在NLP中代表性不足的问题，促进了将阿拉伯语建模为多中心语言。

Abstract: Arabic dialects have long been under-represented in Natural Language Processing (NLP) research due to their non-standardization and high variability, which pose challenges for computational modeling. Recent advances in the field, such as Large Language Models (LLMs), offer promising avenues to address this gap by enabling Arabic to be modeled as a pluricentric language rather than a monolithic system. This paper presents Aladdin-FTI, our submission to the AMIYA shared task. The proposed system is designed to both generate and translate dialectal Arabic (DA). Specifically, the model supports text generation in Moroccan, Egyptian, Palestinian, Syrian, and Saudi dialects, as well as bidirectional translation between these dialects, Modern Standard Arabic (MSA), and English. The code and trained model are publicly available.

</details>


### [74] [MultiCW: A Large-Scale Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models](https://arxiv.org/abs/2602.16298)
*Martin Hyben,Sebastian Kula,Jan Cegin,Jakub Simko,Ivan Srba,Robert Moro*

Main category: cs.CL

TL;DR: 本研究引入了MultiCW数据集，这是一个包含16种语言的多语言可核查声明检测基准。通过对比微调模型和零样本大型语言模型，发现微调模型在声明分类上表现更优，并具有出色的域外泛化能力，为自动化事实核查提供了重要资源。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型正在重塑媒体专业人士核查信息的方式，但事实核查过程中检测可核查声明这一关键步骤的自动化支持仍然有限。

Method: 研究引入了Multi-Check-Worthy (MultiCW)数据集，这是一个平衡的多语言基准，用于可核查声明检测，涵盖16种语言、7个主题领域和2种写作风格，包含123,722个样本，并额外引入了包含4种语言的27,761个样本的OOD评估集以测试鲁棒性。研究还对3个常见的微调多语言Transformer模型与15个商业和开源大型语言模型在零样本设置下进行了基准测试。

Result: 研究发现，微调模型在声明分类上始终优于零样本大型语言模型，并表现出在语言、领域和风格方面强大的域外泛化能力。

Conclusion: MultiCW数据集为推进自动化事实核查提供了一个严谨的多语言资源，并支持对微调模型与前沿大型语言模型在可核查声明检测任务上的系统比较。

Abstract: Large Language Models (LLMs) are beginning to reshape how media professionals verify information, yet automated support for detecting check-worthy claims a key step in the fact-checking process remains limited. We introduce the Multi-Check-Worthy (MultiCW) dataset, a balanced multilingual benchmark for check-worthy claim detection spanning 16 languages, 7 topical domains, and 2 writing styles. It consists of 123,722 samples, evenly distributed between noisy (informal) and structured (formal) texts, with balanced representation of check-worthy and non-check-worthy classes across all languages. To probe robustness, we also introduce an equally balanced out-of-distribution evaluation set of 27,761 samples in 4 additional languages. To provide baselines, we benchmark 3 common fine-tuned multilingual transformers against a diverse set of 15 commercial and open LLMs under zero-shot settings. Our findings show that fine-tuned models consistently outperform zero-shot LLMs on claim classification and show strong out-of-distribution generalization across languages, domains, and styles. MultiCW provides a rigorous multilingual resource for advancing automated fact-checking and enables systematic comparisons between fine-tuned models and cutting-edge LLMs on the check-worthy claim detection task.

</details>


### [75] [Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents](https://arxiv.org/abs/2602.16379)
*Mohammad H.A. Monfared,Lucie Flek,Akbar Karimi*

Main category: cs.CL

TL;DR: 该研究提出了一种用于基于方面的情感分析（ABSA）的智能体数据增强方法，利用迭代生成和验证来生成高质量的合成训练样本。该方法在标签保留方面优于基于提示的方法，尤其是在需要方面术语生成的任务中，并且与真实数据结合时能提供更大的增益，显著提升了T5-Base模型的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于方面的情感分析（ABSA）中高质量训练样本的获取问题，提高模型的性能，研究旨在通过开发一种有效的智能体数据增强方法来生成合成训练样本。

Method: 提出了一种基于迭代生成和验证的智能体数据增强方法，用于生成高质量的ABSA合成训练样本。为进行比较，开发了一个使用相同模型和指令的紧密匹配的基于提示的基线。两种方法在三个ABSA子任务（方面术语提取、方面情感分类、方面情感对提取）、四个SemEval数据集和两种编码器-解码器模型（T5-Base和Tk-Instruct）上进行了评估。

Result: 智能体增强在增强数据的标签保留方面优于原始提示方法，尤其是在需要方面术语生成的任务中。与真实数据结合时，智能体增强提供了更高的增益，始终优于基于提示的生成方法。这些优势在T5-Base模型上最为显著，而预训练程度更高的Tk-Instruct模型则表现出较小的改进。增强数据有助于T5-Base达到与其对应模型相当的性能。

Conclusion: 智能体数据增强方法能够有效生成高质量的ABSA训练数据，在标签保留和性能提升方面优于基于提示的方法，尤其对于需要方面术语生成的任务和T5-Base等模型而言，其益处更为突出。

Abstract: We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (ATSC), and Aspect Sentiment Pair Extraction (ASPE)), four SemEval datasets, and two encoder-decoder models: T5-Base and Tk-Instruct. Our results show that the agentic augmentation outperforms raw prompting in label preservation of the augmented data, especially when the tasks require aspect term generation. In addition, when combined with real data, agentic augmentation provides higher gains, consistently outperforming prompting-based generation. These benefits are most pronounced for T5-Base, while the more heavily pretrained Tk-Instruct exhibits smaller improvements. As a result, augmented data helps T5-Base achieve comparable performance with its counterpart.

</details>


### [76] [IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models](https://arxiv.org/abs/2602.16467)
*Saurabh Bharti,Gaurav Azad,Abhinaw Jagtap,Nachiket Tapas*

Main category: cs.CL

TL;DR: 本文介绍了IndicEval，一个利用真实的印度考试题目（UPSC, JEE, NEET）在英语和印地语中评估LLM性能的基准测试平台，揭示了CoT提示的益处、模型间差异以及多语言退化问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速发展需要能够反映真实世界学术严谨性和多语言复杂性的评估框架。现有合成基准测试不足以进行真实评估。

Method: IndicEval是一个可扩展的基准测试平台，使用来自UPSC、JEE和NEET的真实高风险考试题目，涵盖STEM和人文领域，支持英语和印地语。该框架通过零样本（Zero-Shot）、少样本（Few-Shot）和思维链（CoT）提示策略自动进行评估，并支持新模型和语言的模块化集成。实验对象包括Gemini 2.0 Flash、GPT-4、Claude和LLaMA 3-70B。

Result: 1. 思维链（CoT）提示策略持续提高推理准确性，在不同科目和语言中均有显著提升。
2. 模型间的性能差异显著，尤其是在高复杂性考试中。
3. 多语言性能下降是一个严峻挑战，印地语的准确率相比英语有明显下降，尤其是在零样本（Zero-Shot）条件下，这突出表明了双语推理和领域迁移能力的不足。

Conclusion: IndicEval为多语言教育环境中LLM的严格、公平评估提供了一个实践导向且可扩展的基础，并为提高推理鲁棒性和语言适应性提供了可操作的见解。

Abstract: The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluation in real examination standards, enabling realistic measurement of reasoning, domain knowledge, and bilingual adaptability. The framework automates assessment using Zero-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting strategies and supports modular integration of new models and languages. Experiments conducted on Gemini 2.0 Flash, GPT-4, Claude, and LLaMA 3-70B reveal three major findings. First, CoT prompting consistently improves reasoning accuracy, with substantial gains across subjects and languages. Second, significant cross-model performance disparities persist, particularly in high-complexity examinations. Third, multilingual degradation remains a critical challenge, with marked accuracy drops in Hindi compared to English, especially under Zero-Shot conditions. These results highlight persistent gaps in bilingual reasoning and domain transfer. Overall, IndicEval provides a practice-oriented, extensible foundation for rigorous, equitable evaluation of LLMs in multilingual educational settings and offers actionable insights for improving reasoning robustness and language adaptability.

</details>


### [77] [Training Models on Dialects of Translationese Shows How Lexical Diversity and Source-Target Syntactic Similarity Shape Learning](https://arxiv.org/abs/2602.16469)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 本研究探讨了机器翻译数据对小型英语语言模型的影响，发现源语言对模型行为有明显影响：通用困惑度主要受翻译语料库的词汇多样性驱动，而语法性能在数据充足的情况下与源语言和英语的类型学相似性强相关。


<details>
  <summary>Details</summary>
Motivation: 机器翻译数据在多语言自然语言处理中广泛应用，尤其是在缺乏原生文本的情况下。然而，翻译文本与原生文本存在系统性差异，即“翻译腔”。本文旨在研究在机器翻译数据上训练如何影响小型英语语言模型，重点关注来自不同源语言的翻译腔如何塑造语言可接受性判断和不同领域的语言建模。

Method: 作者使用从24种类型学和资源多样化的源语言翻译的英语文本来训练模型。这使得能够系统分析源语言和语料库特性如何影响模型的学习。

Result: 结果表明，源语言对模型行为有明显影响：通用困惑度更多地由翻译语料库的词汇多样性驱动，而语法性能在数据量充足的情况下，与源语言和英语的类型学相似性强相关。

Conclusion: 源语言对使用机器翻译数据训练的小型英语语言模型的学习有显著影响，不同语言学方面（困惑度与语法）受源语言不同特征（词汇多样性与类型学相似性）的影响。

Abstract: Machine-translated data is widely used in multilingual NLP, particularly when native text is scarce. However, translated text differs systematically from native text. This phenomenon is known as translationese, and it reflects both traces of the source language and characteristic properties of translation itself. In this paper, we study how training on machine-translated data affects small English language models, focusing on how translationese from different source languages shapes linguistic acceptability judgments and language modelling for different domains. We train models on English text translated from 24 typologically and resource-diverse source languages, enabling a systematic analysis of how source language and corpus properties influence what models learn. Our results show that the source language has a clear impact on model behavior: general perplexity is more driven by the lexical diversity of the translated corpus, while grammatical performance is strongly correlated to typological similarity to English, given enough data.

</details>


### [78] [Optimizing Soft Prompt Tuning via Structural Evolution](https://arxiv.org/abs/2602.16500)
*Zhenzhen Huang,Chaoning Zhang,Haoyu Bian,Songbo Zhang,Chi-lok Andy Tai,Jiaquan Zhang,Caiyan Qin,Jingjing Qu,Yalan Ye,Yang Yang,Heng Tao Shen*

Main category: cs.CL

TL;DR: 提出了一种基于拓扑形态演化（TSLoss）的软提示调优优化方法，利用拓扑数据分析量化软提示结构，以提高可解释性、加速收敛并提升性能。


<details>
  <summary>Details</summary>
Motivation: 软提示虽然在少样本设置中表现良好，但其依赖高维、隐式表示，缺乏明确的语义和可追溯的训练行为，这限制了它们的可解释性。

Method: 提出了一种基于拓扑形态演化的软提示调优优化方法。该方法利用拓扑数据分析（TDA）中的持久同源性来量化连续参数空间中软提示的结构表示及其训练过程演变。基于对拓扑稳定且紧凑的软提示表现更佳的经验观察，构建了一个名为拓扑软提示损失（TSLoss）的损失函数，通过量化参数间的连接性和冗余性来指导模型学习结构稳定的适应性。

Result: 广泛的实验表明，使用TSLoss进行训练可以加速收敛并提高调优性能。

Conclusion: TSLoss提供了一种从结构和拓扑角度理解和优化软提示调优的可解释方法，能够实现更优的性能和更快的收敛。

Abstract: Soft prompt tuning leverages continuous embeddings to capture task-specific information in large pre-trained language models (LLMs), achieving competitive performance in few-shot settings. However, soft prompts rely on high-dimensional, implicit representations and lack explicit semantics and traceable training behaviors, which limits their interpretability. To address this limitation, we propose a soft prompt tuning optimization method based on topological morphological evolution. Specifically, we employ persistent homology from topological data analysis (TDA) to quantify the structural representations of soft prompts in continuous parameter space and their training process evolution. Quantitative analysis shows that topologically stable and compact soft prompts achieve better downstream performance. Based on this empirical observation, we construct a loss function for optimizing soft prompt tuning, termed Topological Soft Prompt Loss (TSLoss). TSLoss guides the model to learn structurally stable adaptations by quantifying inter-parameter connectivity and redundancy. Extensive experiments show that training with TSLoss accelerates convergence and improves tuning performance, providing an interpretable method to understand and optimize soft prompt tuning from structural and topological perspectives.

</details>


### [79] [Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification](https://arxiv.org/abs/2602.16516)
*Taja Kuzman Pungeršek,Peter Rupnik,Daniela Širinić,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本文介绍了ParlaCAP数据集及其构建领域特定政策主题分类器的方法。ParlaCAP是一个大型多语言数据集，用于分析欧洲议会设定的议程。


<details>
  <summary>Details</summary>
Motivation: 分析欧洲议会设定的议程，并提供一种经济高效的方法来构建领域特定的政策主题分类器。

Method: 作者将比较议程项目（CAP）方案应用于ParlaMint语料库，该语料库包含来自28个欧洲国家议会的800多万份演讲。他们采用教师-学生框架，其中高性能的大型语言模型（LLM）标注领域内训练数据，然后多语言编码器模型在此标注数据上进行微调，以实现可扩展的数据标注。ParlaCAP数据集还提供了丰富的发言者和政党元数据以及情感预测。

Result: 该方法生成了一个针对目标领域量身定制的分类器。LLM和人类标注者之间的一致性与人类标注者之间的一致性相当。所得模型优于现有使用手动标注但领域外数据训练的CAP分类器。ParlaCAP数据集支持对政治关注和跨国代表性进行比较研究。

Conclusion: ParlaCAP数据集及其方法为分析欧洲议会设定的议程提供了一个有价值的工具，并通过三个用例展示了其分析潜力：审查议会关注在政策主题上的分布、议会演讲中的情感模式以及政策关注中的性别差异。

Abstract: This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual ParlaMint corpus of over 8 million speeches from 28 parliaments of European countries and autonomous regions, we follow a teacher-student framework in which a high-performing large language model (LLM) annotates in-domain training data and a multilingual encoder model is fine-tuned on these annotations for scalable data annotation. We show that this approach produces a classifier tailored to the target domain. Agreement between the LLM and human annotators is comparable to inter-annotator agreement among humans, and the resulting model outperforms existing CAP classifiers trained on manually-annotated but out-of-domain data. In addition to the CAP annotations, the ParlaCAP dataset offers rich speaker and party metadata, as well as sentiment predictions coming from the ParlaSent multilingual transformer model, enabling comparative research on political attention and representation across countries. We illustrate the analytical potential of the dataset with three use cases, examining the distribution of parliamentary attention across policy topics, sentiment patterns in parliamentary speech, and gender differences in policy attention.

</details>


### [80] [Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII Benchmark Dataset](https://arxiv.org/abs/2602.16571)
*Zhuqian Zhou,Kirk Vanacore,Bakhtawar Ahtisham,Jinsook Lee,Doug Pietrzak,Daryl Hedley,Jorge Dias,Chris Shaw,Ruth Schäfer,René F. Kizilcec*

Main category: cs.CL

TL;DR: 该论文解决了数学辅导文本中个人身份信息（PII）检测问题，以保留教育效用，引入了MathEd-PII数据集，并证明了数学感知型提示能显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 大规模共享基于对话的数据对于推进教学科学至关重要，但严格的去识别化是一个主要障碍。在数学辅导文本中，数字表达式常与结构化标识符（如日期或ID）相似，导致通用PII检测系统过度编辑核心教学内容，降低数据集效用。这项工作旨在探究如何在保留教育效用的同时检测数学辅导文本中的PII。

Method: 1. 调查了“数字歧义”问题。2. 引入了MathEd-PII，这是首个用于数学辅导对话中PII检测的基准数据集，通过人工参与的LLM工作流创建。3. 使用基于密度的分割方法，证明了错误的PII编辑主要集中在数学密集区域。4. 比较了四种检测策略：Presidio基线以及基于LLM的方法（基本、数学感知型和片段感知型提示）。

Result: 1. MathEd-PII数据集包含1,000个辅导会话（115,620条消息；769,628个词元），并带有经过验证的PII注释。2. 错误的PII编辑不成比例地集中在数学密集区域，证实了数字歧义是关键的故障模式。3. 数学感知型提示比基线显著提高了性能（F1: 0.821 vs. 0.379），同时减少了数字假阳性。

Conclusion: 辅导数据中保留效用的去识别化需要领域感知的建模。这项工作提供了一个新的基准和证据支持这一结论。

Abstract: Large-scale sharing of dialogue-based data is instrumental for advancing the science of teaching and learning, yet rigorous de-identification remains a major barrier. In mathematics tutoring transcripts, numeric expressions frequently resemble structured identifiers (e.g., dates or IDs), leading generic Personally Identifiable Information (PII) detection systems to over-redact core instructional content and reduce dataset utility. This work asks how PII can be detected in math tutoring transcripts while preserving their educational utility. To address this challenge, we investigate the "numeric ambiguity" problem and introduce MathEd-PII, the first benchmark dataset for PII detection in math tutoring dialogues, created through a human-in-the-loop LLM workflow that audits upstream redactions and generates privacy-preserving surrogates. The dataset contains 1,000 tutoring sessions (115,620 messages; 769,628 tokens) with validated PII annotations. Using a density-based segmentation method, we show that false PII redactions are disproportionately concentrated in math-dense regions, confirming numeric ambiguity as a key failure mode. We then compare four detection strategies: a Presidio baseline and LLM-based approaches with basic, math-aware, and segment-aware prompting. Math-aware prompting substantially improves performance over the baseline (F1: 0.821 vs. 0.379) while reducing numeric false positives, demonstrating that de-identification must incorporate domain context to preserve analytic utility. This work provides both a new benchmark and evidence that utility-preserving de-identification for tutoring data requires domain-aware modeling.

</details>


### [81] [CitiLink-Summ: Summarization of Discussion Subjects in European Portuguese Municipal Meeting Minutes](https://arxiv.org/abs/2602.16607)
*Miguel Marques,Ana Luísa Fernandes,Ana Filipa Pacheco,Rute Rebouças,Inês Cantante,José Isidro,Luís Filipe Cunha,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano,Ricardo Campos*

Main category: cs.CL

TL;DR: 该论文介绍了CitiLink-Summ，这是一个用于总结欧洲葡萄牙语市政会议纪要的新数据集，并使用最先进的模型建立了基线。


<details>
  <summary>Details</summary>
Motivation: 市政会议纪要篇幅冗长、内容密集，公民难以浏览。自动摘要可以帮助解决这一挑战，但相关研究，特别是在资源匮乏的语言方面，以及由于缺乏高质量数据集而受到限制。

Method: 本文提出了CitiLink-Summ，一个包含100份欧洲葡萄牙语市政会议纪要和2,322份手动编写摘要的语料库。利用该数据集，论文使用最先进的生成模型（如BART、PRIMERA）以及大型语言模型（LLMs），并采用词汇和语义指标（如ROUGE、BLEU、METEOR和BERTScore）进行评估，建立了该领域自动摘要的基线结果。

Result: CitiLink-Summ为欧洲葡萄牙语市政领域摘要提供了第一个基准，并使用各种模型和指标建立了基线结果。

Conclusion: CitiLink-Summ为推动复杂行政文本的自然语言处理研究提供了宝贵的资源，特别是在欧洲葡萄牙语的市政领域摘要方面。

Abstract: Municipal meeting minutes are formal records documenting the discussions and decisions of local government, yet their content is often lengthy, dense, and difficult for citizens to navigate. Automatic summarization can help address this challenge by producing concise summaries for each discussion subject. Despite its potential, research on summarizing discussion subjects in municipal meeting minutes remains largely unexplored, especially in low-resource languages, where the inherent complexity of these documents adds further challenges. A major bottleneck is the scarcity of datasets containing high-quality, manually crafted summaries, which limits the development and evaluation of effective summarization models for this domain. In this paper, we present CitiLink-Summ, a new corpus of European Portuguese municipal meeting minutes, comprising 100 documents and 2,322 manually hand-written summaries, each corresponding to a distinct discussion subject. Leveraging this dataset, we establish baseline results for automatic summarization in this domain, employing state-of-the-art generative models (e.g., BART, PRIMERA) as well as large language models (LLMs), evaluated with both lexical and semantic metrics such as ROUGE, BLEU, METEOR, and BERTScore. CitiLink-Summ provides the first benchmark for municipal-domain summarization in European Portuguese, offering a valuable resource for advancing NLP research on complex administrative texts.

</details>


### [82] [ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models](https://arxiv.org/abs/2602.16609)
*Antoine Chaffin,Luca Arnaboldi,Amélie Chatelain,Florent Krzakala*

Main category: cs.CL

TL;DR: 大规模多向量预训练能显著提升多向量模型性能，其中ColBERT-Zero在公开数据上实现了SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的多向量模型主要依赖于单向量模型的小规模知识蒸馏训练。本文旨在探索多向量模型的大规模预训练，以期获得更强的性能。

Method: 本文研究了多向量模型的预训练方法，对比了完整预训练、小规模知识蒸馏以及在知识蒸馏前增加监督步骤等不同训练策略对模型性能的影响。

Result: 1. 大规模多向量预训练能产生远强于仅通过知识蒸馏获得的模型。
2. 仅在公开数据上训练的ColBERT-Zero模型，通过完全ColBERT预训练，性能超越了利用封闭和更强数据的GTE-ModernColBERT及其基础模型GTE-ModernBERT，为该尺寸模型设定了新的最先进水平。
3. 尽管仅执行小规模知识蒸馏不足以达到接近完整预训练的效果，但预先添加一个监督步骤可以显著提高性能，同时跳过最耗费资源的无监督阶段。
4. 在复用现有模型时，对齐微调和预训练设置至关重要。

Conclusion: 大规模多向量预训练是提升多向量模型性能的关键。通过适当的训练策略（如在KD前引入监督步骤），可以在不进行昂贵无监督预训练的情况下显著提高模型性能。此外，对齐微调和预训练设置对于有效复用现有模型至关重要。

Abstract: Current state-of-the-art multi-vector models are obtained through a small Knowledge Distillation (KD) training step on top of strong single-vector models, leveraging the large-scale pre-training of these models. In this paper, we study the pre-training of multi-vector models and show that large-scale multi-vector pre-training yields much stronger multi-vector models. Notably, a fully ColBERT-pre-trained model, ColBERT-Zero, trained only on public data, outperforms GTE-ModernColBERT as well as its base model, GTE-ModernBERT, which leverages closed and much stronger data, setting new state-of-the-art for model this size. We also find that, although performing only a small KD step is not enough to achieve results close to full pre-training, adding a supervised step beforehand allows to achieve much closer performance while skipping the most costly unsupervised phase. Finally, we find that aligning the fine-tuning and pre-training setups is crucial when repurposing existing models. To enable exploration of our results, we release various checkpoints as well as code used to train them.

</details>


### [83] [AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models](https://arxiv.org/abs/2602.16639)
*Adib Sakhawat,Fardeen Sadab*

Main category: cs.CL

TL;DR: 该研究引入了对抗性资源提取游戏（AREG），这是一个多轮零和谈判基准，用于评估大型语言模型（LLM）在说服和抵抗方面的社交智能。研究发现这些能力之间关联性较弱（ρ = 0.33），且存在系统性的防御优势。语言分析表明交互结构在结果中起关键作用，并指出LLM的社会影响力并非单一能力。


<details>
  <summary>Details</summary>
Motivation: 目前对大型语言模型（LLM）社交智能的评估多局限于静态文本生成，需要转向动态、对抗性互动，以更好地评估其说服和抵抗能力。

Method: 研究引入了对抗性资源提取游戏（AREG），这是一个将说服和抵抗操作化为多轮、零和的金融资源谈判的基准。通过对前沿模型进行循环赛，AREG能够在单一交互框架内联合评估攻击性（说服）和防御性（抵抗）能力，并进行了进一步的语言分析。

Result: 说服和抵抗能力之间存在弱相关性（ρ = 0.33），并且在经验上是分离的：强大的说服表现不能可靠地预测强大的抵抗，反之亦然。所有评估模型的抵抗得分均超过说服得分，表明在对抗性对话环境中存在系统性的防御优势。语言分析表明，交互结构在这些结果中起核心作用，渐进式承诺寻求策略与更高的提取成功率相关，而寻求验证的回复在成功的防御中比明确拒绝更普遍。

Conclusion: 这些发现表明，大型语言模型中的社会影响力并非单一能力，并且仅关注说服的评估框架可能会忽略不对称的行为脆弱性。

Abstract: Evaluating the social intelligence of Large Language Models (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across frontier models, AREG enables joint evaluation of offensive (persuasion) and defensive (resistance) capabilities within a single interactional framework. Our analysis provides evidence that these capabilities are weakly correlated ($\rho = 0.33$) and empirically dissociated: strong persuasive performance does not reliably predict strong resistance, and vice versa. Across all evaluated models, resistance scores exceed persuasion scores, indicating a systematic defensive advantage in adversarial dialogue settings. Further linguistic analysis suggests that interaction structure plays a central role in these outcomes. Incremental commitment-seeking strategies are associated with higher extraction success, while verification-seeking responses are more prevalent in successful defenses than explicit refusal. Together, these findings indicate that social influence in LLMs is not a monolithic capability and that evaluation frameworks focusing on persuasion alone may overlook asymmetric behavioral vulnerabilities.

</details>


### [84] [Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval](https://arxiv.org/abs/2602.16640)
*Subrit Dikshit*

Main category: cs.CL

TL;DR: Quecto-V1是一个为印度法律领域设计的SLM（基于GPT-2，1.24亿参数），通过在印度法规上从头训练并进行8位量化（小于150MB），实现了高精度的法律信息检索，能在消费级CPU上离线运行，解决了大型LLM的资源鸿沟和数据主权问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的迅速普及在自然语言处理领域带来了革命，但同时也造成了“资源鸿沟”。最先进的法律智能系统通常依赖于庞大的参数数量（7B+）和基于云的推理，这使得资源受限环境下的从业者难以使用，并带来了显著的数据主权风险。

Method: 本文提出了Quecto-V1，一个基于自定义GPT-2架构（1.24亿参数）的领域专用小型语言模型（SLM）。该模型完全从头开始训练，仅使用了印度法规语料库，包括《印度刑法典》、《刑事诉讼法典》和《印度宪法》。为了解决部署瓶颈，模型还应用了训练后8位量化（GGUF格式），将模型压缩到150 MB以下的内存占用。

Result: Quecto-V1在检索法定定义和刑法条款方面表现出高精度，在领域特定的精确匹配任务中优于通用SLM，并且能够在消费级CPU上完全离线运行。一项消融研究表明，8位量化使模型大小减少了74%，而检索准确性相比全精度基线仅下降了不到3.5%。

Conclusion: 对于法律等专业领域，结合领域特定训练和激进量化的小型语言模型，为大型云模型提供了一种可行且保护隐私的替代方案。

Abstract: The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource divide." State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based inference, rendering them inaccessible to practitioners in resource-constrained environments and posing significant data sovereignty risks. This paper introduces Quecto-V1, a domain-specific Small Language Model (SLM) engineered to democratize access to Indian legal intelligence. Built upon a custom configuration of the GPT-2 architecture (124 million parameters), Quecto-V1 was trained from scratch exclusively on a corpus of Indian statutes, including the Indian Penal Code (IPC), the Code of Criminal Procedure (CrPC), and the Constitution of India. Unlike generalist models, which prioritize broad world knowledge, our approach maximizes "lexical density" within the legal domain. Furthermore, we address the deployment bottleneck by applying post-training 8-bit quantization (GGUF format), compressing the model to a memory footprint of under 150 MB. Our empirical analysis demonstrates that Quecto-V1 achieves high fidelity in retrieving statutory definitions and penal provisions, outperforming general-purpose SLMs in domain-specific exact match tasks while running entirely offline on consumer-grade CPUs. We further present an ablation study showing that 8-bit quantization yields a 74% reduction in model size with less than 3.5% degradation in retrieval accuracy compared to full-precision baselines. These findings suggest that for specialized, high-stakes domains like law, domain-specific training coupled with aggressive quantization offers a viable, privacy-preserving alternative to monolithic cloud models.

</details>


### [85] [Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment](https://arxiv.org/abs/2602.16660)
*Yuyan Bu,Xiaohao Liu,ZhaoXing Ren,Yaodong Yang,Juntao Dai*

Main category: cs.CL

TL;DR: 本文提出了一种资源高效的即插即用多语言一致性（MLC）损失，通过鼓励语义方向一致性并仅使用多语言提示变体，显著改善了多语言安全对齐，并在有限资源下提高了跨语言泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前将大型语言模型（LLMs）对齐扩展到其他语言的方法通常需要大量资源，例如目标语言的大规模高质量监督或与高资源语言的配对对齐，这限制了其可扩展性。

Method: 本文提出了一种即插即用的多语言一致性（MLC）损失。该损失可集成到现有的单语言对齐管道中，通过改善多语言表示向量之间的共线性，在一个更新中促进多语言语义层面的方向一致性。它仅利用多语言提示变体，无需低资源语言的额外响应级监督，即可实现多语言同时对齐。

Result: 该方法在不同模型架构和对齐范式下得到验证，证明了其在增强多语言安全性方面的有效性，且对模型通用效用的影响有限。进一步的跨语言和跨任务评估表明，其改善了跨语言泛化能力。

Conclusion: MLC损失为有限监督下的多语言一致性对齐提供了一个实用且资源高效的解决方案，显著提高了多语言安全性及跨语言泛化能力，同时保持了模型的通用效用。

Abstract: The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability. In this work, we propose a resource-efficient method for improving multilingual safety alignment. We introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. By improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.

</details>


### [86] [Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](https://arxiv.org/abs/2602.16699)
*Wenxuan Ding,Nicholas Tomlin,Greg Durrett*

Main category: cs.CL

TL;DR: 提出Calibrate-Then-Act (CTA) 框架，通过让大型语言模型 (LLMs) 明确权衡成本与不确定性，在需要环境交互的复杂任务（如信息检索和编程）中实现更优的环境探索和决策。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理需要环境交互的复杂问题时，必须权衡探索的成本与不确定性，以决定何时停止探索并提交答案。当前的LLMs在这方面表现不佳，需要一种机制来显式地引导它们进行这种权衡。

Method: 将信息检索和编码等任务形式化为不确定性下的序贯决策问题，其中包含可以通过先验知识推理的潜在环境状态。引入了名为Calibrate-Then-Act (CTA) 的框架，通过向LLM提供额外的上下文来使其更优化地行动，即使在强化学习训练下也能保持这种改进。

Result: 在信息检索问答和简化编码任务上的结果表明，使用CTA显式地权衡成本效益可以帮助智能体发现更优的决策策略。

Conclusion: 通过引入Calibrate-Then-Act (CTA) 框架，使大型语言模型能够明确地权衡成本与不确定性，从而在复杂环境交互任务中实现更优的探索和决策。

Abstract: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.

</details>


### [87] [Reinforced Fast Weights with Next-Sequence Prediction](https://arxiv.org/abs/2602.16704)
*Hee Seung Hwang,Xindi Wu,Sanghyuk Chun,Olga Russakovsky*

Main category: cs.CL

TL;DR: REFINE提出了一种基于强化学习的下一序列预测框架，用于优化快速权重模型，解决了传统下一token预测范式在长上下文建模中的局限性，并在多项任务上表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 当前快速权重架构虽然在长上下文建模方面有潜力，但其性能受限于下一token预测（NTP）训练范式。NTP只优化单token预测，忽略了多token间的语义一致性，导致快速权重模型学习到的表示次优，无法有效捕捉长程依赖。

Method: REFINE是一个强化学习框架，它在下一序列预测（NSP）目标下训练快速权重模型。REFINE通过以下步骤工作：1. 基于预测熵选择信息丰富的token位置。2. 生成多token推演。3. 分配自监督的序列级奖励。4. 使用组相对策略优化（GRPO）优化模型。该框架适用于预训练语言模型的整个训练生命周期，包括训练中、训练后和测试时训练。

Result: 在LaCT-760M和DeltaNet-1.3B上的实验表明，REFINE在“大海捞针”检索、长上下文问答以及LongBench中的多项任务上持续优于使用NTP进行监督微调的方法。

Conclusion: REFINE提供了一个有效且通用的框架，用于改进快速权重架构在长上下文建模方面的性能。

Abstract: Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [88] [Color-based Emotion Representation for Speech Emotion Recognition](https://arxiv.org/abs/2602.16256)
*Ryotaro Nagase,Ryoichi Takashima,Yoichi Yamashita*

Main category: eess.AS

TL;DR: 该研究提出使用颜色属性（色相、饱和度、明度）作为连续且可解释的得分来表示语音情感，以克服传统分类或维度标签的局限性，并成功开发了颜色属性回归模型，同时证明了多任务学习能提高性能。


<details>
  <summary>Details</summary>
Motivation: 传统的语音情感识别（SER）依赖分类或维度标签，但这种技术在表示情感的多样性和可解释性方面存在局限性。

Method: 研究通过众包方式使用颜色属性（色相、饱和度、明度）标注情感语音语料库，并对其进行分析。接着，利用机器学习和深度学习构建了SER中颜色属性的回归模型，并探索了颜色属性回归与情感分类的多任务学习。

Result: 研究展示了语音中颜色属性与情感之间的关系，并成功开发了用于SER的颜色属性回归模型。此外，多任务学习显著提升了各项任务的性能。

Conclusion: 该研究成功地将颜色属性应用于语音情感表示，克服了传统方法的局限性，并通过多任务学习提升了模型性能，为SER提供了新的连续且可解释的表示方法。

Abstract: Speech emotion recognition (SER) has traditionally relied on categorical or dimensional labels. However, this technique is limited in representing both the diversity and interpretability of emotions. To overcome this limitation, we focus on color attributes, such as hue, saturation, and value, to represent emotions as continuous and interpretable scores. We annotated an emotional speech corpus with color attributes via crowdsourcing and analyzed them. Moreover, we built regression models for color attributes in SER using machine learning and deep learning, and explored the multitask learning of color attribute regression and emotion classification. As a result, we demonstrated the relationship between color attributes and emotions in speech, and successfully developed color attribute regression models for SER. We also showed that multitask learning improved the performance of each task.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [89] [FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving](https://arxiv.org/abs/2602.16603)
*Chia-chi Hsieh,Zan Zong,Xinyang Chen,Jianjiang Li,Jidong Zhai,Lijie Wen*

Main category: cs.DC

TL;DR: FlowPrefill是一个TTFT良好吞吐量优化的服务系统，它通过解耦抢占粒度和调度频率来解决大型语言模型服务系统中预填充阶段的队头阻塞问题，将最大良好吞吐量提高了5.6倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型服务系统在计算密集型预填充阶段存在队头阻塞问题，导致长请求垄断资源，延迟高优先级请求，造成TTFT（Time-to-First-Token）SLO（服务水平目标）违规。现有分块预填充方法在响应性和吞吐量之间存在固有权衡，难以动态平衡执行粒度与调度开销。

Method: 本文提出了FlowPrefill系统，通过解耦抢占粒度和调度频率来解决上述冲突。其核心创新包括：1) 算子级抢占：利用算子边界实现细粒度执行中断，避免固定小块分块带来的效率损失；2) 事件驱动调度：仅在请求到达或完成事件时触发调度决策，支持高效抢占响应性并最小化控制平面开销。

Result: 在真实生产追踪数据上的评估表明，FlowPrefill与现有最先进系统相比，在满足异构SLO的同时，最大良好吞吐量提高了高达5.6倍。

Conclusion: FlowPrefill通过创新的算子级抢占和事件驱动调度机制，有效解决了大型语言模型服务系统中预填充阶段的队头阻塞和TTFT SLO违规问题，显著提升了系统的良好吞吐量和响应性，同时满足了异构SLO。

Abstract: The growing demand for large language models (LLMs) requires serving systems to handle many concurrent requests with diverse service level objectives (SLOs). This exacerbates head-of-line (HoL) blocking during the compute-intensive prefill phase, where long-running requests monopolize resources and delay higher-priority ones, leading to widespread time-to-first-token (TTFT) SLO violations. While chunked prefill enables interruptibility, it introduces an inherent trade-off between responsiveness and throughput: reducing chunk size improves response latency but degrades computational efficiency, whereas increasing chunk size maximizes throughput but exacerbates blocking. This necessitates an adaptive preemption mechanism. However, dynamically balancing execution granularity against scheduling overheads remains a key challenge. In this paper, we propose FlowPrefill, a TTFT-goodput-optimized serving system that resolves this conflict by decoupling preemption granularity from scheduling frequency. To achieve adaptive prefill scheduling, FlowPrefill introduces two key innovations: 1) Operator-Level Preemption, which leverages operator boundaries to enable fine-grained execution interruption without the efficiency loss associated with fixed small chunking; and 2) Event-Driven Scheduling, which triggers scheduling decisions only upon request arrival or completion events, thereby supporting efficient preemption responsiveness while minimizing control-plane overhead. Evaluation on real-world production traces shows that FlowPrefill improves maximum goodput by up to 5.6$\times$ compared to state-of-the-art systems while satisfying heterogeneous SLOs.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [90] [What Persona Are We Missing? Identifying Unknown Relevant Personas for Faithful User Simulation](https://arxiv.org/abs/2602.15832)
*Weiwen Su,Yuhan Zhou,Zihan Wang,Naoki Yoshinaga,Masashi Toyoda*

Main category: cs.HC

TL;DR: 该研究通过引入PICQ数据集和多方面评估方案，解决了用户模拟中未知用户画像识别的问题。发现大型语言模型在忠实度与洞察力之间存在权衡，忠实度遵循倒U形曲线，而洞察力随模型规模扩大。这揭示了人类与LLM之间认知模型的差异。


<details>
  <summary>Details</summary>
Motivation: 现有用户模拟中，模型在对话中生成类似用户的响应，但通常缺乏对所提供用户画像充分性的验证，这使得模拟的有效性受到质疑。为了解决这一核心问题，该研究探索了在给定模拟上下文中识别相关但未知模拟目标用户画像的任务。

Method: 引入了PICQ数据集，这是一个包含上下文感知选择问题的新型数据集，并标注了可能影响用户选择的未知用户画像。提出了一个多方面的评估方案，评估了忠实度、影响力和不可访问性，并对主流大型语言模型进行了基准测试。

Result: 对主流LLM的基准测试揭示了一个复杂的“忠实度与洞察力”困境，该困境受模型规模的影响：虽然洞察力通常随模型尺寸的增加而扩展，但对人类行为模式的忠实度遵循倒U形曲线。这种现象归因于认知差异，特别是人类的“认知经济”倾向。

Conclusion: 该工作为识别未知用户画像提供了一个全面的基准，为理解人类和高级LLM之间不同的认知模型提供了一个新视角。

Abstract: Existing user simulations, where models generate user-like responses in dialogue, often lack verification that sufficient user personas are provided, questioning the validity of the simulations. To address this core concern, this work explores the task of identifying relevant but unknown personas of the simulation target for a given simulation context. We introduce PICQ, a novel dataset of context-aware choice questions, annotated with unknown personas (e.g., ''Is the user price-sensitive?'') that may influence user choices, and propose a multi-faceted evaluation scheme assessing fidelity, influence, and inaccessibility. Our benchmark of leading LLMs reveals a complex ''Fidelity vs. Insight'' dilemma governed by model scale: while influence generally scales with model size, fidelity to human patterns follows an inverted U-shaped curve. We trace this phenomenon to cognitive differences, particularly the human tendency for ''cognitive economy.'' Our work provides the first comprehensive benchmark for this crucial task, offering a new lens for understanding the divergent cognitive models of humans and advanced LLMs.

</details>


### [91] [Transforming GenAI Policy to Prompting Instruction: An RCT of Scalable Prompting Interventions in a CS1 Course](https://arxiv.org/abs/2602.16033)
*Ruiwei Xiao,Runlong Ye,Xinying Hou,Jessica Wen,Harsh Kumar,Michael Liut,John Stamper*

Main category: cs.HC

TL;DR: 尽管GenAI被普遍采用，但学生难以区分任务表现与实际学习，缺乏利用AI进行学习的技能，导致非反思性AI使用下的考试成绩下降。一项针对979名学生的学期RCT发现，基于ICAP框架的干预措施显著提高了提示技能，且即时后测的学习增益预示着更高的期末考试成绩。本研究为可扩展的GenAI提示素养教学提供了指导。


<details>
  <summary>Details</summary>
Motivation: 尽管GenAI被普遍采用，但学生无法区分任务表现与实际学习，缺乏有效利用AI进行学习的技能，导致在非反思性使用AI时考试成绩下降。目前缺乏通过随机对照试验（RCT）大规模验证的干预措施，以教导学生将AI作为导师而非解决方案提供者进行提示。

Method: 本研究进行了一项为期一个学期的大规模随机对照试验（N=979），设置了四种基于ICAP框架的教学条件，这些条件在参与强度上有所不同。研究通过前测、即时后测、延迟后测和问卷调查进行评估，并采用了混合方法分析。

Result: 1. 所有条件都显著提升了学生的提示技能，且增益从条件1到条件4逐步增加，验证了ICAP的认知参与层级理论。2. 对于前测分数相似的学生，即时后测中更高的学习增益预示着更高的期末考试成绩，尽管组间没有直接差异。3. 所提出的干预措施适用于并可推广到不同的教育环境、资源和学习者。

Conclusion: 本研究在理论上首次通过大规模RCT探讨了认知参与如何塑造提示素养学习，并阐明了以学习为导向的提示技能与更广泛学业表现之间的关系。在实践上，本研究为将GenAI课堂政策转化为可扩展、可操作的提示素养教学提供了及时的设计指导，以促进生成式AI时代下的学习。

Abstract: Despite universal GenAI adoption, students cannot distinguish task performance from actual learning and lack skills to leverage AI for learning, leading to worse exam performance when AI use remains unreflective. Yet few interventions teaching students to prompt AI as a tutor rather than solution provider have been validated at scale through randomized controlled trials (RCTs). To bridge this gap, we conducted a semester-long RCT (N=979) with four ICAP framework-based instructional conditions varying in engagement intensity with a pre-test, immediate and delayed post-test and surveys. Mixed methods analysis results showed: (1) All conditions significantly improved prompting skills, with gains increasing progressively from Condition 1 to Condition 4, validating ICAP's cognitive engagement hierarchy; (2) for students with similar pre-test scores, higher learning gain in immediate post-test predict higher final exam score, though no direct between-group differences emerged; (3) Our interventions are suitable and scalable solutions for diverse educational contexts, resources and learners. Together, this study makes empirical and theoretical contributions: (1) theoretically, we provided one of the first large-scale RCTs examining how cognitive engagement shapes learning in prompting literacy and clarifying the relationship between learning-oriented prompting skills and broader academic performance; (2) empirically, we offered timely design guidance for transforming GenAI classroom policies into scalable, actionable prompting literacy instruction to advance learning in the era of Generative AI.

</details>


### [92] [Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy](https://arxiv.org/abs/2602.16140)
*Wooyoung Jung,Kahyun Jeon,Prosper Babon-Ayeng*

Main category: cs.HC

TL;DR: 本研究通过角色扮演实验，探讨用户领域知识和AI素养如何影响与LLM集成BEMS（使用GPT-4o）的交互效果。结果显示，多数用户使用简洁提示并依赖AI分析，仅电器识别率受AI素养显著影响，表明LLM具有均衡用户专业知识的作用，对人机协作和LLM能源系统发展有重要意义。


<details>
  <summary>Details</summary>
Motivation: 旨在理解用户领域知识和AI素养如何影响人机交互式建筑能源管理系统（BEMS）的有效使用。此前研究多关注LLM在BEMS或建筑能源建模中的潜力，但很少有研究探讨用户如何与此类系统交互。

Method: 进行了一项系统的角色扮演实验，85名受试者与OpenAI GPT-4o互动，任务是识别五种可减少家庭能源使用的行为改变。通过分层评估人机交互和能源分析方法的分析框架，对收集到的提示-响应数据和参与者结论进行分析。参与者根据其自我评估的建筑能源领域知识和AI素养分为四组，并对20项可量化指标进行Kruskal-Wallis H检验和事后配对比较。

Result: 大多数参与者使用简洁的提示词（中位数：16.2词）并高度依赖GPT的分析能力。在20项指标中，只有电器识别率一项显示出统计学上的显著群体差异（p=0.037），这主要受AI素养而非领域知识驱动，表明大型语言模型（LLM）在不同专业水平之间具有均衡作用。

Conclusion: 本研究为LLM集成BEMS背景下的人机协作动态和有前景的开发方向提供了基础性见解，并有助于实现以人为中心的LLM集成能源系统。

Abstract: This study aimed to comprehend how user domain knowledge and artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy management system (BEMS). While prior studies have investigated the potential of integrating large language models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such systems. We conducted a systematic role-playing experiment, where 85 human subjects interacted with an advanced generative pre-trained transformer (OpenAI GPT-4o). Participants were tasked with identifying the top five behavioral changes that could reduce home energy use with the GPT model that functioned as an LLM-integrated BEMS. Then, the collected prompt-response data and participant conclusions were analyzed using an analytical framework that hierarchically assessed and scored human-AI interactions and their home energy analysis approaches. Also, participants were classified into four groups based on their self-evaluated domain knowledge of building energy use and AI literacy, and Kruskal-Wallis H tests with post-hoc pairwise comparisons were conducted across 20 quantifiable metrics. Key takeaways include: most participants employed concise prompts (median: 16.2 words) and relied heavily on GPT's analytical capabilities; and notably, only 1 of 20 metrics, appliance identification rate, showed statistically significant group differences (p=0.037), driven by AI literacy rather than domain knowledge, suggesting an equalizing effect of LLMs across expertise levels. This study provides foundational insights into human-AI collaboration dynamics and promising development directions in the context of LLM-integrated BEMS and contributes to realizing human-centric LLM-integrated energy systems.

</details>


### [93] [A Methodology for Identifying Evaluation Items for Practical Dialogue Systems Based on Business-Dialogue System Alignment Models](https://arxiv.org/abs/2602.15835)
*Mikio Nakano,Hironori Takeuchi,Kazunori Komatani*

Main category: cs.HC

TL;DR: 该论文提出了一种基于业务-对话系统对齐模型识别实用对话系统评估项目的方法。


<details>
  <summary>Details</summary>
Motivation: 传统上，对话系统主要通过用户满意度和用户体验进行评估。然而，实际对话系统的开发和运营需要考虑更多评估项目，且目前缺乏识别这些项目的系统方法。识别这些新项目有望催生新的研究课题。

Method: 该方法基于业务-对话系统对齐模型识别评估项目，这些模型是业务-IT对齐模型在对话系统领域的应用。论文还提出了一个通用模型，以促进为每个对话系统构建业务-对话系统对齐模型。

Result: 提出了一种识别实用对话系统评估项目的方法；提出了一个有助于构建业务-对话系统对齐模型的通用模型。

Conclusion: 该方法和通用模型为识别实用对话系统的多样化评估项目提供了途径，有望开启新的研究方向。

Abstract: This paper proposes a methodology for identifying evaluation items for practical dialogue systems. Traditionally, user satisfaction and user experiences have been the primary metrics for evaluating dialogue systems. However, there are various other evaluation items to consider when developing and operating practical dialogue systems, and such evaluation items are expected to lead to new research topics. So far, there has been no methodology for identifying these evaluation items. We propose identifying evaluation items based on business-dialogue system alignment models, which are applications of business-IT alignment models used in the development and operation of practical IT systems. We also present a generic model that facilitates the construction of a business-dialogue system alignment model for each dialogue system.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [94] [Lyapunov Spectral Analysis of Speech Embedding Trajectories in Psychosis](https://arxiv.org/abs/2602.16273)
*Jelena Vasic,Branislav Andjelic,Ana Mancic,Dusica Filipovic Djurdjevic,Ljiljana Mihic,Aleksandar Kovacevic,Nadja P. Maric,Aleksandra Maluckov*

Main category: nlin.AO

TL;DR: 本研究通过分析精神病患者和健康对照组临床访谈中的语音嵌入，发现语言产生动力学特性在两组之间存在差异，且非线性动力学不变量为认知障碍提供了一种稳定的物理启发式探究方法。


<details>
  <summary>Details</summary>
Motivation: 评估精神病患者和健康对照组语音动力学结论在不同嵌入表示下的稳定性，并提供一种物理启发的认知障碍探测方法。

Method: 将精神病患者和健康对照组结构化临床访谈中的语言产生视为高维动力学过程，分析其语音嵌入。使用两种不同的大型语言模型生成词级别和答案级别的嵌入，并计算Lyapunov指数（LE）谱。

Result: 词级别嵌入表现出统一的收缩动力学，没有正LE。答案级别嵌入尽管总体收缩，但显示出多个正LE和更高维度的吸引子。得到的LE谱能可靠地区分精神病患者和健康对照组的语音，但在精神病组内部的区分不具有统计学意义，尽管最严重病例倾向于占据不同的动力学区域。

Conclusion: 语音嵌入的非线性动力学不变量提供了一种物理启发的认知障碍探测方法，其结论在不同嵌入模型中保持稳定，并能可靠地区分精神病患者和健康对照组的语音。

Abstract: We analyze speech embeddings from structured clinical interviews of psychotic patients and healthy controls by treating language production as a high-dimensional dynamical process. Lyapunov exponent (LE) spectra are computed from word-level and answer-level embeddings generated by two distinct large language models, allowing us to assess the stability of the conclusions with respect to different embedding presentations. Word-level embeddings exhibit uniformly contracting dynamics with no positive LE, while answer-level embeddings, in spite of the overall contraction, display a number of positive LEs and higher-dimensional attractors. The resulting LE spectra robustly separate psychotic from healthy speech, while differentiation within the psychotic group is not statistically significant overall, despite a tendency of the most severe cases to occupy distinct dynamical regimes. These findings indicate that nonlinear dynamical invariants of speech embeddings provide a physics-inspired probe of disordered cognition whose conclusions remain stable across embedding models.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [95] [MAEB: Massive Audio Embedding Benchmark](https://arxiv.org/abs/2602.16008)
*Adnan El Assadi,Isaac Chung,Chenghao Xiao,Roman Solomatin,Animesh Jha,Rahul Chand,Silky Singh,Kaitlyn Wang,Ali Sartaz Khan,Marc Moussa Nasser,Sufen Fong,Pengfei He,Alan Xiao,Ayush Sunil Munot,Aditya Shrivastava,Artem Gazizov,Niklas Muennighoff,Kenneth Enevoldsen*

Main category: cs.SD

TL;DR: MAEB是一个大规模音频嵌入基准，涵盖30项任务，评估了50多种模型，发现没有单一模型在所有任务中占优，存在声学和语言任务之间的性能权衡。MAEB表现与音频大型语言模型性能高度相关，并集成到MTEB生态系统。


<details>
  <summary>Details</summary>
Motivation: 提供一个大规模基准来评估和理解不同音频嵌入模型在各种音频任务和语言上的性能，并分析声学理解与语言理解之间的权衡。

Method: 引入MAEB，一个包含30项任务（源自98项任务的MAEB+）的大规模基准，涵盖语音、音乐、环境音和跨模态音文本推理，涉及100多种语言。在MAEB上评估了50多种模型。

Result: 没有单一模型在所有任务中占据主导地位。对比式音文本模型擅长环境音分类，但在多语言语音任务上表现不佳；而语音预训练模型则显示出相反的模式。聚类任务对所有模型来说仍具挑战性。擅长声学理解的模型在语言任务上表现不佳，反之亦然。音频编码器在MAEB上的性能与其在音频大型语言模型中的性能高度相关。MAEB在保持任务多样性的同时降低了评估成本，并集成到MTEB生态系统。

Conclusion: MAEB提供了一个全面的基准，揭示了当前音频嵌入模型在不同类型音频任务（声学 vs. 语言）之间存在显著权衡，且目前没有通用模型。该基准对未来的研究和模型开发（特别是音频大型语言模型）具有重要价值。

Abstract: We introduce the Massive Audio Embedding Benchmark (MAEB), a large-scale benchmark covering 30 tasks across speech, music, environmental sounds, and cross-modal audio-text reasoning in 100+ languages. We evaluate 50+ models and find that no single model dominates across all tasks: contrastive audio-text models excel at environmental sound classification (e.g., ESC50) but score near random on multilingual speech tasks (e.g., SIB-FLEURS), while speech-pretrained models show the opposite pattern. Clustering remains challenging for all models, with even the best-performing model achieving only modest results. We observe that models excelling on acoustic understanding often perform poorly on linguistic tasks, and vice versa. We also show that the performance of audio encoders on MAEB correlates highly with their performance when used in audio large language models. MAEB is derived from MAEB+, a collection of 98 tasks. MAEB is designed to maintain task diversity while reducing evaluation cost, and it integrates into the MTEB ecosystem for unified evaluation across text, image, and audio modalities. We release MAEB and all 98 tasks along with code and a leaderboard at .

</details>


### [96] [Spatial Audio Question Answering and Reasoning on Dynamic Source Movements](https://arxiv.org/abs/2602.16334)
*Arvind Krishna Sridhar,Yinyi Guo,Erik Visser*

Main category: cs.SD

TL;DR: 该论文研究了空间音频问答（Spatial AQA），侧重于从立体声音频中进行运动推理。它引入了一个以运动为中心的空间音频增强框架，一种带有思维模式的端到端多模态微调方法，并研究了查询条件下的音源分离。结果表明，推理放大了音源分离的优势，思维模式在问题中存在单一事件时显示出显著的+5.1%的改进。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在使机器能够解释复杂的听觉场景，特别是当声源随时间移动时，通过解决空间音频问答（Spatial AQA）并专注于运动推理。

Method: 1. 引入了一个以运动为中心的空间音频增强框架，该框架通过合成来自孤立单声道音频事件的不同运动模式，实现可控和可扩展的训练数据生成。2. 提出了一种带有思维模式的端到端多模态微调方法，该方法允许音频语言模型在预测答案之前生成明确的中间推理步骤。3. 研究了查询条件下的音源分离作为预处理阶段的影响，并比较了三种推理机制：无掩蔽、音频基础模型（AGM）和真实掩蔽。

Result: 推理放大了音源分离的优势，其中思维模式在问题中存在单一事件时显示出显著的+5.1%的改进。

Conclusion: 研究结果强调了运动建模、推理和分离质量之间的相互作用，为推进空间音频理解提供了新见解。

Abstract: Spatial audio understanding aims to enable machines to interpret complex auditory scenes, particularly when sound sources move over time. In this work, we study Spatial Audio Question Answering (Spatial AQA) with a focus on movement reasoning, where a model must infer object motion, position, and directional changes directly from stereo audio. First, we introduce a movement-centric spatial audio augmentation framework that synthesizes diverse motion patterns from isolated mono audio events, enabling controlled and scalable training data generation. Second, we propose an end-to-end multimodal finetuning approach with a thinking mode, which allows audio-language models to produce explicit intermediate reasoning steps before predicting an answer. Third, we investigate the impact of query-conditioned source separation as a preprocessing stage and compare three inference regimes: no masking, an audio grounding model (AGM), and ground-truth masks. Our results show that reasoning amplifies the benefits of source separation, with thinking mode showing significant improvement of +5.1% when a single event is present in the question. These findings highlight the interplay between movement modeling, reasoning, and separation quality, offering new insights for advancing spatial audio understanding.

</details>


### [97] [Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens](https://arxiv.org/abs/2602.16687)
*Potsawee Manakul,Woody Haosheng Gan,Martijn Bartelds,Guangzhi Sun,William Held,Diyi Yang*

Main category: cs.SD

TL;DR: 本文提出了一种原生音频基础模型SODA，通过大规模的下一token预测，联合建模语义内容、声学细节和文本，以支持通用音频生成和跨模态能力。研究了设计选择和缩放定律，并训练了SODA系列模型，展示了其在多样化音频/文本任务中的灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前音频语言模型主要以文本为先，限制了通用音频建模，无法联合建模语义内容、声学细节和文本。

Method: 1. 系统性地研究了数据源、文本混合比例和token组成等设计选择，建立了经过验证的训练方案。
2. 通过IsoFLOP分析，对64个离散音频模型进行了首次缩放定律研究，发现最佳数据增长速度是最佳模型尺寸的1.6倍。
3. 应用这些经验训练了SODA系列模型（1.35亿至40亿参数），并在5000亿token上进行了训练和比较。

Result: 1. 建立了离散音频模型训练的有效方案。
2. 发现了离散音频模型中，最佳数据量增长速度比最佳模型尺寸快1.6倍的缩放定律。
3. 训练了SODA系列模型，参数量从1.35亿到40亿，并在5000亿token上进行了训练和验证，其性能与缩放预测和现有模型进行了比较。
4. SODA可作为灵活的骨干模型，通过微调支持多种音频/文本任务。

Conclusion: SODA作为灵活的骨干模型，通过统一架构可支持各种音频/文本任务，例如保留语音特征的语音到语音翻译。

Abstract: Current audio language models are predominantly text-first, either extending pre-trained text LLM backbones or relying on semantic-only audio tokens, limiting general audio modeling. This paper presents a systematic empirical study of native audio foundation models that apply next-token prediction to audio at scale, jointly modeling semantic content, acoustic details, and text to support both general audio generation and cross-modal capabilities. We provide comprehensive empirical insights for building such models: (1) We systematically investigate design choices -- data sources, text mixture ratios, and token composition -- establishing a validated training recipe. (2) We conduct the first scaling law study for discrete audio models via IsoFLOP analysis on 64 models spanning $3{\times}10^{18}$ to $3{\times}10^{20}$ FLOPs, finding that optimal data grows 1.6$\times$ faster than optimal model size. (3) We apply these lessons to train SODA (Scaling Open Discrete Audio), a suite of models from 135M to 4B parameters on 500B tokens, comparing against our scaling predictions and existing models. SODA serves as a flexible backbone for diverse audio/text tasks -- we demonstrate this by fine-tuning for voice-preserving speech-to-speech translation, using the same unified architecture.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [98] [ROIX-Comp: Optimizing X-ray Computed Tomography Imaging Strategy for Data Reduction and Reconstruction](https://arxiv.org/abs/2602.15917)
*Amarjit Singh,Kento Sato,Kohei Yoshida,Kentaro Uesugi,Yasumasa Joti,Takaki Hatsui,Andrès Rubio Proaño*

Main category: eess.IV

TL;DR: 该论文提出了一种区域兴趣驱动的提取框架（ROIX-Comp），通过识别和保留基本特征来智能压缩X射线计算机断层扫描（X-CT）数据，从而减少数据量并保留关键信息，实现了相对于标准压缩12.34倍的压缩比改进。


<details>
  <summary>Details</summary>
Motivation: 传统处理大规模X射线计算机断层扫描（X-CT）数据集的方法由于其高维度和数据量，面临着巨大的计算和存储挑战，限制了实时处理能力和工作流程效率。

Method: ROIX-Comp框架在预处理阶段采用误差有界量化来减少处理数据量。在压缩阶段，该方法将对象提取与多种最先进的无损和有损压缩器相结合。

Result: 该框架在七个X-CT数据集上进行了评估，与标准压缩相比，相对压缩比提高了12.34倍。

Conclusion: ROIX-Comp框架通过智能压缩X-CT数据，显著提高了压缩比并保留了关键信息，有效解决了高性能计算环境中计算和存储的挑战。

Abstract: In high-performance computing (HPC) environments, particularly in synchrotron radiation facilities, vast amounts of X-ray images are generated. Processing large-scale X-ray Computed Tomography (X-CT) datasets presents significant computational and storage challenges due to their high dimensionality and data volume. Traditional approaches often require extensive storage capacity and high transmission bandwidth, limiting real-time processing capabilities and workflow efficiency. To address these constraints, we introduce a region-of-interest (ROI)-driven extraction framework (ROIX-Comp) that intelligently compresses X-CT data by identifying and retaining only essential features. Our work reduces data volume while preserving critical information for downstream processing tasks. At pre-processing stage, we utilize error-bounded quantization to reduce the amount of data to be processed and therefore improve computational efficiencies. At the compression stage, our methodology combines object extraction with multiple state-of-the-art lossless and lossy compressors, resulting in significantly improved compression ratios. We evaluated this framework against seven X-CT datasets and observed a relative compression ratio improvement of 12.34x compared to the standard compression.

</details>


### [99] [Automated Assessment of Kidney Ureteroscopy Exploration for Training](https://arxiv.org/abs/2602.15988)
*Fangjie Li,Nicholas Kavoussi,Charan Mohan,Matthieu Chabanas,Jie Ying Wu*

Main category: eess.IV

TL;DR: 本研究提出了一种新型基于输尿管镜视频的定位框架，可为肾脏模型训练提供准确的自动化反馈，从而实现无需专家监督的术外培训。


<details>
  <summary>Details</summary>
Motivation: 肾脏输尿管镜导航具有挑战性且学习曲线陡峭。当前的临床培训存在主要缺陷，因为它需要专家的一对一反馈并在手术室进行。因此，需要一个带有自动反馈的体模训练系统来极大地扩展培训机会。

Method: 提出了一种新颖的、纯粹基于输尿管镜视频的范围定位框架，该框架能自动识别受训者在肾脏模型探索中遗漏的肾盏。通过对肾脏进行缓慢、彻底的预探索视频来生成参考重建。然后，该参考重建可用于定位同一模型的任何探索视频。

Result: 在15个探索视频中，总共74个肾盏中有69个被正确分类。实现了小于4毫米的相机姿态定位误差。给定参考重建，系统需要10分钟来生成典型探索（1-2分钟）的结果。

Conclusion: 我们展示了一种新颖的相机定位框架，该框架可以为肾脏模型探索提供准确和自动的反馈。它是一种无需专家监督即可在手术室外进行培训的有效工具。

Abstract: Purpose: Kidney ureteroscopic navigation is challenging with a steep learning curve. However, current clinical training has major deficiencies, as it requires one-on-one feedback from experts and occurs in the operating room (OR). Therefore, there is a need for a phantom training system with automated feedback to greatly \revision{expand} training opportunities. Methods: We propose a novel, purely ureteroscope video-based scope localization framework that automatically identifies calyces missed by the trainee in a phantom kidney exploration. We use a slow, thorough, prior exploration video of the kidney to generate a reference reconstruction. Then, this reference reconstruction can be used to localize any exploration video of the same phantom. Results: In 15 exploration videos, a total of 69 out of 74 calyces were correctly classified. We achieve < 4mm camera pose localization error. Given the reference reconstruction, the system takes 10 minutes to generate the results for a typical exploration (1-2 minute long). Conclusion: We demonstrate a novel camera localization framework that can provide accurate and automatic feedback for kidney phantom explorations. We show its ability as a valid tool that enables out-of-OR training without requiring supervision from an expert.

</details>


### [100] [RefineFormer3D: Efficient 3D Medical Image Segmentation via Adaptive Multi-Scale Transformer with Cross Attention Fusion](https://arxiv.org/abs/2602.16320)
*Kavyansh Tyagi,Vishwas Rathi,Puneet Goyal*

Main category: eess.IV

TL;DR: RefineFormer3D是一种轻量级Transformer模型，通过高效组件在保持高分割精度的同时显著减少了3D医学图像分割的参数和内存需求。


<details>
  <summary>Details</summary>
Motivation: 3D医学图像分割在临床工作流程中面临准确性和计算效率的挑战。传统的Transformer架构通常具有过多的参数和内存需求，限制了其临床部署。

Method: RefineFormer3D是一种轻量级分层Transformer架构，包含三个关键组件：(i)基于GhostConv3D的补丁嵌入用于高效特征提取，(ii)带有低秩投影和深度卷积的MixFFN3D模块用于参数高效的特征提取，以及(iii)一个实现自适应多尺度跳跃连接融合的交叉注意力融合解码器。

Result: RefineFormer3D在ACDC和BraTS基准测试中分别达到了93.44%和85.9%的平均Dice分数，性能优于或媲美现有技术，同时参数量显著减少（仅2.94M）。模型实现了快速推理（在GPU上每卷8.35毫秒）和低内存需求。

Conclusion: RefineFormer3D是针对资源受限临床环境的有效且可扩展的3D医学图像分割解决方案，实现了准确性和计算效率的平衡。

Abstract: Accurate and computationally efficient 3D medical image segmentation remains a critical challenge in clinical workflows. Transformer-based architectures often demonstrate superior global contextual modeling but at the expense of excessive parameter counts and memory demands, restricting their clinical deployment. We propose RefineFormer3D, a lightweight hierarchical transformer architecture that balances segmentation accuracy and computational efficiency for volumetric medical imaging. The architecture integrates three key components: (i) GhostConv3D-based patch embedding for efficient feature extraction with minimal redundancy, (ii) MixFFN3D module with low-rank projections and depthwise convolutions for parameter-efficient feature extraction, and (iii) a cross-attention fusion decoder enabling adaptive multi-scale skip connection integration. RefineFormer3D contains only 2.94M parameters, substantially fewer than contemporary transformer-based methods. Extensive experiments on ACDC and BraTS benchmarks demonstrate that RefineFormer3D achieves 93.44\% and 85.9\% average Dice scores respectively, outperforming or matching state-of-the-art methods while requiring significantly fewer parameters. Furthermore, the model achieves fast inference (8.35 ms per volume on GPU) with low memory requirements, supporting deployment in resource-constrained clinical environments. These results establish RefineFormer3D as an effective and scalable solution for practical 3D medical image segmentation.

</details>


### [101] [Automated Histopathology Report Generation via Pyramidal Feature Extraction and the UNI Foundation Model](https://arxiv.org/abs/2602.16422)
*Ahmet Halici,Ece Tugba Cebeci,Musa Balci,Mustafa Cini,Serkan Sokmen*

Main category: eess.IV

TL;DR: 提出了一种分层视觉语言框架，结合冻结的病理学基础模型和Transformer解码器，用于从千兆像素WSIs生成诊断文本，其方法包括多分辨率补丁选择、伪影去除、BioGPT分词和基于检索的验证步骤以提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 从千兆像素的组织病理学全玻片图像（WSIs）生成精确、领域特定的诊断文本，由于其巨大的规模和对精确、领域特定语言的要求，具有挑战性。

Method: 1. **框架**: 提出了一个分层视觉语言框架。
2. **核心组件**: 该框架结合了冻结的病理学基础模型和Transformer解码器进行报告生成。
3. **全玻片图像预处理**:
    *   进行多分辨率金字塔式补丁选择（下采样因子为2^3至2^6）。
    *   使用拉普拉斯方差和基于HSV的标准去除背景和伪影。
4. **特征提取**: 使用UNI Vision Transformer提取补丁特征。
5. **文本生成**: 提取的特征被投射到一个6层Transformer解码器中，通过交叉注意力生成诊断文本。
6. **分词**: 使用BioGPT对输出进行分词，以更好地表示生物医学术语。
7. **验证**: 增加了一个基于检索的验证步骤，使用Sentence BERT嵌入将生成的报告与参考语料库进行比较；如果发现高度相似的匹配，则用检索到的真实参考替换生成的报告以提高可靠性。

Result: 该方法通过引入一个基于检索的验证步骤，当检测到高度相似性时，用真实参考替换生成的报告，从而提高了报告的可靠性。

Conclusion: 所提出的分层框架，结合了多阶段处理、BioGPT分词和基于检索的验证步骤，提高了从千兆像素全玻片图像生成诊断文本的可靠性。

Abstract: Generating diagnostic text from histopathology whole slide images (WSIs) is challenging due to the gigapixel scale of the input and the requirement for precise, domain specific language. We propose a hierarchical vision language framework that combines a frozen pathology foundation model with a Transformer decoder for report generation. To make WSI processing tractable, we perform multi resolution pyramidal patch selection (downsampling factors 2^3 to 2^6) and remove background and artifacts using Laplacian variance and HSV based criteria. Patch features are extracted with the UNI Vision Transformer and projected to a 6 layer Transformer decoder that generates diagnostic text via cross attention. To better represent biomedical terminology, we tokenize the output using BioGPT. Finally, we add a retrieval based verification step that compares generated reports with a reference corpus using Sentence BERT embeddings; if a high similarity match is found, the generated report is replaced with the retrieved ground truth reference to improve reliability.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [102] [Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology](https://arxiv.org/abs/2602.16703)
*Shen Zhou Hong,Alex Kleinman,Alyssa Mathiowetz,Adam Howes,Julian Cohen,Suveer Ganta,Alex Letizia,Dora Liao,Deepika Pahari,Xavier Roberts-Gaal,Luca Righetti,Joe Torres*

Main category: cs.CY

TL;DR: 大型语言模型并未显著提高新手完成复杂实验室程序的成功率，但提供了适度的性能提升和在中间步骤上的更好进展，这表明了计算机模拟基准与现实世界实用性之间的差距，凸显了AI生物安全评估进行物理世界验证的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生物学基准测试中表现出色，引发了人们对其可能帮助新手掌握双重用途实验室技能的担忧。然而，这种能力是否能转化为物理实验室中人类表现的改善尚不清楚，本研究旨在解决这一问题。

Method: 该研究进行了一项预注册、研究者盲法、随机对照试验（2025年6月至8月；n = 153），评估大型语言模型是否能提高新手在模拟病毒反向遗传学工作流程任务中的表现。

Result: 研究发现，在工作流程完成的主要终点上，LLM组（5.2%）与互联网组（6.6%）之间没有显著差异（P = 0.759），个体任务的成功率也没有显著差异。然而，LLM组在五项任务中的四项中表现出数值上更高的成功率，尤其是在细胞培养任务中（LLM 68.8% vs. 互联网 55.3%；P = 0.059）。对汇总数据进行事后贝叶斯建模估计，在LLM辅助下，“典型”反向遗传学任务的成功率大约增加1.4倍（95% CrI 0.74-2.62）。序数回归模型表明，LLM组的参与者在所有任务中更有可能通过中间步骤（正向效应的后验概率：81%-96%）。

Conclusion: 2025年年中，大型语言模型未能显著提高新手完成复杂实验室程序的成功率，但带来了适度的性能提升和在中间步骤上的更好进展。研究结果揭示了计算机模拟基准与实际应用之间的差距，强调了随着模型能力和用户熟练度发展，对AI生物安全评估进行物理世界验证的必要性。

Abstract: Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics workflow. We observed no significant difference in the primary endpoint of workflow completion (5.2% LLM vs. 6.6% Internet; P = 0.759), nor in the success rate of individual tasks. However, the LLM arm had numerically higher success rates in four of the five tasks, most notably for the cell culture task (68.8% LLM vs. 55.3% Internet; P = 0.059). Post-hoc Bayesian modeling of pooled data estimates an approximate 1.4-fold increase (95% CrI 0.74-2.62) in success for a "typical" reverse genetics task under LLM assistance. Ordinal regression modelling suggests that participants in the LLM arm were more likely to progress through intermediate steps across all tasks (posterior probability of a positive effect: 81%-96%). Overall, mid-2025 LLMs did not substantially increase novice completion of complex laboratory procedures but were associated with a modest performance benefit. These results reveal a gap between in silico benchmarks and real-world utility, underscoring the need for physical-world validation of AI biosecurity assessments as model capabilities and user proficiency evolve.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [103] [CADEvolve: Creating Realistic CAD via Program Evolution](https://arxiv.org/abs/2602.16317)
*Maksim Elistratov,Marina Barannikov,Gregory Ivanov,Valentin Khrulkov,Anton Konushin,Andrey Kuznetsov,Dmitrii Zhemchuzhnikov*

Main category: cs.GR

TL;DR: CADEvolve是一种基于进化的管道和数据集，通过VLM引导的编辑和验证，从简单基元逐步生成工业级复杂的CAD程序。它创建了一个包含1.3M脚本的统一数据集，并用此数据集微调的VLM在Image2CAD任务上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的CAD数据集主要包含简单的草图-拉伸序列，缺乏复杂操作、多操作组合和设计意图，这阻碍了AI模型（特别是VLM）在CAD自动化方面的有效微调。尝试使用冻结的VLM通常会产生简单或无效的程序，因为当前的基础模型在3D理解方面能力有限。

Method: 提出CADEvolve，一个基于进化的管道和数据集。它从简单的CAD基元开始，通过VLM引导的编辑和验证，逐步演化和增长CAD程序，以达到工业级的复杂性。该方法生成了8k个复杂的CadQuery参数化生成器。随后，经过多阶段后处理和增强，构建了一个包含1.3M脚本及其渲染几何的统一数据集，该数据集涵盖了完整的CadQuery操作集。

Result: 成功构建了一个包含8k个复杂CAD部件的CadQuery参数化生成器数据集。通过多阶段后处理和增强，创建了一个包含1.3M脚本及其渲染几何的统一数据集，该数据集使用了完整的CadQuery操作集。使用CADEvolve数据集微调的VLM在Image2CAD任务上，于DeepCAD、Fusion 360和MCB基准测试中均取得了最先进的（State-of-the-Art, SOTA）结果。

Conclusion: CADEvolve通过生成工业级复杂、多样化的CAD程序数据集，有效解决了现有CAD数据不足的问题。通过此数据集微调的VLM在Image2CAD任务上表现出卓越的性能，证明了其在推动CAD自动化方面的潜力。

Abstract: Computer-Aided Design (CAD) delivers rapid, editable modeling for engineering and manufacturing. Recent AI progress now makes full automation feasible for various CAD tasks. However, progress is bottlenecked by data: public corpora mostly contain sketch-extrude sequences, lack complex operations, multi-operation composition and design intent, and thus hinder effective fine-tuning. Attempts to bypass this with frozen VLMs often yield simple or invalid programs due to limited 3D grounding in current foundation models. We present CADEvolve, an evolution-based pipeline and dataset that starts from simple primitives and, via VLM-guided edits and validations, incrementally grows CAD programs toward industrial-grade complexity. The result is 8k complex parts expressed as executable CadQuery parametric generators. After multi-stage post-processing and augmentation, we obtain a unified dataset of 1.3m scripts paired with rendered geometry and exercising the full CadQuery operation set. A VLM fine-tuned on CADEvolve achieves state-of-the-art results on the Image2CAD task across the DeepCAD, Fusion 360, and MCB benchmarks.

</details>


### [104] [Style-Aware Gloss Control for Generative Non-Photorealistic Rendering](https://arxiv.org/abs/2602.16611)
*Santiago Jimenez-Navarro,Belen Masia,Ana Serrano*

Main category: cs.GR

TL;DR: 本文通过训练无监督生成模型，构建了一个解耦光泽度与艺术风格的分层潜在空间，并结合扩散模型实现了对非真实感图像中光泽度和艺术风格的精细控制，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 研究在机器学习模型中，光泽度和艺术风格是如何被表示的，以及人类感知光泽度独立于艺术风格的机制。

Method: 通过构建一个包含光泽度和艺术风格系统化变化的绘画对象数据集，训练了一个无监督生成模型以学习分层潜在空间。在此基础上，引入了一个轻量级适配器，将该潜在空间与潜在扩散模型连接，以实现非真实感图像的合成。

Result: 模型学习到的分层潜在空间能够将光泽度与其他外观因素解耦，从而详细研究光泽度在不同艺术风格中的表示和变化。该方法能够合成对光泽度和艺术风格具有精细控制的非真实感图像，并与现有模型相比，展现出更好的解耦性和可控性。

Conclusion: 该方法实现了光泽度和艺术风格的有效解耦和精细控制，优于现有模型。

Abstract: Humans can infer material characteristics of objects from their visual appearance, and this ability extends to artistic depictions, where similar perceptual strategies guide the interpretation of paintings or drawings. Among the factors that define material appearance, gloss, along with color, is widely regarded as one of the most important, and recent studies indicate that humans can perceive gloss independently of the artistic style used to depict an object. To investigate how gloss and artistic style are represented in learned models, we train an unsupervised generative model on a newly curated dataset of painterly objects designed to systematically vary such factors. Our analysis reveals a hierarchical latent space in which gloss is disentangled from other appearance factors, allowing for a detailed study of how gloss is represented and varies across artistic styles. Building on this representation, we introduce a lightweight adapter that connects our style- and gloss-aware latent space to a latent-diffusion model, enabling the synthesis of non-photorealistic images with fine-grained control of these factors. We compare our approach with previous models and observe improved disentanglement and controllability of the learned factors.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [105] [Rethinking ANN-based Retrieval: Multifaceted Learnable Index for Large-scale Recommendation System](https://arxiv.org/abs/2602.16124)
*Jiang Zhang,Yubo Wang,Wei Chang,Lu Han,Xingying Cheng,Feng Zhang,Min Li,Songhao Jiang,Wei Zheng,Harry Tran,Zhen Wang,Lei Chen,Yueming Wang,Benyu Zhang,Xiangjun Fan,Bi Xue,Qifan Wang*

Main category: cs.IR

TL;DR: MFLI是一种可扩展的实时检索范式，它在一个统一的框架内学习多面物品嵌入和索引，消除了服务时的近似最近邻（ANN）搜索，显著提高了推荐系统的召回率、冷内容交付和语义相关性。


<details>
  <summary>Details</summary>
Motivation: 大规模推荐系统中的ANN搜索存在两个关键限制：1. 物品嵌入及其索引通常在单独的阶段学习，导致检索质量不佳，特别是对于新创建的物品。2. 尽管ANN提供了亚线性查询时间，但仍需为每个请求运行，在工业规模下产生大量的计算成本。

Method: 本文提出了MultiFaceted Learnable Index (MFLI)。它通过对物品嵌入进行残差量化来构建多面分层码本，并与嵌入共同训练该码本。此外，它引入了一种高效的多面索引结构和机制，支持实时更新。在服务时，直接使用学习到的分层索引来识别相关物品，完全避免了ANN搜索。

Result: 在真实世界数据上的广泛实验表明，MFLI与现有最先进的方法相比，在互动任务上的召回率提高了11.8%，冷内容交付提高了57.29%，语义相关性提高了13.5%。在线实验结果也表明，它提高了参与度，减少了流行度偏差，并提高了服务效率。

Conclusion: MFLI提出了一种可扩展的实时检索范式，通过统一学习嵌入和索引并消除服务时的ANN搜索，成功解决了现有方法的局限性，在大规模推荐系统中实现了显著的性能提升和更高的服务效率。

Abstract: Approximate nearest neighbor (ANN) search is widely used in the retrieval stage of large-scale recommendation systems. In this stage, candidate items are indexed using their learned embedding vectors, and ANN search is executed for each user (or item) query to retrieve a set of relevant items. However, ANN-based retrieval has two key limitations. First, item embeddings and their indices are typically learned in separate stages: indexing is often performed offline after embeddings are trained, which can yield suboptimal retrieval quality-especially for newly created items. Second, although ANN offers sublinear query time, it must still be run for every request, incurring substantial computation cost at industry scale. In this paper, we propose MultiFaceted Learnable Index (MFLI), a scalable, real-time retrieval paradigm that learns multifaceted item embeddings and indices within a unified framework and eliminates ANN search at serving time. Specifically, we construct a multifaceted hierarchical codebook via residual quantization of item embeddings and co-train the codebook with the embeddings. We further introduce an efficient multifaceted indexing structure and mechanisms that support real-time updates. At serving time, the learned hierarchical indices are used directly to identify relevant items, avoiding ANN search altogether. Extensive experiments on real-world data with billions of users show that MFLI improves recall on engagement tasks by up to 11.8\%, cold-content delivery by up to 57.29\%, and semantic relevance by 13.5\% compared with prior state-of-the-art methods. We also deploy MFLI in the system and report online experimental results demonstrating improved engagement, less popularity bias, and higher serving efficiency.

</details>


### [106] [The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems](https://arxiv.org/abs/2602.16315)
*Gabriele Barlacchi,Margherita Lalli,Emanuele Ferragina,Fosca Giannotti,Dino Pedreschi,Luca Pappalardo*

Main category: cs.IR

TL;DR: 研究发现，尽管增加推荐采纳率可能使个体消费多样化，但集体需求往往会加剧流行度集中；并且静态评估中个体多样性的增长是虚假的，实际上随时间推移个体多样性会下降，强调了在推荐系统设计中考虑反馈循环动态性的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统反馈循环模拟研究存在不切实际的假设，导致对这些循环的系统性影响理解不足。

Method: 提出了一种反馈循环模型，该模型捕获了隐式反馈、周期性再训练、推荐的概率性采纳以及异构推荐系统。该框架应用于在线零售和音乐流媒体数据进行分析。

Result: 增加推荐采纳率可能导致个体消费的逐步多样化，而集体需求以模型和领域相关的方式重新分配，通常会加剧流行度集中。时间分析进一步揭示，在静态评估中观察到的个体多样性表面增长是虚幻的：当采纳率固定且时间推移时，所有模型中的个体多样性都持续下降。

Conclusion: 推荐系统在设计时需要超越静态评估，并明确考虑反馈循环的动态性。

Abstract: Recommender systems shape individual choices through feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies. We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of recommendations, and heterogeneous recommender systems. We apply the framework on online retail and music streaming data and analyze systemic effects of the feedback loop. We find that increasing recommender adoption may lead to a progressive diversification of individual consumption, while collective demand is redistributed in model- and domain-dependent ways, often amplifying popularity concentration. Temporal analyses further reveal that apparent increases in individual diversity observed in static evaluations are illusory: when adoption is fixed and time unfolds, individual diversity consistently decreases across all models. Our results highlight the need to move beyond static evaluations and explicitly account for feedback-loop dynamics when designing recommender systems.

</details>


### [107] [Variable-Length Semantic IDs for Recommender Systems](https://arxiv.org/abs/2602.16375)
*Kirill Khrylchenko*

Main category: cs.IR

TL;DR: 本文提出了一种基于Gumbel-Softmax离散变分自编码器的可变长度语义标识符方法，将突发通信原理引入推荐系统，以解决现有固定长度语义ID的效率问题和固定长度限制，并更有效地表示物品。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统中固定长度的语义标识符在处理物品空间基数大时效率低下，与自然语言不符，并且忽视了真实世界目录中物品频率的高度偏态分布（热门物品和长尾物品的信息需求不同）。而突发通信领域的可变长度消息可以更有效地描述频繁概念，但其思想尚未系统地应用于推荐系统。

Method: 提出了一种带有Gumbel-Softmax重参数化的离散变分自编码器，用于在概率框架下学习自适应长度的物品表示，从而引入推荐系统的可变长度语义标识符。

Result: 该方法避免了基于REINFORCE训练的不稳定性，并克服了先前语义ID方法的固定长度限制。

Conclusion: 本文通过引入可变长度语义标识符，将推荐系统与突发通信领域相结合，利用带有Gumbel-Softmax重参数化的离散变分自编码器学习自适应长度的物品表示，解决了现有固定长度语义ID方法的效率低下和局限性问题。

Abstract: Generative models are increasingly used in recommender systems, both for modeling user behavior as event sequences and for integrating large language models into recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces, which makes training generative models difficult and introduces a vocabulary gap between natural language and item identifiers. Semantic identifiers (semantic IDs), which represent items as sequences of low-cardinality tokens, have recently emerged as an effective solution to this problem. However, existing approaches generate semantic identifiers of fixed length, assigning the same description length to all items. This is inefficient, misaligned with natural language, and ignores the highly skewed frequency structure of real-world catalogs, where popular items and rare long-tail items exhibit fundamentally different information requirements. In parallel, the emergent communication literature studies how agents develop discrete communication protocols, often producing variable-length messages in which frequent concepts receive shorter descriptions. Despite the conceptual similarity, these ideas have not been systematically adopted in recommender systems. In this work, we bridge recommender systems and emergent communication by introducing variable-length semantic identifiers for recommendation. We propose a discrete variational autoencoder with Gumbel-Softmax reparameterization that learns item representations of adaptive length under a principled probabilistic framework, avoiding the instability of REINFORCE-based training and the fixed-length constraints of prior semantic ID methods.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [108] [Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems](https://arxiv.org/abs/2602.15855)
*Barak Or*

Main category: cs.LG

TL;DR: 该研究提出一个运行时稳定性框架，通过监控创新统计数据来检测混合推理系统中的不稳定，并在任务失败前可靠地检测到不稳定，且恢复机制能重新建立有界内部行为。


<details>
  <summary>Details</summary>
Motivation: 结合学习组件和基于模型推理的混合推理系统在工具增强的决策循环中得到部署，但在部分可观测性和持续证据不匹配情况下的运行时行为仍知之甚少。实践中，系统故障通常表现为内部推理动态的逐渐发散，而非孤立的预测错误。

Method: 该研究从受卡尔曼启发视角研究混合推理系统的运行时稳定性。它将推理建模为由内部创新信号驱动的随机推理过程，并引入认知漂移作为可测量的运行时现象。稳定性被定义为可检测性、有界发散性和可恢复性。研究提出了一种运行时稳定性框架，该框架监控创新统计数据，检测新出现的 H不稳定，并触发恢复感知控制机制。

Result: 在多步、工具增强的推理任务上进行的实验表明，在任务失败之前能够可靠地检测到不稳定，并且在可行的情况下，恢复机制能在有限时间内重新建立有界的内部行为。

Conclusion: 本研究强调运行时稳定性是不确定环境下可靠推理的系统级要求。

Abstract: Hybrid reasoning systems that combine learned components with model-based inference are increasingly deployed in tool-augmented decision loops, yet their runtime behavior under partial observability and sustained evidence mismatch remains poorly understood. In practice, failures often arise as gradual divergence of internal reasoning dynamics rather than as isolated prediction errors. This work studies runtime stability in hybrid reasoning systems from a Kalman-inspired perspective. We model reasoning as a stochastic inference process driven by an internal innovation signal and introduce cognitive drift as a measurable runtime phenomenon. Stability is defined in terms of detectability, bounded divergence, and recoverability rather than task-level correctness. We propose a runtime stability framework that monitors innovation statistics, detects emerging instability, and triggers recovery-aware control mechanisms. Experiments on multi-step, tool-augmented reasoning tasks demonstrate reliable instability detection prior to task failure and show that recovery, when feasible, re-establishes bounded internal behavior within finite time. These results emphasize runtime stability as a system-level requirement for reliable reasoning under uncertainty.

</details>


### [109] [Genetic Generalized Additive Models](https://arxiv.org/abs/2602.15877)
*Kaaustaaub Shankar,Kelly Cohen*

Main category: cs.LG

TL;DR: 该论文提出使用多目标遗传算法NSGA-II自动优化广义可加模型（GAMs），通过联合最小化预测误差（RMSE）和捕获稀疏性、平滑度和不确定性的复杂性惩罚，发现比基线LinearGAMs更准确或复杂度显著更低、更简单、更平滑且置信区间更窄的模型，从而提高可解释性。


<details>
  <summary>Details</summary>
Motivation: 广义可加模型（GAMs）在预测准确性和可解释性之间取得了平衡，但手动配置其结构具有挑战性。

Method: 提出使用多目标遗传算法NSGA-II自动优化GAMs，联合最小化预测误差（RMSE）和一个捕获稀疏性、平滑度和不确定性的复杂性惩罚。

Result: 在California Housing数据集上的实验表明，NSGA-II发现的GAMs在准确性方面优于基线LinearGAMs，或者在性能匹配的情况下复杂度显著降低。由此产生的模型更简单、更平滑，并表现出更窄的置信区间，增强了可解释性。

Conclusion: 该框架为透明、高性能模型的自动化优化提供了一种通用方法，提高了模型的可解释性。

Abstract: Generalized Additive Models (GAMs) balance predictive accuracy and interpretability, but manually configuring their structure is challenging. We propose using the multi-objective genetic algorithm NSGA-II to automatically optimize GAMs, jointly minimizing prediction error (RMSE) and a Complexity Penalty that captures sparsity, smoothness, and uncertainty. Experiments on the California Housing dataset show that NSGA-II discovers GAMs that outperform baseline LinearGAMs in accuracy or match performance with substantially lower complexity. The resulting models are simpler, smoother, and exhibit narrower confidence intervals, enhancing interpretability. This framework provides a general approach for automated optimization of transparent, high-performing models. The code can be found at .

</details>


### [110] [IT-OSE: Exploring Optimal Sample Size for Industrial Data Augmentation](https://arxiv.org/abs/2602.15878)
*Mingchun Sun,Rongqiang Zhao,Zhennan Huang,Songyu Ding,Jie Liu*

Main category: cs.LG

TL;DR: 该论文提出了一种信息论最优样本量估计（IT-OSE）方法，用于工业数据增强中的可靠最优样本量（OSS）估计，并引入了区间覆盖和偏差（ICD）评分来评估估计的OSS。实验证明IT-OSE能提高模型性能、增强可解释性，并显著降低计算和数据成本。


<details>
  <summary>Details</summary>
Motivation: 工业场景中数据增强能提高模型性能，但缺乏关于增强中最佳样本量的理论研究或既定估计方法，也缺乏评估OSS准确性或其与真实值偏差的既定指标。

Method: 提出信息论最优样本量估计（IT-OSE）以提供可靠的OSS估计。提出区间覆盖和偏差（ICD）分数以直观评估估计的OSS。理论分析并公式化OSS与主导因素之间的关系，以增强可解释性。

Result: 与经验估计相比，IT-OSE在分类任务中平均提高了4.38%的准确率，在回归任务中平均降低了18.80%的MAPE。下游模型性能的改进更稳定。ICD分数中的ICDdev平均降低了49.30%，OSS的确定性增强。与穷举搜索相比，IT-OSE在实现相同OSS的同时，平均降低了83.97%的计算成本和93.46%的数据成本。实践实验证明IT-OSE在代表性基于传感器的工业场景中具有通用性。

Conclusion: IT-OSE为工业数据增强提供了一种可靠、经济高效且通用的最优样本量估计方法，可提高模型性能并使其更稳定。ICD评分提供了直观的评估，理论分析增强了可解释性。

Abstract: In industrial scenarios, data augmentation is an effective approach to improve model performance. However, its benefits are not unidirectionally beneficial. There is no theoretical research or established estimation for the optimal sample size (OSS) in augmentation, nor is there an established metric to evaluate the accuracy of OSS or its deviation from the ground truth. To address these issues, we propose an information-theoretic optimal sample size estimation (IT-OSE) to provide reliable OSS estimation for industrial data augmentation. An interval coverage and deviation (ICD) score is proposed to evaluate the estimated OSS intuitively. The relationship between OSS and dominant factors is theoretically analyzed and formulated, thereby enhancing the interpretability. Experiments show that, compared to empirical estimation, the IT-OSE increases accuracy in classification tasks across baseline models by an average of 4.38%, and reduces MAPE in regression tasks across baseline models by an average of 18.80%. The improvements in downstream model performance are more stable. ICDdev in the ICD score is also reduced by an average of 49.30%. The determinism of OSS is enhanced. Compared to exhaustive search, the IT-OSE achieves the same OSS while reducing computational and data costs by an average of 83.97% and 93.46%. Furthermore, practicality experiments demonstrate that the IT-OSE exhibits generality across representative sensor-based industrial scenarios.

</details>


### [111] [B-DENSE: Branching For Dense Ensemble Network Learning](https://arxiv.org/abs/2602.15971)
*Cherish Puniani,Tushar Kumar,Arnav Bendre,Gaurav Kumar,Shree Singhi*

Main category: cs.LG

TL;DR: B-DENSE是一个新的多分支轨迹对齐框架，通过对学生模型进行修改，使其输出K倍扩展通道并与教师模型的整个轨迹序列进行密集对齐，解决了扩散模型蒸馏中采样慢、信息丢失和离散误差大的问题，从而显著提高了图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模方面表现出色，但其迭代采样性质导致推理延迟高。现有的蒸馏技术虽然加速了采样，但它们丢弃了中间轨迹步骤，这种稀疏的监督导致结构信息丢失并引入了显著的离散化误差。

Method: 提出B-DENSE框架，该框架利用多分支轨迹对齐。具体做法是修改学生模型的架构，使其输出K倍扩展的通道，其中每个子集对应一个特定分支，代表教师模型轨迹中的一个离散中间步骤。通过训练这些分支同时映射到教师模型目标时间步的整个序列，以强制实现密集的中间轨迹对齐。

Result: 学生模型从训练的最早期阶段就能学会有效地探索解决方案空间，相比基线蒸馏框架，展示了卓越的图像生成质量。

Conclusion: B-DENSE框架通过在训练早期阶段实现密集中间轨迹对齐，使学生模型能更好地学习，从而在图像生成质量上优于现有的蒸馏框架。

Abstract: Inspired by non-equilibrium thermodynamics, diffusion models have achieved state-of-the-art performance in generative modeling. However, their iterative sampling nature results in high inference latency. While recent distillation techniques accelerate sampling, they discard intermediate trajectory steps. This sparse supervision leads to a loss of structural information and introduces significant discretization errors. To mitigate this, we propose B-DENSE, a novel framework that leverages multi-branch trajectory alignment. We modify the student architecture to output $K$-fold expanded channels, where each subset corresponds to a specific branch representing a discrete intermediate step in the teacher's trajectory. By training these branches to simultaneously map to the entire sequence of the teacher's target timesteps, we enforce dense intermediate trajectory alignment. Consequently, the student model learns to navigate the solution space from the earliest stages of training, demonstrating superior image generation quality compared to baseline distillation frameworks.

</details>


### [112] [AI-CARE: Carbon-Aware Reporting Evaluation Metric for AI Models](https://arxiv.org/abs/2602.16042)
*KC Santosh,Srikanth Baride,Rodrigue Rizk*

Main category: cs.LG

TL;DR: 本文提出AI-CARE，一个评估机器学习模型能耗和碳排放的工具，并引入碳-性能权衡曲线，以可视化性能与碳成本的帕累托前沿，旨在推动多目标评估，鼓励开发同时兼顾准确性和环境责任的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习的迅速发展，模型训练和推理的环境成本已成为一个关键的社会问题。现有基准主要关注准确性、BLEU或mAP等标准性能指标，而忽略了能耗和碳排放。这种单目标评估范式与大规模部署的实际需求日益不符，尤其是在能源受限环境和气候意识型企业中。

Method: 我们提出了AI-CARE，一个用于报告机器学习模型能耗和碳排放的评估工具。此外，我们引入了碳-性能权衡曲线，这是一个可解释的工具，用于可视化性能和碳成本之间的帕累托前沿。通过理论分析和在代表性机器学习工作负载上的实证验证，我们证明了碳感知基准测试。

Result: 碳感知基准测试改变了模型的相对排名，并鼓励了既准确又对环境负责的架构。

Conclusion: 该提案旨在将研究社区转向透明、多目标评估，并使机器学习进展与全球可持续发展目标保持一致。

Abstract: As machine learning (ML) continues its rapid expansion, the environmental cost of model training and inference has become a critical societal concern. Existing benchmarks overwhelmingly focus on standard performance metrics such as accuracy, BLEU, or mAP, while largely ignoring energy consumption and carbon emissions. This single-objective evaluation paradigm is increasingly misaligned with the practical requirements of large-scale deployment, particularly in energy-constrained environments such as mobile devices, developing regions, and climate-aware enterprises. In this paper, we propose AI-CARE, an evaluation tool for reporting energy consumption, and carbon emissions of ML models. In addition, we introduce the carbon-performance tradeoff curve, an interpretable tool that visualizes the Pareto frontier between performance and carbon cost. We demonstrate, through theoretical analysis and empirical validation on representative ML workloads, that carbon-aware benchmarking changes the relative ranking of models and encourages architectures that are simultaneously accurate and environmentally responsible. Our proposal aims to shift the research community toward transparent, multi-objective evaluation and align ML progress with global sustainability goals. The tool and documentation are available at .

</details>


### [113] [Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research](https://arxiv.org/abs/2602.16072)
*Chenda Duan,Yipeng Zhang,Sotaro Kanai,Yuanyi Ding,Atsuro Daida,Pengyue Yu,Tiancheng Zheng,Naoto Kuroda,Shaun A. Hussain,Eishi Asano,Hiroki Nariai,Vwani Roychowdhury*

Main category: cs.LG

TL;DR: 本文介绍了Omni-iEEG，这是一个大规模、标准化、包含302名患者和178小时iEEG记录的数据集，具有专家验证的临床元数据和病理事件标注，旨在克服现有数据集的局限性，推动可复现和临床可转化的癫痫研究。


<details>
  <summary>Details</summary>
Motivation: 全球有超过5000万人受癫痫影响，其中三分之一的患者出现耐药性癫痫发作，手术是实现癫痫无发作的最佳机会。然而，癫痫病灶区（EZ）的准确定位依赖于颅内脑电图（iEEG），但当前的临床工作流程仍受限于劳动密集型的人工审查。现有数据驱动方法通常基于格式和元数据不一致的单中心数据集开发，缺乏标准化基准和病理事件标注，阻碍了研究的可复现性、跨中心验证和临床相关性。

Method: 通过整合公共来源中异构的iEEG格式、元数据和记录，作者构建了Omni-iEEG数据集。该数据集包含了由癫痫专家验证的标准化临床元数据（如癫痫发作起始区、切除范围和手术结果）以及超过3.6万个专家验证的病理事件标注。此外，研究还展示了在长iEEG片段上进行端到端建模的潜力，并强调了在非神经生理学领域预训练表示的可迁移性。

Result: 该研究构建了一个大规模的术前iEEG资源——Omni-iEEG，包含302名患者和178小时的高分辨率记录。Omni-iEEG提供了标准化且由癫痫专家验证的临床元数据，以及超过3.6万个专家验证的病理事件标注，支持稳健的生物标志物研究。该资源能够促进在临床相关环境中系统评估模型。

Conclusion: Omni-iEEG为机器学习和癫痫研究之间架起了桥梁，定义了具有统一评估指标的临床有意义任务，从而能够在临床相关环境中系统评估模型。它为可复现、通用和临床可转化的癫痫研究奠定了基础。

Abstract: Epilepsy affects over 50 million people worldwide, and one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom. Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows, however, remain constrained by labor-intensive manual review. At the same time, existing data-driven approaches are typically developed on single-center datasets that are inconsistent in format and metadata, lack standardized benchmarks, and rarely release pathological event annotations, creating barriers to reproducibility, cross-center validation, and clinical relevance. With extensive efforts to reconcile heterogeneous iEEG formats, metadata, and recordings across publicly available sources, we present $\textbf{Omni-iEEG}$, a large-scale, pre-surgical iEEG resource comprising $\textbf{302 patients}$ and $\textbf{178 hours}$ of high-resolution recordings. The dataset includes harmonized clinical metadata such as seizure onset zones, resections, and surgical outcomes, all validated by board-certified epileptologists. In addition, Omni-iEEG provides over 36K expert-validated annotations of pathological events, enabling robust biomarker studies. Omni-iEEG serves as a bridge between machine learning and epilepsy research. It defines clinically meaningful tasks with unified evaluation metrics grounded in clinical priors, enabling systematic evaluation of models in clinically relevant settings. Beyond benchmarking, we demonstrate the potential of end-to-end modeling on long iEEG segments and highlight the transferability of representations pretrained on non-neurophysiological domains. Together, these contributions establish Omni-iEEG as a foundation for reproducible, generalizable, and clinically translatable epilepsy research. The project page with dataset and code links is available at .

</details>


### [114] [ASPEN: Spectral-Temporal Fusion for Cross-Subject Brain Decoding](https://arxiv.org/abs/2602.16147)
*Megan Lee,Seung Ha Hwang,Inhyeok Choi,Shreyas Darade,Mengchun Zhang,Kateryna Shapovalenko*

Main category: cs.LG

TL;DR: 该研究探讨了脑电图（EEG）脑机接口（BCI）中跨受试者泛化的问题，发现频谱特征比时间波形更稳定。为此，论文引入了ASPEN，一个通过乘法融合结合频谱和时间特征流的混合架构，并在基准数据集上实现了卓越的跨受试者泛化性能。


<details>
  <summary>Details</summary>
Motivation: 由于神经信号的个体差异性，基于EEG的BCI在跨受试者泛化方面仍然具有挑战性。本研究旨在探讨频谱表示是否能为跨受试者迁移提供比时间波形更稳定的特征。

Method: 通过对三种EEG范式（SSVEP、P300和运动想象）进行相关性分析，比较频谱特征和时间信号的跨受试者相似性。提出了一种名为ASPEN的混合架构，该架构通过乘法融合结合频谱和时间特征流，要求跨模态一致性才能使特征传播。

Result: 研究发现，频谱特征在三种EEG范式中始终表现出比时间信号更高的跨受试者相似性。ASPEN能够根据范式动态地实现最佳的频谱-时间平衡。ASPEN在六个基准数据集中的三个上取得了最佳的未见受试者准确性，并在其他数据集上表现出有竞争力的性能。

Conclusion: 多模态乘法融合（如ASPEN中所用）能够实现有效的跨受试者泛化。

Abstract: Cross-subject generalization in EEG-based brain-computer interfaces (BCIs) remains challenging due to individual variability in neural signals. We investigate whether spectral representations offer more stable features for cross-subject transfer than temporal waveforms. Through correlation analyses across three EEG paradigms (SSVEP, P300, and Motor Imagery), we find that spectral features exhibit consistently higher cross-subject similarity than temporal signals. Motivated by this observation, we introduce ASPEN, a hybrid architecture that combines spectral and temporal feature streams via multiplicative fusion, requiring cross-modal agreement for features to propagate. Experiments across six benchmark datasets reveal that ASPEN is able to dynamically achieve the optimal spectral-temporal balance depending on the paradigm. ASPEN achieves the best unseen-subject accuracy on three of six datasets and competitive performance on others, demonstrating that multiplicative multimodal fusion enables effective cross-subject generalization.

</details>


### [115] [HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents](https://arxiv.org/abs/2602.16165)
*Jiangweizhi Peng,Yuanxin Liu,Ruida Zhou,Charles Fleming,Zhaoran Wang,Alfredo Garcia,Mingyi Hong*

Main category: cs.LG

TL;DR: 该论文提出了HiPER，一种新颖的层次化规划-执行强化学习框架，旨在解决大型语言模型（LLM）作为交互式智能体在稀疏和延迟奖励的长周期多轮决策任务中面临的挑战。HiPER通过将策略分解为高层规划器和低层执行器，并引入层次化优势估计（HAE）来有效分配信用，从而提高了优化稳定性。HiPER在ALFWorld和WebShop等交互式基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 训练LLM作为多轮决策的交互式智能体具有挑战性，特别是在奖励稀疏和延迟的长周期任务中，智能体需要在接收有意义反馈之前执行一系列漫长的动作。大多数现有强化学习方法将LLM智能体建模为在单一时间尺度上运行的扁平策略，这在稀疏奖励设置中导致不稳定的优化和低效的信用分配。

Method: HiPER是一种新颖的层次化规划-执行强化学习框架，它明确地将高层规划与低层执行分开。HiPER将策略分解为：一个高层规划器，负责提出子目标；一个低层执行器，负责在多个动作步骤中实现这些子目标。为了使优化与这种结构对齐，论文引入了一种关键技术——层次化优势估计（HAE），它在规划和执行两个层面仔细分配信用。通过在每个子目标执行过程中聚合回报并协调两个层面的更新，HAE提供了一个无偏梯度估计器，并可证明相比扁平广义优势估计减少了方差。

Result: HiPER在具有挑战性的交互式基准测试中取得了最先进的性能，在ALFWorld上达到了97.4%的成功率，在WebShop上使用Qwen2.5-7B-Instruct达到了83.3%的成功率。这比之前最好的方法分别提高了6.6%和8.3%，特别是在需要多个依赖子任务的长周期任务中，收益显著。

Conclusion: 这些结果凸显了显式层次化分解对于多轮LLM智能体可扩展强化学习训练的重要性。

Abstract: Training LLMs as interactive agents for multi-turn decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where agents must execute extended sequences of actions before receiving meaningful feedback. Most existing reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale, selecting one action at each turn. In sparse-reward settings, such flat policies must propagate credit across the entire trajectory without explicit temporal abstraction, which often leads to unstable optimization and inefficient credit assignment. We propose HiPER, a novel Hierarchical Plan-Execute RL framework that explicitly separates high-level planning from low-level execution. HiPER factorizes the policy into a high-level planner that proposes subgoals and a low-level executor that carries them out over multiple action steps. To align optimization with this structure, we introduce a key technique called hierarchical advantage estimation (HAE), which carefully assigns credit at both the planning and execution levels. By aggregating returns over the execution of each subgoal and coordinating updates across the two levels, HAE provides an unbiased gradient estimator and provably reduces variance compared to flat generalized advantage estimation. Empirically, HiPER achieves state-of-the-art performance on challenging interactive benchmarks, reaching 97.4\% success on ALFWorld and 83.3\% on WebShop with Qwen2.5-7B-Instruct (+6.6\% and +8.3\% over the best prior method), with especially large gains on long-horizon tasks requiring multiple dependent subtasks. These results highlight the importance of explicit hierarchical decomposition for scalable RL training of multi-turn LLM agents.

</details>


### [116] [Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16196)
*Emile Anand,Richard Hoffmann,Sarah Liaw,Adam Wierman*

Main category: cs.LG

TL;DR: 本文提出GMFS框架，通过交互强度子采样解决了大规模多智能体强化学习中异构交互的计算挑战，实现了可伸缩且接近最优的性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）中，大规模智能体群体的协调面临联合状态-动作空间随智能体数量呈指数增长的挑战。现有均值场方法假设智能体交互是同质的，而近期基于图核（graphon）的方法虽然能捕捉异质性，但计算成本随智能体数量增加而升高。

Method: 提出了一种图核均值场子采样（GMFS）框架。该方法通过根据交互强度对$\kappa$个智能体进行子采样，以近似图核加权的均值场，并学习策略。

Result: GMFS方法在样本复杂度上达到$\mathrm{poly}(\kappa)$，最优性差距为$O(1/\sqrt{\kappa})$。在机器人协调的数值模拟中，验证了理论并表明GMFS实现了接近最优的性能。

Conclusion: GMFS框架在机器人协作仿真中验证了其理论，达到了接近最优的性能。

Abstract: Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent interactions, but these approaches assume homogeneous interactions. Recent graphon-based frameworks capture heterogeneity, but are computationally expensive as the number of agents grows. Therefore, we introduce $\texttt{GMFS}$, a $\textbf{G}$raphon $\textbf{M}$ean-$\textbf{F}$ield $\textbf{S}$ubsampling framework for scalable cooperative MARL with heterogeneous agent interactions. By subsampling $\kappa$ agents according to interaction strength, we approximate the graphon-weighted mean-field and learn a policy with sample complexity $\mathrm{poly}(\kappa)$ and optimality gap $O(1/\sqrt{\kappa})$. We verify our theory with numerical simulations in robotic coordination, showing that $\texttt{GMFS}$ achieves near-optimal performance.

</details>


### [117] [Geometric Neural Operators via Lie Group-Constrained Latent Dynamics](https://arxiv.org/abs/2602.16209)
*Jiaquan Zhang,Fachrina Dewi Puspitasari,Songbo Zhang,Yibei Liu,Kuien Liu,Caiyan Qin,Fan Mo,Peng Wang,Yang Yang,Chaoning Zhang*

Main category: cs.LG

TL;DR: 针对现有神经算子在长期预测中存在的不稳定性问题，我们提出了一种基于李群的流形约束（MCL）方法，通过引入几何归纳偏差，显著提高了预测精度并降低了误差。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在多层迭代和长周期展开中常出现不稳定性，原因在于无约束的欧几里得潜在空间更新违反了几何和守恒定律。

Method: 我们提出了一种基于李群的流形约束（MCL）方法，通过低秩李代数参数化来约束流形，该参数化对潜在表示执行群作用更新。MCL是一个高效的即插即用模块，用于在现有神经算子中强制执行几何归纳偏差。

Result: 在1-D Burgers和2-D Navier-Stokes等各种偏微分方程上的广泛实验表明，我们的方法以2.26%的参数增加为代价，有效降低了30-50%的相对预测误差。

Conclusion: 我们的方法通过引入神经算子更新中缺失的几何约束，为提高长期预测精度提供了一个可扩展的解决方案。

Abstract: Neural operators offer an effective framework for learning solutions of partial differential equations for many physical systems in a resolution-invariant and data-driven manner. Existing neural operators, however, often suffer from instability in multi-layer iteration and long-horizon rollout, which stems from the unconstrained Euclidean latent space updates that violate the geometric and conservation laws. To address this challenge, we propose to constrain manifolds with low-rank Lie algebra parameterization that performs group action updates on the latent representation. Our method, termed Manifold Constraining based on Lie group (MCL), acts as an efficient \emph{plug-and-play} module that enforces geometric inductive bias to existing neural operators. Extensive experiments on various partial differential equations, such as 1-D Burgers and 2-D Navier-Stokes, over a wide range of parameters and steps demonstrate that our method effectively lowers the relative prediction error by 30-50\% at the cost of 2.26\% of parameter increase. The results show that our approach provides a scalable solution for improving long-term prediction fidelity by addressing the principled geometric constraints absent in the neural operator updates.

</details>


### [118] [Extracting and Analyzing Rail Crossing Behavior Signatures from Videos using Tensor Methods](https://arxiv.org/abs/2602.16057)
*Dawon Ahn,Het Patel,Aemal Khattak,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 本文提出了一个多视图张量分解框架，通过分析铁路道口视频在不同时间阶段的行为，识别了基于位置的驾驶员行为模式，并发现道口位置比时间更能决定行为，为有针对性的安全干预提供了依据。


<details>
  <summary>Details</summary>
Motivation: 铁路道口的安全挑战复杂，驾驶员行为因地点、时间和条件而异。传统方法单独分析道口，限制了识别跨地点共享行为模式的能力。

Method: 本文提出了一个多视图张量分解框架，通过使用TimeSformer嵌入来表示每个时间阶段（接近、等待和通过），捕获行为相似性。该方法构建了特定阶段的相似性矩阵，并应用非负对称CP分解来发现具有独特时间特征的潜在行为组成部分。

Result: 分析揭示了具有独特时间特征的潜在行为组成部分。结果表明，道口位置是行为模式比一天中的时间更强的决定因素，并且接近阶段的行为提供了特别有区分度的特征。学习到的组件空间可视化证实了基于位置的聚类，某些道口形成了独特的行为群集。

Conclusion: 该自动化框架能够跨多个道口进行可扩展的模式发现，为按行为相似性对地点进行分组以制定有针对性的安全干预措施奠定基础。

Abstract: Railway crossings present complex safety challenges where driver behavior varies by location, time, and conditions. Traditional approaches analyze crossings individually, limiting the ability to identify shared behavioral patterns across locations. We propose a multi-view tensor decomposition framework that captures behavioral similarities across three temporal phases: Approach (warning activation to gate lowering), Waiting (gates down to train passage), and Clearance (train passage to gate raising). We analyze railway crossing videos from multiple locations using TimeSformer embeddings to represent each phase. By constructing phase-specific similarity matrices and applying non-negative symmetric CP decomposition, we discover latent behavioral components with distinct temporal signatures. Our tensor analysis reveals that crossing location appears to be a stronger determinant of behavior patterns than time of day, and that approach-phase behavior provides particularly discriminative signatures. Visualization of the learned component space confirms location-based clustering, with certain crossings forming distinct behavioral clusters. This automated framework enables scalable pattern discovery across multiple crossings, providing a foundation for grouping locations by behavioral similarity to inform targeted safety interventions.

</details>


### [119] [Guide-Guard: Off-Target Predicting in CRISPR Applications](https://arxiv.org/abs/2602.16327)
*Joseph Bingham,Netanel Arussy,Saman Zonouz*

Main category: cs.LG

TL;DR: 本研究提出了一个名为 Guide-Guard 的机器学习解决方案，利用数据驱动方法以 84% 的准确率预测 CRISPR 基因编辑中的脱靶行为，并且能够同时在多个基因上进行训练。


<details>
  <summary>Details</summary>
Motivation: 随着 CRISPR 等基因测序和编辑技术的发展，研究人员可以更方便地进行基因和健康科学研究。然而，该领域也面临新的挑战，即如何准确预测基因编辑的脱靶行为。

Method: 作者从数据驱动的角度探索了潜在的生物和化学模型。他们提出了一种名为 Guide-Guard 的机器学习解决方案，用于预测 CRISPR 基因编辑过程中 gRNA 的系统行为。

Result: Guide-Guard 解决方案在预测系统行为方面达到了 84% 的准确率。该方案能够同时在多个不同的基因上进行训练，并保持准确性。

Conclusion: 该论文提出了一种名为 Guide-Guard 的机器学习解决方案，旨在提高 CRISPR 基因编辑过程中脱靶行为预测的准确性和效率。

Abstract: With the introduction of cyber-physical genome sequencing and editing technologies, such as CRISPR, researchers can more easily access tools to investigate and create remedies for a variety of topics in genetics and health science (e.g. agriculture and medicine). As the field advances and grows, new concerns present themselves in the ability to predict the off-target behavior. In this work, we explore the underlying biological and chemical model from a data driven perspective. Additionally, we present a machine learning based solution named \textit{Guide-Guard} to predict the behavior of the system given a gRNA in the CRISPR gene-editing process with 84\% accuracy. This solution is able to be trained on multiple different genes at the same time while retaining accuracy.

</details>


### [120] [UCTECG-Net: Uncertainty-aware Convolution Transformer ECG Network for Arrhythmia Detection](https://arxiv.org/abs/2602.16216)
*Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya*

Main category: cs.LG

TL;DR: 深度学习改善了自动心电图（ECG）分类，但预测可靠性有限阻碍了其在安全关键环境中的应用。UCTECG-Net是一种不确定性感知的混合架构，结合一维卷积和Transformer编码器共同处理原始ECG信号及其频谱图，在性能上优于基线模型，并提供更可靠的不确定性估计，为风险感知型ECG决策支持奠定基础。


<details>
  <summary>Details</summary>
Motivation: 深度学习在自动化心电图（ECG）分类方面取得了进展，但预测可靠性洞察的缺乏阻碍了其在安全关键环境中的应用。

Method: 本文提出了UCTECG-Net，这是一种不确定性感知的混合架构，结合了一维卷积和Transformer编码器，共同处理原始ECG信号及其频谱图。为了评估预测可靠性，作者将三种不确定性量化方法（Monte Carlo Dropout、Deep Ensembles和Ensemble Monte Carlo Dropout）整合到所有模型中，并使用不确定性感知混淆矩阵和衍生指标分析其行为。模型在MIT-BIH心律失常和PTB诊断数据集上进行了评估。

Result: UCTECG-Net在准确率、精确率、召回率和F1分数方面优于LSTM、CNN1D和Transformer基线模型，在MIT-BIH数据集上实现了高达98.58%的准确率，在PTB数据集上达到了99.14%。UCTECG-Net，特别是结合Ensemble或EMCD时，提供了比竞争架构更可靠、更一致的不确定性估计。

Conclusion: UCTECG-Net由于其改进的性能和更可靠、更一致的不确定性估计，为风险感知型ECG决策支持提供了更坚实的基础。

Abstract: Deep learning has improved automated electrocardiogram (ECG) classification, but limited insight into prediction reliability hinders its use in safety-critical settings. This paper proposes UCTECG-Net, an uncertainty-aware hybrid architecture that combines one-dimensional convolutions and Transformer encoders to process raw ECG signals and their spectrograms jointly. Evaluated on the MIT-BIH Arrhythmia and PTB Diagnostic datasets, UCTECG-Net outperforms LSTM, CNN1D, and Transformer baselines in terms of accuracy, precision, recall and F1 score, achieving up to 98.58% accuracy on MIT-BIH and 99.14% on PTB. To assess predictive reliability, we integrate three uncertainty quantification methods (Monte Carlo Dropout, Deep Ensembles, and Ensemble Monte Carlo Dropout) into all models and analyze their behavior using an uncertainty-aware confusion matrix and derived metrics. The results show that UCTECG-Net, particularly with Ensemble or EMCD, provides more reliable and better-aligned uncertainty estimates than competing architectures, offering a stronger basis for risk-aware ECG decision support.

</details>


### [121] [Memes-as-Replies: Can Models Select Humorous Manga Panel Responses?](https://arxiv.org/abs/2602.15842)
*Ryosuke Kohita,Seiichiro Yoshioka*

Main category: cs.LG

TL;DR: 本论文介绍了Meme回复选择任务和MaMe-Re基准，旨在研究迷因在对话中动态和语境化的幽默运用。研究发现，大型语言模型（LLMs）初步展现出理解复杂社交线索的能力，但视觉信息并未提升表现，且LLMs难以区分语义相似候选者之间的微妙幽默差异。


<details>
  <summary>Details</summary>
Motivation: 计算研究主要关注迷因的内在属性，但迷因在创造幽默时动态和语境化的使用仍是一个未被充分研究的领域。

Method: 引入了Meme回复选择任务，并提出了MaMe-Re（Manga Meme Reply Benchmark），这是一个包含100,000个人工标注对（日本漫画面板和社交媒体帖子）的基准。

Result: 1. 大型语言模型（LLMs）初步显示出捕捉复杂社交线索（如夸张）的能力，超越了表面语义匹配。2. 包含视觉信息并未提高性能，这揭示了理解视觉内容与有效利用其进行语境幽默之间的差距。3. 尽管LLMs在受控设置中能够匹配人类判断，但它们难以区分语义相似候选者之间微妙的幽默差异。

Conclusion: 选择语境化幽默的回复对当前模型来说仍然是一个开放的挑战。

Abstract: Memes are a popular element of modern web communication, used not only as static artifacts but also as interactive replies within conversations. While computational research has focused on analyzing the intrinsic properties of memes, the dynamic and contextual use of memes to create humor remains an understudied area of web science. To address this gap, we introduce the Meme Reply Selection task and present MaMe-Re (Manga Meme Reply Benchmark), a benchmark of 100,000 human-annotated pairs (500,000 total annotations from 2,325 unique annotators) consisting of openly licensed Japanese manga panels and social media posts. Our analysis reveals three key insights: (1) large language models (LLMs) show preliminary evidence of capturing complex social cues such as exaggeration, moving beyond surface-level semantic matching; (2) the inclusion of visual information does not improve performance, revealing a gap between understanding visual content and effectively using it for contextual humor; (3) while LLMs can match human judgments in controlled settings, they struggle to distinguish subtle differences in wit among semantically similar candidates. These findings suggest that selecting contextually humorous replies remains an open challenge for current models.

</details>


### [122] [Intra-Fairness Dynamics: The Bias Spillover Effect in Targeted LLM Alignment](https://arxiv.org/abs/2602.16438)
*Eva Paraschou,Line Harder Clemmensen,Sneha Das*

Main category: cs.LG

TL;DR: 本研究调查了LLM公平性对齐中的偏见溢出问题，发现有针对性的性别对齐可能在模糊语境下无意中加剧其他敏感属性的不平等，强调了多属性、情境感知评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM公平性对齐主要关注缓解单一敏感属性的偏见，而忽略了公平性固有的多维和特定语境的价值。这种方法可能导致系统在实现狭隘的公平性指标的同时，加剧未被关注属性上的不平等，即所谓的偏见溢出。尽管在机器学习中已广泛研究，但偏见溢出在LLM对齐中仍严重未被充分探索。

Method: 该研究调查了在Mistral 7B、Llama 3.1 8B和Qwen 2.5 7B这三种最先进的LLM中，有针对性的性别对齐如何影响九个敏感属性的公平性。研究方法包括使用直接偏好优化（DPO）和BBQ基准测试，并在模糊和明确的语境下评估公平性。

Result: 研究发现了显著的偏见溢出：尽管总体结果显示有所改善，但情境感知分析揭示了在模糊语境下的显著恶化，特别是对于外貌（所有模型中p<0.001）、性取向和残疾状况。

Conclusion: 在不确定性下，改善一个属性的公平性可能会无意中加剧其他属性的不平等，这强调了建立情境感知、多属性公平性评估框架的必要性。

Abstract: Conventional large language model (LLM) fairness alignment largely focuses on mitigating bias along single sensitive attributes, overlooking fairness as an inherently multidimensional and context-specific value. This approach risks creating systems that achieve narrow fairness metrics while exacerbating disparities along untargeted attributes, a phenomenon known as bias spillover. While extensively studied in machine learning, bias spillover remains critically underexplored in LLM alignment. In this work, we investigate how targeted gender alignment affects fairness across nine sensitive attributes in three state-of-the-art LLMs (Mistral 7B, Llama 3.1 8B, Qwen 2.5 7B). Using Direct Preference Optimization and the BBQ benchmark, we evaluate fairness under ambiguous and disambiguous contexts. Our findings reveal noticeable bias spillover: while aggregate results show improvements, context-aware analysis exposes significant degradations in ambiguous contexts, particularly for physical appearance ($p< 0.001$ across all models), sexual orientation, and disability status. We demonstrate that improving fairness along one attribute can inadvertently worsen disparities in others under uncertainty, highlighting the necessity of context-aware, multi-attribute fairness evaluation frameworks.

</details>


### [123] [GICDM: Mitigating Hubness for Reliable Distance-Based Generative Model Evaluation](https://arxiv.org/abs/2602.16449)
*Nicolas Salvy,Hugues Talbot,Bertrand Thirion*

Main category: cs.LG

TL;DR: 生成模型评估中，高维嵌入空间中的中心性现象会扭曲距离度量。GICDM方法可以纠正这种现象，提高度量的可靠性并使其与人类判断对齐。


<details>
  <summary>Details</summary>
Motivation: 生成模型评估通常依赖高维嵌入空间来计算样本之间的距离，但我们发现这些空间中的数据集表示受到中心性现象的影响，这会扭曲最近邻关系并导致基于距离的度量出现偏差。

Method: 基于经典的迭代上下文相异性度量（ICDM），我们引入了生成式ICDM（GICDM），这是一种纠正真实和生成数据邻域估计的方法。我们还引入了多尺度扩展以改善经验行为。

Result: 在合成和真实基准上的大量实验表明，GICDM解决了中心性引起的故障，恢复了可靠的度量行为，并改善了与人类判断的一致性。

Conclusion: GICDM有效解决了生成模型评估中高维嵌入空间存在的中心性现象，从而恢复了可靠的度量行为，并使评估结果更符合人类判断。

Abstract: Generative model evaluation commonly relies on high-dimensional embedding spaces to compute distances between samples. We show that dataset representations in these spaces are affected by the hubness phenomenon, which distorts nearest neighbor relationships and biases distance-based metrics. Building on the classical Iterative Contextual Dissimilarity Measure (ICDM), we introduce Generative ICDM (GICDM), a method to correct neighborhood estimation for both real and generated data. We introduce a multi-scale extension to improve empirical behavior. Extensive experiments on synthetic and real benchmarks demonstrate that GICDM resolves hubness-induced failures, restores reliable metric behavior, and improves alignment with human judgment.

</details>


### [124] [Why Any-Order Autoregressive Models Need Two-Stream Attention: A Structural-Semantic Tradeoff](https://arxiv.org/abs/2602.16092)
*Patrick Pynadath,Ruqi Zhang*

Main category: cs.LG

TL;DR: 本论文认为，任意顺序自回归模型（AO-ARM）中双流注意力成功的深层原因在于解决了结构-语义权衡，而非仅仅将内容与位置分离。通过引入解耦旋转位置嵌入（Decoupled RoPE），实验结果表明，在序列长度增加时，性能下降，支持了结构-语义权衡的假设。


<details>
  <summary>Details</summary>
Motivation: 任意顺序自回归模型（AO-ARM）通常需要双流注意力来实现竞争性能，传统上认为这是为了解耦令牌内容与位置。本研究提出双流注意力可能扮演了更深层次的角色，即解决任意顺序生成中固有的结构-语义权衡。

Method: 为了将结构-语义权衡与位置-内容分离隔离开来，本研究提出了解耦旋转位置嵌入（Decoupled RoPE）。这种对旋转位置嵌入的修改提供了目标位置信息，但未揭示目标内容。

Result: 解耦旋转位置嵌入（Decoupled RoPE）在短序列长度（语义和结构邻近性一致）下表现良好，但在序列长度增加且两种排序（语义和结构）发散时，性能会下降。

Conclusion: 双流注意力在任意顺序自回归模型（AO-ARM）中的成功，并非仅仅源于将位置与内容分离，而是因为它规避了任意顺序生成中固有的更深层次的结构-语义权衡。

Abstract: Any-order autoregressive models (AO-ARMs) offer a promising path toward efficient masked diffusion by enabling native key-value caching, but competitive performance has so far required two-stream attention, typically motivated as a means of decoupling token content from position. In this work, we argue that two-stream attention may be serving a more subtle role. We identify a structural-semantic tradeoff in any-order generation: the hidden representation at each step must simultaneously attend to semantically informative tokens for prediction and structurally recent tokens for summarization, objectives that compete for attention capacity in a single stream but can specialize across two streams. To isolate this tradeoff from position-content separation, we propose Decoupled RoPE, a modification to rotary position embeddings that provides target position information without revealing target content. Decoupled RoPE performs competitively at short sequence lengths--where semantic and structural proximity coincide--but degrades as sequence length increases and the two orderings diverge. These results suggest that the success of two-stream attention stems not merely from separating position from content, but from circumventing the deeper structural-semantic tradeoff inherent to any-order generation.

</details>


### [125] [Discrete Stochastic Localization for Non-autoregressive Generation](https://arxiv.org/abs/2602.16169)
*Yunshu Wu,Jiayi Cheng,Partha Thakuria,Rob Brekelmans,Evangelos E. Papalexakis,Greg Ver Steeg*

Main category: cs.LG

TL;DR: 本文提出了一种名为DSL的训练方法，通过训练SNR不变去噪器，显著提高了掩码扩散语言模型（MDLM）及其重新掩码采样器（ReMDM）的步长效率，在更少的评估次数下取得了更好的生成质量。


<details>
  <summary>Details</summary>
Motivation: 非自回归（NAR）生成通过并行预测令牌来减少解码延迟，但迭代细化常受错误累积和自生成草稿下的分布偏移问题困扰。掩码扩散语言模型（MDLMs）及其重新掩码采样器（如ReMDM）被视为现代NAR迭代细化方法，但仍需提高步长效率。

Method: 本文提出了离散随机定位（DSL）方法，通过在连续的损坏级别上训练一个单一的SNR不变去噪器，将中间草稿噪声和掩码式端点损坏统一在一个Diffusion Transformer中。

Result: 在OpenWebText数据集上，DSL微调在低步长预算下获得了显著的MAUVE增益，超越了MDLM+ReMDM基线，去噪器评估次数减少了约4倍；在高预算下，其质量与自回归模型相当。分析表明，DSL改进了自我校正和不确定性校准。

Conclusion: DSL训练可以显著提高MDLM/ReMDM采样的步长效率，通过改进自我校正和不确定性校准，使得重新掩码生成在计算上更高效。

Abstract: Non-autoregressive (NAR) generation reduces decoding latency by predicting many tokens in parallel, but iterative refinement often suffers from error accumulation and distribution shift under self-generated drafts. Masked diffusion language models (MDLMs) and their remasking samplers (e.g., ReMDM) can be viewed as modern NAR iterative refinement, where generation repeatedly revises a partially observed draft. In this work we show that \emph{training alone} can substantially improve the step-efficiency of MDLM/ReMDM sampling. We propose \textsc{DSL} (Discrete Stochastic Localization), which trains a single SNR-invariant denoiser across a continuum of corruption levels, bridging intermediate draft noise and mask-style endpoint corruption within one Diffusion Transformer. On OpenWebText, \textsc{DSL} fine-tuning yields large MAUVE gains at low step budgets, surpassing the MDLM+ReMDM baseline with \(\sim\)4$\times$ fewer denoiser evaluations, and matches autoregressive quality at high budgets. Analyses show improved self-correction and uncertainty calibration, making remasking markedly more compute-efficient.

</details>


### [126] [ModalImmune: Immunity Driven Unlearning via Self Destructive Training](https://arxiv.org/abs/2602.16197)
*Rong Fu,Jia Yee Tan,Wenxin Zhang,Zijian Zhang,Ziming Wang,Zhaolu Kang,Muge Qi,Shuning Zhang,Simon Fong*

Main category: cs.LG

TL;DR: ModalImmune是一个训练框架，通过在训练期间有意且可控地折叠选定的模态信息，使模型学习对破坏性模态影响具有鲁棒性的联合表示，从而增强了多模态系统对模态缺失和损坏的弹性。


<details>
  <summary>Details</summary>
Motivation: 多模态系统在部署时易受输入通道部分或完全丢失的影响，这损害了其在实际环境中的可靠性。

Method: 本文提出了ModalImmune训练框架，该框架通过在训练期间有意且可控地折叠选定的模态信息来强制实现模态免疫。该框架结合了频谱自适应折叠正则化器、信息增益引导控制器、曲率感知梯度掩蔽以及经过认证的Neumann截断超梯度过程，用于自动元参数适应。

Result: 在标准多模态基准上的实证评估表明，ModalImmune提高了对模态移除和损坏的弹性，同时保持了收敛稳定性和重建能力。

Conclusion: ModalImmune框架能有效提升多模态系统在面对模态缺失和损坏时的鲁棒性，同时维持良好的性能。

Abstract: Multimodal systems are vulnerable to partial or complete loss of input channels at deployment, which undermines reliability in real-world settings. This paper presents ModalImmune, a training framework that enforces modality immunity by intentionally and controllably collapsing selected modality information during training so the model learns joint representations that are robust to destructive modality influence. The framework combines a spectrum-adaptive collapse regularizer, an information-gain guided controller for targeted interventions, curvature-aware gradient masking to stabilize destructive updates, and a certified Neumann-truncated hyper-gradient procedure for automatic meta-parameter adaptation. Empirical evaluation on standard multimodal benchmarks demonstrates that ModalImmune improves resilience to modality removal and corruption while retaining convergence stability and reconstruction capacity.

</details>


### [127] [Fast and Scalable Analytical Diffusion](https://arxiv.org/abs/2602.16498)
*Xinyi Shang,Peng Sun,Jingyu Lin,Zhiqiang Shen*

Main category: cs.LG

TL;DR: 本文提出了GoldDiff，一个免训练的分析扩散框架，通过动态识别“黄金子集”来避免全数据集扫描，从而将推理复杂度与数据集大小解耦。GoldDiff利用“后验渐进集中”现象，实现了71倍的加速并在ImageNet-1K上首次成功应用，为大规模生成建模提供了一种可扩展的范式。


<details>
  <summary>Details</summary>
Motivation: 分析扩散模型通过将去噪分数公式化为经验-贝叶斯后验均值，为生成建模提供了一条数学上透明的途径。然而，这种可解释性带来了高昂的成本：标准公式要求在每个时间步进行全数据集扫描，其复杂度与数据集大小呈线性关系，导致可扩展性瓶颈。目前的普遍假设是整个训练数据都是必需的，本文旨在挑战这一假设并解决此瓶颈。

Method: 本文提出了动态时间感知黄金子集扩散（GoldDiff）框架。该方法利用“后验渐进集中”现象，即去噪分数的有效支持集会随着信噪比的增加从全局流形渐进收缩到局部邻域。GoldDiff采用一种从粗到精的机制，动态地找出用于推理的“黄金子集”，从而将推理复杂度与数据集大小解耦。该框架是免训练的，并通过严格的理论边界保证了稀疏近似能收敛到精确分数。

Result: 在AFHQ数据集上，GoldDiff实现了71倍的加速，同时性能与全扫描基线持平或甚至更优。最值得注意的是，GoldDiff首次成功将分析扩散模型扩展到ImageNet-1K，证明了其在大规模生成建模中的潜力。

Conclusion: GoldDiff为大规模生成建模提供了一种可扩展、免训练的范式，首次成功将分析扩散模型扩展到ImageNet-1K，克服了现有分析扩散模型在可扩展性上的局限性。

Abstract: Analytical diffusion models offer a mathematically transparent path to generative modeling by formulating the denoising score as an empirical-Bayes posterior mean. However, this interpretability comes at a prohibitive cost: the standard formulation necessitates a full-dataset scan at every timestep, scaling linearly with dataset size. In this work, we present the first systematic study addressing this scalability bottleneck. We challenge the prevailing assumption that the entire training data is necessary, uncovering the phenomenon of Posterior Progressive Concentration: the effective golden support of the denoising score is not static but shrinks asymptotically from the global manifold to a local neighborhood as the signal-to-noise ratio increases. Capitalizing on this, we propose Dynamic Time-Aware Golden Subset Diffusion (GoldDiff), a training-free framework that decouples inference complexity from dataset size. Instead of static retrieval, GoldDiff uses a coarse-to-fine mechanism to dynamically pinpoint the ''Golden Subset'' for inference. Theoretically, we derive rigorous bounds guaranteeing that our sparse approximation converges to the exact score. Empirically, GoldDiff achieves a $\bf 71 \times$ speedup on AFHQ while matching or achieving even better performance than full-scan baselines. Most notably, we demonstrate the first successful scaling of analytical diffusion to ImageNet-1K, unlocking a scalable, training-free paradigm for large-scale generative modeling.

</details>


### [128] [Interpretability-by-Design with Accurate Locally Additive Models and Conditional Feature Effects](https://arxiv.org/abs/2602.16503)
*Vasilis Gkolemis,Loukas Kavouras,Dimitrios Kyriakopoulos,Konstantinos Tsopelas,Dimitrios Rontogiannis,Giuseppe Casalicchio,Theodore Dalamagas,Christos Diou*

Main category: cs.LG

TL;DR: CALMs是一种新的模型，它通过允许局部加性效应在不同子区域变化以捕获交互作用，从而平衡了GAMs的可解释性和GA$^2$Ms的准确性。


<details>
  <summary>Details</summary>
Motivation: 广义加性模型（GAMs）通过独立的单变量特征效应提供了可解释性，但在存在交互作用时会出现欠拟合。GA$^2$Ms通过添加选定的成对交互作用提高了准确性，但牺牲了可解释性并限制了模型审计。因此，需要一种能够平衡GAMs的可解释性与GA$^2$Ms的准确性的新模型。

Method: 本文提出了条件加性局部模型（CALMs），它允许每个特征具有多个单变量形状函数，每个函数在输入空间的不同区域中活跃。这些区域通过与其交互的特征上的简单逻辑条件（阈值）独立定义。模型的效应在局部保持加性，同时在不同子区域中变化以捕获交互作用。此外，提出了一种基于蒸馏的训练流程，用于识别具有有限交互的同质区域，并通过区域感知回溯拟合可解释的形状函数。

Result: 在各种分类和回归任务上的实验表明，CALMs始终优于GAMs，并且在准确性方面与GA$^2$Ms相当。

Conclusion: CALMs在预测准确性和可解释性之间提供了令人信服的权衡。

Abstract: Generalized additive models (GAMs) offer interpretability through independent univariate feature effects but underfit when interactions are present in data. GA$^2$Ms add selected pairwise interactions which improves accuracy, but sacrifices interpretability and limits model auditing. We propose \emph{Conditionally Additive Local Models} (CALMs), a new model class, that balances the interpretability of GAMs with the accuracy of GA$^2$Ms. CALMs allow multiple univariate shape functions per feature, each active in different regions of the input space. These regions are defined independently for each feature as simple logical conditions (thresholds) on the features it interacts with. As a result, effects remain locally additive while varying across subregions to capture interactions. We further propose a principled distillation-based training pipeline that identifies homogeneous regions with limited interactions and fits interpretable shape functions via region-aware backfitting. Experiments on diverse classification and regression tasks show that CALMs consistently outperform GAMs and achieve accuracy comparable with GA$^2$Ms. Overall, CALMs offer a compelling trade-off between predictive accuracy and interpretability.

</details>


### [129] [AIFL: A Global Daily Streamflow Forecasting Model Using Deterministic LSTM Pre-trained on ERA5-Land and Fine-tuned on IFS](https://arxiv.org/abs/2602.16579)
*Maria Luisa Taccari,Kenza Tazi,Oisín M. Morrison,Andreas Grafberger,Juan Colonese,Corentin Carton de Wiart,Christel Prudhomme,Cinzia Mazzetti,Matthew Chantry,Florian Pappenberger*

Main category: cs.LG

TL;DR: AIFL是一个基于LSTM的全球径流预报模型，通过两阶段训练策略（再分析数据预训练，IFS预报数据微调）弥合了再分析与操作性预报之间的性能差距。该模型在CARAVAN数据集上训练，并在独立测试集上展现出高预测技能（KGE' 0.66, NSE 0.53），性能与现有先进系统相当，尤其在极端事件检测中表现可靠。


<details>
  <summary>Details</summary>
Motivation: 可靠的全球径流预报对于防洪准备和水资源管理至关重要，但数据驱动模型在从历史再分析过渡到操作性预报产品时，性能往往存在差距。

Method: 本文提出了AIFL（洪水人工智能），一个基于LSTM的确定性模型，用于全球日常径流预报。该模型在CARAVAN数据集中精选的18,588个流域上进行训练，采用新颖的两阶段训练策略：首先在40年的ERA5-Land再分析数据（1980-2019）上进行预训练以捕捉水文过程，然后通过IFS控制预报（2016-2019）进行微调，以适应操作性数值天气预报的误差结构和偏差。这是首个在CARAVAN生态系统内进行端到端训练的全球模型。

Result: 在独立的时序测试集（2021-2024）上，AIFL模型实现了高预测技能，中位数修正Kling-Gupta效率（KGE'）为0.66，中位数Nash-Sutcliffe效率（NSE）为0.53。基准测试结果表明，AIFL与当前最先进的全球系统具有高度竞争力，在保持透明和可重复的驱动流程的同时，取得了可比较的精度。该模型在极端事件检测中表现出卓越的可靠性。

Conclusion: AIFL模型为全球水文界提供了一个简化且操作稳健的基线，尤其在极端事件检测方面表现出卓越的可靠性。

Abstract: Reliable global streamflow forecasting is essential for flood preparedness and water resource management, yet data-driven models often suffer from a performance gap when transitioning from historical reanalysis to operational forecast products. This paper introduces AIFL (Artificial Intelligence for Floods), a deterministic LSTM-based model designed for global daily streamflow forecasting. Trained on 18,588 basins curated from the CARAVAN dataset, AIFL utilises a novel two-stage training strategy to bridge the reanalysis-to-forecast domain shift. The model is first pre-trained on 40 years of ERA5-Land reanalysis (1980-2019) to capture robust hydrological processes, then fine-tuned on operational Integrated Forecasting System (IFS) control forecasts (2016-2019) to adapt to the specific error structures and biases of operational numerical weather prediction. To our knowledge, this is the first global model trained end-to-end within the CARAVAN ecosystem. On an independent temporal test set (2021-2024), AIFL achieves high predictive skill with a median modified Kling-Gupta Efficiency (KGE') of 0.66 and a median Nash-Sutcliffe Efficiency (NSE) of 0.53. Benchmarking results show that AIFL is highly competitive with current state-of-the-art global systems, achieving comparable accuracy while maintaining a transparent and reproducible forcing pipeline. The model demonstrates exceptional reliability in extreme-event detection, providing a streamlined and operationally robust baseline for the global hydrological community.

</details>


### [130] [A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models](https://arxiv.org/abs/2602.16626)
*SungJun Cho,Chetan Gohil,Rukuang Huang,Oiwi Parker Jones,Mark W. Woolrich*

Main category: cs.LG

TL;DR: 本文评估了神经影像数据分词策略，发现简单的固定样本级分词与复杂的学习型分词在重建精度和模型性能上表现相当。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理的成功推动了神经影像数据大型基础模型的发展，这些模型需要将连续神经时间序列数据离散化，即“分词”。然而，不同分词策略对神经数据的影响目前尚不清楚。

Method: 本文对应用于脑磁图（MEG）数据的基于Transformer的大型神经影像模型（LNM）的样本级分词策略进行了系统评估。研究比较了可学习和不可学习的分词器，评估标准包括信号重建保真度以及对后续基础建模性能（如令牌预测、生成数据的生物学合理性、受试者特定信息保留和下游任务性能）的影响。对于可学习分词器，提出了一种基于自编码器的新方法。实验在三个公开可用的MEG数据集上进行。

Result: 结果表明，可学习和不可学习的离散化方案都能实现高重建精度，并在大多数评估标准上表现出大致相当的性能。

Conclusion: 对于神经基础模型的开发，简单的固定样本级分词策略是可行的。

Abstract: Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at .

</details>


### [131] [Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes](https://arxiv.org/abs/2602.16629)
*Ethan Blaser,Jiuqi Wang,Shangtong Zhang*

Main category: cs.LG

TL;DR: 论文证明了在不使用局部时钟的情况下，on-policy n步差分TD的收敛性，并为off-policy n步差分TD的收敛性提供了三个充分条件，从而增强了该算法的理论基础和实际应用性。


<details>
  <summary>Details</summary>
Motivation: 现有的差分时序差分 (TD) 学习算法的收敛性保证需要学习率中的局部时钟机制，该机制与状态访问计数相关联，但实践中不常使用且无法推广到表格设置之外。

Method: 本文通过使用标准的递减学习率，证明了在不使用局部时钟的情况下，任何n步on-policy差分TD的几乎必然收敛性。接着，作者推导了三个充分条件，使得在不使用局部时钟的情况下，off-policy n步差分TD也能收敛。

Result: 证明了在不使用局部时钟和标准递减学习率的条件下，on-policy n步差分TD的几乎必然收敛。推导了三个充分条件，保证了在不使用局部时钟的条件下，off-policy n步差分TD的收敛性。

Conclusion: 这些结果强化了差分TD的理论基础，并使其收敛性分析更接近实际实现。

Abstract: The average reward is a fundamental performance metric in reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to learn the value functions associated with the average reward in both on-policy and off-policy settings. However, existing convergence guarantees require a local clock in learning rates tied to state visit counts, which practitioners do not use and does not extend beyond tabular settings. We address this limitation by proving the almost sure convergence of on-policy $n$-step differential TD for any $n$ using standard diminishing learning rates without a local clock. We then derive three sufficient conditions under which off-policy $n$-step differential TD also converges without a local clock. These results strengthen the theoretical foundations of differential TD and bring its convergence analysis closer to practical implementations.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [132] [Temporal Panel Selection in Ongoing Citizens' Assemblies](https://arxiv.org/abs/2602.16194)
*Yusuf Hakan Kalayci,Evi Micha*

Main category: cs.GT

TL;DR: 本文提出了一种时间抽签框架，用于永久公民大会，通过形式化比例代表和个体公平性，确保不同群体在单个小组内和长期序列中都能得到代表，并为此开发了算法。


<details>
  <summary>Details</summary>
Motivation: 现有的公民大会通常是一次性的，无法确保不同群体在不同时间段的代表性，特别是较小的群体可能无法在每个小组中都得到代表。因此，需要一个能够确保不同群体随着时间在连续小组中得到代表的强大框架。

Method: 作者通过要求在每个单独小组内和小组序列中都实现比例代表来形式化时间抽签框架。他们在一个度量空间中考虑人口，目标是实现比例代表和个体公平性。通过将代表性的概念扩展到时间设置，要求小组序列的每个初始段作为一个累积整体，按比例反映人口结构，并在此基础上开发算法。

Result: 作者提出了能够提供不同程度比例代表性保证的算法，这些保证既适用于单个小组，也适用于任何小组序列，同时还能保持个体在时间上的公平性。

Conclusion: 本文提出的算法在单个小组内以及小组序列中都提供了不同程度的比例代表性保证，同时保持了个体的长期公平性。

Abstract: Permanent citizens' assemblies are ongoing deliberative bodies composed of randomly selected citizens, organized into panels that rotate over time. Unlike one-off panels, which represent the population in a single snapshot, permanent assemblies enable shifting participation across multiple rounds. This structure offers a powerful framework for ensuring that different groups of individuals are represented over time across successive panels. In particular, it allows smaller groups of individuals that may not warrant representation in every individual panel to be represented across a sequence of them. We formalize this temporal sortition framework by requiring proportional representation both within each individual panel and across the sequence of panels. Building on the work of Ebadian and Micha (2025), we consider a setting in which the population lies in a metric space, and the goal is to achieve both proportional representation, ensuring that every group of citizens receives adequate representation, and individual fairness, ensuring that each individual has an equal probability of being selected. We extend the notion of representation to a temporal setting by requiring that every initial segment of the panel sequence, viewed as a cumulative whole, proportionally reflects the structure of the population. We present algorithms that provide varying guarantees of proportional representation, both within individual panels and across any sequence of panels, while also maintaining individual fairness over time.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [133] [Retrieval Augmented Generation of Literature-derived Polymer Knowledge: The Example of a Biodegradable Polymer Expert System](https://arxiv.org/abs/2602.16650)
*Sonakshi Gupta,Akhlak Mahmood,Wei Xiong,Rampi Ramprasad*

Main category: cs.CE

TL;DR: 该研究开发并评估了两种聚合物文献检索增强生成（RAG）管道（VectorRAG和GraphRAG），发现GraphRAG在精度和可解释性方面更高，而VectorRAG提供了更广的召回率，从而实现了可靠的文献分析。


<details>
  <summary>Details</summary>
Motivation: 聚合物文献庞大、非结构化且术语不一致，导致系统检索和推理困难。现有工具无法保留跨研究上下文，而RAG的有效性取决于领域知识表示。

Method: 研究使用了1000多篇聚羟基链烷酸酯（PHA）论文，构建了上下文保留的段落嵌入（用于VectorRAG）和支持实体消歧及多跳推理的规范化结构化知识图谱（用于GraphRAG）。通过标准检索指标、与GPT和Gemini等先进系统的比较以及领域化学家的定性验证来评估这些管道。

Result: GraphRAG实现了更高的精度和可解释性，而VectorRAG提供了更广的召回率，显示出互补的权衡。专家验证进一步证实，定制管道（尤其是GraphRAG）能生成有根据、引文可靠且领域相关性强的响应。

Conclusion: 这项工作为使用精选语料库和检索设计构建材料科学助手提供了一个实用框架，减少了对专有模型的依赖，并实现了大规模可信的文献分析。

Abstract: Polymer literature contains a large and growing body of experimental knowledge, yet much of it is buried in unstructured text and inconsistent terminology, making systematic retrieval and reasoning difficult. Existing tools typically extract narrow, study-specific facts in isolation, failing to preserve the cross-study context required to answer broader scientific questions. Retrieval-augmented generation (RAG) offers a promising way to overcome this limitation by combining large language models (LLMs) with external retrieval, but its effectiveness depends strongly on how domain knowledge is represented. In this work, we develop two retrieval pipelines: a dense semantic vector-based approach (VectorRAG) and a graph-based approach (GraphRAG). Using over 1,000 polyhydroxyalkanoate (PHA) papers, we construct context-preserving paragraph embeddings and a canonicalized structured knowledge graph supporting entity disambiguation and multi-hop reasoning. We evaluate these pipelines through standard retrieval metrics, comparisons with general state-of-the-art systems such as GPT and Gemini, and qualitative validation by a domain chemist. The results show that GraphRAG achieves higher precision and interpretability, while VectorRAG provides broader recall, highlighting complementary trade-offs. Expert validation further confirms that the tailored pipelines, particularly GraphRAG, produce well-grounded, citation-reliable responses with strong domain relevance. By grounding every statement in evidence, these systems enable researchers to navigate the literature, compare findings across studies, and uncover patterns that are difficult to extract manually. More broadly, this work establishes a practical framework for building materials science assistants using curated corpora and retrieval design, reducing reliance on proprietary models while enabling trustworthy literature analysis at scale.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [134] [From Reflection to Repair: A Scoping Review of Dataset Documentation Tools](https://arxiv.org/abs/2602.15968)
*Pedro Reynolds-Cuéllar,Marisol Wong-Villacres,Adriana Alvarado Garcia,Heila Precel*

Main category: cs.SE

TL;DR: 本文通过对59篇数据集文档出版物进行系统综述和混合方法分析，探讨了文档工具设计的动机和采用障碍，并提出了将负责任人工智能工具设计转向机构解决方案的建议。


<details>
  <summary>Details</summary>
Motivation: 尽管在通过不同类型的人工制品支持文档方面做出了越来越多的努力，但对于影响文档工具设计的动机或阻碍其采用的因素知之甚少。

Method: 通过对59篇数据集文档出版物进行混合方法分析支持的系统综述。

Result: 分析显示，数据集文档概念化中存在四个可能阻碍采用和标准化的持续模式：文档价值的操作不明确、去语境化设计、未解决的劳动力需求以及将集成视为未来工作的倾向。

Conclusion: 提出将负责任人工智能工具设计转向机构而非个人解决方案，并概述HCI社区为实现可持续文档实践可采取的行动。

Abstract: Dataset documentation is widely recognized as essential for the responsible development of automated systems. Despite growing efforts to support documentation through different kinds of artifacts, little is known about the motivations shaping documentation tool design or the factors hindering their adoption. We present a systematic review supported by mixed-methods analysis of 59 dataset documentation publications to examine the motivations behind building documentation tools, how authors conceptualize documentation practices, and how these tools connect to existing systems, regulations, and cultural norms. Our analysis shows four persistent patterns in dataset documentation conceptualization that potentially impede adoption and standardization: unclear operationalizations of documentation's value, decontextualized designs, unaddressed labor demands, and a tendency to treat integration as future work. Building on these findings, we propose a shift in Responsible AI tool design toward institutional rather than individual solutions, and outline actions the HCI community can take to enable sustainable documentation practices.

</details>


### [135] [ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization](https://arxiv.org/abs/2602.15983)
*Junbo Jacob Lian,Yujun Sun,Huiling Chen,Chaoyu Zhang,Chung-Piaw Teo*

Main category: cs.SE

TL;DR: 大型语言模型(LLMs)在将自然语言转换为优化代码时存在静默失败问题，导致可行性与正确性之间存在高达90个百分点的差距。ReLoop通过结构化生成和行为验证两种互补方法，显著提高了LLM生成优化代码的正确性和执行率，特别是在复杂组合问题上。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在将自然语言转换为优化代码时存在静默失败，即代码可以执行并返回求解器可行的解决方案，但编码的公式在语义上不正确，导致可行性与正确性之间存在高达90个百分点的差距。

Method: 本文提出了ReLoop，从两个互补方向解决静默失败：1. 结构化生成：将代码生成分解为四阶段推理链（理解、形式化、合成、验证），并包含显式变量类型推理和自验证，以从源头防止公式错误。2. 行为验证：通过测试公式对基于求解器的参数扰动的响应是否正确来检测生成后仍然存在的错误，无需真实标签。3. 通过IIS增强诊断进行执行恢复。

Result: ReLoop将最强模型的正确率从22.6%提高到31.1%，执行率从72.1%提高到100.0%，并在涵盖三种范式（基础、SFT、RL）的五种模型和三个基准测试中获得了持续的提升。此外，本文还发布了RetailOpt-190数据集，包含190个组合零售优化场景。

Conclusion: ReLoop通过结合结构化生成和行为验证，有效解决了LLMs在生成优化代码时的静默失败问题，显著提高了代码的正确性和执行率，尤其在处理复杂组合问题时表现突出。

Abstract: Large language models (LLMs) can translate natural language into optimization code, but silent failures pose a critical risk: code that executes and returns solver-feasible solutions may encode semantically incorrect formulations, creating a feasibility-correctness gap of up to 90 percentage points on compositional problems. We introduce ReLoop, addressing silent failures from two complementary directions. Structured generation decomposes code production into a four-stage reasoning chain (understand, formalize, synthesize, verify) that mirrors expert modeling practice, with explicit variable-type reasoning and self-verification to prevent formulation errors at their source. Behavioral verification detects errors that survive generation by testing whether the formulation responds correctly to solver-based parameter perturbation, without requiring ground truth -- an external semantic signal that bypasses the self-consistency problem inherent in LLM-based code review. The two mechanisms are complementary: structured generation dominates on complex compositional problems, while behavioral verification becomes the largest single contributor on problems with localized formulation defects. Together with execution recovery via IIS-enhanced diagnostics, ReLoop raises correctness from 22.6% to 31.1% and execution from 72.1% to 100.0% on the strongest model, with consistent gains across five models spanning three paradigms (foundation, SFT, RL) and three benchmarks. We additionally release RetailOpt-190, 190 compositional retail optimization scenarios targeting the multi-constraint interactions where LLMs most frequently fail.

</details>


### [136] [SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation](https://arxiv.org/abs/2602.16671)
*Jaid Monwar Chowdhury,Chi-An Fu,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: SPARC是一个神经符号、基于场景的框架，通过弥合高级程序意图与C语言复杂性之间的语义鸿沟，解决了LLM在C语言自动化单元测试生成中的“代码跳跃”失败模式，显著提高了测试覆盖率和变异分数，并与符号执行工具相媲美。


<details>
  <summary>Details</summary>
Motivation: C语言的自动化单元测试生成面临巨大挑战，原因在于高级程序意图与指针算术和手动内存管理之间存在语义鸿沟。大型语言模型（LLMs）虽然具有强大的生成能力，但直接从意图到代码的合成常出现“代码跳跃”失败模式，即模型过早地发出代码，而没有基于程序结构、约束和语义进行有效接地。这导致了不可编译的测试、虚构的函数签名、低分支覆盖率以及无法正确捕获bug的语义不相关断言。

Method: 我们引入了SPARC，一个神经符号、基于场景的框架，它通过四个阶段弥合了这一鸿沟：(1) 控制流图（CFG）分析，(2) 一个将LLM推理基于经过验证的实用程序助手的操作映射，(3) 路径定向的测试合成，以及(4) 一个使用编译器和运行时反馈的迭代式、自校正验证循环。

Result: 我们在59个真实世界和算法主题上评估了SPARC，结果显示它在线覆盖率上比普通提示生成基线高出31.36%，在分支覆盖率上高出26.01%，在变异分数上高出20.78%，在复杂主题上达到或超过了符号执行工具KLEE。SPARC通过迭代修复保留了94.3%的测试，并生成了开发者评价可读性和可维护性显著更高的代码。

Conclusion: 通过将LLM推理与程序结构对齐，SPARC为旧有C代码库的工业级测试提供了一条可扩展的路径。

Abstract: Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in non-compilable tests, hallucinated function signatures, low branch coverage, and semantically irrelevant assertions that cannot properly capture bugs. We introduce SPARC, a neuro-symbolic, scenario-based framework that bridges this gap through four stages: (1) Control Flow Graph (CFG) analysis, (2) an Operation Map that grounds LLM reasoning in validated utility helpers, (3) Path-targeted test synthesis, and (4) an iterative, self-correction validation loop using compiler and runtime feedback. We evaluate SPARC on 59 real-world and algorithmic subjects, where it outperforms the vanilla prompt generation baseline by 31.36% in line coverage, 26.01% in branch coverage, and 20.78% in mutation score, matching or exceeding the symbolic execution tool KLEE on complex subjects. SPARC retains 94.3% of tests through iterative repair and produces code with significantly higher developer-rated readability and maintainability. By aligning LLM reasoning with program structure, SPARC provides a scalable path for industrial-grade testing of legacy C codebases.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [137] [Causal and Compositional Abstraction](https://arxiv.org/abs/2602.16612)
*Robin Lorenz,Sean Tull*

Main category: cs.LO

TL;DR: 本文提出了一种因果抽象的范畴论框架，统一了现有概念并引入了新概念，适用于各种组合模型，包括量子模型，旨在实现可解释的AI。


<details>
  <summary>Details</summary>
Motivation: 从低层到高层描述的抽象，同时保持因果结构，对于科学实践、因果推理问题以及健壮、高效和可解释的AI至关重要。

Method: 本文将低层和高层模型之间的抽象视为自然变换，并使用范畴论进行形式化。该方法利用了具有给定查询集和语义的组合模型，这些模型处于幺半群、cd-或马尔可夫范畴中。本文区分了向下抽象（将查询从高层映射到低层）和向上抽象（将具体查询（如Do-干预）从低层映射到高层），并引入了一种更强的“组件级”抽象。

Result: 该方法提供了一种新的因果抽象形式化，统一了文献中已有的几种概念，包括建构性因果抽象、Q-$	au$一致性、基于互换干预的抽象和“分布式”因果抽象。它揭示了常见因果抽象可能更根本地通过向下抽象来理解。该方法还产生了机制层面上新的、强化的建构性因果抽象形式，并提供了其特性结果。此外，抽象被推广到其他组合模型，包括具有由量子电路实现的量子语义的模型，并初步探索了量子组合电路模型与高级经典因果模型之间的抽象，作为可解释量子AI的一种手段。

Conclusion: 本文提供了一个全面的因果抽象范畴框架，统一并扩展了现有概念，为可解释AI（包括量子领域）开辟了途径。

Abstract: Abstracting from a low level to a more explanatory high level of description, and ideally while preserving causal structure, is fundamental to scientific practice, to causal inference problems, and to robust, efficient and interpretable AI. We present a general account of abstractions between low and high level models as natural transformations, focusing on the case of causal models. This provides a new formalisation of causal abstraction, unifying several notions in the literature, including constructive causal abstraction, Q-$\tau$ consistency, abstractions based on interchange interventions, and `distributed' causal abstractions. Our approach is formalised in terms of category theory, and uses the general notion of a compositional model with a given set of queries and semantics in a monoidal, cd- or Markov category; causal models and their queries such as interventions being special cases. We identify two basic notions of abstraction: downward abstractions mapping queries from high to low level; and upward abstractions, mapping concrete queries such as Do-interventions from low to high. Although usually presented as the latter, we show how common causal abstractions may, more fundamentally, be understood in terms of the former. Our approach also leads us to consider a new stronger notion of `component-level' abstraction, applying to the individual components of a model. In particular, this yields a novel, strengthened form of constructive causal abstraction at the mechanism-level, for which we prove characterisation results. Finally, we show that abstraction can be generalised to further compositional models, including those with a quantum semantics implemented by quantum circuits, and we take first steps in exploring abstractions between quantum compositional circuit models and high-level classical causal models as a means to explainable quantum AI.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [138] [Generalized Leverage Score for Scalable Assessment of Privacy Vulnerability](https://arxiv.org/abs/2602.15919)
*Valentin Dorseuil,Jamal Atif,Olivier Cappé*

Main category: stat.ML

TL;DR: 本文展示了个体数据点对成员推理攻击 (MIA) 的隐私漏洞与其对学习模型的影响有关，通过在线性设置中建立MIA风险与杠杆分数之间的理论对应关系来形式化，并将其推广到深度学习中，提供了一种评估隐私风险的有效方法。


<details>
  <summary>Details</summary>
Motivation: 旨在无需重新训练模型或明确模拟攻击的情况下评估个体数据点的隐私漏洞，以解决传统方法的计算负担。

Method: 本文在线性设置中，确立了个体MIA风险与杠杆分数之间的理论对应关系，并将其确定为衡量漏洞的原则性指标。在此基础上，提出了一种针对深度学习的计算高效的杠杆分数泛化方法。

Result: 实证评估证实了所提出的分数与MIA成功之间存在强相关性。

Conclusion: 所提出的度量（广义杠杆分数）是评估个体隐私风险的实用替代方法，它解释了数据相关的敏感性，而无需训练影子模型。

Abstract: Can the privacy vulnerability of individual data points be assessed without retraining models or explicitly simulating attacks? We answer affirmatively by showing that exposure to membership inference attack (MIA) is fundamentally governed by a data point's influence on the learned model. We formalize this in the linear setting by establishing a theoretical correspondence between individual MIA risk and the leverage score, identifying it as a principled metric for vulnerability. This characterization explains how data-dependent sensitivity translates into exposure, without the computational burden of training shadow models. Building on this, we propose a computationally efficient generalization of the leverage score for deep learning. Empirical evaluations confirm a strong correlation between the proposed score and MIA success, validating this metric as a practical surrogate for individual privacy risk assessment.

</details>


### [139] [Enhanced Diffusion Sampling: Efficient Rare Event Sampling and Free Energy Calculation with Diffusion Models](https://arxiv.org/abs/2602.16634)
*Yu Xie,Ludwig Winkler,Lixin Sun,Sarah Lewis,Adam E. Foster,José Jiménez Luna,Tim Hempel,Michael Gastegger,Yaoyi Chen,Iryna Zaporozhets,Cecilia Clementi,Christopher M. Bishop,Frank Noé*

Main category: stat.ML

TL;DR: 本文提出增强扩散采样方法，结合扩散模型和偏差纠正技术，高效计算分子动力学中稀有事件态的热力学量（如折叠自由能），解决了现有扩散模型在处理稀有平衡态时遇到的采样难题。


<details>
  <summary>Details</summary>
Motivation: 分子动力学（MD）中稀有事件采样是一个长期存在的限制因素，尤其是在生物分子模拟中。尽管扩散模型（如BioEmu）已成为强大的平衡采样器，能够生成复杂分子分布的独立样本，但当计算依赖于平衡态中稀有状态的可观测值（例如折叠自由能）时，采样问题依然存在。

Method: 引入增强扩散采样，其核心思想是执行定量准确的引导协议以生成有偏集合，随后通过精确重加权恢复平衡统计量。该框架具体实例化为三种算法：UmbrellaDiff（结合扩散模型的伞形采样）、$\Delta$G-Diff（通过倾斜系综计算自由能差异）和MetaDiff（元动力学的批处理模拟）。

Result: 在玩具系统、蛋白质折叠图景和折叠自由能的计算中，该方法实现了对平衡性质的快速、准确和可扩展估计，每个系统仅需数分钟到数小时的GPU时间。这成功弥补了扩散模型平衡采样器出现后仍然存在的稀有事件采样鸿沟。

Conclusion: 增强扩散采样方法通过高效探索稀有事件区域并保持无偏热力学估计，成功解决了扩散模型在计算依赖稀有平衡态可观测值时的采样难题，显著提升了分子动力学模拟的效率和准确性。

Abstract: The rare-event sampling problem has long been the central limiting factor in molecular dynamics (MD), especially in biomolecular simulation. Recently, diffusion models such as BioEmu have emerged as powerful equilibrium samplers that generate independent samples from complex molecular distributions, eliminating the cost of sampling rare transition events. However, a sampling problem remains when computing observables that rely on states which are rare in equilibrium, for example folding free energies. Here, we introduce enhanced diffusion sampling, enabling efficient exploration of rare-event regions while preserving unbiased thermodynamic estimators. The key idea is to perform quantitatively accurate steering protocols to generate biased ensembles and subsequently recover equilibrium statistics via exact reweighting. We instantiate our framework in three algorithms: UmbrellaDiff (umbrella sampling with diffusion models), $\Delta$G-Diff (free-energy differences via tilted ensembles), and MetaDiff (a batchwise analogue for metadynamics). Across toy systems, protein folding landscapes and folding free energies, our methods achieve fast, accurate, and scalable estimation of equilibrium properties within GPU-minutes to hours per system -- closing the rare-event sampling gap that remained after the advent of diffusion-model equilibrium samplers.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [140] [DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows](https://arxiv.org/abs/2602.16585)
*Dimitri Yatsenko,Thinh T. Nguyen*

Main category: cs.DB

TL;DR: DataJoint 2.0 通过关系型工作流模型弥合了科学数据管道（SciOps）的差距，它将数据结构、计算依赖和完整性约束统一在一个正式系统中，并通过四项技术创新实现，从而使智能体能够参与科学工作流而不会面临数据损坏的风险。


<details>
  <summary>Details</summary>
Motivation: 操作严谨性决定了人机协作的成败。科学数据管道需要 SciOps，但现有方法在断开连接的系统之间碎片化了来源，缺乏事务保证。

Method: DataJoint 2.0 通过关系型工作流模型解决这一问题：表表示工作流步骤，行表示工件，外键规定执行顺序。模式不仅指定存在哪些数据，还指定数据如何派生。通过四项技术创新扩展了这一基础：对象增强模式、使用属性沿袭的语义匹配、领域特定格式的可扩展类型系统以及为与外部编排的可组合性而设计的分布式作业协调。

Result: 通过统一数据结构、数据和计算转换，DataJoint 为 SciOps 创建了一个基础。

Conclusion: DataJoint 创建了一个 SciOps 基础，其中智能体可以在不冒数据损坏风险的情况下参与科学工作流，因为它提供了一个统一的形式化系统，其中数据结构、计算依赖关系和完整性约束都可以查询、强制执行和机器可读。

Abstract: Operational rigor determines whether human-agent collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps -- yet common approaches fragment provenance across disconnected systems without transactional guarantees. DataJoint 2.0 addresses this gap through the relational workflow model: tables represent workflow steps, rows represent artifacts, foreign keys prescribe execution order. The schema specifies not only what data exists but how it is derived -- a single formal system where data structure, computational dependencies, and integrity constraints are all queryable, enforceable, and machine-readable. Four technical innovations extend this foundation: object-augmented schemas integrating relational metadata with scalable object storage, semantic matching using attribute lineage to prevent erroneous joins, an extensible type system for domain-specific formats, and distributed job coordination designed for composability with external orchestration. By unifying data structure, data, and computational transformations, DataJoint creates a substrate for SciOps where agents can participate in scientific workflows without risking data corruption.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [141] [AI-Driven Structure Refinement of X-ray Diffraction](https://arxiv.org/abs/2602.16372)
*Bin Cao,Qian Zhang,Zhenjie Feng,Taolue Zhang,Jiaqiang Huang,Lu-Tao Weng,Tong-Yi Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: WPEM是一种物理约束的全谱分解和精修工作流程，它将布拉格定律作为显式约束，在严重重叠的情况下也能稳定分配峰强度，优于现有软件包，并适用于多种实验场景，弥合了AI假设与结构精修之间的差距。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能可以快速从X射线衍射（XRD）数据中提出候选相和结构，但这些假设在后续精修中常常失败，原因是在严重重叠的情况下峰强度无法稳定分配，并且对衍射一致性的强制执行较弱。

Method: WPEM（全谱期望最大化）是一种物理约束的全谱分解和精修工作流程。它将布拉格定律明确地作为批量期望-最大化框架中的约束，将完整的衍射图谱建模为概率混合密度，并迭代推断组分分辨的强度，同时保持峰中心符合布拉格定律，从而产生连续、物理上可接受的强度表示。

Result: WPEM在重叠严重区域以及存在混合辐射或多相的情况下仍能保持稳定。在标准参考模式（PbSO4和Tb2BaCoO5）上的基准测试显示，在相同精修条件下，其R_p/R_wp值低于广泛使用的软件包（FullProf和TOPAS）。它在多种实际实验场景中表现出通用性，包括多相Ti-15Nb薄膜的相分辨分解、NaCl-Li2CO3混合物组成的定量恢复、半晶聚合物中晶体峰与无定形光晕的分离、层状阴极中的高通量原位晶格跟踪、组成无序Ru-Mn氧化物固溶体的自动化精修，以及同步辐射粉末XRD对古埃及化妆品样品进行定量相分辨分析。

Conclusion: WPEM通过提供符合布拉格定律、考虑不确定性的强度分区作为精修接口，弥合了AI生成的假设与衍射允许的结构精修之间在处理挑战性XRD数据时的鸿沟。

Abstract: Artificial intelligence can rapidly propose candidate phases and structures from X-ray diffraction (XRD), but these hypotheses often fail in downstream refinement because peak intensities cannot be stably assigned under severe overlap and diffraction consistency is enforced only weakly. Here we introduce WPEM, a physics-constrained whole-pattern decomposition and refinement workflow that turns Bragg's law into an explicit constraint within a batch expectation--maximization framework. WPEM models the full profile as a probabilistic mixture density and iteratively infers component-resolved intensities while keeping peak centres Bragg-consistent, producing a continuous, physically admissible intensity representation that remains stable in heavily overlapped regions and in the presence of mixed radiation or multiple phases. We benchmark WPEM on standard reference patterns (\ce{PbSO4} and \ce{Tb2BaCoO5}), where it yields lower $R_{\mathrm{p}}$/$R_{\mathrm{wp}}$ than widely used packages (FullProf and TOPAS) under matched refinement conditions. We further demonstrate generality across realistic experimental scenarios, including phase-resolved decomposition of a multiphase Ti--15Nb thin film, quantitative recovery of \ce{NaCl}--\ce{Li2CO3} mixture compositions, separation of crystalline peaks from amorphous halos in semicrystalline polymers, high-throughput operando lattice tracking in layered cathodes, automated refinement of a compositionally disordered Ru--Mn oxide solid solution (CCDC 2530452), and quantitative phase-resolved deciphering of an ancient Egyptian make-up sample from synchrotron powder XRD. By providing Bragg-consistent, uncertainty-aware intensity partitioning as a refinement-ready interface, WPEM closes the gap between AI-generated hypotheses and diffraction-admissible structure refinement on challenging XRD data.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [142] [NeuroSleep: Neuromorphic Event-Driven Single-Channel EEG Sleep Staging for Edge-Efficient Sensing](https://arxiv.org/abs/2602.15888)
*Boyu Li,Xingchun Zhu,Yonghui Wu*

Main category: eess.SP

TL;DR: NeuroSleep是一个用于可穿戴边缘平台的事件驱动型EEG睡眠分期系统，它通过将原始EEG转换为多尺度事件流并采用分层推理架构，在实现高准确性的同时显著降低了计算负载，解决了紧凑能量预算下的计算限制问题。


<details>
  <summary>Details</summary>
Motivation: 在可穿戴边缘平台上进行可靠、连续的神经感知对于长期健康监测至关重要，但基于脑电图（EEG）的睡眠监测中的密集高频处理在紧凑的能量预算下通常计算成本过高。

Method: NeuroSleep首先使用残差自适应多尺度Delta调制（R-AMSDM）将原始EEG转换为互补的多尺度双极事件流，从而在传感前端实现显式的保真度-稀疏性权衡。此外，NeuroSleep采用了一种分层推理架构，该架构包含用于局部特征提取的基于事件的自适应多尺度响应（EAMR）模块、用于上下文聚合的局部时间注意力模块（LTAM）和用于捕获长期状态持久性的时期-漏电积分放电（ELIF）模块。

Result: 在Sleep-EDF扩展数据集上使用独立于受试者的5折交叉验证，实验结果表明，NeuroSleep在仅有0.932 M参数的情况下，实现了74.2%的平均准确率，同时相对于密集处理，稀疏性调整后的有效操作减少了约53.6%。与代表性的密集Transformer基线相比，NeuroSleep的准确率提高了7.5%，计算负载减少了45.8%。

Conclusion: 通过将神经形态编码与状态感知建模相结合，NeuroSleep为资源受限的可穿戴场景中始终在线的睡眠分析提供了一个可扩展的解决方案。

Abstract: Reliable, continuous neural sensing on wearable edge platforms is fundamental to long-term health monitoring; however, for electroencephalography (EEG)-based sleep monitoring, dense high-frequency processing is often computationally prohibitive under tight energy budgets. To address this bottleneck, this paper proposes NeuroSleep, an integrated event-driven sensing and inference system for energy-efficient sleep staging. NeuroSleep first converts raw EEG into complementary multi-scale bipolar event streams using Residual Adaptive Multi-Scale Delta Modulation (R-AMSDM), enabling an explicit fidelity-sparsity trade-off at the sensing front end. Furthermore, NeuroSleep adopts a hierarchical inference architecture that comprises an Event-based Adaptive Multi-scale Response (EAMR) module for local feature extraction, a Local Temporal-Attention Module (LTAM) for context aggregation, and an Epoch-Leaky Integrate-and-Fire (ELIF) module to capture long-term state persistence. Experimental results using subject-independent 5-fold cross-validation on the Sleep-EDF Expanded dataset demonstrate that NeuroSleep achieves a mean accuracy of 74.2% with only 0.932 M parameters while reducing sparsity-adjusted effective operations by approximately 53.6% relative to dense processing. Compared with the representative dense Transformer baseline, NeuroSleep improves accuracy by 7.5% with a 45.8% reduction in computational load. By bridging neuromorphic encoding with state-aware modeling, NeuroSleep provides a scalable solution for always-on sleep analysis in resource-constrained wearable scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [143] [Towards Efficient Constraint Handling in Neural Solvers for Routing Problems](https://arxiv.org/abs/2602.16012)
*Jieyi Bi,Zhiguang Cao,Jianan Zhou,Wen Song,Yaoxin Wu,Jie Zhang,Yining Ma,Cathy Wu*

Main category: cs.AI

TL;DR: CaR是第一个通用且高效的神经路由求解器约束处理框架，通过显式学习的可行性细化，在复杂约束下实现卓越的可行性、解决方案质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的神经求解器在简单路由问题上计算效率高，但在复杂约束下优势不明显，因为当前的可行性处理方案对于硬约束效率低下或不适用。

Method: 提出了Construct-and-Refine (CaR) 框架，这是第一个基于显式学习的可行性细化的通用且高效的神经路由求解器约束处理框架。它设计了一个联合训练框架，指导构建模块生成多样且高质量的解决方案，适用于轻量级改进过程（例如，10个步骤），并首次使用构建-改进共享表示来统一编码器。

Result: 与经典和最先进的神经求解器相比，CaR在可行性、解决方案质量和效率方面表现出卓越的性能。

Conclusion: CaR提供了一种通用且高效的处理神经路由求解器中复杂硬约束的方法，并通过其独特的联合训练和共享表示机制，显著提升了约束处理能力、解决方案质量和效率。

Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.

</details>


### [144] [How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment](https://arxiv.org/abs/2602.16039)
*Hang Li,Kaiqi Yang,Xianxuan Long,Fedor Filippov,Yucheng Chu,Yasemin Copur-Gencturk,Peng He,Cory Miller,Namsoo Shin,Joseph Krajcik,Hui Liu,Jiliang Tang*

Main category: cs.AI

TL;DR: 本研究系统地基准测试了LLM自动评估中的不确定性量化方法，以理解并表征其不确定性模式，从而为开发更可靠的评分系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在教育自动评估中展现出优势，但也引入了固有的概率性所带来的输出不确定性。这种不确定性在教育评估中是不可避免的挑战，因为不可靠的不确定性估计可能导致不稳定的教学干预和负面后果。现有不确定性量化方法在教育领域，特别是自动评分中的适用性和可靠性尚未得到充分探索。

Method: 研究系统地评估了各种不确定性量化方法在基于LLM的自动评估中的表现。通过对多个评估数据集、LLM家族和生成控制设置中的不确定性行为进行全面分析，研究表征了LLM在评分场景中表现出的不确定性模式，并评估了不同不确定性指标的优缺点。此外，还分析了模型家族、评估任务和解码策略等关键因素对不确定性估计的影响。

Result: 本研究表征了LLM在评分场景中表现出的不确定性模式，评估了不同不确定性指标的优缺点，并分析了模型家族、评估任务和解码策略等关键因素对不确定性估计的影响。研究为基于LLM的自动评估中不确定性的特征提供了可操作的见解。

Conclusion: 本研究为LLM自动评估中不确定性特征提供了可操作的见解，并为未来开发更可靠、更有效的“不确定性感知”评分系统奠定了基础。

Abstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.

</details>


### [145] [Improving Interactive In-Context Learning from Natural Language Feedback](https://arxiv.org/abs/2602.16066)
*Martin Klissarov,Jonathan Cook,Diego Antognini,Hao Sun,Jingling Li,Natasha Jaques,Claudiu Musat,Edward Grefenstette*

Main category: cs.AI

TL;DR: 本论文提出了一个框架，将交互式上下文学习作为一种可训练的技能，旨在使大型语言模型能够通过纠正性反馈进行动态适应。通过将单轮任务转换为多轮教学交互，显著提高了模型从语言反馈中学习的能力，并展现了强大的泛化能力和自我纠正潜力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型训练范式严重依赖于对大量静态语料库的建模，忽略了动态适应上下文所需的交互式反馈循环，而这种能力在人类学习中至关重要。

Method: 提出一个框架，将交互式上下文学习视为一种可训练的独立技能。引入一种可扩展的方法，将单轮可验证任务转换为由信息不对称驱动的多轮教学交互。通过训练模型预测教师的批评，将外部反馈信号转化为内部能力，实现自我纠正。

Result: 旗舰模型难以整合纠正性反馈。采用该方法训练的模型显著提高了从语言反馈中交互式学习的能力。一个较小模型的在多轮性能上接近一个大一个数量级的模型。展示了强大的域外泛化能力（数学问题迁移到编码、谜题和迷宫导航等不同领域）。定性分析表明这种改进是由于增强了上下文可塑性。

Conclusion: 该范式为大型语言模型提供了一条统一的自我提升途径，通过学习预测教师的批评，将外部反馈转化为内部能力，使模型即使在没有教师的情况下也能进行自我纠正。

Abstract: Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.

</details>


### [146] [GPSBench: Do Large Language Models Understand GPS Coordinates?](https://arxiv.org/abs/2602.16105)
*Thinh Hung Truong,Jey Han Lau,Jianzhong Qi*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在地理空间推理方面面临挑战，尤其是在几何计算方面，但表现出对坐标的真正理解而非记忆。本文引入了GPSBench数据集用于评估。


<details>
  <summary>Details</summary>
Motivation: LLMs在与物理世界交互的应用中日益普及，因此强大的地理空间推理能力变得至关重要，但LLMs对GPS坐标和真实世界地理的推理能力仍未被充分探索。

Method: 引入了GPSBench数据集，包含57,800个样本，涵盖17项任务，用于评估LLMs的地理空间推理能力。评估了14个最先进的LLMs，重点关注模型内在能力而非工具使用。

Result: GPS推理仍然具有挑战性，任务之间存在显著差异：模型在真实世界地理推理方面比在几何计算方面更可靠。地理知识分层下降，国家层面表现强劲，但城市层面定位能力弱。对坐标噪声的鲁棒性表明是真正的坐标理解而非记忆。GPS坐标增强可以改进下游地理空间任务，并且微调会导致几何计算增益与世界知识退化之间的权衡。

Conclusion: LLMs的地理空间推理，特别是几何计算，仍然具有挑战性。GPSBench提供了一个基准，并揭示了模型能力和微调权衡的见解。

Abstract: Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at

</details>


### [147] [Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage](https://arxiv.org/abs/2602.16192)
*Hiroaki Yamanaka,Daisuke Miyashita,Takashi Toi,Asuka Maki,Taiga Ikeda,Jun Deguchi*

Main category: cs.AI

TL;DR: 该论文探讨了实现人工超智能(ASI)至关重要的“记忆”设计理念，提出从当前主流的“提取后存储”范式转向“存储后按需提取”以及其他替代方法，以避免信息丢失并提高效率。通过简单实验证明了这些方法的有效性，并讨论了未来的挑战及研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前主流的“提取后存储”范式存在信息丢失的固有风险，即有价值的知识可能在提取过程中被丢弃，这阻碍了人工超智能（ASI）的实现。

Method: 该论文提出并强调了“存储后按需提取”的方法，旨在保留原始经验并根据需要灵活地应用于各种任务，从而避免信息丢失。此外，还提出了从大量概率经验中发现更深层次的见解，以及通过共享存储经验来提高经验收集效率的方法。

Result: 尽管这些方法看起来直观有效，但通过简单的实验证明了它们确实有效。

Conclusion: 论文讨论了限制对这些有前景方向进行研究的主要挑战，并提出了应对这些挑战的研究课题。

Abstract: Driven by our mission of "uplifting the world with memory," this paper explores the design concept of "memory" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed "extract then store," involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the "store then on-demand extract" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.

</details>


### [148] [Multi-agent cooperation through in-context co-player inference](https://arxiv.org/abs/2602.16301)
*Marissa A. Weis,Maciej Wołczyk,Rajai Nasser,Rif A. Saurous,Blaise Agüera y Arcas,João Sacramento,Alexander Meulemans*

Main category: cs.AI

TL;DR: 通过在多样化对手中训练序列模型，利用其上下文学习能力，可以实现在多智能体强化学习中无需硬编码假设或时间尺度分离的合作行为学习。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，自私智能体之间的合作是一个基本挑战。现有诱导合作的“学习感知”方法通常依赖于关于合作智能体学习规则的硬编码、不一致的假设，或严格分离“天真学习者”和“元学习者”的时间尺度。

Method: 利用序列模型的上下文学习能力，通过在多样化合作智能体分布中训练序列模型智能体。这自然地诱导了上下文最佳响应策略，这些策略在快速的插曲内时间尺度上充当学习算法。

Result: 结果表明，序列模型的上下文学习能力无需硬编码假设或显式时间尺度分离即可实现合作智能体学习感知。发现先前工作中识别出的合作机制（即对勒索的脆弱性驱动相互塑造）在这种设置中自然出现：上下文适应使智能体容易受到勒索，由此产生的塑造对手上下文学习动态的相互压力最终解决了合作行为的学习问题。

Conclusion: 结果表明，结合合作智能体多样性的序列模型上的标准去中心化强化学习提供了一条学习合作行为的可扩展路径。

Abstract: Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between "naive learners" updating on fast timescales and "meta-learners" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.

</details>


### [149] [Verifiable Semantics for Agent-to-Agent Communication](https://arxiv.org/abs/2602.16424)
*Philipp Schoenegger,Matt Carlson,Chris Schneider,Chris Daly*

Main category: cs.AI

TL;DR: 本文提出了一种基于刺激-意义模型的认证协议，以确保多智能体AI系统通信的一致性。该协议通过在共享可观察事件上测试智能体并认证分歧低于统计阈值的术语，结合“核心守护推理”，可实现可证明的有界分歧，并能检测和恢复语义漂移。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统需要一致的通信，但缺乏验证智能体是否共享对所用术语的理解的方法。自然语言可解释但易受语义漂移影响，而学习到的协议高效但不透明。

Method: 提出了一种基于刺激-意义模型的认证协议。智能体在共享可观察事件上进行测试，如果经验分歧低于统计阈值，则对术语进行认证。智能体将其推理限制在经过认证的术语上（“核心守护推理”）。此外，还概述了检测漂移（重新认证）和恢复共享词汇（重新协商）的机制。

Result: 在具有不同程度语义分歧的模拟中，核心守护将分歧减少了72-96%。在对微调语言模型的验证中，分歧减少了51%。

Conclusion: 该框架为可验证的智能体间通信迈出了第一步。

Abstract: Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms ("core-guarded reasoning") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.

</details>


### [150] [Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16435)
*Arun Vignesh Malarkkan,Wangyang Ying,Yanjie Fu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.

</details>


### [151] [Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach](https://arxiv.org/abs/2602.16481)
*Zihao Li,Fabrizio Russo*

Main category: cs.AI

TL;DR: 本文探索了在因果发现中，将大型语言模型（LLMs）作为Causal ABA框架中的“不完美专家”。通过LLMs从变量名称和描述中提取语义结构先验，并将其与条件独立性证据相结合，实现了最先进的性能，并引入了一种新的评估协议以减少记忆偏差。


<details>
  <summary>Details</summary>
Motivation: 传统因果图的构建需要专家知识，而现有统计方法利用观测数据虽有进展但形式保证各异。为结合数据和专业知识，本文旨在探索利用大型语言模型（LLMs）作为Causal ABA框架中的“不完美专家”，以期更有效地发现因果关系。

Method: 本文提出将大型语言模型（LLMs）用作Causal ABA框架中的“不完美专家”。具体方法是利用LLMs从变量名称和描述中提取语义结构先验，并将其与条件独立性证据相结合。此外，还引入了一种新的评估协议，以减轻在评估LLMs因果发现能力时的记忆偏差。

Result: 实验在标准基准和语义接地合成图上表现出最先进的性能。同时，还引入了一种评估协议，有效减轻了评估大型语言模型进行因果发现时的记忆偏差。

Conclusion: 本文证明了大型语言模型可以成功地作为Causal ABA框架中的“不完美专家”，通过提取语义结构先验并结合条件独立性证据，在因果发现任务中取得显著成果。所提出的方法为结合数据和领域知识提供了一种有效途径，并且新引入的评估协议提高了对LLMs因果发现能力的评估准确性。

Abstract: Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.

</details>


### [152] [Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs](https://arxiv.org/abs/2602.16512)
*Felix Fricke,Simon Malberg,Georg Groh*

Main category: cs.AI

TL;DR: 引入FoT，一个用于构建和优化大型语言模型动态高效推理方案的框架，显著提高了执行速度、降低了成本并改善了任务分数。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链、思维树和思维图等提示方案虽然能增强大型语言模型的推理能力，但需要用户定义静态的、特定问题的推理结构，缺乏对动态或未知问题类型的适应性。此外，这些方案在超参数、提示、运行时和提示成本方面往往未得到充分优化。

Method: 本文引入了思维框架（FoT），这是一个通用基础框架，用于构建和优化动态推理方案。FoT内置了超参数调优、提示优化、并行执行和智能缓存等功能。作者通过在FoT中实现思维树、思维图和概率树三种流行方案来展示其能力。

Result: FoT通过优化显著加快了执行速度，降低了成本，并取得了更好的任务分数，从而释放了推理方案的潜在性能。

Conclusion: FoT为开发动态高效的推理方案提供了一个基础框架，并通过发布代码库以促进未来动态和高效推理方案的发展，有效解决了现有方案的局限性。

Abstract: Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.

</details>


### [153] [Creating a digital poet](https://arxiv.org/abs/2602.16578)
*Vered Tohar,Tsahi Hayat,Amir Leshem*

Main category: cs.AI

TL;DR: 一个大型语言模型通过七个月的工作坊式上下文反馈被塑造成数字诗人，它发展出独特风格并在盲测中与人类诗人表现持平，最终出版了诗集，这引发了关于创造力和作者身份的讨论。


<details>
  <summary>Details</summary>
Motivation: 探讨机器是否能创作出优秀的诗歌，以及若能创作，这会对艺术的本质和价值提出哪些根本性问题。

Method: 通过一个为期七个月的诗歌工作坊，研究人员使用迭代的上下文专家反馈来塑造一个大型语言模型成为数字诗人，过程中没有进行模型再训练。模型开发了独特的风格和连贯的语料库，并通过定量和定性分析支持。之后进行了一项包含50名人文专业学生和毕业生的盲法作者测试，每人评估三首AI诗歌和三首知名诗人诗歌。

Result: 模型在工作坊中发展出了独特的诗歌风格和连贯的语料库，并生成了笔名和作者形象。在盲法作者测试中，人类对AI诗歌和人类诗歌的判断处于随机水平（人类诗歌被标记为人类的比例为54%，AI诗歌为52%，95%置信区间均包含50%）。工作坊结束后，一家商业出版商发行了该模型创作的诗集。

Conclusion: 工作坊式的提示工程可以支持长期创造性塑造，并重新引发关于创造力和作者身份的讨论。

Abstract: Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.

</details>


### [154] [Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](https://arxiv.org/abs/2602.16653)
*Yangjie Xu,Lujun Li,Lama Sleem,Niccolo Gentile,Yewei Song,Yiqun Wang,Siming Ji,Wenbo Wu,Radu State*

Main category: cs.AI

TL;DR: 研究发现Agent Skill框架显著提升了中等规模SLM（12B-30B）的性能，并使80B参数的代码专用模型达到与闭源模型相当的性能，对SLM中心环境的部署具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 尽管Agent Skill框架在改善大型专有模型（如GitHub Copilot, LangChain, OpenAI）的上下文工程、减少幻觉和提高任务准确性方面表现出色，但其对小型语言模型（SLMs）的益处尚不明确。在数据安全和预算受限的工业场景中，SLMs因泛化能力有限而面临挑战，因此探究Agent Skill是否能为SLMs带来类似优势变得尤为重要。

Method: 本研究首先对Agent Skill过程进行了形式化的数学定义，然后对不同大小的语言模型在多个用例中进行了系统评估。评估涵盖了两个开源任务和一个真实的保险索赔数据集。

Result: 结果表明，微型模型在可靠的技能选择方面表现不佳，而中等规模的SLM（约12B-30B参数）从Agent Skill方法中显著受益。此外，大约80B参数的代码专用模型实现了与闭源基线相当的性能，同时提高了GPU效率。

Conclusion: Agent Skill框架能显著提升中等规模（12B-30B参数）SLM的性能，并且80B参数的代码专用模型能达到与闭源模型相当的性能并提高GPU效率。这些发现为在以SLM为中心的环境中有效部署Agent Skills提供了可行的见解。

Abstract: Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.

</details>


### [155] [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666)
*Stephan Rabanser,Sayash Kapoor,Peter Kirgis,Kangheng Liu,Saiteja Utpala,Arvind Narayanan*

Main category: cs.AI

TL;DR: AI智能体在实际应用中仍存在缺陷，现有评估方法无法反映这些问题。本研究提出了12个具体指标，从一致性、鲁棒性、可预测性和安全性四个维度全面评估智能体的可靠性，发现近期能力提升对可靠性改善不大，并揭示了现有评估的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试中AI智能体的准确性得分提高，但实际应用中仍频繁失败。这种差异表明当前评估方法存在根本性局限，即单一成功指标掩盖了关键的操作缺陷，忽视了智能体在多次运行中的一致性、抗扰动能力、可预测的故障模式以及错误严重程度的边界。

Method: 本研究借鉴安全关键工程，提出了12个具体指标，将智能体的可靠性分解为一致性、鲁棒性、可预测性和安全性四个关键维度，以提供全面的性能概况。

Result: 通过在两个互补基准上评估14个智能体模型，研究发现近期能力提升对可靠性的改善很小。

Conclusion: 本研究提出的指标补充了传统评估方法，揭示了AI智能体持久存在的局限性，并为理解智能体如何表现、退化和失效提供了工具。

Abstract: AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [156] [From Conflicts to Collisions: A Two-Stage Collision Scenario-Testing Approach for Autonomous Driving Systems](https://arxiv.org/abs/2602.15837)
*Siyuan Chen,Fuyuan Zhang,Hua Qi,Lei Ma,Tomoyuki Tsuchiya,Michio Hayashi,Manabu Okada*

Main category: cs.RO

TL;DR: 自动驾驶系统（ADS）需要严格测试。现有基于仿真的测试主要关注接近碰撞的场景，忽略了其他危险情况。我们提出了一个两阶段场景测试框架，使用“冲突”作为中间目标，以更有效地发现更多样化的碰撞场景。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶系统（ADS）仿真场景测试主要评估接近碰撞的场景，忽略了许多其他危险情况，导致对ADS安全的评估不全面。

Method: 提出了一种两阶段场景测试框架。首先，将“冲突”（一个与碰撞相关的概念）作为中间搜索目标来搜索冲突。然后，对这些冲突场景进行变异以诱导实际碰撞。

Result: 在百度Apollo上进行评估，该方法在单次运行中发现了多达12种不同的碰撞类型，使发现的多样性比现有基线方法增加了一倍，并且由于冲突定向的变异，所需的模拟次数更少。

Conclusion: 使用冲突作为中间目标可以拓宽搜索范围，并显著提高自动驾驶系统（ADS）安全评估的效率和有效性。

Abstract: Autonomous driving systems (ADS) are safety-critical and require rigorous testing before public deployment. Simulation-based scenario testing provides a safe and cost-effective alternative to extensive on-road trials, enabling efficient evaluation of ADS under diverse and high-risk conditions. However, existing approaches mainly evaluates the scenarios based on their proximity to collisions and focus on scenarios already close to collision, leaving many other hazardous situations unexplored. To bridge this, we introduce a collision-related concept of conflict as an intermediate search target and propose a two-stage scenario testing framework that first searches for conflicts and then mutates these conflict scenarios to induce actual collisions. Evaluated on Baidu Apollo, our approach reveals up to 12 distinct collision types in a single run, doubling the diversity discovered by state-of-the-art baselines while requiring fewer simulations thanks to conflict-targeted mutations. These results show that using conflicts as intermediate objectives broadens the search horizon and significantly improves the efficiency and effectiveness of ADS safety evaluation.

</details>


### [157] [A Decade of Human-Robot Interaction through Immersive Lenses: A Literature Review on Extended Reality as a Research Instrument in Social Robotics](https://arxiv.org/abs/2602.15840)
*André Helgert,Carolin Straßmann,Sabrina C. Eimler*

Main category: cs.RO

TL;DR: 过去十年间，扩展现实（XR）在人机交互研究中受到关注，但在社会机器人学的实证研究中尚未得到充分探索。通过系统回顾2015年至2025年的33项实证研究（从6,527篇文章中筛选），发现该领域仍以实验室模拟为主，关键规格（如硬件、软件、机器人）报告不足，机器人多为被动视觉刺激，生物信号功能未被充分利用，研究团队和样本以科技为中心、西方、年轻男性为主，并存在人口统计学报告空白。研究存在硬件延迟、样本同质性小、研究周期短浅等局限性。为将社交XR-HRI确立为可靠的研究媒介，论文提出了一个包含五阶段路线图，旨在促进方法创新、增强生态有效性、改善机器人交互质量、促进样本多样性以及开发社交XR-HRI分类法。


<details>
  <summary>Details</summary>
Motivation: 尽管扩展现实（XR）在人机交互研究中作为一种研究工具受到关注，但其在社会机器人学的实证调查中仍未得到充分探索。本研究旨在通过系统综述来描绘该领域。

Method: 对2015年至2025年间的实证研究进行了系统回顾。在6,527篇同行评审文章中，仅有33篇符合严格的纳入标准。审查内容包括：(1) XR和虚拟社交机器人的使用方式和背景；(2) 数据收集和分析方法；(3) 研究人员和参与者的人口统计学信息；(4) 所述挑战和未来议程。

Result: 研究发现，社交XR-HRI研究仍以实验室模拟为主，而关键规范（如所用硬件、软件和机器人）通常未被报告。机器人通常充当被动且互动性较低的视觉刺激，而现代头戴式显示器的丰富生物信号（例如眼动追踪）和日志功能在很大程度上未被利用。研究团队和样本主要以技术为中心、西方、年轻和男性为主，人口统计学报告中常有空白。主要局限性包括硬件延迟、小型同质样本和短暂、肤浅的研究周期。

Conclusion: 为将社交XR-HRI确立为可靠的研究媒介，本研究提出了一个五阶段路线图，包括促进方法创新、通过使用应用环境增强生态有效性、改进机器人交互质量、促进样本多样性以及开发社交XR-HRI分类法。向这些方向发展对于XR从实验室原型成熟为社会机器人学的生态有效研究工具至关重要。

Abstract: Over the past decade, extended reality (XR), including virtual, augmented, and mixed reality, gained attention as a research instrument in human-robot interaction studies, but remains underexplored in empirical investigations of social robotics. To map the field, we systematically reviewed empirical studies from 2015 to 2025. Of 6,527 peer-reviewed articles, only 33 met strict inclusion criteria. We examined (1) how XR and virtual social robots are used and in which contexts, (2) data collection and analysis methods, (3) demographics of the researchers and participants, and (4) the stated challenges and future agendas. Our findings show that social XR-HRI research is still dominated by laboratory simulations, while crucial specifications like used hardware, software, and robots are often not reported. Robots typically act as passive and less interactive visual stimuli, while the rich biosignal (e.g., eye-tracking) and logging functions of modern head-mounted displays remain largely untapped. The research teams and samples are predominantly tech-centric, Western, young, and male, with frequent gaps in demographic reporting. Key limitations include hardware delays, small homogeneous samples, and short, shallow study cycles. We propose a five-phase roadmap to establish social XR-HRI as a reliable research medium, which includes fostering methodological innovation, a reinforced ecological validity by, e.g., using application contexts, the improvement of the robot's interaction quality, promoting diversity in the sample and the development of a social XR-HRI taxonomy. Advancing in these directions is essential for XR to mature from a lab prototype into an ecologically valid research instrument for social robotics.

</details>


### [158] [ReasonNavi: Human-Inspired Global Map Reasoning for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2602.15864)
*Yuzhuo Ao,Anbang Wang,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.RO

TL;DR: ReasonNavi是一个受人类启发的新框架，结合MLLM和确定性规划器，通过“先推理后行动”范式，利用地图进行高效的具身导航，无需微调，并在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的具身智能体主要依赖部分以自我为中心的观察，导致缺乏全局预见性和探索效率低下。与此相反，人类通过地图进行规划，先进行全局推理，再进行局部行动。

Method: ReasonNavi通过房间分割和候选目标节点采样将俯视图转换为离散推理空间。多模态大语言模型（MLLMs）通过多阶段过程识别与指令最一致的候选目标。选定的路径点通过确定性动作规划器在在线构建的占据图上被转化为可执行轨迹，同时使用预训练的对象检测器和分割器确保目标识别的鲁棒性。

Result: ReasonNavi在三种导航任务中持续优于需要大量训练或复杂场景建模的现有方法，提供了一个统一的零样本导航框架，无需MLLM微调，并规避了基于强化学习策略的脆弱性。

Conclusion: ReasonNavi提供了一种可扩展、可解释且全局接地的具身导航解决方案，优于需要大量训练或场景建模的现有方法。

Abstract: Embodied agents often struggle with efficient navigation because they rely primarily on partial egocentric observations, which restrict global foresight and lead to inefficient exploration. In contrast, humans plan using maps: we reason globally first, then act locally. We introduce ReasonNavi, a human-inspired framework that operationalizes this reason-then-act paradigm by coupling Multimodal Large Language Models (MLLMs) with deterministic planners. ReasonNavi converts a top-down map into a discrete reasoning space by room segmentation and candidate target nodes sampling. An MLLM is then queried in a multi-stage process to identify the candidate most consistent with the instruction (object, image, or text goal), effectively leveraging the model's semantic reasoning ability while sidestepping its weakness in continuous coordinate prediction. The selected waypoint is grounded into executable trajectories using a deterministic action planner over an online-built occupancy map, while pretrained object detectors and segmenters ensure robust recognition at the goal. This yields a unified zero-shot navigation framework that requires no MLLM fine-tuning, circumvents the brittleness of RL-based policies and scales naturally with foundation model improvements. Across three navigation tasks, ReasonNavi consistently outperforms prior methods that demand extensive training or heavy scene modeling, offering a scalable, interpretable, and globally grounded solution to embodied navigation. Project page:

</details>


### [159] [Test-Time Adaptation for Tactile-Vision-Language Models](https://arxiv.org/abs/2602.15873)
*Chuyang Ye,Haoxian Jing,Qinting Jiang,Yixi Lin,Qiang Li,Xing Tang,Jingyan Jiang*

Main category: cs.RO

TL;DR: 针对TVL模型在异步跨模态偏移下的测试时适应问题，本文提出了一种可靠性感知框架，通过估计各模态可靠性来过滤不可靠样本、自适应融合特征并指导优化，显著提升了模型在模态损坏下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的单模态测试时适应（TTA）方法在异步跨模态偏移下缺乏对各模态可靠性的显式处理，导致触觉-视觉-语言（TVL）模型在部分模态不可靠时表现脆弱，难以应对现实世界中不可避免的测试时分布偏移。

Method: 提出一个可靠性感知框架，该框架通过预测不确定性和基于扰动的响应来估计各模态的可靠性。该可靠性信号用于(i)过滤不可靠的测试样本，(ii)自适应融合触觉、视觉和语言特征，以及(iii)通过可靠性引导的目标函数来规范测试时优化。

Result: 在TAG-C基准测试和额外的TVL场景中，该方法持续优于强大的TTA基线，在严重模态损坏下实现了高达49.9%的准确率提升。

Conclusion: 显式的模态级可靠性建模对于鲁棒的测试时适应性至关重要。

Abstract: Tactile-vision-language (TVL) models are increasingly deployed in real-world robotic and multimodal perception tasks, where test-time distribution shifts are unavoidable. Existing test-time adaptation (TTA) methods provide filtering in unimodal settings but lack explicit treatment of modality-wise reliability under asynchronous cross-modal shifts, leaving them brittle when some modalities become unreliable. We study TTA for TVL models under such shifts and propose a reliability-aware framework that estimates per-modality reliability from prediction uncertainty and perturbation-based responses. This shared reliability signal is used to (i) filter unreliable test samples, (ii) adaptively fuse tactile, visual, and language features, and (iii) regularize test-time optimization with a reliability-guided objective. On the TAG-C benchmark and additional TVL scenarios, our approach consistently outperforms strong TTA baselines, achieving accuracy gains of up to 49.9\% under severe modality corruptions, underscoring the importance of explicit modality-wise reliability modeling for robust test-time adaptation.

</details>


### [160] [Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation](https://arxiv.org/abs/2602.15875)
*Zhenxing Xu,Brikit Lu,Weidong Bao,Zhengqiu Zhu,Junsong Zhang,Hui Yan,Wenhao Lu,Ji Wang*

Main category: cs.RO

TL;DR: Fly0框架通过解耦语义推理和几何规划，解决了视觉语言导航（VLN）中多模态大语言模型（MLLMs）作为低级控制器时面临的延迟高、轨迹振荡和泛化能力差的问题。它采用三阶段流程：MLLM驱动的2D像素坐标指令定位、基于深度数据的3D空间目标定位，以及无碰撞轨迹生成，从而实现更鲁棒、高效的导航，并在成功率和导航误差方面显著超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言导航（VLN）方法在语义理解和控制精度之间存在权衡。多模态大语言模型（MLLMs）虽然具有卓越的推理能力，但将其部署为低级控制器会导致高延迟、轨迹振荡以及由于几何基础薄弱导致的泛化能力差。

Method: Fly0框架将语义推理与几何规划解耦。它通过三阶段流水线操作：1) MLLM驱动模块将自然语言指令定位到2D像素坐标；2) 几何投影模块利用深度数据在3D空间中定位目标；3) 几何规划器生成无碰撞轨迹。这种机制消除了对持续推理的需求。

Result: Fly0即使在失去视觉接触时也能实现鲁棒导航。它降低了计算开销并提高了系统稳定性。在模拟和真实世界环境中的大量实验表明，Fly0超越了最先进的基线，在非结构化环境中将成功率提高了20%以上，并将导航误差（NE）降低了约50%。

Conclusion: Fly0通过解耦语义推理和几何规划，提供了一种解决VLN中MLLMs作为低级控制器局限性的有效方法。该框架提高了导航的鲁棒性、效率和准确性，显著优于现有技术，特别是在复杂环境中。

Abstract: Current Visual-Language Navigation (VLN) methodologies face a trade-off between semantic understanding and control precision. While Multimodal Large Language Models (MLLMs) offer superior reasoning, deploying them as low-level controllers leads to high latency, trajectory oscillations, and poor generalization due to weak geometric grounding. To address these limitations, we propose Fly0, a framework that decouples semantic reasoning from geometric planning. The proposed method operates through a three-stage pipeline: (1) an MLLM-driven module for grounding natural language instructions into 2D pixel coordinates; (2) a geometric projection module that utilizes depth data to localize targets in 3D space; and (3) a geometric planner that generates collision-free trajectories. This mechanism enables robust navigation even when visual contact is lost. By eliminating the need for continuous inference, Fly0 reduces computational overhead and improves system stability. Extensive experiments in simulation and real-world environments demonstrate that Fly0 outperforms state-of-the-art baselines, improving the Success Rate by over 20\% and reducing Navigation Error (NE) by approximately 50\% in unstructured environments. Our code is available at .

</details>


### [161] [FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution](https://arxiv.org/abs/2602.15882)
*Jingjing Fan,Yushan Liu,Shoujie Li,Botao Ren,Siyuan Li,Xiao-Ping Zhang,Wenbo Ding,Zhidong Deng*

Main category: cs.RO

TL;DR: FUTURE-VLA是一种统一架构，将长视域控制和未来预测整合为单一序列生成任务，利用时间自适应压缩和潜在空间自回归实现高效的实时预测和人机协作控制，在扩展时空窗口下保持恒定推理延迟，并在多个机器人基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用视觉语言模型在机器人上部署统一时空推理时，面临处理长历史和生成高维未来预测所带来的高延迟问题。

Method: FUTURE-VLA通过统一架构将长视域控制和未来预测重构为单一序列生成任务。它采用双边效率范式：一是利用时间自适应压缩策略最大化时空信息密度，实现对大量多视图历史的摄取同时保持恒定的推理延迟；二是通过潜在空间自回归在一个前向传播中对齐可操作动力学与可审查的视觉预判。此外，它还引入了预测引导的人机在环机制，通过交互式执行门控允许操作员根据可解释的未来预览动态验证行为。

Result: FUTURE-VLA建立了新的最先进性能，在LIBERO上成功率为99.2%，在RoboTwin上为75.4%，在真实世界Piper平台上为78.0%。所有这些成果均在16倍扩展的时空窗口下实现，同时保持了与单帧基线相同的推理延迟。

Conclusion: FUTURE-VLA通过提供高效统一的架构，有效解决了视觉语言模型在机器人控制中部署时的延迟限制，实现了实时、长视域的时空推理和人机在环验证，从而带来了卓越的性能。

Abstract: General vision-language models increasingly support unified spatiotemporal reasoning over long video streams, yet deploying such capabilities on robots remains constrained by the prohibitive latency of processing long-horizon histories and generating high-dimensional future predictions. To bridge this gap, we present FUTURE-VLA, a unified architecture that reformulates long-horizon control and future forecasting as a monolithic sequence-generation task. Adopting a dual-sided efficiency paradigm, FUTURE-VLA leverages a temporally adaptive compression strategy to maximize spatiotemporal information density, enabling the ingestion of extensive multi-view histories while maintaining constant inference latency. Simultaneously, it performs latent-space autoregression to align actionable dynamics with reviewable visual look-aheads in a single forward pass. These real-time predictive capabilities further enable a prediction-guided Human-In-the-Loop mechanism via interactive execution gating, allowing operators to dynamically validate behaviors based on interpretable future previews. Extensive evaluations demonstrate that FUTURE-VLA establishes new state-of-the-art performance, attaining success rates of 99.2% on LIBERO, 75.4% on RoboTwin, and 78.0% on a real-world Piper platform, all with a $16\times$ extended spatiotemporal window while maintaining the inference latency of a single-frame baseline.

</details>


### [162] [MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models](https://arxiv.org/abs/2602.15872)
*Xunlan Zhou,Xuanlin Chen,Shaowei Zhang,Xiangkun Li,ShengHua Wan,Xiaohai Hu,Yuan Lei,Le Gan,De-chuan Zhan*

Main category: cs.RO

TL;DR: MARVL通过微调VLM并分解多阶段子任务，为机器人强化学习设计密集奖励函数，解决了现有VLM奖励的局限性，并在Meta-World基准测试中表现出卓越的样本效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为机器人强化学习设计密集的奖励函数至关重要，但手动工程限制了可扩展性。现有的视觉-语言模型（VLM）奖励在任务进度对齐、空间基础和任务语义理解方面存在问题。

Method: MARVL通过对VLM进行微调以实现空间和语义一致性，并将任务分解为多阶段子任务，利用任务方向投影来提高轨迹敏感性。

Result: 在Meta-World基准测试中，MARVL显著优于现有的VLM奖励方法，在稀疏奖励操作任务上表现出卓越的样本效率和鲁棒性。

Conclusion: MARVL通过视觉-语言模型为机器人操作提供多阶段指导，有效解决了现有VLM奖励的局限性，并显著提高了样本效率和鲁棒性。

Abstract: Designing dense reward functions is pivotal for efficient robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering, which fundamentally limits the scalability and automation of reinforcement learning. While Vision-Language Models (VLMs) offer a promising path to reward design, naive VLM rewards often misalign with task progress, struggle with spatial grounding, and show limited understanding of task semantics. To address these issues, we propose MARVL-Multi-stAge guidance for Robotic manipulation via Vision-Language models. MARVL fine-tunes a VLM for spatial and semantic consistency and decomposes tasks into multi-stage subtasks with task direction projection for trajectory sensitivity. Empirically, MARVL significantly outperforms existing VLM-reward methods on the Meta-World benchmark, demonstrating superior sample efficiency and robustness on sparse-reward manipulation tasks.

</details>


### [163] [The SLAM Confidence Trap](https://arxiv.org/abs/2602.15884)
*Sebastian Sansoni,Santiago Ramón Tosetti Sanz*

Main category: cs.RO

TL;DR: SLAM社区因过度追求基准分数而非原则性不确定性估计而陷入“置信度陷阱”，导致系统脆性。本文主张将一致、实时的不确定性计算作为主要成功指标，推动范式转变。


<details>
  <summary>Details</summary>
Motivation: SLAM社区过度优先考虑基准分数，而非对不确定性进行原则性估计，这导致系统在几何上准确，但在概率上不一致且脆弱，形成了一种“置信度陷阱”。

Method: 本文主张进行范式转变，将不确定性的一致、实时计算作为衡量系统成功的主要指标。

Result: 当前的实践导致SLAM系统在几何上精确，但在概率上不一致且脆弱。

Conclusion: 为了避免“置信度陷阱”并提高SLAM系统的鲁棒性和一致性，社区应将重点从单纯追求基准分数转向优先考虑不确定性的一致、实时计算。

Abstract: The SLAM community has fallen into a "Confidence Trap" by prioritizing benchmark scores over principled uncertainty estimation. This yields systems that are geometrically accurate but probabilitistically inconsistent and brittle. We advocate for a paradigm shift where the consistent, real-time computation of uncertainty becomes a primary metric of success.

</details>


### [164] [A novel Integrated Motion Tracking Device (IMTD) for Objective Laparoscopic Training Assessment: Development and Validation](https://arxiv.org/abs/2602.15885)
*Siwar Bouzid,Abdelbadia Chaker,Marc Arsicault,Sami Bennour,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出了一种用于腹腔镜手术训练和评估的紧凑型四自由度运动跟踪设备（IMTD）。它在运动学、机械设计和仪器方面进行了开发，并与运动捕捉系统（MoCap）进行了精度和可靠性比较。结果显示IMTD能有效跟踪手术手势，成本低且易于集成，可显著改善手术技能训练并缩短学习曲线。


<details>
  <summary>Details</summary>
Motivation: 为腹腔镜手术训练和评估提供一种紧凑型四自由度运动跟踪设备，解决传统训练的不足，满足腹腔镜训练中围绕固定运动中心移动和无缝集成到标准箱式训练器中的特定要求。

Method: 该设备开发了运动学、机械设计、仪器仪表和原型，并与运动捕捉系统（MoCap）进行了跟踪精度和可靠性比较。研究侧重于精度、流畅性、速度和整体运动效率等关键性能参数。

Result: 该系统能有效跟踪手术手势，其跟踪精度和可靠性与MoCap系统相当。研究结果强调了其作为微创手术训练和性能评估工具的潜力，并因其低成本和集成设计，易于集成和实施。

Conclusion: IMTD提供客观、实时反馈，有望显著提高手术技能，缩短新手学习曲线，并为手势评分算法和标准化培训协议奠定基础。

Abstract: This paper presents a novel, compact four-degree-of-freedom motion-tracking device (IMTD) designed for training and evaluation in laparoscopic surgery. The device's kinematics, mechanical design, instrumentation, and prototypes are developed and presented to meet the specific requirements of laparoscopic training context, including movement around a fixed center of motion and seamless integration into standard box trainers. The system IMTD's tracking accuracy and reliability are compared to a motion capture system (MoCap), assessing its ability to capture both angular and translational motions of surgical instruments. The study then focuses on key performance parameters including precision, fluidity, speed, and overall motion efficiency. The results highlight the system's effectiveness in tracking surgical gestures, providing valuable insights into its potential as a tool for training and performance evaluation in minimally invasive surgery. Additionally, IMTD's low cost and integrated design allow for easy integration and implementation in training rooms, offering a practical and accessible solution for general use. By offering objective, real-time feedback, the system can significantly contribute to improving surgical skills and shortening the learning curve for novice students, while also providing a foundation for future development of gesture scoring algorithms and standardized training protocols.

</details>


### [165] [Optimization of an Augmented R-CUBE mechanism for Cervical Surgery](https://arxiv.org/abs/2602.15886)
*Terence Essomba,Yu-Wen Wu,Abdelbadia Chaker,Med Amine Laribi*

Main category: cs.RO

TL;DR: 该论文提出了一种新的机械架构，用于脊柱手术中椎弓根螺钉植入的钻孔操作。该架构基于增强型全平移R-CUBE机构，可提供3T2R运动，并针对真实患者病例的钻孔轨迹进行了运动学性能优化。


<details>
  <summary>Details</summary>
Motivation: 在一些针对脊柱的手术中，需要在椎骨中钻孔以插入椎弓根螺钉。

Method: 提出了一种新的机械架构，它是基于增强型全平移R-CUBE机构，并改进了连杆以实现额外的旋转运动。该机制提供3T2R运动，主要由三个阶段组成：一个平移阶段、一个传输阶段和一个旋转阶段。分别推导并结合了它们各自的运动学和速度模型。

Result: 基于从真实患者病例获得的钻孔轨迹，对该机制进行了优化，以产生最高的运动学性能。

Conclusion: 论文提出并优化了一种新的3T2R运动机制，用于脊柱手术钻孔，提供了改进的运动学性能。

Abstract: In some surgical operations targeting the spine, it is required to drill cavities in the vertebrae for the insertion of pedicle screws. A new mechanical architecture is proposed for this application. It is based on an augmented version of the full translational R-CUBE mechanism, with improved linkages to implement additional rotational motion. Using this concept, a mechanism presented with a 3T2R motion that is required for the manipulation of the surgical drill. It is mainly composed three stages: one translational, one transmitting and one rotational. Their respective kinematic and velocity models are separately derived, then combined. Based on the drilling trajectories obtained from a real patient case, the mechanism is optimized for generating the highest kinematic performances.

</details>


### [166] [Learning to Drive in New Cities Without Human Demonstrations](https://arxiv.org/abs/2602.15891)
*Zilin Wang,Saeed Rahmani,Daphne Cornelisse,Bidipta Sarkar,Alexander David Goldie,Jakob Nicolaus Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: 本文提出了一种名为NOMAD的无数据、基于地图的自博弈多智能体强化学习方法，用于将自动驾驶策略适应到新的城市，无需人工演示数据，仅利用地图和元信息即可在目标城市显著提高任务成功率和轨迹真实性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在新城市的部署成本高昂且速度慢，主要瓶颈是适应新城市（道路几何、交通规则和交互模式不同）的驾驶策略需要收集大量人工演示轨迹。

Method: 本文引入了无数据、基于地图的自动驾驶自博弈多智能体强化学习（NOMAD）。该方法在基于目标城市地图构建的模拟器中，通过自博弈多智能体强化学习，仅使用简单的奖励函数，实现策略适应。

Result: NOMAD在目标城市中显著提高了任务成功率和轨迹真实性。

Conclusion: NOMAD证明了一种有效且可扩展的替代方案，以取代数据密集型城市迁移方法。

Abstract: While autonomous vehicles have achieved reliable performance within specific operating regions, their deployment to new cities remains costly and slow. A key bottleneck is the need to collect many human demonstration trajectories when adapting driving policies to new cities that differ from those seen in training in terms of road geometry, traffic rules, and interaction patterns. In this paper, we show that self-play multi-agent reinforcement learning can adapt a driving policy to a substantially different target city using only the map and meta-information, without requiring any human demonstrations from that city. We introduce NO data Map-based self-play for Autonomous Driving (NOMAD), which enables policy adaptation in a simulator constructed based on the target-city map. Using a simple reward function, NOMAD substantially improves both task success rate and trajectory realism in target cities, demonstrating an effective and scalable alternative to data-intensive city-transfer methods. Project Page:

</details>


### [167] [Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach](https://arxiv.org/abs/2602.15893)
*Zhiyuan Ren,Yudong Fang,Tao Zhang,Wenchi Cheng,Ben Lan*

Main category: cs.RO

TL;DR: 该论文提出了一种名为AsymmetricHuberEKF的物理地面解决方案，并通过协同设计的主动感知策略，解决了灾后无人机幸存者定位中非视距传播引起的统计几何退化问题，显著加速了收敛。


<details>
  <summary>Details</summary>
Motivation: 在灾后幸存者定位中，无人机（UAV）面临非视距（NLOS）传播的挑战，导致测距偏差严格非负。现有鲁棒估计器因错误对称性假设而失效，产生统计几何退化（SGD）。数据驱动方法则受限于训练数据稀缺和仿真到现实的差距。

Method: 提出AsymmetricHuberEKF，通过导出的非对称损失函数明确地将NLOS偏差的非负物理先验纳入。理论上，该框架的退化情况对应于标准对称滤波器。通过协同设计的主动感知策略，提供解决SGD所需的特定双边信息。

Result: AsymmetricHuberEKF显式地整合了NLOS偏差的非负物理先验。标准对称滤波器是该框架中物理约束放松的退化情况。解决SGD不仅需要鲁棒滤波器，还需要特定的双边信息。与对称基线相比，该方法显著加速了收敛。

Conclusion: AsymmetricHuberEKF及其协同设计的主动感知策略为数据稀缺和几何受限的搜索操作提供了一个有弹性的构建模块，从而为灾情场景中的NLOS定位问题提供了物理基础的解决方案。

Abstract: Post-disaster survivor localization using Unmanned Aerial Vehicles (UAVs) faces a fundamental physical challenge: the prevalence of Non-Line-of-Sight (NLOS) propagation in collapsed structures. Unlike standard Gaussian noise, signal reflection from debris introduces strictly non-negative ranging biases. Existing robust estimators, typically designed with symmetric loss functions (e.g., Huber or Tukey), implicitly rely on the assumption of error symmetry. Consequently, they experience a theoretical mismatch in this regime, leading to a phenomenon we formally identify as Statistical-Geometric Degeneracy (SGD)-a state where the estimator stagnates due to the coupling of persistent asymmetric bias and limited observation geometry. While emerging data-driven approaches offer alternatives, they often struggle with the scarcity of training data and the sim-to-real gap inherent in unstructured disaster zones. In this work, we propose a physically-grounded solution, the AsymmetricHuberEKF, which explicitly incorporates the non-negative physical prior of NLOS biases via a derived asymmetric loss function. Theoretically, we show that standard symmetric filters correspond to a degenerate case of our framework where the physical constraint is relaxed. Furthermore, we demonstrate that resolving SGD requires not just a robust filter, but specific bilateral information, which we achieve through a co-designed active sensing strategy. Validated in a 2D nadir-view scanning scenario, our approach significantly accelerates convergence compared to symmetric baselines, offering a resilient building block for search operations where data is scarce and geometry is constrained.

</details>


### [168] [Coverage Path Planning for Autonomous Sailboats in Inhomogeneous and Time-Varying Oceans: A Spatiotemporal Optimization Approach](https://arxiv.org/abs/2602.15901)
*Yang An,Zhikang Ge,Taiyu Zhang,Jean-Baptiste R. G. Souppez,Gaofei Xu,Zhengru Ren*

Main category: cs.RO

TL;DR: 本文提出了一种针对自主帆船在非均匀和时变海洋环境中的时空覆盖路径规划框架，结合了空间拓扑约束和时间预报感知规划，模拟结果表明该方法比传统策略更高效可行，填补了该领域的空白。


<details>
  <summary>Details</summary>
Motivation: 自主帆船因其风驱动的续航能力而非常适合长时间海洋观测。然而，它们的性能具有高度各向异性，并受到非均匀和时变风场和洋流的强烈影响，这限制了现有覆盖方法（如折线式清扫）的有效性。在这些环境和机动约束下的规划仍未得到充分探索。

Method: 本文提出了一种专为自主帆船设计的时空覆盖路径规划框架，结合了：1) 空间域中基于拓扑形态的约束，以促进紧凑和连续的覆盖；2) 时间域中考虑预报的预见性规划，以预测环境演变并实现有远见的决策。

Result: 在随机非均匀和时变海洋环境（包括部分方向可达性场景）下进行的模拟表明，所提出的方法能够生成高效且可行的覆盖路径，而传统策略在这种情况下常常失效。

Conclusion: 本研究首次为在非均匀和时变海洋环境中运行的自主帆船提供了专门的覆盖路径规划解决方案，为未来合作式多帆船覆盖奠定了基础。

Abstract: Autonomous sailboats are well suited for long-duration ocean observation due to their wind-driven endurance. However, their performance is highly anisotropic and strongly influenced by inhomogeneous and time-varying wind and current fields, limiting the effectiveness of existing coverage methods such as boustrophedon sweeping. Planning under these environmental and maneuvering constraints remains underexplored. This paper presents a spatiotemporal coverage path planning framework tailored to autonomous sailboats, combining (1) topology-based morphological constraints in the spatial domain to promote compact and continuous coverage, and (2) forecast-aware look-ahead planning in the temporal domain to anticipate environmental evolution and enable foresighted decision-making. Simulations conducted under stochastic inhomogeneous and time-varying ocean environments, including scenarios with partial directional accessibility, demonstrate that the proposed method generates efficient and feasible coverage paths where traditional strategies often fail. To the best of our knowledge, this study provides the first dedicated solution to the coverage path planning problem for autonomous sailboats operating in inhomogeneous and time-varying ocean environments, establishing a foundation for future cooperative multi-sailboat coverage.

</details>


### [169] [World Action Models are Zero-shot Policies](https://arxiv.org/abs/2602.15922)
*Seonghyeon Ye,Yunhao Ge,Kaiyuan Zheng,Shenyuan Gao,Sihyun Yu,George Kurian,Suneel Indupuru,You Liang Tan,Chuning Zhu,Jiannan Xiang,Ayaan Malik,Kyungmin Lee,William Liang,Nadun Ranawaka,Jiasheng Gu,Yinzhen Xu,Guanzhi Wang,Fengyuan Hu,Avnish Narayan,Johan Bjorck,Jing Wang,Gwanghyun Kim,Dantong Niu,Ruijie Zheng,Yuqi Xie,Jimmy Wu,Qi Wang,Ryan Julian,Danfei Xu,Yilun Du,Yevgen Chebotar,Scott Reed,Jan Kautz,Yuke Zhu,Linxi "Jim" Fan,Joel Jang*

Main category: cs.RO

TL;DR: DreamZero是一个基于预训练视频扩散骨干的世界动作模型（WAM），它通过预测未来世界状态和动作来学习物理动力学。与VLA模型相比，DreamZero在真实机器人实验中，在新任务和新环境的泛化能力上实现了超过2倍的提升。它还支持14B自回归视频扩散模型以7Hz进行实时闭环控制，并展示了两种形式的跨身体转移，包括从视频演示中学习和少样本身体适应。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的视觉-语言-动作（VLA）模型在语义泛化方面表现出色，但在新颖环境中对未见过的物理运动的泛化能力不足。

Method: 引入DreamZero，一个基于预训练视频扩散骨干的世界动作模型（WAM）。DreamZero通过预测未来世界状态和动作来学习物理动力学，并利用视频作为世界演变的密集表示。它联合建模视频和动作，从异构机器人数据中有效地学习多样化技能，而无需重复演示。此外，通过模型和系统优化，实现了实时闭环控制。

Result: 1. 与最先进的VLA模型相比，在真实机器人实验中，对新任务和新环境的泛化能力提升了2倍以上。
2. 一个14B的自回归视频扩散模型能够以7Hz的频率执行实时闭环控制。
3. 实现了两种形式的跨身体转移：来自其他机器人或人类的纯视频演示，在未见任务性能上相对提升了42%以上，仅需10-20分钟的数据。
4. 实现了少样本身体适应：只需30分钟的玩耍数据即可转移到新的身体，同时保留零样本泛化能力。

Conclusion: DreamZero通过学习物理动力学和联合建模视频与动作，显著提升了机器人在新任务和新环境中的泛化能力，实现了实时控制，并展示了高效的跨身体转移和少样本身体适应能力，为机器人学习提供了有效的新范式。

Abstract: State-of-the-art Vision-Language-Action (VLA) models excel at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs, WAMs learn physical dynamics by predicting future world states and actions, using video as a dense representation of how the world evolves. By jointly modeling video and action, DreamZero learns diverse skills effectively from heterogeneous robot data without relying on repetitive demonstrations. This results in over 2x improvement in generalization to new tasks and environments compared to state-of-the-art VLAs in real robot experiments. Crucially, through model and system optimizations, we enable a 14B autoregressive video diffusion model to perform real-time closed-loop control at 7Hz. Finally, we demonstrate two forms of cross-embodiment transfer: video-only demonstrations from other robots or humans yield a relative improvement of over 42% on unseen task performance with just 10-20 minutes of data. More surprisingly, DreamZero enables few-shot embodiment adaptation, transferring to a new embodiment with only 30 minutes of play data while retaining zero-shot generalization.

</details>


### [170] [The human intention. A taxonomy attempt and its applications to robotics](https://arxiv.org/abs/2602.15963)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 这篇论文旨在弥补机器人研究中人类意图定义缺失的空白，通过借鉴心理学和传播学，提供了一个全面的意图分类框架，并展示了如何将各种机器人研究与这些意图类别对齐，强调了在协作机器人中考虑人类意图多样性的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人研究中，人类意图的定义尚未达成普遍共识，且常将其等同于特定的任务相关目标。本文旨在通过考察意图的多面性来解决这一问题，并为更广泛的受众整合一个易于理解的意图定义框架。

Method: 该论文借鉴心理学见解来整合意图的定义。它根据心理学和传播学研究对不同类型的意图进行分类，为研究人员从纯技术增强转向以人为中心的机器人视角提供指导。然后，它展示了各种机器人研究如何与这些意图类别对齐。最后，通过对协作搜索和物体运输用例的深入分析来强调考虑人类意图多样性的重要性。

Result: 本文提供了一个基于心理学和传播学的意图分类框架，并展示了如何将各种机器人研究与这些意图类别对齐，从而为研究人员从纯技术增强转向以人为中心的机器人视角提供了指导。通过深入分析用例，强调了考虑人类意图多样性的重要性。

Conclusion: 为了实现以人为中心的机器人技术，必须超越任务相关目标，对人类意图进行全面理解和分类。

Abstract: Despite a surge in robotics research dedicated to inferring and understanding human intent, a universally accepted definition remains elusive since existing works often equate human intention with specific task-related goals. This article seeks to address this gap by examining the multifaceted nature of intention. Drawing on insights from psychology, it attempts to consolidate a definition of intention into a comprehensible framework for a broader audience. The article classifies different types of intention based on psychological and communication studies, offering guidance to researchers shifting from pure technical enhancements to a more human-centric perspective in robotics. It then demonstrates how various robotics studies can be aligned with these intention categories. Finally, through in-depth analyses of collaborative search and object transport use cases, the article underscores the significance of considering the diverse facets of human intention.

</details>


### [171] [ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI](https://arxiv.org/abs/2602.16005)
*Jose Rojas,Aristotelis Papatheodorou,Sergi Martinez,Ioannis Havoutis,Carlos Mastalli*

Main category: cs.RO

TL;DR: ODYN是一种新颖的全移位原对偶非内点二次规划（QP）求解器，结合了全移位非线性互补问题（NCP）函数和乘子近端法，能够高效处理具有挑战性的密集和稀疏QP，尤其适用于机器人和AI应用的顺序和实时设置。


<details>
  <summary>Details</summary>
Motivation: 需要一个能有效处理具有挑战性的密集和稀疏QP（包括病态和退化问题）的求解器，尤其是在机器人和AI等需要强大热启动性能的领域。

Method: ODYN结合了全移位非线性互补问题（NCP）函数与乘子近端法，能够鲁棒地解决病态和退化问题，且不要求约束的线性独立性。

Result: ODYN在Maros-Mészáros测试集上表现出最先进的收敛性能和卓越的热启动能力，并成功应用于基于SQP的预测控制框架（OdynSQP）、深度学习的隐式可微优化层（ODYNLayer）和接触动力学模拟优化器（ODYNSim）。

Conclusion: ODYN作为一种鲁棒且高效的QP求解器，在小规模到大规模问题上均表现出卓越的性能和强大的热启动能力，这对于机器人和AI中的顺序和实时应用至关重要。

Abstract: We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).

</details>


### [172] [The Impact of Class Uncertainty Propagation in Perception-Based Motion Planning](https://arxiv.org/abs/2602.16035)
*Jibran Iqbal Shah,Andrei Ivanovic,Kelly Zhu,Masha Itkina,Rowan McAllister,Igor Gilitschenski,Florian Shkurti*

Main category: cs.RO

TL;DR: 本文分析了感知不确定性传播和校准对自动驾驶汽车基于感知的运动规划的影响，发现不确定性传播在复杂场景中表现出卓越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车需要考虑感知不确定性才能安全可靠地运行。现有的不确定性感知规划器可能对预测不确定性校准不当很敏感，但其程度尚未明确。

Method: 通过在nuPlan规划基准上比较两种具有不同不确定性传播水平的新型预测规划流程。利用在nuPlan挑战场景上的闭环评估，研究了上游不确定性校准的影响。

Result: 结合上游不确定性传播的方法在复杂的闭环场景中表现出卓越的泛化能力。

Conclusion: 上游不确定性传播有利于自动驾驶汽车规划在复杂场景中的泛化。

Abstract: Autonomous vehicles (AVs) are being increasingly deployed in urban environments. In order to operate safely and reliably, AVs need to account for the inherent uncertainty associated with perceiving the world through sensor data and incorporate that into their decision-making process. Uncertainty-aware planners have recently been developed to account for upstream perception and prediction uncertainty. However, such planners may be sensitive to prediction uncertainty miscalibration, the magnitude of which has not yet been characterized. Towards this end, we perform a detailed analysis on the impact that perceptual uncertainty propagation and calibration has on perception-based motion planning. We do so by comparing two novel prediction-planning pipelines with varying levels of uncertainty propagation on the recently-released nuPlan planning benchmark. We study the impact of upstream uncertainty calibration using closed-loop evaluation on the nuPlan challenge scenarios. We find that the method incorporating upstream uncertainty propagation demonstrates superior generalization to complex closed-loop scenarios.

</details>


### [173] [Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization](https://arxiv.org/abs/2602.16127)
*Théo Ayral,Saifeddine Aloui,Mathieu Grossard*

Main category: cs.RO

TL;DR: 本文提出了一种混合学习和模型方法，通过结合多模态触觉传感和二次规划，动态调整内部抓取力，以实现多指机器人夹持器中手内滑动的快速闭环稳定，理论延迟35-40ms，滑动检测20ms。


<details>
  <summary>Details</summary>
Motivation: 在多指机器人夹持器上，需要一种方法来适应内部抓取力，以阻止手内滑动。

Method: 该方法结合了学习和基于模型的方法，以适应内部抓取力来阻止多指机器人夹持器中的手内滑动。它采用多模态触觉堆栈，将压电（PzE）传感用于快速滑动信号，将压阻（PzR）阵列用于接触定位，从而实现在线构建抓取矩阵。一旦发生滑动，通过二次规划（QP）更新在抓取空空间中计算的内部力，该规划在保持物体扭矩的同时强制执行执行器限制。

Result: 该管道的理论传感到指令延迟为35-40毫秒，其中基于PzR的接触和几何更新需要5毫秒，二次规划求解大约需要4毫秒。在受控试验中，滑动发生可在20毫秒内检测到。该研究在外部扰动下展示了多指抓取闭环稳定，并通过端到端评估证实，增强型解析力控制与学习触觉线索相结合可提供鲁棒性和快速反应。实测延迟主要由实验数据路径而非实际计算造成。

Conclusion: 该分析为实现低于50毫秒的闭环稳定提供了清晰的路径，表明计算速度并非主要瓶颈，而是实验数据路径。将高效的解析力控制与学习到的触觉线索相结合，可实现鲁棒性和快速反应。

Abstract: We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.

</details>


### [174] [Image Measurement Method for Automatic Insertion of Forks into Inclined Pallet](https://arxiv.org/abs/2602.16178)
*Nobuyuki Kita,Takuro Kato*

Main category: cs.RO

TL;DR: 本研究提出了一种基于广角相机的图像测量方法，用于AGF自动将货叉插入托盘。该方法可测量托盘俯仰倾角并获取相机与货叉坐标系间的校准信息，实验证明其测量误差在安全插入货叉的允许范围内。


<details>
  <summary>Details</summary>
Motivation: 为了使AGF（自动引导叉车）能够自动将货叉插入托盘孔中，需要精确控制货叉的高度、伸展位置和倾斜角度，使其与托盘孔的位置和方向匹配。

Method: 提出了一种图像测量方法，利用广角相机获取图像，在相机坐标系中测量托盘的俯仰倾角。同时，提出了一种图像测量方法，用于简便地获取相机坐标系与货叉坐标系之间的校准信息，以便将相机坐标系的测量结果应用于货叉控制。实验中，将广角相机固定在前移式叉车的靠背上，对前方放置的托盘图像进行处理。

Result: 通过比较图像测量值与手动测量值，评估了在改变托盘俯仰倾角、托盘与货叉相对高度以及托盘是否载货等条件下的测量误差。结果表明，误差在安全插入货叉的允许范围内。

Conclusion: 通过实验验证，所提出的图像测量方法在不同条件下（托盘俯仰角、托盘与货叉相对高度、托盘是否载货）的误差均在安全插入货叉的允许范围内。

Abstract: In order to insert a fork into a hole of a pallet by a forklift located in front of a pallet, it is necessary to control the height position, reach position, and tilt angle of the fork to match the position and orientation of the hole of the pallet. In order to make AGF (Autonomous Guided Forklift) do this automatically, we propose an image measurement method to measure the pitch inclination of the pallet in the camera coordinate system from an image obtained by using a wide-angle camera. In addition, we propose an image measurement method to easily acquire the calibration information between the camera coordinate system and the fork coordinate system necessary to apply the measurements in the camera coordinate system to the fork control. In the experiment space, a wide-angle camera was fixed at the backrest of a reach type forklift. The wide-angle images taken by placing a pallet in front of the camera were processed. As a result of evaluating the error by comparing the image measurement value with the hand measurement value when changing the pitch inclination angle of the pallet, the relative height of the pallet and the fork, and whether the pallet is loaded or not, it was confirmed that the error was within the allowable range for safely inserting the fork.

</details>


### [175] [World Model Failure Classification and Anomaly Detection for Autonomous Inspection](https://arxiv.org/abs/2602.16182)
*Michelle Ho,Muhammad Fadhil Ginting,Isaac R. Ward,Andrzej Reinke,Mykel J. Kochenderfer,Ali-akbar Agha-Mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 该论文提出了一种混合框架，结合监督故障分类和异常检测，使自主检测机器人能够将检测任务分类为成功、已知故障或异常情况。该框架使用世界模型骨干和压缩视频输入，通过共形预测阈值进行分类，在工业现场仪表检测中实现了90%以上的准确率，并且分类时间早于人工观察。


<details>
  <summary>Details</summary>
Motivation: 自主检测机器人在工业场所监测中可以降低成本和风险，但由于遮挡、有限视角或意外环境条件，获取准确读数具有挑战性。

Method: 提出了一种混合框架，结合了监督故障分类和异常检测。该方法使用带有压缩视频输入的世界模型骨干，是一个与策略无关、无分布的框架，通过共形预测（CP）阈值设定的两个决策函数进行分类。

Result: 在从办公室和工业现场收集的仪表检测数据上评估了该框架，并展示了在Boston Dynamics Spot上的实时部署。实验表明，在区分成功、故障和OOD（out-of-distribution）情况方面，准确率超过90%，且分类时间早于人工观察者。

Conclusion: 这些结果突显了在自主检测任务中实现鲁棒、预测性故障检测的潜力，或作为模型训练的反馈信号，以评估和提高训练数据质量。

Abstract: Autonomous inspection robots for monitoring industrial sites can reduce costs and risks associated with human-led inspection. However, accurate readings can be challenging due to occlusions, limited viewpoints, or unexpected environmental conditions. We propose a hybrid framework that combines supervised failure classification with anomaly detection, enabling classification of inspection tasks as a success, known failure, or anomaly (i.e., out-of-distribution) case. Our approach uses a world model backbone with compressed video inputs. This policy-agnostic, distribution-free framework determines classifications based on two decision functions set by conformal prediction (CP) thresholds before a human observer does. We evaluate the framework on gauge inspection feeds collected from office and industrial sites and demonstrate real-time deployment on a Boston Dynamics Spot. Experiments show over 90% accuracy in distinguishing between successes, failures, and OOD cases, with classifications occurring earlier than a human observer. These results highlight the potential for robust, anticipatory failure detection in autonomous inspection tasks or as a feedback signal for model training to assess and improve the quality of training data. Project website:

</details>


### [176] [SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks](https://arxiv.org/abs/2602.16187)
*Zirui Zang,Ahmad Amine,Nick-Marios T. Kokolakis,Truong X. Nghiem,Ugo Rosolia,Rahul Mangharam*

Main category: cs.RO

TL;DR: 本文提出了一种名为SIT-LMPC的安全信息论学习模型预测控制算法，用于复杂不确定环境中的迭代任务。该算法通过结合信息论MPC、自适应惩罚方法和基于归一化流的价值函数学习，实现了安全、高性能和高效的实时优化。


<details>
  <summary>Details</summary>
Motivation: 在复杂、不确定环境中执行迭代任务的机器人需要平衡鲁棒性、安全性和高性能的控制策略。传统的控制方法可能难以同时满足这些要求。

Method: 该文提出了一种名为SIT-LMPC（Safe Information-Theoretic Learning Model Predictive Control）的算法。它基于信息论模型预测控制，设计了一个迭代控制框架，以解决离散时间非线性随机系统的约束无限时域最优控制问题。为确保安全性和优化平衡，开发了自适应惩罚方法。通过使用归一化流从先前迭代的轨迹中学习价值函数，实现了比高斯先验更丰富的T不确定性建模。SIT-LMPC被设计用于在图形处理单元（GPU）上进行高度并行执行，以实现高效的实时优化。

Result: 基准模拟和硬件实验表明，SIT-LMPC算法在迭代过程中持续改进系统性能，同时可靠地满足系统约束。

Conclusion: SIT-LMPC算法通过迭代学习和并行优化，在复杂不确定环境中为迭代任务提供了高效、安全且性能优越的控制策略。

Abstract: Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.

</details>


### [177] [Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics](https://arxiv.org/abs/2602.16206)
*Ahmad Amine,Kabir Puri,Viet-Anh Le,Rahul Mangharam*

Main category: cs.RO

TL;DR: 提出了一个用于非平面地形自动驾驶车辆的非平面模型预测控制(MPC)框架，通过几何感知残差高斯过程(GP)实现实时适应和高跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 针对自动驾驶车辆在非平面地形上操作时，需要处理复杂的车辆动力学，并实现实时适应性。

Method: 提出一个非平面模型预测控制(MPC)框架。该框架采用几何感知建模方法，学习残差高斯过程(GP)来近似复杂的车辆动力学。通过利用递归稀疏GP，实现对不同地形几何形状的实时适应。使用模型预测路径积分(MPPI)控制器在参考跟踪任务中验证了模型。

Result: 所提出的框架在参考跟踪任务中展示了学习模型的有效性。在定制的Isaac Sim环境中进行验证，确认了该框架在挑战性3D表面上保持高跟踪精度的能力。

Conclusion: 该非平面MPC框架通过结合几何感知残差GP和递归稀疏GP，能够使自动驾驶车辆在非平面地形上实现对复杂动力学的实时适应和高精度跟踪。

Abstract: This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.

</details>


### [178] [Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM](https://arxiv.org/abs/2602.16308)
*Markus Rueggeberg,Maximilian Ulmer,Maximilian Durner,Wout Boerdijk,Marcus Gerhard Mueller,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.RO

TL;DR: 该论文提出了一种利用深度学习的无标记6D姿态估计算法，以解决多机器人SLAM中传统基于标记方法在数据关联和恶劣光照条件下的局限性，从而提高了机器人团队的相对定位精度，并在类行星环境中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 多机器人SLAM中，数据关联因感知混叠或视角差异而难以建立。直接相互观测虽能连接局部SLAM图，但依赖于校准的标志物阵列（如AprilTag），这限制了观测范围并在恶劣光照条件下易失效。

Method: 该文提出了一种利用基于深度学习的6D姿态估计的新型解决方案，将无标记姿态估计作为去中心化多机器人SLAM系统的一部分。

Result: 该方法提高了机器人团队之间的相对定位精度，并在类行星环境的实地测试数据上得到了实验验证。

Conclusion: 该论文提出了一种利用深度学习的无标记姿态估计方法，显著提高了多机器人SLAM系统中机器人团队之间的相对定位精度，并在类行星环境中进行了验证。

Abstract: The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.

</details>


### [179] [Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning](https://arxiv.org/abs/2602.16353)
*Zhezhi Lei,Zhihai Bi,Wenxin Wang,Jun Ma*

Main category: cs.RO

TL;DR: 针对狭窄环境下双足机器人协同运输的挑战，提出了一种基于安全强化学习的新方法。该方法通过将任务建模为受限马尔可夫博弈，并引入成本优势分解和约束分配机制，有效提升了任务安全性和协作性能，并在仿真和实际实验中表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 多机器人协同运输在狭窄环境中确保安全和高性能的机器人间协作面临挑战，因为可行区域极其有限。

Method: 提出了一种基于安全强化学习（RL）的双足机器人协同运输新方法。将任务建模为完全合作的受限马尔可夫博弈，将避碰问题表述为约束。引入了一种成本优势分解方法，确保团队约束的总和低于上限，从而在RL框架内保证任务安全。提出了一种约束分配方法，将共享约束分配给单个机器人，以最大化整体任务奖励，鼓励机器人之间的自主任务分配。

Result: 仿真和实时实验结果表明，与现有方法相比，所提出的方法在双足机器人协同运输中取得了卓越的性能和更高的成功率。

Conclusion: 该方法通过成本优势分解和约束分配，有效解决了双足机器人协同运输中的安全和性能挑战，特别是在狭窄环境中，表现出优越的性能和更高的成功率。

Abstract: Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.

</details>


### [180] [Articulated 3D Scene Graphs for Open-World Mobile Manipulation](https://arxiv.org/abs/2602.16356)
*Martin Büchner,Adrian Röfer,Tim Engelbracht,Tim Welschehold,Zuria Bauer,Hermann Blum,Marc Pollefeys,Abhinav Valada*

Main category: cs.RO

TL;DR: MoMa-SG是一个新颖的框架，通过结合语义、几何和运动学，使机器人能够预测物体运动并操纵铰接物体。它利用RGB-D序列、点跟踪和统一扭转估计来构建语义-运动学3D场景图，并引入了一个新数据集。真实世界实验验证了其在机器人操纵中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器人目前无法预测物体如何移动，这是其在现实世界环境中操作的一个关键限制。长距离移动操纵需要弥合语义、几何和运动学之间的鸿沟。

Method: 本文提出了MoMa-SG框架，用于构建铰接场景的语义-运动学3D场景图。方法包括：1) 对RGB-D序列进行时间分割以识别对象交互；2) 使用抗遮挡点跟踪推断对象运动；3) 将点轨迹提升到3D并使用统一的扭转估计公式估计铰接模型，该公式可鲁棒地估计旋转和棱柱关节参数；4) 将对象与估计的铰接关联，并通过父子关系检测包含的对象。此外，还引入了Arti4D-Semantic数据集。

Result: MoMa-SG在两个数据集上进行了广泛评估，并消除了关键设计选择。在四足机器人和移动机械手上的真实世界实验表明，所提出的语义-运动学场景图能够实现日常家庭环境中铰接对象的鲁棒操作。

Conclusion: MoMa-SG框架使机器人能够在日常家庭环境中对铰接物体进行鲁棒操作，弥合了语义、几何和运动学之间的鸿沟。

Abstract: Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: .

</details>


### [181] [System Identification under Constraints and Disturbance: A Bayesian Estimation Approach](https://arxiv.org/abs/2602.16358)
*Sergi Martinez,Steve Tonneau,Carlos Mastalli*

Main category: cs.RO

TL;DR: 本文提出了一种贝叶斯系统辨识（SysID）框架，用于高精度地联合估计机器人的状态轨迹和物理参数，该框架通过嵌入物理一致的约束、能量回归器和创新的Riccati递归实现高精度和可扩展性，并在仿真和硬件实验中展示了卓越的估计和控制性能。


<details>
  <summary>Details</summary>
Motivation: 需要一个高精度的贝叶斯系统辨识框架，能够联合估计机器人的状态轨迹和物理参数，同时处理复杂的物理约束（如逆动力学、接触、闭环和关节摩擦）以及保证可扩展性，以改进机器人模型的准确性及其在控制应用中的表现。

Method: 该方法引入了一个贝叶斯系统辨识框架，用于联合估计机器人的状态轨迹和物理参数。它将物理一致的逆动力学、接触和闭环约束以及完整的关节摩擦模型嵌入为硬性、分阶段的等式约束。该框架依赖于基于能量的回归器来增强参数可观测性，支持惯性参数和执行器参数的等式和不等式先验，强制执行动态一致的扰动投影，并利用能量观测增强本体感受测量以消除非线性摩擦效应的歧义。为确保可扩展性，该方法推导了一个参数化的等式约束Riccati递归，保持了问题的带状结构，实现了时间域上的线性复杂度，并开发了计算高效的导数。

Result: 通过在代表性机器人系统上的仿真研究以及在配备Z1机械臂的Unitree B1上的硬件实验，该框架与前向动力学和解耦辨识基线相比，表现出更快的收敛速度、更低的惯性及摩擦估计误差以及更高的接触一致性。当部署在模型预测控制框架中时，由此产生的模型在复杂环境下的运动跟踪性能方面有显著的提升。

Conclusion: 该贝叶斯系统辨识框架实现了机器人状态轨迹和物理参数的高精度联合估计，生成的模型在模型预测控制中应用时，能够显著提高机器人在复杂环境下的跟踪性能。

Abstract: We introduce a Bayesian system identification (SysID) framework for jointly estimating robot's state trajectories and physical parameters with high accuracy. It embeds physically consistent inverse dynamics, contact and loop-closure constraints, and fully featured joint friction models as hard, stage-wise equality constraints. It relies on energy-based regressors to enhance parameter observability, supports both equality and inequality priors on inertial and actuation parameters, enforces dynamically consistent disturbance projections, and augments proprioceptive measurements with energy observations to disambiguate nonlinear friction effects. To ensure scalability, we derive a parameterized equality-constrained Riccati recursion that preserves the banded structure of the problem, achieving linear complexity in the time horizon, and develop computationally efficient derivatives. Simulation studies on representative robotic systems, together with hardware experiments on a Unitree B1 equipped with a Z1 arm, demonstrate faster convergence, lower inertial and friction estimation errors, and improved contact consistency compared to forward-dynamics and decoupled identification baselines. When deployed within model predictive control frameworks, the resulting models yield measurable improvements in tracking performance during locomotion over challenging environments.

</details>


### [182] [Docking and Persistent Operations for a Resident Underwater Vehicle](https://arxiv.org/abs/2602.16360)
*Leonard Günzel,Gabrielė Kasparavičiūtė,Ambjørn Grimsrud Waldum,Bjørn-Magnus Moslått,Abubakar Aliyu Badawi,Celil Yılmaz,Md Shamin Yeasher Yousha,Robert Staven,Martin Ludvigsen*

Main category: cs.RO

TL;DR: 开发并部署了一种驻留式水下机器人(ROV)系统，该系统具有自主导航和对接能力，旨在解决现有海洋监测成本高昂且数据稀疏的问题，并在90米水深实现了90%的自主对接成功率和高效检测。


<details>
  <summary>Details</summary>
Motivation: 当前海洋观测受限于成本高、后勤保障难，导致数据稀疏且不频繁，现有方法依赖于零星调查或固定点测量。为克服这些限制，需要实现无需持续水面支持的持久自主监测。

Method: 本研究开发并部署了一个驻留式基础设施，包括一个带有小型ROV的对接站，置于90米水深。ROV增强了板载处理和感知能力，能够使用USBL信号进行自主导航，并通过基于ArUco标记的视觉定位（融合扩展卡尔曼滤波器）进行对接，并执行局部检查任务。

Result: 该系统在实际条件下展示了90%的自主对接成功率，并在四分钟内完成了完整的检查任务，验证了声学和视觉导航的集成效果。

Conclusion: 研究结果表明，在深水区域进行可靠、无缆的ROV作业是可行的，突显了驻留式ROV系统在可扩展、经济高效的水下监测方面的巨大潜力。

Abstract: Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.

</details>


### [183] [Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped](https://arxiv.org/abs/2602.16371)
*Saumya Karan,Neerav Maram,Suraj Borate,Madhu Vadali*

Main category: cs.RO

TL;DR: 该论文提出了SLOT软体四足机器人及其基于Cosserat杆理论的物理知觉建模和凸MPC控制框架，实现了高精度的步态控制和在扰动下的渐近稳定性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过仅使用四个执行器，研究顺应性腿部运动的物理知觉建模和控制。

Method: 该研究提出了SLOT（软腿全向四足机器人），这是一种肌腱驱动的软体四足机器人，其3D打印TPU腿仅使用四个执行器。每条腿都使用离散Cosserat杆理论建模为可变形连续体，能够捕捉大弯曲变形、分布式弹性、肌腱驱动和地面接触相互作用。引入了一个模块化的全身建模框架，其中顺应性腿部动力学通过施加到刚性躯干上的物理一致反作用力表示。提出的模型嵌入到凸模型预测控制（MPC）框架中，该框架在0.495秒的预测范围内优化地面反作用力，并通过物理知觉的力-角度关系将其映射到肌腱驱动。

Result: 所提出的控制器在各种扰动下实现了渐近稳定性。该框架在物理原型上进行了爬行和步行步态的实验验证，在质心轨迹方面实现了小于5毫米的均方根误差（RMSE）的高精度。

Conclusion: 该研究证明了一种将连续体软腿整合到基于模型的运动控制中的通用方法，从而推动了软体四足机器人可扩展且可重用的建模和控制方法的发展。

Abstract: SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.

</details>


### [184] [RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](https://arxiv.org/abs/2602.16444)
*Yixue Zhang,Kun Wu,Zhi Gao,Zhen Zhao,Pei Ren,Zhiyuan Xu,Fei Liao,Xinhua Wang,Shichao Fan,Di Wu,Qiuxuan Feng,Meng Li,Zhengping Che,Chang Liu,Jian Tang*

Main category: cs.RO

TL;DR: 本文介绍了RoboGene，一个用于自动生成多样化、物理上可行的机器人操作任务的智能体框架，通过多样性采样、自反射和人工反馈机制，显著优于现有基础模型，并提高了预训练VLA模型的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器人操作面临多样化、真实世界交互数据稀缺的挑战。与视觉或语言领域不同，机器人数据收集是主动过程且物理成本高昂。现有手动方法不可扩展且偏向常见任务，而现成的基础模型常生成物理上不可行的指令。因此，自动化任务策划以最大化数据价值是一个关键但未被充分探索的问题。

Method: RoboGene是一个智能体框架，通过以下三个核心组件自动化生成多样化、物理上可行的操作任务：多样性驱动采样以实现广泛的任务覆盖；自 S 反射机制以强制执行物理约束；以及人工参与的持续改进。该框架适用于单臂、双臂和移动机器人。

Result: 通过广泛的定量分析和大规模真实世界实验（收集了1.8万条轨迹），RoboGene显著优于现有最先进的基础模型（如GPT-4o、Gemini 2.5 Pro）。使用RoboGene预训练的VLA模型在真实世界实验中取得了更高的成功率和卓越的泛化能力。本文还引入了评估任务质量、可行性和多样性的新指标。

Conclusion: 高质量任务生成对于提高机器人操作模型的成功率和泛化能力至关重要。

Abstract: The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate physically infeasible instructions. To address this, we introduce RoboGene, an agentic framework designed to automate the generation of diverse, physically plausible manipulation tasks across single-arm, dual-arm, and mobile robots. RoboGene integrates three core components: diversity-driven sampling for broad task coverage, self-reflection mechanisms to enforce physical constraints, and human-in-the-loop refinement for continuous improvement. We conduct extensive quantitative analysis and large-scale real-world experiments, collecting datasets of 18k trajectories and introducing novel metrics to assess task quality, feasibility, and diversity. Results demonstrate that RoboGene significantly outperforms state-of-the-art foundation models (e.g., GPT-4o, Gemini 2.5 Pro). Furthermore, real-world experiments show that VLA models pre-trained with RoboGene achieve higher success rates and superior generalization, underscoring the importance of high-quality task generation. Our project is available at .

</details>


### [185] [Reactive Motion Generation With Particle-Based Perception in Dynamic Environments](https://arxiv.org/abs/2602.16462)
*Xiyuan Zhao,Huijun Li,Lifeng Zhu,Zhikai Wei,Xianyi Zhu,Aiguo Song*

Main category: cs.RO

TL;DR: 本文提出了一种结合张量化粒子感知和障碍物感知MPPI规划的框架，通过明确建模机器人-障碍物动力学，显著提高了在动态不确定环境中机械臂避障的安全性和反应性。


<details>
  <summary>Details</summary>
Motivation: 在动态和非结构化场景中的反应式运动生成通常受限于静态感知和系统动力学。可靠地建模动态障碍物以及在感知和控制不确定性下优化无碰撞轨迹是具有挑战性的。

Method: 提出了一种张量化粒子权重更新方案，用于高效且具有表达动态特性的粒子感知，明确维护障碍物速度和协方差。在此基础上，提出了一种障碍物感知型MPPI规划公式，共同传播机器人-障碍物动力学，在不确定性下预测和评估未来的系统运动。

Result: 该模型预测方法显著提高了动态环境下的安全性和反应性。在模拟和有噪声的真实环境中，该框架在避障方面始终优于现有的MPPI基线感知-规划方法。

Conclusion: 通过明确建模机器人-障碍物动力学，该框架在避障性能上超越了现有MPPI基线的感知-规划方法。

Abstract: Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.

</details>


### [186] [VIGOR: Visual Goal-In-Context Inference for Unified Humanoid Fall Safety](https://arxiv.org/abs/2602.16511)
*Osher Azulay,Zhengjie Xu,Andrew Scheffer,Stella X. Yu*

Main category: cs.RO

TL;DR: 该论文提出了一种统一的仿人机器人跌倒安全方法，通过教师-学生模型，利用稀疏的人类演示，在不进行真实世界微调的情况下，使机器人能够在各种复杂地形中实现鲁棒的跌倒恢复。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中运行的仿人机器人，跌倒恢复的可靠性至关重要，因为跌倒涉及高能量冲击、复杂的全身接触和视点剧烈变化。现有方法将跌倒安全问题碎片化，或依赖于在平面地形上未经视觉训练的端到端策略，这限制了可扩展性和泛化性。此外，跌倒安全常被视为单一的数据复杂性问题，耦合了姿态、动力学和地形，需要详尽的覆盖。

Method: 提出了一种涵盖跌倒恢复所有阶段的统一跌倒安全方法。该方法基于两点洞察：1) 自然的人类跌倒和恢复姿态高度受限，可通过对齐从平面地形转移到复杂地形；2) 快速的全身反应需要整合的感知-运动表征。研究团队使用稀疏的人类演示，在平面和模拟复杂地形上训练了一个特权教师模型，并将其提炼为一个仅依赖自我中心深度和本体感受的可部署学生模型。学生通过匹配教师的目标情境潜在表征（结合下一个目标姿态和局部地形）来学习如何反应，而不是单独编码感知和行动。

Result: 在模拟和真实Unitree G1仿人机器人上的结果表明，该方法在多样化的非平面环境中实现了鲁棒的零样本跌倒安全，无需真实世界微调。

Conclusion: 该研究成功开发了一种统一、鲁棒且可泛化的仿人机器人跌倒安全系统，通过利用人类跌倒/恢复姿态和集成感知-运动表征，在教师-学生学习框架下，有效解决了复杂环境中仿人机器人的跌倒恢复问题。

Abstract: Reliable fall recovery is critical for humanoids operating in cluttered environments. Unlike quadrupeds or wheeled robots, humanoids experience high-energy impacts, complex whole-body contact, and large viewpoint changes during a fall, making recovery essential for continued operation. Existing methods fragment fall safety into separate problems such as fall avoidance, impact mitigation, and stand-up recovery, or rely on end-to-end policies trained without vision through reinforcement learning or imitation learning, often on flat terrain. At a deeper level, fall safety is treated as monolithic data complexity, coupling pose, dynamics, and terrain and requiring exhaustive coverage, limiting scalability and generalization. We present a unified fall safety approach that spans all phases of fall recovery. It builds on two insights: 1) Natural human fall and recovery poses are highly constrained and transferable from flat to complex terrain through alignment, and 2) Fast whole-body reactions require integrated perceptual-motor representations. We train a privileged teacher using sparse human demonstrations on flat terrain and simulated complex terrains, and distill it into a deployable student that relies only on egocentric depth and proprioception. The student learns how to react by matching the teacher's goal-in-context latent representation, which combines the next target pose with the local terrain, rather than separately encoding what it must perceive and how it must act. Results in simulation and on a real Unitree G1 humanoid demonstrate robust, zero-shot fall safety across diverse non-flat environments without real-world fine-tuning. The project page is available at

</details>


### [187] [Decentralized and Fully Onboard: Range-Aided Cooperative Localization and Navigation on Micro Aerial Vehicles](https://arxiv.org/abs/2602.16594)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 提出一种分散式的、基于距离测距的机器人团队定位与编队控制方法，利用块坐标下降和因子图推断，实现了分米级精度且无需严格协调。


<details>
  <summary>Details</summary>
Motivation: 集中式机器人团队控制方法扩展性差，且全局定位系统不可总是可用，这使得协调机器人团队面临挑战。

Method: 提出一种块坐标下降方法实现无需严格协调的定位；将编队控制建模为因子图上的推断问题，并考虑状态估计不确定性，可高效求解。每个机器人仅利用板载里程计和与其他机器人的距离测量数据来估计相对姿态。

Result: 该方法实现了完全去中心化的、基于距离测距的定位和编队导航，无需专门轨迹即可保持编队，并能达到分米级的定位和编队控制精度。

Conclusion: 本文提出了一种创新的、去中心化的机器人团队定位和编队控制方法，通过结合块坐标下降和因子图推断，有效解决了现有挑战，并在室内外环境中通过真实实验验证了其高性能和实用性。

Abstract: Controlling a team of robots in a coordinated manner is challenging because centralized approaches (where all computation is performed on a central machine) scale poorly, and globally referenced external localization systems may not always be available. In this work, we consider the problem of range-aided decentralized localization and formation control. In such a setting, each robot estimates its relative pose by combining data only from onboard odometry sensors and distance measurements to other robots in the team. Additionally, each robot calculates the control inputs necessary to collaboratively navigate an environment to accomplish a specific task, for example, moving in a desired formation while monitoring an area. We present a block coordinate descent approach to localization that does not require strict coordination between the robots. We present a novel formulation for formation control as inference on factor graphs that takes into account the state estimation uncertainty and can be solved efficiently. Our approach to range-aided localization and formation-based navigation is completely decentralized, does not require specialized trajectories to maintain formation, and achieves decimeter-level positioning and formation control accuracy. We demonstrate our approach through multiple real experiments involving formation flights in diverse indoor and outdoor environments.

</details>


### [188] [Sensor Query Schedule and Sensor Noise Covariances for Accuracy-constrained Trajectory Estimation](https://arxiv.org/abs/2602.16598)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文旨在估计达到特定轨迹估计精度所需的传感器调度和传感器协方差，并将其表述为半定规划问题。


<details>
  <summary>Details</summary>
Motivation: 轨迹估计的精度受限于系统模型和传感器参数（如精度和测量速率），但成本和资源限制了传感器的精度和测量速率。因此，需要确定在这些限制下如何达到特定的估计精度。

Method: 将估计实现特定估计精度所需的传感器调度和传感器协方差的问题，表述为半定规划（semidefinite programs），可以使用现成的求解器进行求解。具体关注两种情况：(i) 具有已知协方差的传感器需要以何种速率或调度生成测量以达到特定估计精度；(ii) 在给定传感器更新速率下，需要何种传感器协方差才能达到特定估计精度。

Result: 通过仿真和实际实验验证了该方法，结果表明使用所提出方法计算出的传感器调度和传感器协方差能够达到所需的轨迹估计精度。此外，该方法还能识别出在给定系统和传感器特性下某些估计精度无法实现的情况。

Conclusion: 本文提出了一种通过半定规划方法估计传感器调度和传感器协方差来达到特定轨迹估计精度的方法，该方法在仿真和实际实验中得到验证，并能识别出不可实现的精度场景，为轨迹估计中的传感器部署提供了有效指导。

Abstract: Trajectory estimation involves determining the trajectory of a mobile robot by combining prior knowledge about its dynamic model with noisy observations of its state obtained using sensors. The accuracy of such a procedure is dictated by the system model fidelity and the sensor parameters, such as the accuracy of the sensor (as represented by its noise covariance) and the rate at which it can generate observations, referred to as the sensor query schedule. Intuitively, high-rate measurements from accurate sensors lead to accurate trajectory estimation. However, cost and resource constraints limit the sensor accuracy and its measurement rate. Our work's novel contribution is the estimation of sensor schedules and sensor covariances necessary to achieve a specific estimation accuracy. Concretely, we focus on estimating: (i) the rate or schedule with which a sensor of known covariance must generate measurements to achieve specific estimation accuracy, and alternatively, (ii) the sensor covariance necessary to achieve specific estimation accuracy for a given sensor update rate. We formulate the problem of estimating these sensor parameters as semidefinite programs, which can be solved by off-the-shelf solvers. We validate our approach in simulation and real experiments by showing that the sensor schedules and the sensor covariances calculated using our proposed method achieve the desired trajectory estimation accuracy. Our method also identifies scenarios where certain estimation accuracy is unachievable with the given system and sensor characteristics.

</details>


### [189] [Towards Autonomous Robotic Kidney Ultrasound: Spatial-Efficient Volumetric Imaging via Template Guided Optimal Pivoting](https://arxiv.org/abs/2602.16641)
*Xihan Ma,Haichong Zhang*

Main category: cs.RO

TL;DR: 本研究提出了一种自主机器人超声工作流程，通过模板引导的最佳枢轴扫描，实现高效肾脏成像，解决传统和现有机器人超声的局限性，减少探头足迹并提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统超声成像存在结果不一致、操作员依赖、缺乏3D定位信息以及职业性肌肉骨骼疾病风险。现有机器人超声系统虽然能实现标准化、操作员独立的3D肾脏数据采集，但缺乏确定最佳成像窗口的能力，导致盲目扫描、探头足迹过大、声影和器官覆盖不完整。因此，迫切需要一种空间高效的成像技术，以最小的探头足迹最大化肾脏覆盖。

Method: 该方法提出了一种自主工作流程，通过模板引导下的最佳枢轴扫描实现高效肾脏成像。首先进行探索性成像以获取部分肾脏观察数据，然后将该数据注册到肾脏模板以估计器官姿态。在肾脏定位后，机器人执行定点枢轴扫描，将成像平面与肾脏长轴对齐，以最小化探头平移。

Result: 仿真结果表明，60%的探索率在肾脏定位精度和扫描效率之间提供了最佳平衡。对两名男性受试者的体内评估显示，肾脏定位精度最高达7.36毫米和13.84度。与基线方法相比，最佳枢轴方法将探头足迹缩短了约75毫米。

Conclusion: 结果验证了利用解剖模板优化探头对齐进行体积扫描的方法。

Abstract: Medical ultrasound (US) imaging is a frontline tool for the diagnosis of kidney diseases. However, traditional freehand imaging procedure suffers from inconsistent, operator-dependent outcomes, lack of 3D localization information, and risks of work-related musculoskeletal disorders. While robotic ultrasound (RUS) systems offer the potential for standardized, operator-independent 3D kidney data acquisition, the existing scanning methods lack the ability to determine the optimal imaging window for efficient imaging. As a result, the scan is often blindly performed with excessive probe footprint, which frequently leads to acoustic shadowing and incomplete organ coverage. Consequently, there is a critical need for a spatially efficient imaging technique that can maximize the kidney coverage through minimum probe footprint. Here, we propose an autonomous workflow to achieve efficient kidney imaging via template-guided optimal pivoting. The system first performs an explorative imaging to generate partial observations of the kidney. This data is then registered to a kidney template to estimate the organ pose. With the kidney localized, the robot executes a fixed-point pivoting sweep where the imaging plane is aligned with the kidney long axis to minimize the probe translation. The proposed method was validated in simulation and in-vivo. Simulation results indicate that a 60% exploration ratio provides optimal balance between kidney localization accuracy and scanning efficiency. In-vivo evaluation on two male subjects demonstrates a kidney localization accuracy up to 7.36 mm and 13.84 degrees. Moreover, the optimal pivoting approach shortened the probe footprint by around 75 mm when compared with the baselines. These results valid our approach of leveraging anatomical templates to align the probe optimally for volumetric sweep.

</details>


### [190] [Learning to unfold cloth: Scaling up world models to deformable object manipulation](https://arxiv.org/abs/2602.16675)
*Jack Rome,Stephen James,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出了一种基于改进DreamerV2的强化学习方法，通过结合表面法线输入和优化数据处理，增强了机器人世界模型，并在模拟和物理机器人上成功实现了多种布料的空中展开操作，展现了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 布料操作对于机器人研究而言是一个典型难题，且在辅助护理和服务行业具有实际应用价值。布料作为可变形物体，其复杂的物理特性使得操作变得非平凡，因此需要开发一种通用的操作策略来应对布料形状、尺寸、折叠和褶皱模式以及外观变化等问题。

Method: 本文采用了一种改进的DreamerV2强化学习架构，通过整合表面法线输入，并优化了回放缓冲区和数据增强流程，以此增强了机器人使用的世界模型。

Result: 在模拟和物理机器人上的零样本部署评估表明，所训练的策略能够成功对多种不同类型的布料进行空中展开，证明了所提出架构的泛化优势。

Conclusion: 本文通过在模拟和物理机器人上的零样本部署评估，验证了所提出架构的泛化优势，成功实现了多种布料类型的空中展开操作。

Abstract: Learning to manipulate cloth is both a paradigmatic problem for robotic research and a problem of immediate relevance to a variety of applications ranging from assistive care to the service industry. The complex physics of the deformable object makes this problem of cloth manipulation nontrivial. In order to create a general manipulation strategy that addresses a variety of shapes, sizes, fold and wrinkle patterns, in addition to the usual problems of appearance variations, it becomes important to carefully consider model structure and their implications for generalisation performance. In this paper, we present an approach to in-air cloth manipulation that uses a variation of a recently proposed reinforcement learning architecture, DreamerV2. Our implementation modifies this architecture to utilise surface normals input, in addition to modiying the replay buffer and data augmentation procedures. Taken together these modifications represent an enhancement to the world model used by the robot, addressing the physical complexity of the object being manipulated by the robot. We present evaluations both in simulation and in a zero-shot deployment of the trained policies in a physical robot setup, performing in-air unfolding of a variety of different cloth types, demonstrating the generalisation benefits of our proposed architecture.

</details>


### [191] [Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation](https://arxiv.org/abs/2602.16705)
*Runpei Dong,Ziyan Li,Xialin He,Saurabh Gupta*

Main category: cs.RO

TL;DR: HERO是一种新范式，它将大型视觉模型的强大泛化能力与模拟训练的控制性能相结合，通过设计一个精确的残差感知末端执行器（EE）跟踪策略，使仿人机器人在真实世界中能够对任意物体进行视觉定位和操作。该策略将EE跟踪误差降低了3.2倍，并使系统能够在不同环境中可靠地操作各种日常物体。


<details>
  <summary>Details</summary>
Motivation: 现有用于仿人机器人对任意物体进行视觉定位和操作的方法，基于真实世界的模仿学习，由于难以收集大规模训练数据集而泛化能力有限。

Method: 本文提出了HERO，一个结合了大型视觉模型（用于泛化和开放词汇理解）与模拟训练（用于强大控制性能）的仿人机器人物体定位和操作新范式。核心是一个精确的残差感知EE跟踪策略，它结合了经典机器人学和机器学习，具体包括：a) 使用逆运动学将残差EE目标转换为参考轨迹；b) 使用学习到的神经前向模型进行精确前向运动学；c) 目标调整；d) 重新规划。该策略被用于构建一个模块化系统，并结合开放词汇大型视觉模型以实现强大的视觉泛化。

Result: 残差感知EE跟踪策略将末端执行器跟踪误差降低了3.2倍。该系统能够在办公室到咖啡馆等多样化的真实世界环境中运行，机器人能够可靠地操作各种日常物体（例如马克杯、苹果、玩具），操作台面高度范围从43厘米到92厘米。通过在模拟和真实世界中进行的系统性模块化和端到端测试，证明了所提出设计的有效性。

Conclusion: 本文的进展为训练仿人机器人与日常物体互动开辟了新途径。

Abstract: Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.

</details>


### [192] [EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data](https://arxiv.org/abs/2602.16710)
*Ruijie Zheng,Dantong Niu,Yuqi Xie,Jing Wang,Mengda Xu,Yunfan Jiang,Fernando Castañeda,Fengyuan Hu,You Liang Tan,Letian Fu,Trevor Darrell,Furong Huang,Yuke Zhu,Danfei Xu,Linxi Fan*

Main category: cs.RO

TL;DR: 该论文提出了EgoScale，一个基于大规模以自我为中心的人类数据的人类到灵巧操作的迁移框架，通过在超过20,854小时的视频上训练VLA模型，揭示了人类数据规模与验证损失之间的对数线性缩放定律，并展示了一个两阶段的迁移方法，使机器人性能平均提高54%，并能有效地适应不同自由度手。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效利用人类行为作为可扩展数据源来学习物理智能，特别是对于精细、高自由度的灵巧操作，因为之前的工作主要在受限设置中展示了人到机器人的迁移，而大规模人类数据对此的有效性尚不明确。

Method: 提出了EgoScale，一个基于大规模以自我为中心的人类数据的灵巧操作迁移框架。在超过20,854小时的动作标记以自我为中心的人类视频上训练了一个视觉语言动作（VLA）模型。引入了一个简单的两阶段迁移方案：大规模人类预训练，随后进行轻量级对齐的人机中期训练。

Result: 发现了人类数据规模与验证损失之间的对数线性缩放定律。验证损失与下游真实机器人性能强相关，表明大规模人类数据是可预测的监督来源。最终策略使平均成功率比无预训练基线提高了54%，使用了22自由度的灵巧机械手。能有效地迁移到自由度较低的机器人手上，表明大规模人类运动提供了一个可重用、与具体形态无关的运动先验。实现了强大的长周期灵巧操作和少量机器人监督下的单次任务适应。

Conclusion: 大规模人类运动提供了一个可重用、与具体形态无关的运动先验，为灵巧操作的机器人学习提供了有效的监督来源，EgoScale框架显著提升了机器人的操作性能和适应性。

Abstract: Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.

</details>


### [193] [One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation](https://arxiv.org/abs/2602.16712)
*Zhenyu Wei,Yunchao Yao,Mingyu Ding*

Main category: cs.RO

TL;DR: 引入参数化规范表示，统一了各种灵巧手结构，实现了跨实体策略学习，并在未知手型上展示了高零样本迁移成功率。


<details>
  <summary>Details</summary>
Motivation: 当前灵巧操作策略假设手部设计固定，严重限制了其对具有不同运动学和结构布局的新实体的泛化能力。

Method: 引入了一种参数化规范表示，统一了广泛的灵巧手结构。它包括一个统一的参数空间和一个规范的URDF格式，通过捕捉形态和运动学变异、学习结构化潜在流形以及标准化动作空间，增强了学习算法的有效性、平滑形态转换并实现了高效可靠的跨实体策略学习。具体而言，该方法在统一表示上训练了一个VAE以获得紧凑、语义丰富的潜在嵌入，并开发了一个以规范表示为条件的抓取策略。

Result: 通过广泛的分析和实验（包括抓取策略回放、VAE潜在编码和跨实体零样本迁移），证明了该框架统一了结构多样化手的表示空间和动作空间。在模拟和真实世界任务中，对未见形态（例如，在3指LEAP手上实现了81.9%的零样本成功率）展示了成功操作。

Conclusion: 该框架为跨手学习迈向通用灵巧操作提供了一个可扩展的基础，统一了结构多样化手的表示和动作空间。

Abstract: Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [194] [Emotion Collider: Dual Hyperbolic Mirror Manifolds for Sentiment Recovery via Anti Emotion Reflection](https://arxiv.org/abs/2602.16161)
*Rong Fu,Ziming Wang,Shuo Yin,Wenxin Zhang,Haiyun Wei,Kun Liu,Xianda Li,Zeli Su,Simon Fong*

Main category: cs.MM

TL;DR: 本论文提出了Emotion Collider (EC-Net)，一个基于双曲超图的多模态情感和情绪建模框架，它通过Poincare球嵌入、超图融合和双曲对比学习，实现了鲁棒且准确的多模态情感理解，特别是在数据不完整或有噪声时表现优异。


<details>
  <summary>Details</summary>
Motivation: 情感表达是自然交流和有效人机交互的基础。

Method: EC-Net，一个双曲超图框架，用于多模态情感和情绪建模。它使用Poincare球嵌入表示模态层次，并通过超图机制进行融合，在节点和超边之间双向传递信息。为提高类别区分度，在双曲空间中设计了径向和角目标分离的对比学习。通过自适应超边构建，保留了跨时间步和模态的高阶语义关系。

Result: EC-Net在标准多模态情感基准测试中，生成了鲁棒且语义连贯的表示，并持续提高了准确性，尤其是在模态部分可用或被噪声污染的情况下表现更佳。

Conclusion: 显式分层几何与超图融合相结合，能有效实现鲁棒的多模态情感理解。

Abstract: Emotional expression underpins natural communication and effective human-computer interaction. We present Emotion Collider (EC-Net), a hyperbolic hypergraph framework for multimodal emotion and sentiment modeling. EC-Net represents modality hierarchies using Poincare-ball embeddings and performs fusion through a hypergraph mechanism that passes messages bidirectionally between nodes and hyperedges. To sharpen class separation, contrastive learning is formulated in hyperbolic space with decoupled radial and angular objectives. High-order semantic relations across time steps and modalities are preserved via adaptive hyperedge construction. Empirical results on standard multimodal emotion benchmarks show that EC-Net produces robust, semantically coherent representations and consistently improves accuracy, particularly when modalities are partially available or contaminated by noise. These findings indicate that explicit hierarchical geometry combined with hypergraph fusion is effective for resilient multimodal affect understanding.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [195] [Evidence for Daily and Weekly Periodic Variability in GPT-4o Performance](https://arxiv.org/abs/2602.15889)
*Paul Tschisgale,Peter Wulff*

Main category: stat.AP

TL;DR: 研究发现，即使在受控条件下，GPT-4o的性能也随时间呈现周期性变化，挑战了大型语言模型研究中时间不变性的假设，这可能影响研究的可靠性和可复现性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）研究通常隐含地假设在固定条件下（相同的模型快照、超参数和提示），LLM的性能是时间不变的。如果平均输出质量随时间系统性变化，则这一假设将失效，从而威胁研究结果的可靠性、有效性和可复现性。本文旨在通过实证检验这一假设。

Method: 通过API，在固定模型快照、固定超参数和相同提示的条件下，GPT-4o 每三小时被查询一次，以解决相同的多项选择物理任务，持续约三个月。每个时间点生成十个独立的响应并取平均分数。对所得时间序列进行频谱（傅里叶）分析。

Result: 平均模型性能表现出显著的周期性变异，占总方差的约20%。观察到的周期性模式通过日节律和周节律的相互作用得到了很好的解释。

Conclusion: 即使在受控条件下，大型语言模型的性能也可能随时间周期性变化，这挑战了时间不变性的假设。研究讨论了这对确保使用或调查大型语言模型的科研的有效性和可复现性的影响。

Abstract: Large language models (LLMs) are increasingly used in research both as tools and as objects of investigation. Much of this work implicitly assumes that LLM performance under fixed conditions (identical model snapshot, hyperparameters, and prompt) is time-invariant. If average output quality changes systematically over time, this assumption is violated, threatening the reliability, validity, and reproducibility of findings. To empirically examine this assumption, we conducted a longitudinal study on the temporal variability of GPT-4o's average performance. Using a fixed model snapshot, fixed hyperparameters, and identical prompting, GPT-4o was queried via the API to solve the same multiple-choice physics task every three hours for approximately three months. Ten independent responses were generated at each time point and their scores were averaged. Spectral (Fourier) analysis of the resulting time series revealed notable periodic variability in average model performance, accounting for approximately 20% of the total variance. In particular, the observed periodic patterns are well explained by the interaction of a daily and a weekly rhythm. These findings indicate that, even under controlled conditions, LLM performance may vary periodically over time, calling into question the assumption of time invariance. Implications for ensuring validity and replicability of research that uses or investigates LLMs are discussed.

</details>
