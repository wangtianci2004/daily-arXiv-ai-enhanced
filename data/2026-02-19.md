<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 34]
- [cs.CL](#cs.CL) [Total: 30]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.DL](#cs.DL) [Total: 1]
- [eess.SP](#eess.SP) [Total: 2]
- [cs.IR](#cs.IR) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.LG](#cs.LG) [Total: 23]
- [cs.SI](#cs.SI) [Total: 1]
- [hep-ex](#hep-ex) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.AI](#cs.AI) [Total: 20]
- [quant-ph](#quant-ph) [Total: 1]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.RO](#cs.RO) [Total: 23]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.HC](#cs.HC) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Spanning the Visual Analogy Space with a Weight Basis of LoRAs](https://arxiv.org/abs/2602.15727)
*Hila Manor,Rinon Gal,Haggai Maron,Tomer Michaeli,Gal Chechik*

Main category: cs.CV

TL;DR: 针对视觉类比学习中现有单一LoRA模块泛化受限的问题，本文提出了LoRWeB方法，通过动态组合LoRA基模块实现任务特异性模型，从而在视觉转换任务中达到最先进的性能和更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉类比学习方法通过单一LoRA模块适应文本到图像模型，但在捕获多样视觉转换空间时，固定适应模块限制了泛化能力。

Method: 本文提出LoRWeB方法，通过动态组合学习到的转换基元，在推理时针对每个类比任务进行模型专门化。该方法包含两个关键组件：1) 可学习的LoRA模块基，用于跨越不同视觉转换空间；2) 一个轻量级编码器，根据输入类比对动态选择和加权这些基LoRA。

Result: LoRWeB实现了最先进的性能，并显著提高了对未见视觉转换的泛化能力。

Conclusion: LoRA基分解是实现灵活视觉操作的一个有前途的方向。

Abstract: Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\{\mathbf{a}$, $\mathbf{a}'$, $\mathbf{b}\}$, the goal is to generate $\mathbf{b}'$ such that $\mathbf{a} : \mathbf{a}' :: \mathbf{b} : \mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a "space of LoRAs". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in

</details>


### [2] [GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation](https://arxiv.org/abs/2602.15072)
*Abdul Joseph Fofanah,Lian Wen,Alpha Alimamy Kamara,Zhongyi Zhang,David Chen,Albert Patrick Sankoh*

Main category: cs.CV

TL;DR: GRAFNet是一种受生物学启发的架构，通过模拟人类视觉系统的分层组织，解决了结肠镜检查中息肉分割的挑战，并在多个公共基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜检查中准确的息肉分割对于癌症预防至关重要，但由于息肉形态多样性、与正常结构的高度视觉相似性以及对鲁棒多尺度检测的需求而具有挑战性。现有深度学习方法存在单向处理、弱多尺度融合和缺乏解剖学约束的问题，导致假阳性和假阴性。

Method: 提出GRAFNet，一个受生物学启发的架构，模仿人类视觉系统的分层组织。它集成了三个关键模块：1) 引导式非对称注意力模块（GAAM）强调息肉边界；2) 多尺度视网膜模块（MSRM）进行并行多特征分析；3) 引导式皮层注意力反馈模块（GCAFM）进行迭代细化。这些模块通过息肉编码器-解码器模块（PEDM）统一，并通过分辨率自适应反馈强制执行空间-语义一致性。

Result: 在五个公共基准（Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen）上，GRAFNet展示了持续的最先进性能，Dice分数提高了3-8%，泛化能力比领先方法高10-20%，同时提供了可解释的决策路径。

Conclusion: 这项工作建立了一个新的范例，其中神经计算原理弥合了AI准确性和临床可信推理之间的差距。

Abstract: Accurate polyp segmentation in colonoscopy is essential for cancer prevention but remains challenging due to: (1) high morphological variability (from flat to protruding lesions), (2) strong visual similarity to normal structures such as folds and vessels, and (3) the need for robust multi-scale detection. Existing deep learning approaches suffer from unidirectional processing, weak multi-scale fusion, and the absence of anatomical constraints, often leading to false positives (over-segmentation of normal structures) and false negatives (missed subtle flat lesions). We propose GRAFNet, a biologically inspired architecture that emulates the hierarchical organisation of the human visual system. GRAFNet integrates three key modules: (1) a Guided Asymmetric Attention Module (GAAM) that mimics orientation-tuned cortical neurones to emphasise polyp boundaries, (2) a MultiScale Retinal Module (MSRM) that replicates retinal ganglion cell pathways for parallel multi-feature analysis, and (3) a Guided Cortical Attention Feedback Module (GCAFM) that applies predictive coding for iterative refinement. These are unified in a Polyp Encoder-Decoder Module (PEDM) that enforces spatial-semantic consistency via resolution-adaptive feedback. Extensive experiments on five public benchmarks (Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen) demonstrate consistent state-of-the-art performance, with 3-8% Dice improvements and 10-20% higher generalisation over leading methods, while offering interpretable decision pathways. This work establishes a paradigm in which neural computation principles bridge the gap between AI accuracy and clinically trustworthy reasoning. Code is available at .

</details>


### [3] [Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124)
*Shiyu Xuan,Dongkai Wang,Zechao Li,Jinhui Tang*

Main category: cs.CV

TL;DR: 该论文提出了一种解耦框架，将目标检测与交互识别（IR）分离，并利用多模态大型语言模型（MLLM）实现零样本IR。通过确定性生成方法将IR表述为视觉问答任务，实现免训练零样本IR。此外，还设计了空间感知池化模块和单程确定性匹配方法以提高性能和效率。该方法在零样本性能、跨数据集泛化能力以及与任意目标检测器集成方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 零样本人-物交互（HOI）检测面临挑战，特别是在交互识别（IR）方面，由于交互的组合多样性而难以实现。现有方法将IR与特定检测器紧密耦合，并依赖粗粒度视觉-语言模型（VLM）特征，限制了对未知交互的泛化能力。

Method: 1. 提出了一种解耦框架，将目标检测与交互识别（IR）分离。
2. 利用多模态大型语言模型（MLLM）进行零样本IR。
3. 引入了一种确定性生成方法，将IR表述为视觉问答任务，并强制执行确定性输出，实现免训练的零样本IR。
4. 设计了一个空间感知池化模块，集成了外观和成对空间线索，以增强性能和效率。
5. 开发了一种单程确定性匹配方法，可在单次前向传递中预测所有候选交互。

Result: 1. 在HICO-DET和V-COCO数据集上取得了卓越的零样本性能。
2. 展示了强大的跨数据集泛化能力。
3. 具备与任何目标检测器集成的灵活性，无需重新训练。

Conclusion: 提出的解耦框架通过分离目标检测和交互识别，并利用MLLM的确定性生成方法，有效地解决了零样本HOI检测中交互识别的挑战。结合空间感知池化和单程确定性匹配，该方法在性能、泛化能力和灵活性方面均表现出显著优势。

Abstract: Zero-shot Human-object interaction (HOI) detection aims to locate humans and objects in images and recognize their interactions. While advances in open-vocabulary object detection provide promising solutions for object localization, interaction recognition (IR) remains challenging due to the combinatorial diversity of interactions. Existing methods, including two-stage methods, tightly couple IR with a specific detector and rely on coarse-grained vision-language model (VLM) features, which limit generalization to unseen interactions. In this work, we propose a decoupled framework that separates object detection from IR and leverages multi-modal large language models (MLLMs) for zero-shot IR. We introduce a deterministic generation method that formulates IR as a visual question answering task and enforces deterministic outputs, enabling training-free zero-shot IR. To further enhance performance and efficiency by fine-tuning the model, we design a spatial-aware pooling module that integrates appearance and pairwise spatial cues, and a one-pass deterministic matching method that predicts all candidate interactions in a single forward pass. Extensive experiments on HICO-DET and V-COCO demonstrate that our method achieves superior zero-shot performance, strong cross-dataset generalization, and the flexibility to integrate with any object detectors without retraining. The codes are publicly available at .

</details>


### [4] [Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories](https://arxiv.org/abs/2602.15154)
*Praditha Alwis,Soumyadeep Chandra,Deepak Ravikumar,Kaushik Roy*

Main category: cs.CV

TL;DR: 该论文提出了一种模型无关的方法，通过分析累积样本损失（CSL）来检测视频数据集中（如动作识别、阶段检测和事件分割任务）的标注错误（例如错标和乱序）。CSL是帧在训练周期中通过模型检查点时产生的平均损失，其轨迹作为帧级可学习性的动态指纹。方法通过识别持续高损失或不规则损失模式的帧来标记潜在的标注错误。


<details>
  <summary>Details</summary>
Motivation: 高质量的视频数据集对于训练鲁棒模型至关重要，但现实世界的数据集常存在标注错误，如错标和乱序，这些错误对需要时间一致性的阶段标注任务尤其有害。

Method: 该方法首先训练一个视频分割模型，并在每个epoch保存模型权重。然后，通过计算每帧在训练过程中经过模型检查点时的平均损失（定义为累积样本损失CSL）。如果帧的CSL轨迹持续较高或不规则，则表明该帧可能存在标注错误，因为模型难以学习。该方法不依赖于标注错误的真实标签，且具有通用性。

Result: 在EgoPER和Cholec80数据集上的实验表明，该方法具有很强的检测性能，能有效识别细微的不一致性，如错标和帧乱序。

Conclusion: 所提出的方法为数据集审计和提高基于视频的机器学习训练可靠性提供了一个强大的工具。

Abstract: High-quality video datasets are foundational for training robust models in tasks like action recognition, phase detection, and event segmentation. However, many real-world video datasets suffer from annotation errors such as *mislabeling*, where segments are assigned incorrect class labels, and *disordering*, where the temporal sequence does not follow the correct progression. These errors are particularly harmful in phase-annotated tasks, where temporal consistency is critical. We propose a novel, model-agnostic method for detecting annotation errors by analyzing the Cumulative Sample Loss (CSL)--defined as the average loss a frame incurs when passing through model checkpoints saved across training epochs. This per-frame loss trajectory acts as a dynamic fingerprint of frame-level learnability. Mislabeled or disordered frames tend to show consistently high or irregular loss patterns, as they remain difficult for the model to learn throughout training, while correctly labeled frames typically converge to low loss early. To compute CSL, we train a video segmentation model and store its weights at each epoch. These checkpoints are then used to evaluate the loss of each frame in a test video. Frames with persistently high CSL are flagged as likely candidates for annotation errors, including mislabeling or temporal misalignment. Our method does not require ground truth on annotation errors and is generalizable across datasets. Experiments on EgoPER and Cholec80 demonstrate strong detection performance, effectively identifying subtle inconsistencies such as mislabeling and frame disordering. The proposed approach provides a powerful tool for dataset auditing and improving training reliability in video-based machine learning.

</details>


### [5] [Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift](https://arxiv.org/abs/2602.15167)
*Xiaoyi Wen,Fei Jiang*

Main category: cs.CV

TL;DR: 该论文提出了一种分布深度学习框架，用于医学成像（特别是4D流MRI）的超分辨率，旨在通过在计算流体动力学（CFD）模拟上训练并在真实数据上微调来克服领域偏移问题，从而提高模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的超分辨率方法在真实临床环境中因领域偏移而失效，因为低分辨率数据采集机制与简单的下采样不同，导致模型泛化能力差。需要增强低质量医学影像数据，尤其是4D流MRI，以改进异常检测并评估动脉瘤破裂风险。

Method: 提出了一种分布深度学习框架。首先在计算流体动力学（CFD）模拟及其下采样对应物上进行初始训练。然后，在一个小型的、协调的4D流MRI和CFD配对数据集上进行微调。推导了分布估计器的理论性质。将此方法应用于4D流MRI以提高分辨率。

Result: 所提出的框架通过真实数据应用显著优于传统深度学习方法。这表明了分布学习在解决领域偏移和提高临床实际场景中超分辨率性能方面的有效性。

Conclusion: 分布深度学习能够通过解决领域偏移问题，有效提高临床实际场景中的超分辨率性能和模型鲁棒性，尤其是在4D流MRI增强方面。

Abstract: Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.

</details>


### [6] [Time-Archival Camera Virtualization for Sports and Visual Performances](https://arxiv.org/abs/2602.15181)
*Yunxiao Zhang,William Stone,Suryansh Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种用于摄像机虚拟化的神经体渲染方法，具有高效的时间归档能力，克服了3DGS在处理快速、非刚性动态场景方面的局限性，适用于体育赛事广播等应用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景（特别是快节奏体育和舞台表演）中实现空间和时间连贯、真实感渲染以及高效时间归档仍面临挑战。基于3D Gaussian Splatting (3DGS) 的动态场景方法依赖精确的3D点云，且无法处理大范围、非刚性、快速运动以及多个主体的独立运动。

Method: 该方法重新考虑了摄像机虚拟化和高效时间归档的神经体渲染公式。通过将动态场景建模为在给定时间跨多个同步摄像机视图的刚性变换，执行神经表示学习。

Result: 在测试时提供增强的视觉渲染质量，并支持时间归档，允许用户回溯任何过去的动态场景实例并执行新颖视图合成，从而实现直播事件的回放、分析和存档的追溯渲染。

Conclusion: 本文提出的具有时间归档功能的神经体渲染方法为动态场景中的摄像机虚拟化提供了一个鲁棒的解决方案，特别适用于体育赛事广播和相关应用，解决了现有方法的局限性。

Abstract: Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...

</details>


### [7] [How to Train Your Long-Context Visual Document Model](https://arxiv.org/abs/2602.15257)
*Austin Veselka*

Main category: cs.CV

TL;DR: 首次对长上下文视觉语言模型（最长344K上下文）的训练进行了全面、大规模研究，旨在解决长文档视觉问答中的现有模型训练不可复现问题。通过系统研究和广泛评估，模型在MMLongBenchDoc上取得了SOTA性能，并揭示了关于训练策略、数据管道和跨模态长上下文迁移的关键发现，同时发布了改进的基准测试集。


<details>
  <summary>Details</summary>
Motivation: 现有的强大开源长上下文视觉语言模型（如Qwen3 VL和GLM 4.5/6V）的训练配方和数据管道不可复现，这阻碍了该领域的研究和发展。

Method: 系统地研究了24B和32B参数模型的持续预训练、监督微调和偏好优化。通过广泛的长上下文（LC）评估和消融实验来弥补现有研究空白。开发了合成数据管道。

Result: 在24B和32B参数规模的模型上，MMLongBenchDoc实现了最先进的性能。主要发现包括：(i) 匹配评估上下文长度的训练优于更长上下文的训练；(ii) 使用页面索引进行训练和评估能显著提升长文档性能；(iii) 合成数据管道能够通过持续预训练和监督微调实现模型自改进；(iv) 视觉长上下文训练可以迁移到长上下文文本性能。同时发布了MMLBD-C，一个经过手动纠正的MMLongBenchDoc版本。

Conclusion: 本文为长上下文视觉语言模型（最长344K上下文）的训练提供了一个全面且可复现的框架，解决了现有模型训练配方不可复现的问题。研究取得了MMLongBenchDoc上的最先进性能，并提供了关于训练策略（如上下文长度匹配、页面索引）、合成数据管线自改进以及视觉长上下文到文本长上下文迁移的实用见解。此外，还发布了MMLBD-C，一个改进后的基准测试集。

Abstract: We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.

</details>


### [8] [Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization](https://arxiv.org/abs/2602.15277)
*Muhammad J. Alahmadi,Peng Gao,Feiyi Wang,Dongkuan*

Main category: cs.CV

TL;DR: 本文提出了一种名为E^2D的新型数据集蒸馏方法，通过高效的初始化和两阶段优化策略，解决了大规模数据蒸馏中准确性和效率之间的权衡，实现了SOTA性能并大幅提升了速度。


<details>
  <summary>Details</summary>
Motivation: 现有的解耦式蒸馏方法在大规模数据集蒸馏中面临效率与准确性的权衡：基于优化的方法准确度高但计算量大，而免优化的方法效率高但牺牲了准确性。该研究旨在克服这一折衷。

Method: E^2D采用高效的流水线，首先通过全图像初始化以保留语义完整性和特征多样性。随后，它使用两阶段优化策略：探索阶段执行统一更新并识别高损失区域；开发阶段则将更新集中在这些区域以加速收敛。

Result: 在ImageNet-1K基准测试中，E^2D超越了现有最优方法，速度提高了18倍。在ImageNet-21K上，该方法显著提高了准确性，同时仍保持4.3倍的速度提升。

Conclusion: 目标导向、减少冗余的更新策略，而非蛮力优化，能有效弥合大规模数据集蒸馏中准确性和效率之间的差距。

Abstract: Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at .

</details>


### [9] [Consistency-Preserving Diverse Video Generation](https://arxiv.org/abs/2602.15287)
*Xinshuang Liu,Runfa Blark Li,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种用于流匹配视频生成器的联合采样框架，该框架在保持时间一致性的同时提高了批次多样性，并通过在潜在空间中操作避免了昂贵的视频解码。


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成成本高昂，导致每个提示的样本数量少，因此需要高跨视频多样性来最大化每个批次的价值。现有方法在提高多样性时往往会损害视频内部的时间一致性，并且需要通过视频解码器进行昂贵的反向传播。

Method: 提出了一种用于流匹配视频生成器的联合采样框架。该方法首先应用多样性驱动的更新，然后仅移除会降低时间一致性目标的组件。为避免图像空间梯度，作者使用轻量级潜在空间模型计算多样性和时间一致性目标，从而避免了视频解码和解码和解码器反向传播。

Result: 在最先进的文本到视频流匹配模型上进行的实验表明，该方法在多样性方面与强大的联合采样基线相当，同时显著提高了时间一致性和色彩自然度。

Conclusion: 该研究提出了一种新颖的联合采样框架，有效解决了文本到视频生成中多样性和时间一致性之间的权衡问题，并显著降低了计算成本，为高质量、高效的视频生成提供了新途径。

Abstract: Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.

</details>


### [10] [Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models](https://arxiv.org/abs/2602.15315)
*Tai Le-Gia,Jaehyun Ahn*

Main category: cs.CV

TL;DR: 该论文提出了一种无需训练的3D脑部MRI零样本异常检测（ZSAD）框架，通过结合2D基础模型的多个轴向切片来构建局部体素化tokens，有效解决了现有方法无法捕获体积结构的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的2D零样本异常检测（ZSAD）方法难以扩展到3D医学图像，且现有方法依赖于切片级特征和视觉-语言模型，未能有效捕获体积结构。

Method: 该框架通过聚合由2D基础模型处理的多轴切片来构建局部体素化tokens。这些3D补丁tokens恢复了立方空间上下文，并直接与基于距离的批次级异常检测管道集成。

Result: 该框架提供了紧凑的3D表示，可在标准GPU上实际计算，无需微调、提示或监督。结果表明，无需训练的批次级ZSAD可以有效地从2D编码器扩展到完整的3D MRI体积。

Conclusion: 该研究为体积异常检测提供了一种简单且鲁棒的方法，成功地将无需训练的批次级ZSAD从2D编码器扩展到完整的3D MRI体积。

Abstract: Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.

</details>


### [11] [Sparrow: Text-Anchored Window Attention with Visual-Semantic Glimpsing for Speculative Decoding in Video LLMs](https://arxiv.org/abs/2602.15318)
*Libo Zhang,Zhaoning Zhang,Wangyang Hong,Peng Qiao,Dongsheng Li*

Main category: cs.CV

TL;DR: Sparrow框架通过视觉感知的文本锚定窗口注意力、中间层视觉状态桥接以及多token预测策略，解决了在视频大语言模型（Vid-LLMs）中应用推测解码时性能严重下降的问题，实现了平均2.82倍的加速。


<details>
  <summary>Details</summary>
Motivation: 推测解码在视频大语言模型（Vid-LLMs）中应用时面临严重的性能崩溃，这是由于键值缓存爆炸和上下文窗口不匹配导致草稿模型陷入注意力稀释和负面视觉增益的困境。

Method: 提出了Sparrow框架，利用视觉感知的文本锚定窗口注意力通过隐藏状态重用来将视觉计算完全卸载到目标模型；利用中间层视觉状态桥接来训练草稿模型，以过滤低级视觉噪声；并引入多token预测策略来弥合训练-推理的分布偏移。

Result: Sparrow框架即使在25k视觉token的情况下，也能实现平均2.82倍的加速，有效解决了长序列中的性能下降问题。

Conclusion: Sparrow为实时长视频任务提供了一个实用的解决方案，有效解决了视频大语言模型中推测解码的性能退化问题。

Abstract: Although speculative decoding is widely used to accelerate Vision-Language Models (VLMs) inference, it faces severe performance collapse when applied to Video Large Language Models (Vid-LLMs). The draft model typically falls into the trap of attention dilution and negative visual gain due to key-value cache explosion and context window mismatches. We observe a visual semantic internalization phenomenon in Vid-LLMs, indicating that critical visual semantics are implicitly encoded into text hidden states during deep-layer interactions, which renders raw visual inputs structurally redundant during deep inference. To address this, we propose the Sparrow framework, which first utilizes visually-aware text-anchored window attention via hidden state reuse to fully offload visual computation to the target model, and leverages intermediate-layer visual state bridging to train the draft model with semantic-rich intermediate states, thereby filtering out low-level visual noise. Additionally, a multi-token prediction strategy is introduced to bridge the training-inference distribution shift. Experiments show that Sparrow achieves an average speedup of 2.82x even with 25k visual tokens, effectively resolving the performance degradation in long sequences and offering a practical solution for real-time long video tasks.

</details>


### [12] [CREMD: Crowd-Sourced Emotional Multimodal Dogs Dataset](https://arxiv.org/abs/2602.15349)
*Jinho Baek,Houwei Cao,Kate Blackwell*

Main category: cs.CV

TL;DR: 本研究推出了CREMD数据集，旨在探究不同呈现模式（如语境、音频、视频）和标注者特征（如狗主人身份、性别、专业经验）对狗情绪识别的影响。研究发现，视觉语境显著提高了标注一致性，音频增强了标注者的信心，且非狗主人和男性标注者展现出意料之外的更高一致性。


<details>
  <summary>Details</summary>
Motivation: 狗情绪识别对于增强人犬互动、改进兽医护理以及开发用于监测犬类健康的自动化系统至关重要。然而，由于情绪评估的主观性以及缺乏标准化的“真实情况”方法，准确解释狗的情绪极具挑战性。

Method: 研究引入了CREMD（Crowd-sourced Emotional Multimodal Dogs Dataset）数据集，包含923个狗视频片段。这些视频以三种不同模式呈现：无语境无音频、有语境无音频、以及有语境有音频。研究分析了来自不同背景（包括狗主人、专业人士及不同人口统计学和经验水平的个体）的标注者对这些视频的标注，以探究不同呈现模式和标注者特征如何影响狗情绪的感知和标注。

Result: 1. 添加视觉语境显著提高了标注一致性，但由于设计限制（缺乏无语境带音频的条件及有限的清晰音频可用性），关于音频线索的发现尚无定论。
2. 与预期相反，非狗主人和男性标注者表现出比狗主人和女性标注者更高的一致性水平；而专业人士的一致性水平更高，这与初始假设相符。
3. 音频的存在显著增加了标注者识别特定情绪（特别是愤怒和恐惧）的信心。

Conclusion: 本研究通过分析CREMD数据集，揭示了影响狗情绪识别的关键因素，包括视觉语境、音频线索和标注者特征。研究结果为未来狗情绪识别数据集的构建和自动化系统开发提供了宝贵的见解，并指出了未来研究在音频条件设计上的改进方向。

Abstract: Dog emotion recognition plays a crucial role in enhancing human-animal interactions, veterinary care, and the development of automated systems for monitoring canine well-being. However, accurately interpreting dog emotions is challenging due to the subjective nature of emotional assessments and the absence of standardized ground truth methods. We present the CREMD (Crowd-sourced Emotional Multimodal Dogs Dataset), a comprehensive dataset exploring how different presentation modes (e.g., context, audio, video) and annotator characteristics (e.g., dog ownership, gender, professional experience) influence the perception and labeling of dog emotions. The dataset consists of 923 video clips presented in three distinct modes: without context or audio, with context but no audio, and with both context and audio. We analyze annotations from diverse participants, including dog owners, professionals, and individuals with varying demographic backgrounds and experience levels, to identify factors that influence reliable dog emotion recognition. Our findings reveal several key insights: (1) while adding visual context significantly improved annotation agreement, our findings regarding audio cues are inconclusive due to design limitations (specifically, the absence of a no-context-with-audio condition and limited clean audio availability); (2) contrary to expectations, non-owners and male annotators showed higher agreement levels than dog owners and female annotators, respectively, while professionals showed higher agreement levels, aligned with our initial hypothesis; and (3) the presence of audio substantially increased annotators' confidence in identifying specific emotions, particularly anger and fear.

</details>


### [13] [DAV-GSWT: Diffusion-Active-View Sampling for Data-Efficient Gaussian Splatting Wang Tiles](https://arxiv.org/abs/2602.15355)
*Rong Fu,Jiekai Wu,Haiyun Wei,Yee Tan Jia,Wenxin Zhang,Yang Li,Xiaowen Ma,Wangyu Wu,Simon Fong*

Main category: cs.CV

TL;DR: DAV-GSWT是一种数据高效的框架，利用扩散先验和主动视图采样，从最少输入观察中合成高质量的高斯泼溅Wang Tiles，以减少大规模虚拟环境所需的数据量。


<details>
  <summary>Details</summary>
Motivation: 现有的高斯泼溅Wang Tiles方法在生成广阔景观时，受限于对密集采样范例重建的依赖，导致需要大量数据。

Method: DAV-GSWT框架结合了扩散先验和主动视图采样。它将分层不确定性量化机制与生成扩散模型相结合，自主识别最具信息量的视点，并“幻化”缺失的结构细节，以确保无缝的瓦片过渡。

Result: 实验结果表明，该系统显著减少了所需数据量，同时保持了大规模虚拟环境所需的视觉完整性和交互性能。

Conclusion: DAV-GSWT能够以最少的输入数据创建具有高质量高斯泼溅Wang Tiles的大规模虚拟环境。

Abstract: The emergence of 3D Gaussian Splatting has fundamentally redefined the capabilities of photorealistic neural rendering by enabling high-throughput synthesis of complex environments. While procedural methods like Wang Tiles have recently been integrated to facilitate the generation of expansive landscapes, these systems typically remain constrained by a reliance on densely sampled exemplar reconstructions. We present DAV-GSWT, a data-efficient framework that leverages diffusion priors and active view sampling to synthesize high-fidelity Gaussian Splatting Wang Tiles from minimal input observations. By integrating a hierarchical uncertainty quantification mechanism with generative diffusion models, our approach autonomously identifies the most informative viewpoints while hallucinating missing structural details to ensure seamless tile transitions. Experimental results indicate that our system significantly reduces the required data volume while maintaining the visual integrity and interactive performance necessary for large-scale virtual environments.

</details>


### [14] [GMAIL: Generative Modality Alignment for generated Image Learning](https://arxiv.org/abs/2602.15368)
*Shentong Mo,Sukmin Yun*

Main category: cs.CV

TL;DR: GMAIL框架通过将生成图像视为独立模态，并在同一潜在空间中与真实图像对齐，有效利用生成图像训练视觉-语言模型，显著提升了多项任务的性能，解决了模态差异导致的模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 尽管生成图像提供了丰富的数据源，但由于真实和合成领域之间的模态差异，不加区别地将生成的图像作为真实图像用于训练可能会导致模式崩溃。

Method: 该论文提出了GMAIL框架，将生成的图像明确视为与真实图像不同的模态。它通过多模态学习方法在同一潜在空间中桥接真实和生成的图像模态。具体而言，首先使用跨模态对齐损失在生成的图像上对模型进行微调，然后使用此对齐模型进一步训练各种视觉-语言模型。

Result: GMAIL框架显著提高了图像字幕、零样本图像检索、零样本图像分类和长字幕检索等任务的性能。它还显示出积极的生成数据扩展趋势，并显著增强了大型多模态模型LLaVA的字幕性能。

Conclusion: GMAIL框架通过在共享潜在空间中对齐合成图像和真实图像模态，有效利用了生成模型，提升了生成图像学习在各种视觉-语言任务中的效果，并易于与现有模型结合。

Abstract: Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.

</details>


### [15] [Bridging Day and Night: Target-Class Hallucination Suppression in Unpaired Image Translation](https://arxiv.org/abs/2602.15383)
*Shuwei Li,Lei Tan,Robby T. Tan*

Main category: cs.CV

TL;DR: 该论文提出了一种新的框架，用于解决日夜非配对图像翻译中的语义幻觉问题，通过双头判别器检测幻觉内容并利用类别原型进行抑制，从而显著提高下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 日夜非配对图像翻译对下游任务至关重要，但由于外观变化大和缺乏直接的像素级监督，现有方法常引入语义幻觉，导致目标类别物体（如交通标志、车辆和人造光效果）被错误合成，从而显著降低下游性能。

Method: 提出了一种新颖的框架，用于在非配对翻译过程中检测和抑制目标类别特征的幻觉。通过设计一个双头判别器来执行语义分割以识别背景区域中的幻觉内容。引入了类别特定原型，通过聚合标注的目标域对象的特征构建，作为每个类别的语义锚点。该框架建立在基于薛定谔桥的翻译模型之上，执行迭代细化，将检测到的幻觉特征在特征空间中明确地推离类别原型，从而在翻译过程中保留对象语义。

Result: 在定性和定量方面均优于现有方法。在BDD100K数据集上，该方法将日夜域适应的mAP提高了15.5%，对于容易产生幻觉的类别（如交通信号灯），增幅达到了31.7%。

Conclusion: 该方法有效解决了日夜图像翻译中的语义幻觉问题，显著提升了下游任务的性能，并超越了现有方法。

Abstract: Day-to-night unpaired image translation is important to downstream tasks but remains challenging due to large appearance shifts and the lack of direct pixel-level supervision. Existing methods often introduce semantic hallucinations, where objects from target classes such as traffic signs and vehicles, as well as man-made light effects, are incorrectly synthesized. These hallucinations significantly degrade downstream performance. We propose a novel framework that detects and suppresses hallucinations of target-class features during unpaired translation. To detect hallucination, we design a dual-head discriminator that additionally performs semantic segmentation to identify hallucinated content in background regions. To suppress these hallucinations, we introduce class-specific prototypes, constructed by aggregating features of annotated target-domain objects, which act as semantic anchors for each class. Built upon a Schrodinger Bridge-based translation model, our framework performs iterative refinement, where detected hallucination features are explicitly pushed away from class prototypes in feature space, thus preserving object semantics across the translation show that our method outperforms existing approaches both qualitatively and quantitatively. On the BDD100K dataset, it improves mAP by 15.5% for day-to-night domain adaptation, with a notable 31.7% gain for classes such as traffic lights that are prone to hallucinations.

</details>


### [16] [Efficient Generative Modeling beyond Memoryless Diffusion via Adjoint Schrödinger Bridge Matching](https://arxiv.org/abs/2602.15396)
*Jeongwoo Shin,Jinhwan Sul,Joonseok Lee,Jaewong Choi,Jaemoo Choi*

Main category: cs.CV

TL;DR: Adjoint Schrödinger Bridge Matching (ASBM)是一种生成建模框架，通过分两阶段学习最优的Schrödinger Bridge前向动态和后向生成动态，在高维空间中恢复最优轨迹。它能生成更直、更高效的采样路径，并在图像生成中以更少的采样步骤提高保真度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型由于无信息、无记忆的前向过程导致独立的数据-噪声耦合，通常产生高度弯曲的轨迹和噪声分数目标。

Method: 提出Adjoint Schrödinger Bridge Matching (ASBM)框架。第一阶段，将Schrödinger Bridge (SB)前向动态视为耦合构建问题，通过数据到能量采样的视角学习，将数据传输到能量定义的先验。第二阶段，通过由诱导的最优耦合监督的简单匹配损失学习后向生成动态。

Result: ASBM产生了显著更直、更高效的采样路径。与现有工作相比，ASBM在处理高维数据时具有显著提高的稳定性和效率。在图像生成上的大量实验表明，ASBM以更少的采样步骤提高了保真度。通过蒸馏到一步生成器，进一步展示了其最优轨迹的有效性。

Conclusion: ASBM提供了一个稳定高效的生成建模框架，通过学习最优、更少弯曲的轨迹，克服了传统扩散模型中无记忆前向过程的局限性，从而在图像生成中以更少的采样步骤实现了更高的保真度。

Abstract: Diffusion models often yield highly curved trajectories and noisy score targets due to an uninformative, memoryless forward process that induces independent data-noise coupling. We propose Adjoint Schrödinger Bridge Matching (ASBM), a generative modeling framework that recovers optimal trajectories in high dimensions via two stages. First, we view the Schrödinger Bridge (SB) forward dynamic as a coupling construction problem and learn it through a data-to-energy sampling perspective that transports data to an energy-defined prior. Then, we learn the backward generative dynamic with a simple matching loss supervised by the induced optimal coupling. By operating in a non-memoryless regime, ASBM produces significantly straighter and more efficient sampling paths. Compared to prior works, ASBM scales to high-dimensional data with notably improved stability and efficiency. Extensive experiments on image generation show that ASBM improves fidelity with fewer sampling steps. We further showcase the effectiveness of our optimal trajectory via distillation to a one-step generator.

</details>


### [17] [Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461)
*Marija Ivanovska,Vitomir Štruc*

Main category: cs.CV

TL;DR: 本文首次对开源多模态大语言模型（MLLMs）在单幅图像活体攻击检测（MAD）方面的零样本评估进行了系统研究。结果显示，MLLMs在不进行微调的情况下，在多种活体攻击技术上表现出非凡的判别能力，其中LLaVA1.6-Mistral-7B模型在等错误率（EER）方面超越了现有基线至少23%，达到了最先进的水平。研究表明多模态预训练能隐式编码面部不一致性，为生物识别安全和法医图像分析提供了新的可复现、可解释的竞争力基础。


<details>
  <summary>Details</summary>
Motivation: 面部活体攻击威胁生物识别验证，而现有活体攻击检测（MAD）系统大多需要任务特定的训练，并且对未见过的攻击类型泛化能力差。同时，开源多模态大语言模型（MLLMs）展现出强大的视觉-语言推理能力，但其在生物识别取证领域的潜力尚未得到充分探索。

Method: 本研究首次对开源多模态大语言模型（MLLMs）进行系统性的零样本评估，用于单幅图像活体攻击检测（MAD）。评估使用了公开可用的模型权重和标准化的、可复现的协议，涵盖了多种活体攻击技术。

Result: 许多MLLMs在不进行任何微调或领域适应的情况下，展现出显著的判别能力。其中，LLaVA1.6-Mistral-7B模型达到了最先进的性能，在等错误率（EER）方面超越了高竞争力的任务特定MAD基线至少23%。结果表明，多模态预训练能够隐式编码指示活体攻击伪影的细微面部不一致性，从而实现零样本的取证敏感性。

Conclusion: 开源多模态大语言模型（MLLMs）为生物识别安全和法医图像分析提供了可复现、可解释且具有竞争力的新基础。这项新兴能力也预示着通过有针对性的微调或轻量级适应来开发最先进的活体攻击检测（MAD）系统的新机会，从而在保持可解释性的同时进一步提高准确性和效率。

Abstract: Face morphing attacks threaten biometric verification, yet most morphing attack detection (MAD) systems require task-specific training and generalize poorly to unseen attack types. Meanwhile, open-source multimodal large language models (MLLMs) have demonstrated strong visual-linguistic reasoning, but their potential in biometric forensics remains underexplored. In this paper, we present the first systematic zero-shot evaluation of open-source MLLMs for single-image MAD, using publicly available weights and a standardized, reproducible protocol. Across diverse morphing techniques, many MLLMs show non-trivial discriminative ability without any fine-tuning or domain adaptation, and LLaVA1.6-Mistral-7B achieves state-of-the-art performance, surpassing highly competitive task-specific MAD baselines by at least 23% in terms of equal error rate (EER). The results indicate that multimodal pretraining can implicitly encode fine-grained facial inconsistencies indicative of morphing artifacts, enabling zero-shot forensic sensitivity. Our findings position open-source MLLMs as reproducible, interpretable, and competitive foundations for biometric security and forensic image analysis. This emergent capability also highlights new opportunities to develop state-of-the-art MAD systems through targeted fine-tuning or lightweight adaptation, further improving accuracy and efficiency while preserving interpretability. To support future research, all code and evaluation protocols will be released upon publication.

</details>


### [18] [RPT-SR: Regional Prior attention Transformer for infrared image Super-Resolution](https://arxiv.org/abs/2602.15490)
*Youngwan Jin,Incheol Park,Yagiz Nalcakan,Hyeongjin Ju,Sanghyeop Yeo,Shiho Kim*

Main category: cs.CV

TL;DR: RPT-SR是一种新型红外图像超分辨率Vision Transformer模型，专为固定视角的红外场景设计。它通过结合区域先验令牌和局部令牌的双令牌框架来利用持久空间先验，在不同红外波段（LWIR和SWIR）上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 通用超分辨率模型（特别是Vision Transformers）在固定或准静态视角的红外成像场景（如监控和自动驾驶）中效率低下，因为它们未能利用此类场景中固有的强大、持久的空间先验，导致冗余学习和次优性能。

Method: 本文提出了用于红外图像超分辨率的区域先验注意力Transformer (RPT-SR)。该模型通过双令牌框架将场景布局信息明确编码到注意力机制中，该框架融合了：1) 可学习的区域先验令牌（作为场景全局结构的持久记忆）；2) 局部令牌（捕获当前输入的帧特定内容）。通过在注意力机制中利用这些令牌，模型允许先验动态调节局部重建过程。

Result: 广泛的实验验证了该方法。RPT-SR在涵盖长波（LWIR）和短波（SWIR）光谱的各种数据集中建立了新的最先进性能，证明了其广泛的适用性和多功能性，与大多数专注于单一红外波段的现有工作不同。

Conclusion: RPT-SR通过新颖的双令牌注意力机制，利用持久的空间先验，有效解决了通用超分辨率模型在固定视角红外成像中的效率低下问题，并在各种红外波段上取得了卓越的性能。

Abstract: General-purpose super-resolution models, particularly Vision Transformers, have achieved remarkable success but exhibit fundamental inefficiencies in common infrared imaging scenarios like surveillance and autonomous driving, which operate from fixed or nearly-static viewpoints. These models fail to exploit the strong, persistent spatial priors inherent in such scenes, leading to redundant learning and suboptimal performance. To address this, we propose the Regional Prior attention Transformer for infrared image Super-Resolution (RPT-SR), a novel architecture that explicitly encodes scene layout information into the attention mechanism. Our core contribution is a dual-token framework that fuses (1) learnable, regional prior tokens, which act as a persistent memory for the scene's global structure, with (2) local tokens that capture the frame-specific content of the current input. By utilizing these tokens into an attention, our model allows the priors to dynamically modulate the local reconstruction process. Extensive experiments validate our approach. While most prior works focus on a single infrared band, we demonstrate the broad applicability and versatility of RPT-SR by establishing new state-of-the-art performance across diverse datasets covering both Long-Wave (LWIR) and Short-Wave (SWIR) spectra

</details>


### [19] [Semantic-Guided 3D Gaussian Splatting for Transient Object Removal](https://arxiv.org/abs/2602.15516)
*Aditi Prabakaran,Priyesh Shukla*

Main category: cs.CV

TL;DR: 提出了一种基于语义过滤的框架，利用视觉-语言模型（如CLIP）通过分类识别瞬态对象，以解决3D高斯泼溅重建中瞬态对象导致的伪影问题，该方法在RobustNeRF基准测试上显著提高了重建质量，同时保持了较低的内存开销和实时渲染性能。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅(3DGS)重建中，随意多视角捕获中的瞬态对象会导致鬼影伪影。现有解决方案存在内存开销大或受视差模糊影响的缺点。

Method: 提出了一种语义过滤框架，利用视觉-语言模型（如CLIP）进行类别感知的瞬态去除。具体做法是：在训练迭代中，累积渲染视图与干扰文本提示之间的CLIP相似性得分，对于每个高斯点。超过校准阈值的高斯点会进行不透明度正则化和周期性修剪。该方法通过独立于运动模式识别物体类别来解决视差模糊。

Result: 在RobustNeRF基准测试的四个序列上，相对于普通3DGS，重建质量得到了显著提升，同时保持了最小的内存开销和实时渲染性能。

Conclusion: 阈值校准和与基线的比较验证了语义引导是一种在可预测干扰类别场景中去除瞬态对象的实用策略。

Abstract: Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.

</details>


### [20] [Advanced Acceptance Score: A Holistic Measure for Biometric Quantification](https://arxiv.org/abs/2602.15535)
*Aman Verma,Seshan Srirangarajan,Sumantra Dutta Roy*

Main category: cs.CV

TL;DR: 本文提出了一种名为“高级接受度得分”的新型整体评估指标，用于量化手势生物特征的适应度得分质量，该指标比现有方法更合适且可靠。


<details>
  <summary>Details</summary>
Motivation: 量化手势中的生物特征涉及从手势和身份感知特征空间中导出适应度得分。然而，评估这些得分的质量仍然是一个悬而未决的问题。现有的生物识别能力估计文献依赖于错误率，但这些错误率并不能指示得分的优劣。因此，本文旨在提出一套全面的评估方法来解决这一问题。

Method: 本文首先将输出分数的排序顺序和相关性作为评估的主要基础。具体而言，考虑了排序偏差以及对高排名手势的高分数和低排名手势的低分数的奖励。此外，还补偿了输出分数和真实分数趋势之间的对应关系，并考虑了手势身份特征之间的解耦作为折扣因子。通过将这些元素与适当的权重相结合，本文提出了一种整体评估指标——“高级接受度得分”。为了评估所提出方法的有效性，在三个数据集上使用五个最先进的模型进行了深入的实验。

Result: 实验结果表明，使用本文提出的度量标准选择的最优分数比现有其他度量标准更合适。此外，本文提出的度量标准与现有度量标准表现出相关性，进一步验证了其可靠性。

Conclusion: 本文提出了一种新颖的整体评估指标“高级接受度得分”，该指标在评估手势生物特征的适应度得分方面比现有方法更合适且可靠。

Abstract: Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \href{ }{code} public.

</details>


### [21] [Dynamic Training-Free Fusion of Subject and Style LoRAs](https://arxiv.org/abs/2602.15539)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种动态的、免训练的LoRA融合框架，通过在正向传播中进行特征级权重选择和在逆向去噪中进行基于度量的梯度校正，实现了连贯的主题-风格合成，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多LoRA组合方法在生成用户指定的主题和风格时，大多采用静态统计启发式方法融合LoRA权重，这偏离了LoRA学习自适应特征调整的初衷，且忽略了采样输入的随机性。

Method: 本文提出了一种动态的、免训练的融合框架。在生成过程的正向传播阶段，对于每个应用LoRA的层，通过计算基础模型原始特征与主题LoRA及风格LoRA生成特征之间的KL散度，自适应地选择最合适的权重进行融合。在逆向去噪阶段，通过动态应用基于CLIP和DINO分数等目标度量导出的梯度校正，进一步优化生成轨迹，提供持续的语义和风格指导。该方法结合了特征级选择和度量引导的潜在空间调整这两种互补机制，贯穿整个扩散时间线。

Result: 广泛的实验表明，在多样化的主题-风格组合上，本文方法在定性和定量上均优于现有的最先进LoRA融合方法。

Conclusion: 该方法通过动态的特征级选择和度量引导的潜在空间调整，实现了无需重新训练即可生成连贯的主题-风格合成图像，并在定性和定量评估中优于现有LoRA融合方法。

Abstract: Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.

</details>


### [22] [Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2602.15556)
*Guangtao Lyu,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Xueting Li,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 针对LVLM幻觉问题，本文提出免训练注意力干预方法PADE。该方法利用模型内部的正向注意力动态（PAD）识别核心视觉区域，并通过自适应干预和系统-token补偿来提高视觉基础和减少幻觉，实验证实其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型多模态语言模型（LVLMs）在多模态推理方面表现出色，但仍容易产生幻觉，即输出与视觉输入或用户指令不一致。现有免训练方法（如对比解码和辅助专家模型）计算开销大、可能引入干扰，且静态内部信号增强方法易受注意力槽（attention sink）现象的影响。

Method: 提出了一种免训练的注意力干预方法PADE（Positive Attention Dynamics Enhancement）。该方法通过构建PAD（Positive Attention Dynamics）图来识别语义核心视觉区域，采用逐头中位绝对偏差缩放（per-head Median Absolute Deviation Scaling）自适应控制干预强度，并利用系统-token补偿（System-Token Compensation）来维持对复杂用户指令的注意力并支持长期输出一致性。

Result: 在多个LVLM和基准测试上的实验表明，PADE显著改善了视觉基础能力并有效减少了幻觉。

Conclusion: 证明了利用内部注意力动态对于实现可靠多模态推理的有效性。

Abstract: LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.

</details>


### [23] [Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning](https://arxiv.org/abs/2602.15579)
*Amal Lahchim,Lambros Athanasiou*

Main category: cs.CV

TL;DR: 本文提出了一种全自动机器学习流程，用于高精度地在OCT图像中进行血管分割和分类，并取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管冠状动脉光学相干断层成像（OCT）能高分辨率可视化冠状动脉血管解剖结构，但其分析面临噪声、成像伪影和复杂组织结构带来的挑战。

Method: 该方法是一个全自动的血管分割和分类流程，集成了图像预处理、导丝伪影去除、极坐标到笛卡尔坐标转换、无监督K-means聚类以及局部特征提取。提取的特征随后用于训练逻辑回归（Logistic Regression）和支持向量机（Support Vector Machine）分类器，以实现像素级的血管分类。

Result: 实验结果表明该方法表现出色，实现了高达1.00的精确度（precision）、召回率（recall）和F1分数，以及99.68%的整体分类准确率。该方法能够准确检测血管边界，同时保持较低的计算复杂性并仅需最少的人工标注。

Conclusion: 该方法为自动化OCT图像分析提供了一个可靠且高效的解决方案，并有望应用于临床决策支持和实时医学图像处理。

Abstract: Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.

</details>


### [24] [An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment](https://arxiv.org/abs/2602.15584)
*Flavien Armangeon,Thibaud Ehret,Enric Meinhardt-Llopis,Rafael Grompone von Gioi,Guillaume Thibault,Marc Petit,Gabriele Facciolo*

Main category: cs.CV

TL;DR: 本文介绍了IRIS-v2，一个全面的数据集，以解决工业设施功能图与2D和3D场景数据对齐的挑战，并通过结合分割和图匹配来减少对齐时间。


<details>
  <summary>Details</summary>
Motivation: 由于现有手动对齐方法的繁琐性、工业现场的复杂性、图纸与实际不一致以及缺乏公开的工业数据集，导致旧工业设施功能图与2D和3D场景数据对齐难以扩展。

Method: 该论文引入了一个名为IRIS-v2的综合数据集，并提出了一种结合分割和图匹配的对齐方法。

Result: 该方法旨在减少功能图与2D和3D场景对齐所需的时间。

Conclusion: IRIS-v2数据集支持未来研究，并且结合分割和图匹配的方法旨在减少功能图与2D/3D场景对齐所需的时间。

Abstract: Aligning functional schematics with 2D and 3D scene acquisitions is crucial for building digital twins, especially for old industrial facilities that lack native digital models. Current manual alignment using images and LiDAR data does not scale due to tediousness and complexity of industrial sites. Inconsistencies between schematics and reality, and the scarcity of public industrial datasets, make the problem both challenging and underexplored. This paper introduces IRIS-v2, a comprehensive dataset to support further research. It includes images, point clouds, 2D annotated boxes and segmentation masks, a CAD model, 3D pipe routing information, and the P&ID (Piping and Instrumentation Diagram). The alignment is experimented on a practical case study, aiming at reducing the time required for this task by combining segmentation and graph matching.

</details>


### [25] [Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation](https://arxiv.org/abs/2602.15650)
*Marco Salmè,Federico Siciliano,Fabrizio Silvestri,Paolo Soda,Rosa Sicilia,Valerio Guarrasi*

Main category: cs.CV

TL;DR: 该论文提出了概念增强多模态RAG（CEMRAG），这是一个统一的框架，通过将视觉表征分解为可解释的临床概念并与多模态RAG集成，改进了放射学报告生成（RRG）中的可解释性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 通过视觉语言模型（VLMs）进行放射学报告生成（RRG）在临床应用中面临挑战，因为缺乏可解释性以及容易产生与影像证据不符的幻觉。现有研究通常将可解释性和准确性视为独立目标。

Method: 本文提出了概念增强多模态RAG（CEMRAG），这是一个统一的框架，它将视觉表征分解为可解释的临床概念，并将其与多模态RAG集成。这种方法利用丰富的上下文提示进行RRG。

Result: 在MIMIC-CXR和IU X-Ray数据集上，针对多种VLM架构、训练方案和检索配置进行的实验表明，CEMRAG在临床准确性指标和标准NLP衡量标准上，持续优于传统的RAG和仅概念基线。这些结果挑战了可解释性和性能之间的假设权衡，表明透明的视觉概念可以增强而非损害医学VLM的诊断准确性。

Conclusion: CEMRAG通过增强可解释性和事实准确性，为临床上可信赖的AI辅助放射学提供了一条原则性途径，证明了透明的视觉概念可以提高诊断准确性。

Abstract: Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.

</details>


### [26] [A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models](https://arxiv.org/abs/2602.15656)
*Mustafa Yurdakul,Zeynep Sena Bastug,Ali Emre Gok,Sakir Taşdemir*

Main category: cs.CV

TL;DR: 该研究引入了一个新的公开草莓成熟度数据集，并在其上评估了YOLO模型，发现YOLOv8s在mAP@50方面表现最佳，为智能农业应用建立了基础参考点。


<details>
  <summary>Details</summary>
Motivation: 草莓成熟度的传统视觉评估方法主观且易出错，急需计算机辅助系统。然而，缺乏全面、可访问的数据集阻碍了该领域研究的比较。

Method: 研究创建了一个新的公开草莓成熟度数据集，包含566张图像和1,201个标记对象，数据在土耳其的两个不同温室中、可变光照和环境条件下收集。使用基于YOLOv8、YOLOv9和YOLO11的模型对该数据集进行了比较测试。

Result: YOLOv9c模型获得了最高精度（90.94%），YOLO11s模型获得了最高召回率（83.74%）。在通用性能指标mAP@50方面，YOLOv8s模型表现最佳，成功率为86.09%。结果表明，小型和中型模型在此类数据集上工作更平衡和高效。

Conclusion: 本研究为智能农业应用建立了基础参考点，表明小型和中型YOLO模型在此类数据集上表现出有效的平衡和效率。

Abstract: The strawberry (Fragaria x ananassa), known worldwide for its economic value and nutritional richness, is a widely cultivated fruit. Determining the correct ripeness level during the harvest period is crucial for both preventing losses for producers and ensuring consumers receive a quality product. However, traditional methods, i.e., visual assessments alone, can be subjective and have a high margin of error. Therefore, computer-assisted systems are needed. However, the scarcity of comprehensive datasets accessible to everyone in the literature makes it difficult to compare studies in this field. In this study, a new and publicly available strawberry ripeness dataset, consisting of 566 images and 1,201 labeled objects, prepared under variable light and environmental conditions in two different greenhouses in Turkey, is presented to the literature. Comparative tests conducted on the data set using YOLOv8, YOLOv9, and YOLO11-based models showed that the highest precision value was 90.94% in the YOLOv9c model, while the highest recall value was 83.74% in the YOLO11s model. In terms of the general performance criterion mAP@50, YOLOv8s was the best performing model with a success rate of 86.09%. The results show that small and medium-sized models work more balanced and efficiently on this type of dataset, while also establishing a fundamental reference point for smart agriculture applications.

</details>


### [27] [Bayesian Optimization for Design Parameters of 3D Image Data Analysis](https://arxiv.org/abs/2602.15660)
*David Exler,Joaquin Eduardo Urrutia Gómez,Martin Krüger,Maike Schliephake,John Jbeily,Mario Vitacolonna,Rüdiger Rudolf,Markus Reischl*

Main category: cs.CV

TL;DR: 该研究提出了一种名为3D数据分析优化管道的方法，通过两个贝叶斯优化阶段，自动化地优化3D生物医学图像的分割模型选择、后处理参数和分类器设计，并引入辅助标注流程，以解决模型选择和参数调整的瓶颈，减少手动分析工作量。


<details>
  <summary>Details</summary>
Motivation: 在大型3D生物医学图像分析中，手动分析不切实际，而深度学习的分割和分类至关重要。然而，选择合适的模型和调整参数在实践中仍然是一个主要瓶颈。

Method: 该方法引入了3D数据分析优化管道，它包含两个贝叶斯优化阶段。第一阶段，使用领域适应的合成基准数据集选择分割模型并优化后处理参数，并引入了一个分割质量指标作为目标函数。第二阶段，优化分类器的设计选择，如编码器和分类器头架构、先验知识的整合和预训练策略；此阶段还包含一个辅助类别标注工作流以减少手动标注工作量。

Result: 在四个案例研究中，3D数据分析优化管道能够高效地为单个数据集识别有效的模型和参数配置。

Conclusion: 该管道通过自动化模型选择和参数调整、减少标注工作量，促进了3D生物医学图像分割和分类的设计与参数化。

Abstract: Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.

</details>


### [28] [Criteria-first, semantics-later: reproducible structure discovery in image-based sciences](https://arxiv.org/abs/2602.15712)
*Jan Bumberger*

Main category: cs.CV

TL;DR: 针对自然科学和生命科学中图像分析的局限性，本文提出一种“准则优先、语义在后”的统一框架，将语义无关的结构提取与下游的语义映射分离，以实现可复现的、跨领域和长期监测的图像分析。


<details>
  <summary>Details</summary>
Motivation: 当前的图像分析范式是“语义优先”，通过预测或强制执行特定领域标签来恢复结构。这种范式在图像科学最有价值的条件下（如开放式科学发现、跨传感器/站点可比性、以及领域本体和标签集随时间漂移的长期监测）系统性地失效。

Method: 本文提出一种“准则优先、语义在后”的演绎反演方法。引入了一个统一的框架用于“准则优先”的结构发现，它将由明确准则定义的、语义无关的结构提取与下游映射到领域本体或词汇表中的语义过程分离。

Result: 该方法为基于图像的科学分析提供了一个可复现的、领域通用的支架。它生成由明确优化准则定义的稳定分区、结构场或层次结构，而非依赖局部领域本体。语义被重新定位到下游，作为发现的结构产品到领域本体或词汇表的明确映射，从而实现多元解释和显式交叉引用，而无需重写上游提取过程。基于控制论、观察即区分和信息论，该方法在标签无法扩展时能反复出现。

Conclusion: 可复现的科学要求第一分析层执行准则驱动、语义无关的结构发现。该方法还概述了超越类别准确性的验证，以及将结构产品视为用于长期监测和数字孪生的FAIR（可查找、可访问、可互操作、可重用）、AI就绪的数字对象的意义。

Abstract: Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.

</details>


### [29] [Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation](https://arxiv.org/abs/2602.15724)
*Shutian Gu,Chengkai Huang,Ruoyu Wang,Lina Yao*

Main category: cs.CV

TL;DR: 本文提出了一种检索增强框架，通过引入指令级范例检索和步骤级候选修剪，提高了基于LLM的视觉语言导航（VLN）的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在视觉语言导航（VLN）中，基于提示的LLM导航由于模型需要重复从头解释指令并在每一步对嘈杂且冗长的可导航候选进行推理，导致决策效率低下。

Method: 本文提出了一种检索增强框架，通过在两个互补的层面引入检索来提高效率和稳定性。在篇章层面，指令级嵌入检索器选择语义相似的成功导航轨迹作为上下文范例。在步骤层面，模仿学习的候选检索器在LLM推理之前修剪不相关的可导航方向。这两个检索模块都是轻量级、模块化的，并且独立于LLM进行训练。

Result: 在Room-to-Room (R2R) 基准测试中，我们的方法在已见和未见环境中都显著提高了成功率、Oracle成功率和SPL。消融研究进一步表明，指令级范例检索和候选修剪对全局指导和分步决策效率提供了互补的好处。

Conclusion: 检索增强的决策支持是增强基于LLM的视觉语言导航的一种有效且可扩展的策略。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.

</details>


### [30] [Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding](https://arxiv.org/abs/2602.15734)
*Guile Wu,David Huang,Bingbing Liu,Dongfeng Bai*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.

</details>


### [31] [Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models](https://arxiv.org/abs/2602.15772)
*Sen Ye,Mengde Xu,Shuyang Gu,Di He,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: 该论文提出了Reason-Reflect-Refine (R3) 框架，通过多步“生成-理解-重新生成”过程，解决了多模态模型中生成与理解能力之间的权衡冲突，同时增强了两种能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型研究面临一个关键挑战，即增强生成能力通常会牺牲理解能力，反之亦然。分析认为其主要原因是生成与理解之间可能存在冲突，从而在模型内部形成竞争动态。

Method: 提出Reason-Reflect-Refine (R3) 框架，将单步生成任务重构为“生成-理解-重新生成”的多步过程。通过在生成过程中明确利用模型的理解能力来解决问题。

Result: 成功缓解了优化困境，实现了更强的生成结果，并提高了与生成过程相关的理解能力。

Conclusion: 该框架为设计下一代统一多模态模型提供了有价值的见解。

Abstract: Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of "generate-understand-regenerate". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at .

</details>


### [32] [NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy](https://arxiv.org/abs/2602.15775)
*Laura Salort-Benejam,Antonio Agudo*

Main category: cs.CV

TL;DR: NeRFscopy 是一个自监督管道，用于从单目视频对可变形内窥镜组织进行新视角合成和 3D 重建，它采用神经渲染、可变形模型和高效的图像利用，在准确性上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜在医学成像中至关重要，但从内窥镜视频进行鲁棒的动态 3D 重建面临挑战，包括组织可变形性、单目相机、光照变化、遮挡和未知相机轨迹。开发这样的管道可以增强可视化、提高诊断准确性、辅助治疗计划和指导手术程序。

Method: 该方法引入了 NeRFscopy，一个受神经渲染启发的自监督流程。它包含一个可变形模型，该模型具有一个规范辐射场和一个由 SE(3) 变换参数化的时间相关变形场。此外，通过引入复杂的项来有效利用彩色图像，从而在不假设任何模板或预训练模型的情况下，完全从数据中学习 3D 隐式模型。

Result: NeRFscopy 在新视角合成方面取得了准确的结果，并且在各种具有挑战性的内窥镜场景中优于竞争方法。

Conclusion: NeRFscopy 为单目视频中可变形内窥镜组织的视角合成和 3D 重建提供了一个准确的自监督解决方案，解决了该领域的重大挑战。

Abstract: Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.

</details>


### [33] [Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers](https://arxiv.org/abs/2602.15783)
*Lucas Sancéré,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \pm 1.5$ ($\pm$ standard error) and $85.1 \pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \pm 0.5$.

</details>


### [34] [VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819)
*Hui Ren,Yuval Alaluf,Omer Bar Tal,Alexander Schwing,Antonio Torralba,Yael Vinker*

Main category: cs.CV

TL;DR: 该论文提出了一种数据高效的顺序素描生成方法，通过调整预训练的文本到视频扩散模型来生成素描过程。该方法利用大型语言模型（LLM）进行语义规划和笔画排序，并使用视频扩散模型作为高质量、时间连贯视觉的渲染器。它采用两阶段微调策略，将笔画排序的学习与素描外观的学习解耦，即使只有少量手绘素描数据也能生成高质量的顺序素描。


<details>
  <summary>Details</summary>
Motivation: 大多数生成模型将素描视为静态图像，忽略了创意绘画中固有的时间结构（即笔画以有意义的顺序绘制的顺序过程）。

Method: 该方法通过将素描表示为笔画在空白画布上逐步绘制的短视频，并由文本指定的排序指令引导，来生成素描过程。它利用预训练的文本到视频扩散模型进行调整。其核心思想是结合大型语言模型（LLM）的语义规划和笔画排序能力，以及视频扩散模型的高质量、时间连贯的视觉渲染能力。引入了两阶段微调策略：第一阶段使用具有受控时间结构的合成形状组合来学习笔画排序；第二阶段从极少量的（例如七个）手动制作的素描过程中提取视觉外观，这些过程捕获了全局绘制顺序和单个笔画的连续形成。

Result: 尽管人类绘制的素描数据量极其有限，该方法仍能生成高质量的顺序素描，这些素描严格遵循文本指定的顺序，并展现出丰富的视觉细节。此外，该方法通过画笔风格条件和自回归素描生成等扩展，展示了其灵活性，实现了额外的可控性和交互式、协作式绘画。

Conclusion: 该研究成功地开发了一种数据高效且灵活的顺序素描生成方法，能够生成遵循文本指定顺序并具有丰富视觉细节的高质量素描。它克服了现有模型对素描时间结构的忽视，并为交互式和协作式绘画应用提供了新的可能性。

Abstract: Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [35] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: EduResearchBench是一个针对教育学术写作的综合评估平台，通过分层原子任务分解框架评估LLM在学术写作中的能力。研究提出了课程学习策略，并训练了专用模型EduWrite，结果显示，在垂直领域，数据质量密度和分层训练课程比参数规模更具决定性。


<details>
  <summary>Details</summary>
Motivation: 现有基准评估LLM学术写作能力时，侧重单一、整体性生成，缺乏反映复杂学术研究工作流的细粒度评估。

Method: 引入EduResearchBench，首个专注于教育学术写作的综合评估平台，基于分层原子任务分解（HATD）框架，将研究工作流分解为六个研究模块和24个细粒度原子任务。提出了课程学习策略，从基础技能逐步培养能力。利用5.5万原始学术样本，整理了1.1万高质量指令对，训练了专门的教育学术写作模型EduWrite。

Result: 实验表明，EduWrite（30B）在多项核心指标上显著优于更大的通用模型（72B）。

Conclusion: 在垂直领域，数据质量密度和分层阶段式训练课程比参数规模更具决定性。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [36] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: 提出了一种名为Indic-TunedLens的新型框架，用于印度语言的多语言LLM解释性，通过学习共享仿射变换并调整隐藏状态，显著优于现有方法，尤其对形态丰富、低资源语言效果更佳。


<details>
  <summary>Details</summary>
Motivation: 多语言大型语言模型（LLMs）越来越多地部署在印度等语言多样性地区，但大多数解释性工具仍然是为英语量身定制的。先前的研究表明，LLMs通常在以英语为中心的表示空间中运行，使得跨语言解释性成为一个紧迫的问题。

Method: 引入了Indic-TunedLens，这是一个专门用于印度语言的解释性框架，它学习共享的仿射变换。与直接解码中间激活的标准Logit Lens不同，Indic-TunedLens调整每个目标语言的隐藏状态，使它们与目标输出分布对齐，以实现更忠实地解码模型表示。

Result: 在MMLU基准上对10种印度语言进行了评估，发现它显著优于最先进的解释性方法，特别是对于形态丰富、低资源的语言。

Conclusion: 本研究为多语言Transformer的层级语义编码提供了关键见解。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at . Our code is available at .

</details>


### [37] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 本文提出了一种名为CGRA DeBERTa的概念引导残差领域增强Transformer框架，用于增强对《圣训》语料库的神学问答。该模型通过结合概念先验知识和选择性令牌放大，在准确性方面显著超越了现有模型，同时保持了计算效率。


<details>
  <summary>Details</summary>
Motivation: 由于领域特定语义、长上下文依赖和概念敏感推理，对古典伊斯兰文本进行精确问答仍然具有挑战性。

Method: CGRA DeBERTa模型建立在定制的DeBERTa Transformer骨干上，采用轻量级LoRA自适应和残差概念感知门控机制。定制的DeBERTa嵌入块学习全局和位置上下文，而概念引导残差块则从包含12个核心术语的伊斯兰概念词典中融入神学先验知识。概念门控机制通过重要性加权注意力选择性地放大语义关键令牌，应用1.04至3.00的差异化缩放，同时保持上下文完整性、强化领域特定语义表示并实现准确高效的跨度提取，同时保持计算效率。

Result: CGRA模型在专门构建的42591个问答对数据集上进行了训练。CGRA DeBERTa的EM分数达到97.85，相较于BERT的75.87和DeBERTa的89.77，绝对提高了8.08分。该模型仅增加了约8%的推理开销。定性评估显示其在提取、辨别和神学精确性方面表现更佳。

Conclusion: 本研究提出了高效、可解释且准确的圣训问答系统，能够提供具有必要神学细微差别的教育材料。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [38] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 该论文介绍了他们在AVerImaTeC共享任务中获得第三名的系统，该系统结合了检索增强生成（RAG）管道和反向图像搜索（RIS）模块，实现了具有竞争力的性能，成本效益高且易于复现。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是展示其在AVerImaTeC共享任务中获得第三名的系统，并由于其简单性、竞争性能和易于复现性，将其作为进一步实验的入门级系统。

Method: 该系统结合了检索增强生成（RAG）管道和反向图像搜索（RIS）模块。它由三个解耦模块组成：基于相似性搜索的文本检索模块、基于API访问的RIS的图像检索模块以及使用GPT5.1的生成模块。

Result: 该系统在AVerImaTeC共享任务中获得了第三名，每次事实核查只需一次多模态LLM调用即可提供有竞争力的性能，使用OpenAI Batch API通过GPT5.1的平均成本为0.013美元。

Conclusion: 该论文建议将其系统作为进一步实验的易于访问的起点，并公开了代码、提示、向量存储以及对方案运行成本和进一步改进方向的见解。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [39] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 本研究关注LLM智能体在使用不透明工具时面临的挑战，为此提出了OpaqueToolsBench基准来评估智能体在不明确工具环境下的表现，并提出了一种名为ToolObserver的框架，通过观察工具调用轨迹的执行反馈来迭代改进工具文档。ToolObserver在OpaqueToolsBench上表现优于现有方法，且更高效。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM智能体基准假设工具文档完善，但现实世界中的工具（如通用搜索API）往往不透明，缺乏明确的最佳实践或失败模式，这限制了LLM智能体在实际任务中的表现。因此，研究LLM智能体如何通过交互和改进文档来提高在不透明工具环境中的性能是必要的。

Method: 1. 创建了OpaqueToolsBench，一个包含三个不同面向任务环境的基准：通用函数调用、交互式国际象棋和长轨迹智能体搜索。每个环境都提供未充分说明的工具，模型必须学习有效使用这些工具来完成任务。2. 提出了一种名为ToolObserver的简单框架，该框架通过观察工具调用轨迹的执行反馈来迭代细化工具文档。

Result: 1. 现有自动文档工具的方法在工具不透明时成本高昂且不可靠。2. ToolObserver方法在OpaqueToolsBench上的所有数据集上均优于现有方法，即使在相对困难的设置中也是如此。3. 在测试时工具探索设置中，ToolObserver方法也具有高效率，消耗的总token数比最佳基线少3.5-7.5倍。

Conclusion: ToolObserver框架通过观察工具执行反馈来迭代细化工具文档，有效解决了LLM智能体在不透明工具环境中使用工具的挑战，显著提升了LLM智能体的性能和效率。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [40] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: 本研究介绍了Linguistic eXtractor (LX)，一个用于测量消费者情感和评估的微调大型语言模型。LX在准确性上超越了现有模型，并揭示了情感如何直接或通过产品评分影响购买行为，为营销研究提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 从非结构化文本中准确测量消费者情感和评估，仍然是营销研究和实践的核心挑战。

Method: 本研究引入了Linguistic eXtractor (LX)模型，这是一个经过消费者撰写文本微调的大型语言模型，这些文本还带有消费者自报的16种消费相关情感和4种评估构念（信任、承诺、推荐和情绪）的评分标签。研究将LX应用于在线零售数据，使用看似不相关的回归分析。

Result: LX在开放式调查回复中实现了81%的macro-F1准确率，在第三方标注的Amazon和Yelp评论中实现了超过95%的准确率，持续优于GPT-4 Turbo、RoBERTa和DeepSeek等领先模型。应用结果证实，评论中表达的情感可以预测产品评分，而产品评分反过来又可以预测购买行为。大多数情感效应由产品评分介导，但有些情感（如不满和平静）直接影响购买，表明情感语调提供了超越星级评分的有意义信号。

Conclusion: 这项研究为消费者感知测量建立了新的方法论基础，展示了利用大型语言模型推进营销研究和实践的新方法，从而实现了对消费者数据中营销构念的有效检测。

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [41] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis是一个为LLMs设计的新型记忆框架，它通过结合System-1相似性搜索和System-2全局选择机制，并利用基础图和分层图组织记忆，解决了现有方法在全局推理上的不足，并在长期记忆基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）记忆检索方法（如RAG和Graph-RAG）主要通过基于相似性的机制（System-1风格检索）来检索历史消息。这种方法虽然高效，但在需要全局推理或全面覆盖所有相关信息的场景中表现不佳。

Method: Mnemis是一个新颖的内存框架，它将System-1相似性搜索与System-2机制（称为全局选择）相结合。该框架将记忆组织成一个用于相似性检索的基础图和一个用于语义层次结构自上而下、深思熟虑遍历的层次图。这种方法结合了两种检索路径的互补优势，以检索语义和结构上都相关的记忆项。

Result: Mnemis在长期记忆基准测试中超越了所有比较方法，使用GPT-4.1-mini在LoCoMo上获得93.9分，在LongMemEval-S上获得91.6分，达到了最先进的性能。

Conclusion: Mnemis通过结合System-1和System-2检索机制，并利用新型图结构，有效解决了现有LLM内存检索方法的局限性，在长期记忆任务中实现了卓越性能。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [42] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: 本文介绍了NeuroSymActive，一个结合神经符号推理和价值引导探索的框架，用于知识图谱问答，在提高准确性的同时减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型和神经推理系统在处理需要精确、结构化多跳推理的知识密集型查询时面临挑战。将图结构与神经模型集成并非易事，因为将图事实嵌入到提示中效率低下且脆弱，而纯符号或大量搜索的方法在检索中成本高昂，且缺乏基于梯度的优化。

Method: NeuroSymActive是一个模块化框架，结合了可微分的神经符号推理层和主动的、价值引导的知识图谱问答探索控制器。该方法将软统一风格的符号模块与神经路径评估器和蒙特卡洛风格的探索策略相结合，优先扩展高价值路径。

Result: 在标准KGQA基准测试中，NeuroSymActive取得了强大的答案准确性，同时与常见的检索增强基线相比，减少了昂贵的图查找和模型调用次数。

Conclusion: NeuroSymActive在知识图谱问答任务中展现出强大的答案准确性，同时显著降低了图查找和模型调用的开销，优于现有的检索增强基线方法。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [43] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 本研究展示了通过结构化提示，LLMs可以在极低资源语言（如图卢语）上实现基本对话能力，通过结合语法文档、负面约束和合成数据，显著降低了词汇污染并提高了语法准确性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能在其训练数据中几乎没有的语言（如图卢语，一种拥有200万以上使用者但数字存在极少的德拉维语）中进行对话。旨在通过结构化提示，在不微调LLM的情况下，能否诱导基本的对话能力。

Method: 通过结构化提示、结合显式语法文档、负面约束（抑制相关语言高概率词元）、罗马化标准化以及通过自玩生成质量受控的合成数据来解决图卢语训练数据缺失的挑战。评估在人工策划的保留集上进行，并由母语者验证。

Result: 将词汇污染从80%降至5%，同时实现了85%的语法准确性。跨模型分析显示，负面约束持续带来12-18个百分点的改进，而语法文档的效果因模型架构而异（8-22个百分点）。

Conclusion: 通过结合结构化提示、语法文档、负面约束和自玩合成数据，大型语言模型可以在训练数据中几乎不存在的低资源语言（如图卢语）上实现有效的基本对话能力，且模型架构对语法文档效果有显著影响。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [44] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 该研究针对芬兰二战卡累利阿撤离者家庭访谈的数字化档案，开发了一个分类框架并利用大型语言模型（LLM）对其进行了大规模标注，以将35万条休闲活动和组织成员提及转换为结构化数据，用于后续的社会融合研究。


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案虽然能大规模研究社会生活，但直接从文本中提取的信息往往难以定量回答历史学家或社会学家提出的研究问题。尤其在芬兰二战卡累利阿撤离者家庭访谈数据中，提取出了7.1万个独特的活动和组织名称，数量过于庞大无法直接分析。

Method: 研究开发了一个捕捉参与关键方面的分类框架（活动/组织类型、社交性、规律性和体力要求）。通过标注黄金标准数据集进行可靠评估，并测试大型语言模型能否大规模应用该模式。最终采用多模型运行的简单投票方法。

Result: 结果显示，一个开源的大型语言模型能够与专家判断高度匹配。该方法成功标注了35万个实体，生成了一个用于下游社会融合及相关结果研究的结构化资源。

Conclusion: 该研究成功地将大型语言模型应用于数字化历史档案的结构化处理，解决了大规模非结构化数据难以定量分析的问题，为社会学和历史学研究提供了新的工具和资源。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly. We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [45] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在生成复杂且健壮的代码方面面临挑战。TAROT提出了一种测试驱动且能力自适应的课程强化微调方法，通过构建四层测试套件并解耦课程进展与原始奖励分数来优化代码生成，结果表明最佳课程策略与模型的固有能力紧密相关。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）正在改变编码范式，但合成算法复杂和健壮的代码仍然是一个关键挑战。激励LLM的深度推理能力对于克服这一障碍至关重要。现有的强化微调（RFT）方法忽略了测试用例固有的异构难度和粒度，导致奖励信号分布不平衡，进而导致训练期间梯度更新偏差。

Method: 本文提出了测试驱动和能力自适应的课程强化微调（TAROT）方法。TAROT系统地为每个问题构建了一个四层测试套件（基础、中等、复杂、边缘），为课程设计和评估提供了受控的难度景观。TAROT将课程进展与原始奖励分数解耦，从而实现能力条件评估，并从课程策略组合中进行原则性选择。

Result: TAROT促进了稳定的优化和更高效的能力获取。实验结果表明，代码生成中RFT的最佳课程与模型的固有能力密切相关：能力较弱的模型在从易到难的课程中获得更大的收益，而能力较强的模型在先难后易的课程中表现更佳。TAROT持续提高了生成代码的功能正确性和鲁棒性。

Conclusion: TAROT提供了一种可复现的方法，能够根据模型的固有能力自适应地调整课程设计，从而持续提高生成代码的功能正确性和鲁棒性。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at .

</details>


### [46] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 该研究引入了自然语言处理中的“期望检测”任务，构建了RedHOTExpect Reddit语料库（4.5K帖子）来研究患者对治疗的在线期望，并使用大型语言模型进行标注。分析发现，在关于身体疾病或治疗的帖子中，乐观和积极的表达更为突出，且患者主要讨论积极结果。


<details>
  <summary>Details</summary>
Motivation: 患者对其治疗的期望对治疗成功有重要影响，但主要在临床环境中研究。在线平台可能包含患者不愿在其他地方分享的期望。目前尚无研究检查用户在线讨论的期望类型及其表达方式，这可能是因为期望在自然语言处理（NLP）中尚未被研究。

Method: 引入“期望检测”任务。构建RedHOTExpect语料库（4.5K Reddit帖子）以研究医疗领域的期望。使用大型语言模型（LLM）对数据进行银标，并进行手动验证（标签准确率约78%）。在此基础上，分析表征期望的语言模式，并探讨患者的期望及其原因。

Result: 与心理健康语境相比，在关于身体或治疗相关疾病的帖子中，乐观和积极的表达更为明显。在数据集中，患者主要讨论益处而非负面结果。

Conclusion: 该研究引入了期望检测的NLP任务，并构建了RedHOTExpect语料库。研究结果揭示了患者在线表达期望的语言模式，特别是在身体疾病讨论中乐观和积极表达的普遍性，以及对治疗益处的关注。RedHOTExpect语料库可供进一步研究。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from

</details>


### [47] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: 本文介绍了LuxMT，一个基于Gemma 3 27B的卢森堡语机器翻译系统，并在LB-FR和LB-EN翻译上取得了显著提升，甚至对LB-DE也有效。同时，研究探索了LuxEmbedder作为质量评估指标的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了评估机器翻译性能，该研究构建了一个新颖的基准。此外，该研究旨在探索LuxEmbedder作为质量评估指标的潜力。研究动机是为了提高卢森堡语的机器翻译质量，并开发新的评估工具。

Method: 该研究引入了基于Gemma 3 27B的LuxMT机器翻译系统，并针对卢森堡语（LB）到法语（FR）和英语（EN）的翻译进行了微调。训练数据来源于LuxAlign并行语料库和Google Translate增强的LB议会文本。数据通过LuxEmbedder（LB句嵌入）过滤，以移除低等效的段落对。性能评估通过构建一个包含LB-FR、LB-EN和LB-FR（可能为LB-EN重复或笔误）的人工翻译数据的新基准进行。研究还探索了LuxEmbedder作为质量评估指标的潜力。

Result: LuxMT在LB-FR和LB-EN翻译上相对于Gemma 3基线展现出显著提升，甚至在训练数据不含德语的情况下，对LB-DE翻译也显示出强劲的改进。LuxEmbedder作为质量评估指标时，与其它基于参考的指标显示出强相关性。

Conclusion: LuxMT在卢森堡语机器翻译方面表现出色，并建议进一步研究LuxEmbedder作为质量评估指标的实用性，但需谨慎使用。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [48] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: 提出Fine-Refine，一个细粒度框架，通过分解、验证和迭代纠正原子单元来减少LLM在对话系统中的幻觉，显著提高了事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）的幻觉问题对对话系统产生负面影响，导致事实不准确的响应，误导用户并损害系统信任。现有细化方法在响应层面操作，忽略了单个响应可能包含多个可验证或不可验证的事实。

Method: 提出Fine-Refine框架，将对话响应分解为原子单元，利用外部知识验证每个单元，通过困惑度评估流畅性，并迭代纠正粒度错误。

Result: 在HybriDialogue和OpendialKG数据集上，Fine-Refine显著提高了真实性，对话事实分数最高提升7.63点，对话质量有轻微权衡。

Conclusion: 该论文提出了一个细粒度的纠正框架Fine-Refine，显著提升了对话系统的真实性，并对对话质量产生较小影响。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [49] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 该论文提出了ExpertWeaver，一个无需训练的框架，通过利用Gated Linear Unit（GLU）的激活模式，将预训练的密集模型转换为稀疏的Mixture-of-Experts（MoE）模型，其性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从头开始训练高质量的MoE模型成本高昂。现有将密集模型转换为MoE的方法（动态结构剪枝和下循环）破坏了密集模型固有的激活模式，导致专家构建次优。

Method: 该方法认为Gated Linear Unit（GLU）机制为密集到MoE的转换提供了一个天然蓝图。研究表明，GLU的细粒度神经元级激活模式揭示了一种粗粒度结构，即由一致激活的通用神经元和动态激活的专业神经元组成的固有MoE架构。基于此发现，引入了ExpertWeaver，一个无需训练的框架，它根据神经元的激活模式进行分区，并构建具有层适应性配置的共享专家和专业路由专家。

Result: ExpertWeaver在作为无需训练的动态结构剪枝技术和作为实现卓越MoE初始化的下循环策略方面，都显著优于现有方法。

Conclusion: ExpertWeaver通过利用GLU的激活模式，有效地将密集模型转换为MoE，从而在无需训练的情况下实现卓越的性能。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [50] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: ZeroSyl是一种简单的、免训练的方法，直接从冻结的WavLM模型中提取音节单元，在词汇、句法和叙事基准测试中优于现有的音节分词器，并且在句法建模方面展现出更好的扩展性。


<details>
  <summary>Details</summary>
Motivation: 纯语音语言模型面临挑战，即自监督语音编码器的离散token导致序列过长，而现有的音节单元方法（如Sylber和SyllableLM）依赖于复杂的多阶段训练流程。

Method: ZeroSyl通过计算WavLM中间层特征的L2范数，直接从冻结的WavLM模型中提取音节边界和嵌入。提取的片段经过均值池化，使用K-means进行离散化，然后用于训练语言模型。

Result: ZeroSyl在音节分割性能上具有竞争力，并在词汇、句法和叙事基准测试中优于现有的音节分词器。扩展实验表明，虽然细粒度单元对词汇任务有益，但ZeroSyl发现的音节单元在句法建模方面表现出更好的扩展行为。

Conclusion: ZeroSyl提供了一种简单、有效且免训练的方法，用于从纯语音中提取音节单元，在多个语言任务上实现了优异的性能，并且在句法建模方面具有更好的扩展性，解决了纯语音语言模型中的序列过长问题。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [51] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: 本文介绍了Perspectives，一个Discourse Analysis Tool Suite的交互式扩展，旨在帮助数字人文（DH）学者探索和组织大规模、非结构化的文档集合，通过人工参与的聚类和细化机制，揭示文档中的主题和情感。


<details>
  <summary>Details</summary>
Motivation: 赋能数字人文（DH）学者探索和组织大规模、非结构化的文档集合。

Method: Perspectives 实现了一个灵活的、以方面为中心的文档聚类管道，具有人工参与的细化能力。该过程通过文档重写提示和基于指令的嵌入来定义分析视角进行初步引导，并通过聚类细化工具和嵌入模型微调机制与用户意图进一步对齐。

Result: 通过演示，展示了数字人文研究人员如何利用Perspectives的交互式文档地图来发现主题、情感或其他相关类别。

Conclusion: Perspectives enables数字人文研究人员获取洞察并为后续深入分析准备数据。

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [52] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 本文提出了一种结合模型蒸馏和任务特定对比损失的训练方案，用于创建紧凑、高性能的文本嵌入模型。新模型（jina-embeddings-v5-text-small/nano）在同等规模模型中达到或超越SOTA，并支持长文本、多语言及截断/二值量化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本嵌入模型通常使用对比损失函数进行训练，但如何有效地训练紧凑型、高性能模型仍是挑战。本文旨在开发一种新的训练范式来解决小型模型训练效率和性能的问题。

Method: 引入了一种新颖的训练方案，该方案将模型蒸馏技术与任务特定的对比损失函数相结合，以生成紧凑且高性能的嵌入模型。

Result: 1. 该方法在训练小型模型方面比单独使用纯对比学习或蒸馏的训练范式更有效。
2. 生成的模型（jina-embeddings-v5-text-small和jina-embeddings-v5-text-nano）在同等规模模型中，其基准分数超越或匹配了最先进水平。
3. jina-embeddings-v5-text模型还支持长文本（高达32k token）和多种语言，并能生成在截断和二值量化下仍保持鲁棒性的嵌入。

Conclusion: 结合模型蒸馏和任务特定对比损失的训练方案能有效生成高性能的紧凑型文本嵌入模型，为文本嵌入模型的发展提供了新的方向，且其模型权重已开源，有望推动进一步研究。

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [53] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: Text-to-SQL在实际应用中因静态工作流而受限。SquRL是一个强化学习框架，通过动态工作流构建增强大型语言模型（LLMs）的推理能力，在广泛使用的Text-to-SQL基准测试中，尤其在复杂和分布外查询上，始终优于最佳静态工作流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL系统依赖单一静态工作流，这从根本上限制了它们在分布外和长尾场景中的可扩展性。用户需要通过大量实验选择合适的方法，而论文旨在使系统能够在推理时自适应地构建工作流。

Method: 1. 通过理论和经验分析，证明最优的动态策略始终优于最佳静态工作流。2. 提出了SquRL，一个强化学习框架，用于增强LLMs在自适应工作流构建中的推理能力。3. 设计了一个基于规则的奖励函数。4. 引入了两种有效的训练机制：动态actor掩码（鼓励更广泛的探索）和伪奖励（提高训练效率）。

Result: 1. 最优的动态策略始终优于最佳静态工作流。2. 动态工作流构建始终优于最佳静态工作流方法。3. 在复杂和分布外查询上，性能提升尤为显著。

Conclusion: 通过自适应工作流构建，SquRL框架显著提升了Text-to-SQL的性能，尤其在处理复杂和分布外查询时，证明了动态方法相比静态工作流的优越性。

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at

</details>


### [54] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 该研究提出了一种症状特异性且受临床启发的框架，通过症状引导的交叉注意力机制，利用情感感知的语音表征，从语音中估计抑郁症的严重程度，并在EDAIC数据集上取得了优于现有工作的性能，同时提高了可解释性。


<details>
  <summary>Details</summary>
Motivation: 抑郁症表现出多种症状，但大多数现有工作将抑郁症预测视为二元标签或整体严重程度评分，而没有明确地建模症状特异性信息。这限制了它们提供与临床筛查相关的症状层面分析的能力。

Method: 该方法提出一个症状特异性且受临床启发框架，用于从语音中估计抑郁症的严重程度。它使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知的语音表征对齐，以识别参与者语音中哪些片段对每个症状更重要。为解决症状随时间表达方式的差异，引入了一个可学习的症状特异性参数，自适应地控制注意力分布的锐度。

Result: 在标准临床数据集EDAIC上的结果表明，该方法性能有所提升，优于现有工作。此外，分析注意力分布显示，包含与多种抑郁症状相关线索的语句被赋予更高的注意力，这突出了该方法的可解释性。

Conclusion: 这些发现强调了症状引导和情感感知模型对于基于语音的抑郁症筛查的重要性。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [55] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: 本文提出STAPO，通过识别并屏蔽由“虚假tokens”引起的梯度放大更新，解决了大型语言模型RL微调中的训练不稳定性问题，并在数学推理任务上显著提高了性能和熵稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习（RL）微调方法在改善大型语言模型推理能力时，过度依赖启发式技术（如熵正则化和重加权），并且常常出现后期性能崩溃，导致推理质量下降和训练不稳定。这是因为虚假tokens（占约0.01%）在正确响应中出现时，虽然对推理结果贡献小，但却继承了完整的序列级奖励，导致梯度更新异常放大。

Method: 研究推导出RL中token级策略梯度的大小与token概率和局部策略熵呈负相关，并证明了训练不稳定性是由极少数（约0.01%）的“虚假tokens”引起的。基于此观察，提出了虚假Token感知策略优化（STAPO）方法，该方法选择性地屏蔽虚假tokens引起的梯度更新，并对有效tokens上的损失进行重新规范化。

Result: 在六个数学推理基准上，使用Qwen 1.7B、8B和14B基础模型进行测试，STAPO始终表现出卓越的熵稳定性，并比GRPO、20-Entropy和JustRL平均提高了7.13%的性能。

Conclusion: STAPO通过选择性地屏蔽由虚假tokens引起的梯度更新并对有效tokens上的损失进行重新规范化，显著提高了大型语言模型在数学推理任务上的RL微调的稳定性和性能。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [56] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 该论文介绍了NileTTS，一个38小时的埃及阿拉伯语文本转语音（TTS）数据集，以及一个开源的微调模型，以解决该方言资源匮乏的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管神经文本转语音（TTS）技术取得了进展，但许多阿拉伯方言种类仍然很少被提及，大多数资源集中在现代标准阿拉伯语（MSA）和海湾方言上，导致埃及阿拉伯语（最广泛理解的阿拉伯语方言）资源严重不足。

Method: 他们通过一种新颖的合成管道构建了NileTTS数据集：大型语言模型（LLM）生成埃及阿拉伯语内容，然后使用音频合成工具将其转换为自然语音，接着进行自动转录和说话人分离，并进行手动质量验证。随后，他们在这个数据集上微调了最先进的多语言TTS模型XTTS v2。

Result: 主要贡献包括：(1) 第一个公开可用的埃及阿拉伯语TTS数据集NileTTS，(2) 一个可复现的方言TTS合成数据生成管道，以及(3) 一个开源的微调模型。

Conclusion: 所有资源都已发布，以推动埃及阿拉伯语语音合成研究的发展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [57] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 该论文提出了一个针对诺斯罗普·弗莱叙事体裁的全新角色功能框架，该框架将荣格原型理论中的四个普遍角色功能（主角、导师、对手、同伴）细化为十六个特定体裁的角色。通过使用六个大型语言模型对40部叙事作品进行验证，该框架取得了82.5%的平均平衡准确率和0.600的弗莱斯 Kappa一致性，展示了其在计算叙事学中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的计算方法主要关注叙事模式而非角色功能，本研究旨在通过考察原型角色如何在弗莱的体裁中表现，从而补充基于模式的分析。

Method: 1. 借鉴荣格原型理论，将四个普遍角色功能（主角、导师、对手、同伴）映射到荣格的心理结构组成部分。 2. 基于原型作品，将这些功能专门化为16个特定体裁的角色。 3. 使用六个大型语言模型，通过评估40部叙事作品中的角色与角色对应关系，对框架进行多模型研究验证，包括正样本和负样本。

Result: 1. 大型语言模型实现了显著的性能（平均平衡准确率为82.5%），模型间一致性强（弗莱斯 Kappa系数为0.600）。 2. 性能因体裁（72.7%至89.9%）和角色（52.5%至99.2%）而异。 3. 定性分析表明，差异反映了真实的叙事特性，包括浪漫体裁中的功能分布和讽刺体裁中有意的原型颠覆。

Conclusion: 这种基于角色的方法展示了大型语言模型支持的计算叙事学方法的潜力，并为未来叙事生成方法和交互式故事讲述应用的发展奠定了基础。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $\kappa$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [58] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 该论文引入了平均最小距离（AMD）和对称平均最小距离（SAMD）作为词汇语义变化检测（LSCD）的新度量，并证明它们在不同条件下（特别是在降维和使用非专业编码器时，AMD表现更佳；SAMD则在专业编码器下表现出色）比现有度量（APD和PRT）更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 词汇语义变化检测（LSCD）越来越依赖上下文语言模型嵌入，但大多数方法仍然使用少量语义变化度量（主要是平均成对距离APD和词原型余弦距离PRT）来量化变化。

Method: 该研究引入了平均最小距离（AMD）和对称平均最小距离（SAMD），这些新度量通过跨时间段的词语用法之间的局部对应关系来量化语义变化。研究在多种语言、编码器模型和表示空间中进行了评估。

Result: 结果表明，AMD通常提供更鲁棒的性能，特别是在降维和使用非专业编码器的情况下；而SAMD在专业编码器下表现出色。

Conclusion: 研究建议LSCD可以从考虑APD和PRT之外的替代语义变化度量中受益，其中AMD为基于上下文嵌入的分析提供了一个鲁棒的选择。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [59] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 本文提出了一种端到端的流程，利用稀疏自编码器（SAEs）生成并引导潜在文本干预，然后进行稳健的因果效应估计。该流程通过协变量残差化解决了文本中处理与协变量信息混淆导致的估计偏差，并被证明能有效引发特征变化和降低估计误差。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，理解文本对下游结果的因果效应是一项核心任务。估计这些效应需要研究人员进行系统地改变文本特征的受控实验。尽管大型语言模型（LLMs）在生成文本方面具有潜力，但生成和评估受控变异需要更仔细的关注。天真的因果效应估计会遭受显著偏差，因为文本本质上混淆了处理（treatment）和协变量（covariate）信息。

Method: 本文提出了一种端到端的流程，用于生成和因果估计潜在的文本干预。该流程首先通过稀疏自编码器（SAEs）进行假设生成和指导，随后进行稳健的因果估计。为解决文本内在混淆处理和协变量信息导致的估计偏差，本文提出了一种基于协变量残差化（covariate residualization）的解决方案。

Result: 天真的因果效应估计会遭受显著偏差。本文提出的流程能有效引发目标特征的变化，并减轻估计误差。实验结果表明，该流程为文本作为干预措施情境下的因果效应估计提供了稳健的基础。

Conclusion: 该流程能够有效引发目标特征的变化并减轻估计误差，为文本作为干预措施（text-as-treatment）情境下的因果效应估计提供了稳健的基础。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [60] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在低资源语言（如古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语）的词形还原和词性标注任务中的表现。结果显示，在少量样本设置下，LLMs在大多数语言上表现出色或具有竞争力，表明它们在数据匮乏的语言标注任务中具有潜力，尽管对形态复杂和非拉丁文字的语言仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 低资源语言对词形还原和词性标注等自然语言处理任务提出了持续的挑战。

Method: 本文研究了包括GPT-4变体和Mistral模型在内的大型语言模型在少量样本和零样本设置下，对四种历史和语言多样性欠佳的低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语）执行词形还原和词性标注任务的能力。研究使用了一个包含对齐训练和域外测试语料库的新基准，评估了基础模型在词形还原和词性标注方面的性能，并将其与任务特定的RNN基线PIE进行了比较。

Result: 大型语言模型，即使未经微调，在少量样本设置下，在大多数语言的词性标注和词形还原方面均表现出具有竞争力或更优的性能。对于具有复杂形态和非拉丁字母的语言，仍然存在重大挑战。

Conclusion: 在数据匮乏的情况下，大型语言模型是启动语言标注任务的可信且相关的选择，可以作为有效的标注辅助工具。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [61] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 本研究推出了FineMuSe，一个包含二元和细粒度标注的西班牙语多模态性别歧视检测数据集，并提出了一种分层分类法。评估发现，多模态大型语言模型在检测细微性别歧视方面表现良好，但在识别通过视觉线索传达的共存性别歧视类型时仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视以多种形式出现，使其检测具有挑战性。现有的自动化工具通常仅限于二元分类，导致更细微的性别歧视表现因缺乏细粒度、上下文敏感的标签而未被发现。

Method: 1. 构建了FineMuSe，一个包含二元和细粒度标注的西班牙语多模态性别歧视检测新数据集。
2. 引入了一个全面的分层分类法，涵盖性别歧视、非性别歧视形式以及反讽和幽默等修辞手法。
3. 评估了各种大型语言模型在二元和细粒度性别歧视检测方面的表现。

Result: 多模态大型语言模型在识别细致入微的性别歧视形式方面与人类标注者表现相当；然而，当这些性别歧视类型通过视觉线索传达时，模型难以捕捉共存的性别歧视类型。

Conclusion: 本研究通过提供新的数据集和分类法并评估大型语言模型，成功解决了在线性别歧视细微形式的检测挑战，突出了模型在细致检测方面的优势以及在处理视觉共现方面的不足。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [62] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: MLLM 在单轮图表生成中表现出色，但在多轮探索性数据分析（EDA）中的能力未被充分探索。本文引入 ChartEditBench，一个用于增量、视觉接地图表编辑的基准，包含 5,000 个修改链。还提出了一个鲁棒的评估框架。实验发现，MLLM 在多轮设置中性能显著下降，尤其在数据转换方面，但在样式编辑上表现良好。ChartEditBench 为多模态编程提供了一个挑战性测试平台。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLM）在单轮图表生成方面表现出色，但它们在支持真实世界探索性数据分析（EDA）方面的能力尚未得到充分探索。在实践中，用户通过多轮交互迭代地完善可视化，这需要维持共同点、跟踪先前的编辑并适应不断变化的偏好。

Method: 引入了 ChartEditBench，这是一个用于通过代码进行增量、视觉接地图表编辑的基准测试，包含 5,000 个难度受控的修改链和一个经过严格人工验证的子集。该基准侧重于持续、上下文感知的编辑。此外，提出了一种鲁棒的评估框架，通过整合基于执行的保真度检查、像素级视觉相似性和逻辑代码验证，来减轻“LLM 作为评判者”指标的局限性。

Result: 对最先进 MLLM 的实验表明，在多轮设置中，由于错误累积和共享上下文的崩溃，性能显著下降。MLLM 在样式编辑方面表现强劲，但在以数据为中心的转换上经常出现执行失败。

Conclusion: ChartEditBench 为基础、意图感知的多模态编程提供了一个具有挑战性的测试平台。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [63] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 本文介绍了*-PLUIE，一种改进的、任务特定的、基于困惑度的LLM-judge指标，它与人类评估具有更强的相关性，同时计算成本较低。


<details>
  <summary>Details</summary>
Motivation: 评估自动生成文本质量的LLM-judge方法计算成本高昂且需要后处理。

Method: 本文基于ParaPLUIE（一种无需生成文本即可估计“是/否”答案置信度的基于困惑度的LLM-judge指标），引入了*-PLUIE，这是ParaPLUIE的任务特定提示变体。

Result: 个性化*-PLUIE与人类评分表现出更强的相关性。

Conclusion: 个性化*-PLUIE在保持低计算成本的同时，与人类评估具有更强的相关性。

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [64] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文提出了一种改革后的仅编码器Avey模型，通过引入多项架构创新（如解耦参数化、稳定性归一化、神经压缩），使其在性能和长上下文处理效率上优于现有的Transformer编码器。


<details>
  <summary>Details</summary>
Motivation: 紧凑的预训练双向编码器在计算和内存受限的工业NLP中至关重要。Avey作为一种自回归、无注意力且自然支持仅编码器适应的替代方案被提出。本文旨在改进Avey以提升其在仅编码器任务上的性能和效率。

Method: 作者重新制定了Avey模型，使其适应仅编码器范式，并提出了几项架构创新，包括解耦的静态和动态参数化、面向稳定性的归一化和神经压缩。

Result: 重新制定的Avey架构在四个广泛使用的基于Transformer的编码器面前表现出优势，在标准的token分类和信息检索基准测试中持续超越它们，并且在处理长上下文时能更有效地扩展。

Conclusion: 该模型在标准token分类和信息检索基准测试中持续优于四种广泛使用的基于Transformer的编码器，并且在处理长上下文时表现出更高的效率。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [65] [Structure-Aware Piano Accompaniment via Style Planning and Dataset-Aligned Pattern Retrieval](https://arxiv.org/abs/2602.15074)
*Wanyu Zang,Yang Yu,Meng Yu*

Main category: cs.SD

TL;DR: 该论文提出了一种符号钢琴伴奏的结构感知方法，将高层规划与音符层实现解耦。该方法使用一个轻量级Transformer预测每小节的风格规划，然后通过检索器从语料库中选择并重新和声人类演奏的钢琴模式。实验表明，该方法能生成多样化、风格实现强的长篇伴奏，且在推理时具有有效性。


<details>
  <summary>Details</summary>
Motivation: 解决符号钢琴伴奏的生成问题，提出一种将高层规划与音符层实现解耦的结构感知方法。

Method: 方法包括两个阶段：1. 高层规划：一个轻量级Transformer根据乐段/乐句结构和功能和声预测可解释的每小节风格规划。2. 音符层实现：一个检索器从语料库中选择并重新和声人类演奏的钢琴模式。检索被公式化为模式匹配，通过一个明确的能量函数进行，该函数包含和声可行性、结构角色兼容性、声部进行连续性、风格偏好和重复控制等项。系统输入结构化的主旋律谱和可选的关键词提示，生成钢琴伴奏MIDI。

Result: Transformer风格规划器引导的检索生成了多样化的长篇伴奏，具有很强的风格实现能力。研究还对规划器消融进行了分析，并量化了风格间的隔离度。

Conclusion: 该推理时方法在钢琴伴奏生成方面表现出有效性。

Abstract: We introduce a structure-aware approach for symbolic piano accompaniment that decouples high-level planning from note-level realization. A lightweight transformer predicts an interpretable, per-measure style plan conditioned on section/phrase structure and functional harmony, and a retriever then selects and reharmonizes human-performed piano patterns from a corpus. We formulate retrieval as pattern matching under an explicit energy with terms for harmonic feasibility, structural-role compatibility, voice-leading continuity, style preferences, and repetition control. Given a structured lead sheet and optional keyword prompts, the system generates piano-accompaniment MIDI. In our experiments, transformer style-planner-guided retrieval produces diverse long-form accompaniments with strong style realization. We further analyze planner ablations and quantify inter-style isolation. Experimental results demonstrate the effectiveness of our inference-time approach for piano accompaniment generation.

</details>


### [66] [S-PRESSO: Ultra Low Bitrate Sound Effect Compression With Diffusion Autoencoders And Offline Quantization](https://arxiv.org/abs/2602.15082)
*Zineb Lahrichi,Gaëtan Hadjeres,Gaël Richard,Geoffroy Peeters*

Main category: cs.SD

TL;DR: S-PRESSO是一种48kHz音效压缩模型，利用潜在扩散模型在超低比特率（0.096 kbps，750倍压缩）下实现高压缩比，在音质和声学相似性方面优于现有基线模型，尽管会牺牲精确保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的音频压缩方法受限于低分辨率音频，并且在极低比特率下性能显著下降，导致出现明显的听觉伪影。

Method: 本文提出了S-PRESSO模型，这是一个48kHz音效压缩模型，通过离线量化在低至0.096 kbps的超低比特率下生成连续和离散嵌入。该模型依靠预训练的潜在扩散模型来解码由潜在编码器学习的压缩音频嵌入。利用扩散解码器的生成先验，实现了极低的帧率（低至1Hz，即750倍压缩率），在牺牲精确保真度的前提下，生成了令人信服且逼真的重建。

Result: S-PRESSO在极高压缩率下（低至0.096 kbps，750倍压缩率），在音频质量、声学相似性和重建指标上均优于连续和离散基线模型，即使以牺牲精确保真度为代价，也能产生令人信服和逼真的重建。

Conclusion: S-PRESSO通过利用生成模型，成功实现了48kHz音效在超低比特率下的高压缩率和良好的感知质量，解决了现有方法在高压缩率下分辨率受限和音质下降的问题。

Abstract: Neural audio compression models have recently achieved extreme compression rates, enabling efficient latent generative modeling. Conversely, latent generative models have been applied to compression, pushing the limits of continuous and discrete approaches. However, existing methods remain constrained to low-resolution audio and degrade substantially at very low bitrates, where audible artifacts are prominent. In this paper, we present S-PRESSO, a 48kHz sound effect compression model that produces both continuous and discrete embeddings at ultra-low bitrates, down to 0.096 kbps, via offline quantization. Our model relies on a pretrained latent diffusion model to decode compressed audio embeddings learned by a latent encoder. Leveraging the generative priors of the diffusion decoder, we achieve extremely low frame rates, down to 1Hz (750x compression rate), producing convincing and realistic reconstructions at the cost of exact fidelity. Despite operating at high compression rates, we demonstrate that S-PRESSO outperforms both continuous and discrete baselines in audio quality, acoustic similarity and reconstruction metrics.

</details>


### [67] [UniTAF: A Modular Framework for Joint Text-to-Speech and Audio-to-Face Modeling](https://arxiv.org/abs/2602.15651)
*Qiangong Zhou,Nagasaka Tomohiro*

Main category: cs.SD

TL;DR: 本研究将TTS和A2F模型合并，以通过内部特征迁移提高文本生成音频和面部表情的一致性，并验证了重用TTS中间表示进行语音和面部表情联合建模的可行性。


<details>
  <summary>Details</summary>
Motivation: 提高由文本生成的音频与面部表情之间的一致性。

Method: 将TTS和A2F两个独立模型合并为一个统一模型，通过内部特征迁移来提高音频与面部表情的一致性。同时，探讨了将TTS的情感控制机制扩展到联合模型中。

Result: 从系统设计角度，验证了重用TTS中间表示进行语音和面部表情联合建模的可行性，并为后续的语音表情协同设计提供了工程实践参考。

Conclusion: 通过将TTS和A2F模型统一，实现内部特征迁移，可以提高文本生成音频和面部表情的一致性；重用TTS的中间表示对于语音和面部表情的联合建模是可行的，并为未来的协同设计提供了工程指导。

Abstract: This work considers merging two independent models, TTS and A2F, into a unified model to enable internal feature transfer, thereby improving the consistency between audio and facial expressions generated from text. We also discuss the extension of the emotion control mechanism from TTS to the joint model. This work does not aim to showcase generation quality; instead, from a system design perspective, it validates the feasibility of reusing intermediate representations from TTS for joint modeling of speech and facial expressions, and provides engineering practice references for subsequent speech expression co-design. The project code has been open source at:

</details>


### [68] [The Equalizer: Introducing Shape-Gain Decomposition in Neural Audio Codecs](https://arxiv.org/abs/2602.15491)
*Samir Sadok,Laurent Girin,Xavier Alameda-Pineda*

Main category: cs.SD

TL;DR: 神经音频编解码器（NACs）对输入信号电平变化不鲁棒，导致编码效率低下。本文提出了一种名为Equalizer的形状-增益分解方法，在NAC编码器前将增益和形状分离处理，从而显著提高比特率-失真性能并降低复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的神经音频编解码器（NACs）通常在同一个潜在空间中联合编码语音/音频信号的短时能量（增益）和归一化结构（形状），导致它们对输入信号电平的全局变化鲁棒性差。这种变化对编码器输出的嵌入向量及其量化产生强烈影响，导致编码码本冗余和次优的比特率-失真性能。

Method: 本文提出了一种名为Equalizer的方法，将经典的语音/音频编码中广泛使用的形状-增益分解引入到NAC框架中。该原理是在NAC编码器之前，将输入信号短期分解为增益和归一化形状向量。形状向量由NAC处理，而增益则通过标量量化并单独传输。解码信号由NAC的归一化输出和量化增益重建。

Result: 在语音信号上进行的实验表明，这种普遍适用于任何NAC的方法，能够显著提升比特率-失真性能，并大幅降低复杂度。

Conclusion: 将形状-增益分解（Equalizer方法）引入神经音频编解码器（NAC）框架中，可以显著提高NAC的比特率-失真性能，并大幅降低其复杂度，使其更具鲁棒性和效率。

Abstract: Neural audio codecs (NACs) typically encode the short-term energy (gain) and normalized structure (shape) of speech/audio signals jointly within the same latent space. As a result, they are poorly robust to a global variation of the input signal level in the sense that such variation has strong influence on the embedding vectors at the output of the encoder and their quantization. This methodology is inherently inefficient, leading to codebook redundancy and suboptimal bitrate-distortion performance. To address these limitations, we propose to introduce shape-gain decomposition, widely used in classical speech/audio coding, into the NAC framework. The principle of the proposed Equalizer methodology is to decompose the input signal -- before the NAC encoder -- into gain and normalized shape vector on a short-term basis. The shape vector is processed by the NAC, while the gain is quantized with scalar quantization and transmitted separately. The output (decoded) signal is reconstructed from the normalized output of the NAC and the quantized gain. Our experiments conducted on speech signals show that this general methodology, easily applicable to any NAC, enables a substantial gain in bitrate-distortion performance, as well as a massive reduction in complexity.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [69] [Artificial Intelligence Specialization in the European Union: Underexplored Role of the Periphery at NUTS-3 Level](https://arxiv.org/abs/2602.15249)
*Victor Herrero-Solana*

Main category: cs.DL

TL;DR: 该研究分析了2015-2024年欧洲NUTS-3级别区域AI研究的地理分布、专业化程度和引用影响力。发现主要都市中心产量高，但东欧和西班牙的边缘地区AI专业化程度最高。区域专业化与引用影响力几乎没有相关性，并识别出四种不同的区域类型，表明AI研究为边缘地区提供了发展竞争性科学利基的战略机遇，但国际可见性不仅需要研究量。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在考察2015-2024年间欧洲NUTS-3级别区域人工智能（AI）研究产出的地理分布，并分析其专业化程度与引用影响力之间的关系，以理解AI研究在不同区域的发展模式和战略意义。

Method: 研究使用了Clarivate InCites的文献计量数据和引用主题分类系统，分析了“电气工程、电子与计算机科学”以及“人工智能与机器学习”这两个主题层级。对781个NUTS-3区域计算了相对专业化指数（RSI）和相对引用影响力（RCI）。

Result: 研究发现，巴黎、华沙和马德里等主要大都市中心在AI研究产出总量上领先。然而，边缘地区，特别是来自东欧和西班牙的地区，表现出最高的相对AI专业化水平。区域专业化与引用影响力之间几乎没有关联性。研究识别出四种独特的区域类型：高影响力专业化区域（如格拉纳达、哈恩、维尔纽斯）、高产出但低影响力区域（如布加斯、多个波兰地区）、高影响力非专业化区域（如丹麦菲英），以及选择性卓越的多样化组合区域（如德国地区）。

Conclusion: AI研究为边缘地区提供了发展竞争性科学利基的战略机遇。然而，要获得国际可见性，仅有研究量是不够的，还需要结合其他因素以提升影响力。

Abstract: This study examines the geographical distribution of Artificial Intelligence (AI) research production across European regions at the NUTS-3 level for the period 2015-2024. Using bibliometric data from Clarivate InCites and the Citation Topics classification system, we analyze two hierarchical levels of thematic aggregation: Electrical Engineering, Electronics & Computer Science (Macro Citation Topic 4) and Artificial Intelligence & Machine Learning (Meso Citation Topic 4.61). We calculate the Relative Specialization Index (RSI) and Relative Citation Impact (RCI) for 781 NUTS-3 regions. While major metropolitan hubs such as Paris (IIle-de-France), Warszawa, and Madrid lead in absolute production volume, our findings reveal that peripheral regions, particularly from Eastern Europe and Spain, exhibit the highest levels of relative AI specialization. Notably, we find virtually no correlation between regional specialization and citation impact, identifying four distinct regional profiles: high-impact specialized regions (e.g., Granada, Jaen, Vilniaus), high-volume but low-impact regions (e.g., Bugas, several Polish regions), high-impact non-specialized regions, with Fyn (Denmark) standing out as a remarkable outlier achieving exceptional citation impact (RCI > 4) despite low specialization, and diversified portfolios with selective excellence (e.g., German regions). These results suggest that AI research represents a strategic opportunity for peripheral regions to develop competitive scientific niches, though achieving international visibility requires more than research volume alone.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [70] [Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient](https://arxiv.org/abs/2602.15036)
*Saumyadip Mukhopadhyay,Kiho Yang,Kasyap Thottasserymana Vasudevan,Mounica Jyothi Divvela,Selim Dogru,Dilip Krishnamurthy,Fergo Treska,Werner Gillijns,Ryan Ryoung han Kim,Kumara Sastry,Vivek Singh*

Main category: eess.SP

TL;DR: 该论文探讨了加速计算(AC)和人工智能(AI)如何通过重新设计软件堆栈，解决科学计算中不断增长的计算需求，特别是在计算光刻领域，从而提供显著的性能提升和改进的解决方案。


<details>
  <summary>Details</summary>
Motivation: 从气候科学到药物发现，科学计算需求近年来急剧增长，这得益于更大的数据集、更复杂的模型和更高的模拟保真度。这种增长速度远远超过晶体管缩放，导致成本、能耗和排放的不可持续增长。半导体制造也不例外，计算光刻作为其最大的工作负载，随着微型化进入埃时代变得异常复杂，需要更精确的建模、复杂的校正和更广泛的解决方案空间探索。

Method: 该方法利用加速计算(AC)并结合AI作为计算密集型步骤的高保真替代物。针对计算光刻，NVIDIA cuLitho重新设计了核心原语（衍射光学、计算几何、多变量优化、数据处理），并重新投入一部分节省的计算资源进行焦点校正以提高工艺弹性。

Result: NVIDIA cuLitho实现了57倍的端到端加速。这种扩展的计算能力能够实现更严谨的解决方案，包括曲线掩模、高数值孔径极紫外(high-NA EUV)光刻和亚原子建模。IMEC的硅实验表明，与传统方法相比，工艺窗口提高了35%，边缘放置误差降低了19%。这是首次量化芯片级演示AC和AI在硅片上对光刻的益处。

Conclusion: 加速计算和人工智能，结合NVIDIA cuLitho等重新设计的软件堆栈，为科学工作负载提供了一个可持续的下一代计算平台，带来了显著的加速，并能够在计算光刻等领域实现卓越的解决方案。

Abstract: From climate science to drug discovery, scientific computing demands have surged dramatically in recent years -- driven by larger datasets, more sophisticated models, and higher simulation fidelity. This growth rate far outpaces transistor scaling, leading to unsustainably rising costs, energy consumption, and emissions. Semiconductor manufacturing is no exception. Computational lithography -- involving transferring circuitry to silicon in diffraction-limited conditions -- is the largest workload in semiconductor manufacturing. It has also grown exceptionally complex as miniaturization has advanced in the angstrom-era, requiring more accurate modeling, intricate corrections, and broader solution-space exploration. Accelerated computing (AC) offers a solution by dramatically freeing up the compute and power envelope. AI augments these gains by serving as high-fidelity surrogates for compute-intensive steps. Together, they present a sustainable, next-generation computing platform for scientific workloads. This new paradigm needs a fundamental redesign of the software stack. For computational lithography, NVIDIA cuLitho reinvents the core primitives -- diffractive optics, computational geometry, multi-variant optimization, data processing -- to achieve a transformative 57X end-to-end acceleration. Beyond dramatically faster cycles, this expanded compute envelope enables more rigorous solutions, including curvilinear masks, high-numerical aperture extreme ultraviolet (high-NA EUV) lithography, and subatomic modeling. We reinvest a small fraction of the freed-up compute to include through-focus correction for better process resilience. Silicon experiments at IMEC show significant benefits compared to conventional methods -- 35% better process window and 19% better edge placement error. This is the first quantified chip-scale demonstration of the lithography benefits of AC and AI in silicon.

</details>


### [71] [Combining scEEG and PPG for reliable sleep staging using lightweight wearables](https://arxiv.org/abs/2602.15042)
*Jiawei Wang,Liang Xu,Shuntian Zheng,Yu Guan,Kaichen Wang,Ziqing Zhang,Chen Chen,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 本研究开发了一种基于scEEG-PPG融合的短窗口（30秒-30分钟）4类睡眠分期方法，Mamba增强融合策略在MESA数据集上表现最佳，尤其显著改善了轻度睡眠分类性能，并成功泛化至其他数据集，为轻量级可穿戴设备睡眠监测提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 轻量级可穿戴设备（如单通道脑电图scEEG或光电容积描记PPG）在可靠睡眠分期方面仍面临挑战。
scEEG在轻度睡眠阶段表现有限。
PPG虽成本低廉且有效捕捉自主神经信号，但现有PPG方法依赖于全夜记录（8-10小时），这不利于及时提供睡眠干预反馈。
因此，需要开发一种在短窗口限制下进行有效睡眠分期的方法。

Method: 1. 评估了每种模态所需的时间上下文（30秒-30分钟），以理解监测窗口与睡眠分期性能的关系。
2. 研究了三种融合策略：分数级融合、实现特征级交互的交叉注意力融合、以及结合时间上下文建模的Mamba增强融合。
3. 在多民族动脉粥样硬化研究（MESA）数据集上进行训练和评估。
4. 在克利夫兰家庭研究（CFS）和睡眠呼吸暂停、减肥手术和CPAP（ABC）数据集上进行跨数据集验证。

Result: Mamba增强融合在MESA数据集上取得了最佳性能：
- Cohen's Kappa ($\kappa$) = 0.798
- 准确率 (Acc) = 86.9%
- 轻度睡眠分类 F1-score：85.63% (scEEG单独为77.76%)
- 轻度睡眠分类 召回率：82.85% (scEEG单独为69.95%)
该方法在CFS和ABC数据集上的泛化能力良好。

Conclusion: scEEG-PPG融合是一种有前景的轻量级可穿戴睡眠监测方法，有望实现更便捷的睡眠健康评估。该方法在MESA数据集上表现最佳，并在不同人群的CFS和ABC数据集上泛化良好。

Abstract: Reliable sleep staging remains challenging for lightweight wearable devices such as single-channel electroencephalography (scEEG) or photoplethysmography (PPG). scEEG offers direct measurement of cortical activity and serves as the foundation for sleep staging, yet exhibits limited performance on light sleep stages. PPG provides a low-cost complement that captures autonomic signatures effective for detecting light sleep. However, prior PPG-based methods rely on full night recordings (8 - 10 hours) as input context, which is less practical to provide timely feedback for sleep intervention. In this work, we investigate scEEG-PPG fusion for 4-class sleep staging under short-window (30 s - 30 min) constraints. First, we evaluate the temporal context required for each modality, to better understand the relationship of sleep staging performance with respect to monitoring window. Second, we investigate three fusion strategies: score-level fusion, cross-attention fusion enabling feature-level interactions, and Mamba-enhanced fusion incorporating temporal context modeling. Third, we train and evaluate on the Multi-Ethnic Study of Atherosclerosis (MESA) dataset and perform cross-dataset validation on the Cleveland Family Study (CFS) and the Apnea, Bariatric surgery, and CPAP (ABC) datasets. The Mamba-enhanced fusion achieves the best performance on MESA (Cohen's Kappa $\kappa$ = 0.798, Acc = 86.9%), with particularly notable improvement in light sleep classification (F1-score: 85.63% vs. 77.76%, recall: 82.85% vs. 69.95% for scEEG alone), and generalizes well to CFS and ABC datasets with different populations. These findings suggest that scEEG-PPG fusion is a promising approach for lightweight wearable based sleep monitoring, offering a pathway toward more accessible sleep health assessment. Source code of this project can be found at:

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [72] [Automatic Funny Scene Extraction from Long-form Cinematic Videos](https://arxiv.org/abs/2602.15381)
*Sibendu Paul,Haotian Jiang,Caren Chen*

Main category: cs.IR

TL;DR: 本文提出了一个端到端系统，用于自动识别和排名电影长片中的幽默场景，该系统结合了视觉、文本和音频线索，并在场景检测和幽默识别方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 从电影作品中自动提取引人入胜的高质量幽默场景对于制作引人注目的视频预览和快餐式内容至关重要，有助于提高流媒体平台的用户参与度。然而，电影长片的时长和复杂叙事对场景定位构成了挑战，同时幽默对多种模态的依赖及其细微风格增加了额外复杂性。

Method: 本文提出了一个端到端系统，用于自动识别和排序电影长片中的幽默场景，该系统包含镜头检测、多模态场景定位和针对电影内容优化的幽默标注。关键创新包括：结合视觉和文本线索的新型场景分割方法、通过引导式三元组挖掘改进的镜头表示，以及利用音频和文本的多模态幽默标注框架。

Result: 该系统在OVSD数据集上的场景检测方面比最先进技术提高了18.3%的AP，在长文本幽默检测方面F1分数达到0.834。对五部电影作品的广泛评估表明，该管道提取的片段中有87%旨在搞笑，98%的场景被准确本地化。

Conclusion: 该系统成功推广至预告片，表明其在增强内容创作流程、提升用户参与度以及简化多种电影媒体格式的快餐式内容生成方面的巨大潜力。

Abstract: Automatically extracting engaging and high-quality humorous scenes from cinematic titles is pivotal for creating captivating video previews and snackable content, boosting user engagement on streaming platforms. Long-form cinematic titles, with their extended duration and complex narratives, challenge scene localization, while humor's reliance on diverse modalities and its nuanced style add further complexity. This paper introduces an end-to-end system for automatically identifying and ranking humorous scenes from long-form cinematic titles, featuring shot detection, multimodal scene localization, and humor tagging optimized for cinematic content. Key innovations include a novel scene segmentation approach combining visual and textual cues, improved shot representations via guided triplet mining, and a multimodal humor tagging framework leveraging both audio and text. Our system achieves an 18.3% AP improvement over state-of-the-art scene detection on the OVSD dataset and an F1 score of 0.834 for detecting humor in long text. Extensive evaluations across five cinematic titles demonstrate 87% of clips extracted by our pipeline are intended to be funny, while 98% of scenes are accurately localized. With successful generalization to trailers, these results showcase the pipeline's potential to enhance content creation workflows, improve user engagement, and streamline snackable content generation for diverse cinematic media formats.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [73] [StrokeNeXt: A Siamese-encoder Approach for Brain Stroke Classification in Computed Tomography Imagery](https://arxiv.org/abs/2602.15087)
*Leo Thomas Ramos,Angel D. Sappa*

Main category: eess.IV

TL;DR: StrokeNeXt是一种基于双分支ConvNeXt的卒中分类模型，在CT图像上表现优异，准确率和F1分数高达0.988，且推理速度快、收敛快。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一种用于2D计算机断层扫描（CT）图像中卒中分类的模型，以提高卒中检测和亚型分类的准确性和效率。

Method: 本文提出了StrokeNeXt模型，该模型采用双分支设计，包含两个ConvNeXt编码器。特征通过一个基于堆叠1D操作（包括瓶颈投影和转换层）的轻量级卷积解码器进行融合，并使用一个紧凑的分类头。模型在一个包含6,774张CT图像的精选数据集上进行评估，旨在解决卒中检测以及缺血性和出血性卒中亚型分类问题。

Result: StrokeNeXt在准确率和F1分数上均高达0.988，持续优于卷积和基于Transformer的基线模型。配对统计测试证实性能提升具有统计学意义。类别的敏感性和特异性分析表明模型在不同诊断类别中表现出鲁棒性。校准分析显示预测误差低于竞争方法，混淆矩阵结果表明误分类率低。此外，模型具有低推理时间和快速收敛的特点。

Conclusion: StrokeNeXt是一个高效、鲁棒且快速收敛的模型，在2D CT图像卒中分类任务中表现优异，显著优于现有方法。

Abstract: We present StrokeNeXt, a model for stroke classification in 2D Computed Tomography (CT) images. StrokeNeXt employs a dual-branch design with two ConvNeXt encoders, whose features are fused through a lightweight convolutional decoder based on stacked 1D operations, including a bottleneck projection and transformation layers, and a compact classification head. The model is evaluated on a curated dataset of 6,774 CT images, addressing both stroke detection and subtype classification between ischemic and hemorrhage cases. StrokeNeXt consistently outperforms convolutional and Transformer-based baselines, reaching accuracies and F1-scores of up to 0.988. Paired statistical tests confirm that the performance gains are statistically significant, while class-wise sensitivity and specificity demonstrate robust behavior across diagnostic categories. Calibration analysis shows reduced prediction error compared to competing methods, and confusion matrix results indicate low misclassification rates. In addition, the model exhibits low inference time and fast convergence.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [74] [Unforgeable Watermarks for Language Models via Robust Signatures](https://arxiv.org/abs/2602.15323)
*Huijia Lin,Kameron Shahabi,Min Jae Song*

Main category: cs.CR

TL;DR: 本文引入了具有不可伪造性和可恢复性的新水印方案，以应对大型语言模型文本难以区分的挑战。该方案基于鲁棒数字签名，首次实现了对内容归属和细粒度可追溯性的安全保护，克服了现有方案对虚假归因保护有限的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的文本与人类写作日益难以区分，导致对内容来源验证工具的需求增加。现有水印方案在模型质量保持和鲁棒检测方面有所进展，但在防止虚假归因方面保护有限，这是研究的主要动机。

Method: 1. 引入了“不可伪造性”和“可恢复性”两个新颖的保障来强化水印方案的健全性。不可伪造性阻止了伪造阳性（即非水印模型输出却被标记为水印）的产生；可恢复性确保一旦检测到水印，能识别出原始来源文本。
2. 核心技术是引入了一种新的加密原语，称为“鲁棒（或可恢复）数字签名”。这种签名允许验证与已签名消息相近的消息，同时阻止伪造与所有先前签名消息相距较远的消息。
3. 证明了任何标准数字签名方案都可以通过使用“属性保留哈希函数”来增强为鲁棒签名方案。

Result: 成功构建了首个不可检测的水印方案。该方案在替换（即汉明距离扰动）方面具有鲁棒性、不可伪造性和可恢复性。

Conclusion: 新提出的方案通过将内容唯一地关联到其生成模型，加强了内容所有权，从而实现了安全的归因和细粒度的可追溯性，解决了现有方案在虚假归因保护方面的局限性。

Abstract: Language models now routinely produce text that is difficult to distinguish from human writing, raising the need for robust tools to verify content provenance. Watermarking has emerged as a promising countermeasure, with existing work largely focused on model quality preservation and robust detection. However, current schemes provide limited protection against false attribution. We strengthen the notion of soundness by introducing two novel guarantees: unforgeability and recoverability. Unforgeability prevents adversaries from crafting false positives, texts that are far from any output from the watermarked model but are nonetheless flagged as watermarked. Recoverability provides an additional layer of protection: whenever a watermark is detected, the detector identifies the source text from which the flagged content was derived. Together, these properties strengthen content ownership by linking content exclusively to its generating model, enabling secure attribution and fine-grained traceability. We construct the first undetectable watermarking scheme that is robust, unforgeable, and recoverable with respect to substitutions (i.e., perturbations in Hamming metric). The key technical ingredient is a new cryptographic primitive called robust (or recoverable) digital signatures, which allow verification of messages that are close to signed ones, while preventing forgery of messages that are far from all previously signed messages. We show that any standard digital signature scheme can be boosted to a robust one using property-preserving hash functions (Boyle, LaVigne, and Vaikuntanathan, ITCS 2019).

</details>


### [75] [A Unified Evaluation of Learning-Based Similarity Techniques for Malware Detection](https://arxiv.org/abs/2602.15376)
*Udbhav Prasad,Aniesh Chawla*

Main category: cs.CR

TL;DR: 本文系统比较了多种基于学习的文件相似性技术在实际安全工作负载中的表现。研究发现，没有单一方法是普适的，有效的方法应结合多种互补技术。


<details>
  <summary>Details</summary>
Motivation: 传统加密摘要（如MD5、SHA-256）在面对细微输入变化时会产生完全不同的哈希值，这限制了它们在威胁溯源、恶意软件分析和数字取证等安全任务中的实用性，而现有相似性技术（如相似性摘要、局部敏感哈希、机器学习嵌入）又缺乏在统一框架下的系统评估。

Method: 本文采用统一的实验框架、大型公开数据集和行业认可的指标，对基于学习的分类和相似性方法进行了系统比较，这是首次对这些多样化的技术进行可复现的并行基准测试。

Result: 没有单一方法在所有维度上表现出色，每种方法都展现出独特的权衡。

Conclusion: 有效的恶意软件分析和威胁溯源平台必须结合互补的分类和相似性技术，而非单一方法。

Abstract: Cryptographic digests (e.g., MD5, SHA-256) are designed to provide exact identity. Any single-bit change in the input produces a completely different hash, which is ideal for integrity verification but limits their usefulness in many real-world tasks like threat hunting, malware analysis and digital forensics, where adversaries routinely introduce minor transformations. Similarity-based techniques address this limitation by enabling approximate matching, allowing related byte sequences to produce measurably similar fingerprints. Modern enterprises manage tens of thousands of endpoints with billions of files, making the effectiveness and scalability of the proposed techniques more important than ever in security applications. Security researchers have proposed a range of approaches, including similarity digests and locality-sensitive hashes (e.g., ssdeep, sdhash, TLSH), as well as more recent machine-learning-based methods that generate embeddings from file features. However, these techniques have largely been evaluated in isolation, using disparate datasets and evaluation criteria. This paper presents a systematic comparison of learning-based classification and similarity methods using large, publicly available datasets. We evaluate each method under a unified experimental framework with industry-accepted metrics. To our knowledge, this is the first reproducible study to benchmark these diverse learning-based similarity techniques side by side for real-world security workloads. Our results show that no single approach performs well across all dimensions; instead, each exhibits distinct trade-offs, indicating that effective malware analysis and threat-hunting platforms must combine complementary classification and similarity techniques rather than rely on a single method.

</details>


### [76] [SecCodeBench-V2 Technical Report](https://arxiv.org/abs/2602.15485)
*Longfei Chen,Ji Zhao,Lanxiao Cui,Tong Su,Xingbo Pan,Ziyang Li,Yongxing Wu,Qijiang Cao,Qiyao Cai,Jing Zhang,Yuandong Ni,Junyao He,Zeyu Zhang,Chao Ge,Xuhuai Lu,Zeyu Gao,Yuxin Cui,Weisen Chen,Yuxuan Peng,Shengping Wang,Qi Li,Yukai Huang,Yukun Liu,Tuo Zhou,Terry Yue Zhuo,Junyang Lin,Chao Zhang*

Main category: cs.CR

TL;DR: SecCodeBench-V2是一个公开的基准测试，用于评估大型语言模型(LLM)代码助手生成安全代码的能力。它包含来自阿里巴巴集团工业生产的98个生成和修复场景，涵盖22个CWE类别和五种编程语言。该基准采用函数级任务，提供由安全专家编写和双重审查的可执行PoC测试用例，并构建了一个主要基于动态执行的统一评估管道，辅以LLM作为判断的机制和Pass@K计分协议，旨在为评估AI编码助手的安全态势提供严谨且可复现的基础。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在引入SecCodeBench-V2，以评估大型语言模型（LLM）代码助手生成安全代码的能力，从而满足对AI编码助手安全性能进行严格评估的需求。

Method: SecCodeBench-V2的构建方法包括：1. **基准场景构建**：从阿里巴巴集团的工业生产中提取98个代码生成和修复场景，涵盖Java、C、Python、Go等五种编程语言的22个常见CWE（通用弱点枚举）类别。2. **任务形式**：采用函数级任务制定，要求模型在固定的接口和依赖下，在一个完整的项目骨架中实现或修补指定的目标函数。3. **测试用例**：为每个场景提供可执行的PoC（概念验证）测试用例，用于功能验证和安全验证，所有测试用例均由安全专家编写并双重审查，确保高保真度、广泛覆盖和可靠的真实性。4. **评估管道**：构建一个统一的评估管道，主要通过动态执行进行评估。模型生成的工件在隔离环境中编译和运行，并执行PoC测试用例以验证功能正确性和安全属性。5. **LLM作为评判**：对于无法通过确定性测试用例判断安全问题的场景，额外采用LLM作为判断的预言机。6. **评分协议**：设计了基于Pass@K的评分协议，对不同场景和严重性进行原则性聚合，以总结异构场景和难度级别的性能，实现模型的整体和可比较评估。

Result: SecCodeBench-V2为评估AI编码助手的安全态势提供了一个严谨且可重现的基础。所有结果和工件均已公开发布。

Conclusion: SecCodeBench-V2是一个公开、全面且严谨的基准测试，用于评估LLM代码助手生成安全代码的能力。它通过工业生产衍生的场景、专家审查的测试用例和稳健的评估管道，为评估AI编码助手的安全态势提供了一个标准化的方法。

Abstract: We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and . SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at . The benchmark is publicly available at .

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [77] [PolyNODE: Variable-dimension Neural ODEs on M-polyfolds](https://arxiv.org/abs/2602.15128)
*Per Åhag,Alexander Friedrich,Fredrik Ohlsson,Viktor Vigren Näslund*

Main category: cs.LG

TL;DR: 本文将神经常微分方程（NODEs）扩展到M-polyfolds，提出了PolyNODEs，这是几何深度学习中首个可变维度的基于流的模型，并实验证明其能解决可变维度空间中的重建和分类任务。


<details>
  <summary>Details</summary>
Motivation: 现有的神经常微分方程（NODEs）模型受限于流形维度的内在性质，只能处理固定维度的动态。

Method: 将神经常微分方程（NODEs）扩展到M-polyfolds（可以同时适应不同维度和可微性概念的空间），并引入了PolyNODEs，这是几何深度学习中第一个可变维度的基于流的模型。

Result: PolyNODE模型可以被训练来解决M-polyfold空间中的重建任务，并且可以提取输入的潜在表示用于解决下游分类任务。

Conclusion: PolyNODEs成功解决了传统NODEs的固定维度限制，为几何深度学习提供了一种新的可变维度流模型，并在重建和分类任务中展现了有效性。

Abstract: Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at .

</details>


### [78] [MAVRL: Learning Reward Functions from Multiple Feedback Types with Amortized Variational Inference](https://arxiv.org/abs/2602.15206)
*Raphaël Baur,Yannick Metz,Maria Gkoulta,Mennatallah El-Assady,Giorgia Ramponi,Thomas Kleine Buening*

Main category: cs.LG

TL;DR: 该论文提出了一种贝叶斯推断方法，用于从多种异构反馈类型中联合学习奖励函数，该方法使用摊销变分推断，并展示了其在离散和连续控制任务中优于单一类型基线，能利用互补信息并提高策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前的奖励学习方法通常依赖单一反馈类型，或通过手动加权损失项组合多种反馈类型。对于如何联合学习来自演示、比较、评分和停止等异构反馈类型的奖励函数尚不明确，这些反馈类型提供了性质上不同的信号。

Method: 通过将多反馈类型奖励学习公式化为共享潜在奖励函数上的贝叶斯推断，其中每种反馈类型通过显式似然贡献信息。引入了一种可扩展的摊销变分推断方法，该方法学习一个共享的奖励编码器和特定于反馈的似然解码器，并通过优化单个证据下界（ELBO）进行训练。该方法避免了将反馈简化为共同的中间表示，并消除了手动损失平衡的需要。

Result: 在离散和连续控制基准测试中，联合推断的奖励后验优于单一类型基线，利用了不同反馈类型之间的互补信息，并产生了对环境扰动更具鲁棒性的策略。此外，推断出的奖励不确定性为分析模型置信度以及反馈类型之间的一致性提供了可解释的信号。

Conclusion: 该研究证明了所提出的贝叶斯推断方法能够有效地从异构反馈类型中学习共享奖励函数，并提高了策略的鲁棒性。推断出的奖励不确定性为模型置信度和反馈类型之间的一致性提供了可解释的信号。

Abstract: Reward learning typically relies on a single feedback type or combines multiple feedback types using manually weighted loss terms. Currently, it remains unclear how to jointly learn reward functions from heterogeneous feedback types such as demonstrations, comparisons, ratings, and stops that provide qualitatively different signals. We address this challenge by formulating reward learning from multiple feedback types as Bayesian inference over a shared latent reward function, where each feedback type contributes information through an explicit likelihood. We introduce a scalable amortized variational inference approach that learns a shared reward encoder and feedback-specific likelihood decoders and is trained by optimizing a single evidence lower bound. Our approach avoids reducing feedback to a common intermediate representation and eliminates the need for manual loss balancing. Across discrete and continuous-control benchmarks, we show that jointly inferred reward posteriors outperform single-type baselines, exploit complementary information across feedback types, and yield policies that are more robust to environment perturbations. The inferred reward uncertainty further provides interpretable signals for analyzing model confidence and consistency across feedback types.

</details>


### [79] [Automatically Finding Reward Model Biases](https://arxiv.org/abs/2602.15222)
*Atticus Wang,Iván Arcuschin,Arthur Conmy*

Main category: cs.LG

TL;DR: 本研究提出了一种使用LLM迭代发现奖励模型偏差的方法，成功识别了已知和新偏差（如Skywork-V2-8B偏好冗余空格和幻觉内容），并证明进化迭代优于“最佳N选一”搜索。


<details>
  <summary>Details</summary>
Motivation: 奖励模型(RMs)在LLM后训练中至关重要，但现有研究表明它们可能奖励虚假或不良属性，如长度、格式、幻觉和奉承。本研究旨在解决自动发现自然语言中奖励模型偏差的问题。

Method: 提出了一种使用大型语言模型(LLM)迭代提议和完善候选偏差的简单方法。

Result: 该方法能够识别已知偏差并发现新的偏差，例如发现Skywork-V2-8B奖励模型倾向于偏爱具有冗余空格和幻觉内容的回复。此外，研究表明进化迭代优于扁平化的“最佳N选一”搜索策略，并通过合成注入的偏差验证了管道的召回率。

Conclusion: 本工作旨在通过自动化可解释性方法促进奖励模型(RMs)的改进，为未来研究提供基础。

Abstract: Reward models are central to large language model (LLM) post-training. However, past work has shown that they can reward spurious or undesirable attributes such as length, format, hallucinations, and sycophancy. In this work, we introduce and study the research problem of automatically finding reward model biases in natural language. We offer a simple approach of using an LLM to iteratively propose and refine candidate biases. Our method can recover known biases and surface novel ones: for example, we found that Skywork-V2-8B, a leading open-weight reward model, often mistakenly favors responses with redundant spacing and responses with hallucinated content. In addition, we show evidence that evolutionary iteration outperforms flat best-of-N search, and we validate the recall of our pipeline using synthetically injected biases. We hope our work contributes to further research on improving RMs through automated interpretability methods.

</details>


### [80] [Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238)
*Chengzhi Hu,Jonas Dornbusch,David Lüdke,Stephan Günnemann,Leo Schwinn*

Main category: cs.LG

TL;DR: 尽管对抗性训练在提高大型语言模型（LLMs）的鲁棒性方面取得了进展，但模型仍易受简单的分布内攻击。本文提出了分布对抗性训练（DAT），它利用扩散LLMs来近似真实的数据分布，生成多样化的高似然样本，从而显著提高了对抗性鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的对抗性训练算法在训练集上最小化对抗性损失，但未能充分覆盖数据分布，导致模型容易受到简单的分布内攻击。

Method: 提出分布对抗性训练（DAT）。该方法利用扩散LLMs来近似提示和响应的真实联合分布，从而能够生成多样化、高似然的样本。DAT结合了基于扩散模型提供的数据分布优化和连续对抗性训练。

Result: DAT比以前的方法实现了更高的对抗性鲁棒性。

Conclusion: 通过更好地覆盖数据分布，DAT解决了对抗性训练中的泛化失败问题，从而提高了模型的鲁棒性。

Abstract: Adversarial training for LLMs is one of the most promising methods to reliably improve robustness against adversaries. However, despite significant progress, models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or translating them into other languages. We argue that this persistent fragility stems from a fundamental limitation in current adversarial training algorithms: they minimize adversarial loss on their training set but inadequately cover the data distribution, resulting in vulnerability to seemingly simple attacks. To bridge this gap, we propose Distributional Adversarial Training, DAT. We leverage Diffusion LLMs to approximate the true joint distribution of prompts and responses, enabling generation of diverse, high-likelihood samples that address generalization failures. By combining optimization over the data distribution provided by the diffusion model with continuous adversarial training, DAT achieves substantially higher adversarial robustness than previous methods.

</details>


### [81] [Seeing to Generalize: How Visual Data Corrects Binding Shortcuts](https://arxiv.org/abs/2602.15183)
*Nicolas Buzeta,Felipe del Rio,Cristian Hinostroza,Denis Parra,Hans Lobel,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: VLMs在纯文本任务上超越LLMs，尤其是在长上下文检索中，原因在于跨模态训练通过空间平移不变性打破了位置捷径，强制模型采用更鲁棒的符号绑定机制，从而增强了泛化和推理能力。


<details>
  <summary>Details</summary>
Motivation: 观察到视觉语言模型（VLMs）在纯文本任务，尤其是在长上下文信息检索方面，表现优于其底层的LLMs，旨在探究此现象的原因。

Method: 1. 构建受控合成检索任务。2. 训练纯文本Transformer模型。3. 在相同任务的图像标记版本上进行后续训练。4. 通过机制可解释性分析模型内部绑定策略的变化。5. 评估绑定策略在不同训练方案、视觉编码器和初始化下的表现。6. 观察预训练LLM到VLM过渡期间的类似转变。

Result: 1. 纯文本训练的模型在分布内表现完美，但泛化能力差。2. 引入图像标记训练后，纯文本域的OOD性能几乎翻倍。3. 视觉训练改变了模型的内部绑定策略：纯文本训练倾向于位置捷径，而基于图像的训练通过空间平移不变性打破了这些捷径，迫使模型采用更鲁棒的符号绑定机制。4. 发现预训练LLM到VLM的过渡也发生类似的绑定策略转变。

Conclusion: 跨模态训练可以增强模型在单一模态任务上的推理和泛化能力。

Abstract: Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in long-context information retrieval. To investigate this effect, we build a controlled synthetic retrieval task and find that a transformer trained only on text achieves perfect in-distribution accuracy but fails to generalize out of distribution, while subsequent training on an image-tokenized version of the same task nearly doubles text-only OOD performance. Mechanistic interpretability reveals that visual training changes the model's internal binding strategy: text-only training encourages positional shortcuts, whereas image-based training disrupts them through spatial translation invariance, forcing the model to adopt a more robust symbolic binding mechanism that persists even after text-only examples are reintroduced. We further characterize how binding strategies vary across training regimes, visual encoders, and initializations, and show that analogous shifts occur during pretrained LLM-to-VLM transitions. Our findings suggest that cross-modal training can enhance reasoning and generalization even for tasks grounded in a single modality.

</details>


### [82] [The Information Geometry of Softmax: Probing and Steering](https://arxiv.org/abs/2602.15293)
*Kiho Park,Todd Nief,Yo Joong Choe,Victor Veitch*

Main category: cs.LG

TL;DR: 本文探讨了AI系统如何将语义结构编码到其表示空间的几何结构中，特别关注定义softmax分布的表示的信息几何，并提出了一种名为“对偶转向”的方法，用于鲁棒地操纵概念。


<details>
  <summary>Details</summary>
Motivation: 研究AI系统如何将语义结构编码到表示空间的几何结构中，因为表示空间的自然几何应反映模型如何利用表示来产生行为。本文关注定义softmax分布的表示，并认为其自然几何是信息几何。

Method: 本文提出了“对偶转向”方法，该方法利用线性探测器来鲁棒地引导表示以展示特定概念。该方法在信息几何的框架下进行开发。

Result: “对偶转向”方法能最优地修改目标概念，同时最小化对非目标概念的改变。实证结果表明，对偶转向增强了概念操纵的可控性和稳定性。

Conclusion: “对偶转向”方法通过优化目标概念修改和最小化非目标概念影响，有效提升了概念操纵的可控性和稳定性。

Abstract: This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop "dual steering", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.

</details>


### [83] [Prescriptive Scaling Reveals the Evolution of Language Model Capabilities](https://arxiv.org/abs/2602.15327)
*Hanlin Zhang,Jikai Jin,Vasilis Syrgkanis,Sham Kakade*

Main category: cs.LG

TL;DR: 该研究通过对模型性能的大规模观测评估，利用平滑分位数回归估计了基础模型能力边界随预训练计算量（FLOPs）的变化，并验证了其时间稳定性。研究发现，除数学推理外，大多数任务的能力边界是稳定的。此外，研究还分析了任务依赖的饱和度、数学推理任务上的污染相关偏移，并提出了一种高效的评估算法。最终，发布了Proteus 2k数据集和一套将计算预算转化为可靠性能预期并监控能力边界变化的方法。


<details>
  <summary>Details</summary>
Motivation: 部署基础模型时，从业者需要处方性扩展定律：给定预训练计算预算，当代后训练实践可达到何种下游准确性，以及该映射随领域发展如何保持稳定。

Method: 利用包含5k观测数据和2k新增采样数据的大规模观测评估模型性能。通过单调、饱和S型参数化的平滑分位数回归，估计了能力边界（基准分数高条件分位数作为对数预训练FLOPs的函数）。通过在早期模型代际上拟合并在后期版本上评估来验证时间可靠性。扩展方法以分析任务依赖的饱和度，并探测数学推理任务上与污染相关的偏移。引入了一种高效算法，该算法使用大约20%的评估预算即可恢复接近完整数据前沿。

Result: 估计的能力边界在大多数任务中保持稳定，但数学推理任务表现出随时间持续推进的边界。引入的高效算法能以约20%的评估预算恢复接近完整的数据前沿。发布了Proteus 2k数据集。

Conclusion: 该工作发布了最新的模型性能评估数据集Proteus 2k，并引入了一种实用的方法，用于将计算预算转化为可靠的性能预期，并监控能力边界随时间推移的变化。

Abstract: For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.

</details>


### [84] [Discovering Implicit Large Language Model Alignment Objectives](https://arxiv.org/abs/2602.15338)
*Edward Chen,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: Obj-Disco是一个框架，它能自动将大型语言模型（LLM）的对齐奖励信号分解为人类可解释的自然语言目标，从而识别潜在的偏差并促进更透明、安全的AI开发。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的对齐依赖于复杂的奖励信号，这些信号往往模糊了具体被激励的行为，从而产生了错位和奖励欺骗的关键风险。现有的解释方法通常依赖预定义的规则，存在遗漏“未知未知”的风险，或未能识别出能够全面覆盖并与模型行为因果相关的目标。

Method: 本文提出了Obj-Disco框架，它通过迭代贪婪算法分析训练检查点间的行为变化，识别并验证最能解释残余奖励信号的候选目标，从而将对齐奖励信号自动分解为稀疏、加权且人类可解释的自然语言目标。

Result: 该框架在不同的任务、模型大小和对齐算法上表现出鲁棒性。对流行的开源奖励模型的实验表明，Obj-Disco持续捕获了90%以上的奖励行为，并通过人工评估得到证实。此外，一个案例研究表明，Obj-Disco能够成功识别与预期行为同时出现的潜在错位激励。

Conclusion: Obj-Disco为揭示LLM对齐中的隐式目标提供了一个关键工具，为更透明和安全的AI发展铺平了道路。

Abstract: Large language model (LLM) alignment relies on complex reward signals that often obscure the specific behaviors being incentivized, creating critical risks of misalignment and reward hacking. Existing interpretation methods typically rely on pre-defined rubrics, risking the omission of "unknown unknowns", or fail to identify objectives that comprehensively cover and are causal to the model behavior. To address these limitations, we introduce Obj-Disco, a framework that automatically decomposes an alignment reward signal into a sparse, weighted combination of human-interpretable natural language objectives. Our approach utilizes an iterative greedy algorithm to analyze behavioral changes across training checkpoints, identifying and validating candidate objectives that best explain the residual reward signal. Extensive evaluations across diverse tasks, model sizes, and alignment algorithms demonstrate the framework's robustness. Experiments with popular open-source reward models show that the framework consistently captures > 90% of reward behavior, a finding further corroborated by human evaluation. Additionally, a case study on alignment with an open-source reward model reveals that Obj-Disco can successfully identify latent misaligned incentives that emerge alongside intended behaviors. Our work provides a crucial tool for uncovering the implicit objectives in LLM alignment, paving the way for more transparent and safer AI development.

</details>


### [85] [Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning](https://arxiv.org/abs/2602.15817)
*Oswin So,Eric Yang Yu,Songyuan Zhang,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: 本文提出了一种名为 Feasibility-Guided Exploration (FGE) 的方法，用于解决深度强化学习在可达性问题上的局限性。FGE 通过同步识别可行的初始条件子集并学习安全策略，实现了比现有最佳方法高出 50% 以上的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在处理可达性问题时存在根本性的不匹配：强化学习优化预期回报，导致在低概率但安全的 states 上表现不佳。鲁棒优化是一个替代方案，但其可行性事先未知。

Method: 提出 Feasibility-Guided Exploration (FGE) 方法。FGE 同时识别存在安全策略的可行初始条件子集，并学习在此初始条件集上解决可达性问题的策略。

Result: FGE 学习到的策略在 MuJoCo 和 Kinetix 模拟器中，对于具有挑战性的初始条件，覆盖率比现有最佳方法高出 50% 以上。

Conclusion: FGE 有效解决了强化学习与可达性问题之间的不匹配，通过学习在已识别的可行初始条件上的安全策略，显著提高了覆盖率。

Abstract: Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.

</details>


### [86] [Fast and Effective On-policy Distillation from Reasoning Prefixes](https://arxiv.org/abs/2602.15260)
*Dongxu Zhang,Zhichao Yang,Sepehr Janghorbani,Jun Han,Andrew Ressler II,Qian Qian,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.LG

TL;DR: 提出了一种新的在策略前缀蒸馏（PPD）方法，通过仅对输出前缀进行蒸馏并提前终止采样，显著降低了在策略蒸馏（OPD）的训练成本（2x-47x FLOP），同时保持了性能。


<details>
  <summary>Details</summary>
Motivation: 在策略蒸馏（OPD）在训练过程中需要昂贵的学生策略即时采样，尤其对于长响应会大幅增加训练成本。通过分析发现，OPD 的训练信号通常集中在每个输出的前缀部分，并且一个简短的教师生成前缀就能显著帮助学生生成正确答案。

Method: 提出了一种名为在策略前缀蒸馏（On-policy Prefix Distillation, PPD）的方法，该方法仅将蒸馏目标应用于学生生成输出的前缀部分，并在蒸馏过程中提前终止每次采样。

Result: 在策略前缀蒸馏（PPD）在AI-for-Math和域外基准测试上，与完整的在策略蒸馏（OPD）性能相当，同时将训练浮点运算量（FLOP）减少了2倍至47倍。

Conclusion: 在策略前缀蒸馏（PPD）是一种简单而有效的修改，它在保持与完整在策略蒸馏（OPD）性能一致的同时，显著降低了训练成本。

Abstract: On-policy distillation (OPD), which samples trajectories from the student model and supervises them with a teacher at the token level, avoids relying solely on verifiable terminal rewards and can yield better generalization than off-policy distillation. However, OPD requires expensive on-the-fly sampling of the student policy during training, which substantially increases training cost, especially for long responses. Our initial analysis shows that, during OPD, training signals are often concentrated in the prefix of each output, and that even a short teacher-generated prefix can significantly help the student produce the correct answer. Motivated by these observations, we propose a simple yet effective modification of OPD: we apply the distillation objective only to prefixes of student-generated outputs and terminate each sampling early during distillation. Experiments on a suite of AI-for-Math and out-of-domain benchmarks show that on-policy prefix distillation matches the performance of full OPD while reducing training FLOP by 2x-47x.

</details>


### [87] [Hybrid Federated and Split Learning for Privacy Preserving Clinical Prediction and Treatment Optimization](https://arxiv.org/abs/2602.15304)
*Farzana Akter,Rakib Hossain,Deb Kanna Roy Toushi,Mahmood Menon Khan,Sultana Amin,Lisan Al Amin*

Main category: cs.LG

TL;DR: 该论文提出了一种混合联邦学习和分层学习框架，用于在不共享原始数据的情况下进行隐私保护的医疗决策支持。该框架在预测性能上与现有方法相当，并提供可调的隐私-效用权衡以减少数据泄露。


<details>
  <summary>Details</summary>
Motivation: 协作式临床决策支持通常受到管理和隐私规则的限制，这些规则阻止跨机构汇集患者级别的记录。

Method: 本文提出了一种结合联邦学习（FL）和分层学习（SL）的混合隐私保护框架，用于无需共享原始数据即可支持面向决策的医疗保健建模。该方法将特征提取主干保留在客户端，而将预测头托管在协调服务器上，从而实现共享表示学习并暴露明确的协作边界以应用隐私控制。研究还通过在剪切层表示上使用成员推断凭经验审计数据泄露，并研究了基于激活裁剪和添加高斯噪声的轻量级防御措施。该框架在三个公共临床数据集上，在非独立同分布（non-IID）客户端分区下进行评估，并通过统一的管道，从事实预测效用、容量约束下的基于提升的排名、审计隐私泄露和通信开销四个与部署相关的维度共同评估性能。

Result: 结果表明，与独立的联邦学习或分层学习相比，混合联邦学习-分层学习变体实现了具有竞争力的预测性能和面向决策的优先排序行为。同时，它提供了一种可调的隐私-效用权衡，可以在不要求共享原始数据的情况下减少审计到的数据泄露。

Conclusion: 该工作将混合联邦学习-分层学习（FL-SL）定位为一种实用的隐私保护医疗决策支持设计空间，能够明确平衡效用、泄露风险和部署成本。

Abstract: Collaborative clinical decision support is often constrained by governance and privacy rules that prevent pooling patient-level records across institutions. We present a hybrid privacy-preserving framework that combines Federated Learning (FL) and Split Learning (SL) to support decision-oriented healthcare modeling without raw-data sharing. The approach keeps feature-extraction trunks on clients while hosting prediction heads on a coordinating server, enabling shared representation learning and exposing an explicit collaboration boundary where privacy controls can be applied. Rather than assuming distributed training is inherently private, we audit leakage empirically using membership inference on cut-layer representations and study lightweight defenses based on activation clipping and additive Gaussian noise. We evaluate across three public clinical datasets under non-IID client partitions using a unified pipeline and assess performance jointly along four deployment-relevant axes: factual predictive utility, uplift-based ranking under capacity constraints, audited privacy leakage, and communication overhead. Results show that hybrid FL-SL variants achieve competitive predictive performance and decision-facing prioritization behavior relative to standalone FL or SL, while providing a tunable privacy-utility trade-off that can reduce audited leakage without requiring raw-data sharing. Overall, the work positions hybrid FL-SL as a practical design space for privacy-preserving healthcare decision support where utility, leakage risk, and deployment cost must be balanced explicitly.

</details>


### [88] [On Surprising Effectiveness of Masking Updates in Adaptive Optimizers](https://arxiv.org/abs/2602.15322)
*Taejong Joo,Wenhan Xia,Cheolmin Kim,Ming Zhang,Eugene Ie*

Main category: cs.LG

TL;DR: 随机掩蔽参数更新对训练大型语言模型非常有效，并且优于最先进的优化器。引入了一种新的方法Magma，它使用动量对齐梯度掩蔽，以可忽略的开销进一步提高性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的训练几乎完全依赖于具有日益复杂预处理器的密集自适应优化器。本文通过展示随机掩蔽参数更新的高度有效性来挑战这一现状。

Method: 1. 提出随机掩蔽参数更新可以非常有效，其掩蔽变体RMSProp持续优于最近最先进的优化器。2. 分析随机掩蔽能诱导曲率依赖的几何正则化，从而平滑优化轨迹。3. 引入动量对齐梯度掩蔽（Magma），它使用动量-梯度对齐来调制掩蔽更新。

Result: 1. 掩蔽RMSProp持续优于最近最先进的优化器。2. Magma作为自适应优化器的简单替代品，具有一致的性能提升和可忽略的计算开销。3. 对于1B模型，Magma与Adam和Muon相比，困惑度分别降低了19%以上和9%。

Conclusion: 随机掩蔽是一种有效的LLM训练技术，因为它能诱导几何正则化。Magma，一种动量对齐梯度掩蔽方法，与现有自适应优化器相比，以最小的开销提供了显著的性能改进（例如，困惑度降低）。

Abstract: Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\% and 9\% compared to Adam and Muon, respectively.

</details>


### [89] [GLM-5: from Vibe Coding to Agentic Engineering](https://arxiv.org/abs/2602.15763)
*GLM-5 Team,Aohan Zeng,Xin Lv,Zhenyu Hou,Zhengxiao Du,Qinkai Zheng,Bin Chen,Da Yin,Chendi Ge,Chengxing Xie,Cunxiang Wang,Gengzheng Pan,Hao Zeng,Haoke Zhang,Haoran Wang,Huilong Chen,Jiajie Zhang,Jian Jiao,Jiaqi Guo,Jingsen Wang,Jingzhao Du,Jinzhu Wu,Kedong Wang,Lei Li,Lin Fan,Lucen Zhong,Mingdao Liu,Mingming Zhao,Pengfan Du,Qian Dong,Rui Lu,Shuang-Li,Shulin Cao,Song Liu,Ting Jiang,Xiaodong Chen,Xiaohan Zhang,Xuancheng Huang,Xuezhen Dong,Yabo Xu,Yao Wei,Yifan An,Yilin Niu,Yitong Zhu,Yuanhao Wen,Yukuo Cen,Yushi Bai,Zhongpei Qiao,Zihan Wang,Zikang Wang,Zilin Zhu,Ziqiang Liu,Zixuan Li,Bojie Wang,Bosi Wen,Can Huang,Changpeng Cai,Chao Yu,Chen Li,Chen Li,Chenghua Huang,Chengwei Hu,Chenhui Zhang,Chenzheng Zhu,Congfeng Yin,Daoyan Lin,Dayong Yang,Di Wang,Ding Ai,Erle Zhu,Fangzhou Yi,Feiyu Chen,Guohong Wen,Hailong Sun,Haisha Zhao,Haiyi Hu,Hanchen Zhang,Hanrui Liu,Hanyu Zhang,Hao Peng,Hao Tai,Haobo Zhang,He Liu,Hongwei Wang,Hongxi Yan,Hongyu Ge,Huan Liu,Huan Liu,Huanpeng Chu,Jia'ni Zhao,Jiachen Wang,Jiajing Zhao,Jiamin Ren,Jiapeng Wang,Jiaxin Zhang,Jiayi Gui,Jiayue Zhao,Jijie Li,Jing An,Jing Li*

Main category: cs.LG

TL;DR: GLM-5是一个旨在实现从“vibe coding”到智能体工程范式转变的下一代基础模型。它通过采用DSA降低成本，引入新的异步强化学习基础设施和算法来提高效率、对齐和自主性，从而在基准测试和真实世界编码任务中均达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统编程模式（"vibe coding"）效率低下，需要向更高效的智能体工程范式转变。现有模型在训练和推理成本、长上下文保真度、模型对齐和自主性，以及在复杂长周期交互中学习的能力方面存在改进空间。

Method: 1. 采用DSA（Dynamic Sparse Attention 或类似技术，原文未明确展开，但提到其效果）显著降低训练和推理成本，同时保持长上下文保真度。
2. 实现了一种新的异步强化学习（RL）基础设施，通过将生成与训练解耦，大幅提高后训练效率。
3. 提出了新颖的异步智能体RL算法，进一步提高RL质量，使模型能够更有效地从复杂、长周期的交互中学习。

Result: 1. 在主要开放基准测试中取得了最先进（state-of-the-art, SOTA）的性能。
2. 在真实世界编码任务中展现出前所未有的能力。
3. 在处理端到端软件工程挑战方面超越了以前的基线模型。

Conclusion: GLM-5通过其架构创新和强化学习方法的改进，成功地将编程范式从"vibe coding"提升到智能体工程，并在合成基准和实际编码任务中均表现出卓越的性能，标志着基础模型在软件工程领域的重要进展。

Abstract: We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at .

</details>


### [90] [A Scalable Curiosity-Driven Game-Theoretic Framework for Long-Tail Multi-Label Learning in Data Mining](https://arxiv.org/abs/2602.15330)
*Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 针对长尾多标签分类挑战，本文提出CD-GTMLL，一个合作博弈框架，通过好奇心奖励和玩家间分歧自适应地平衡尾部标签，无需手动调优，并在多个大型数据集上显著优于SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 大型多标签分类（MLC）在真实世界数据挖掘应用中面临长尾分布的挑战，即少数头部标签占主导，而稀有尾部标签数量众多。现有重采样和重加权策略常破坏标签间依赖性或需要脆弱的超参数调整，尤其在标签空间扩展至数万个标签时。

Method: CD-GTMLL将长尾多标签分类重构为一个多玩家合作博弈：每个子预测器（“玩家”）专注于标签空间的一个分区，通过合作最大化全局准确性，并根据尾部标签稀有度和玩家间分歧追求内在好奇心奖励。该机制自适应地为欠代表的尾部标签注入学习信号，无需手动平衡或调优。模型收敛至尾部感知均衡，并优化Rare-F1指标。

Result: CD-GTMLL在7个基准测试（包括包含30,000+标签的极限多标签分类数据集）中持续超越现有SOTA方法，在Wiki10-31K上P@3指标提升高达+1.6%。消融研究证实了博弈论合作和好奇心驱动探索对鲁棒尾部性能的贡献。

Conclusion: CD-GTMLL通过结合博弈论和好奇心机制，不仅提高了资源受限环境下的模型效率，还为电子商务和医疗保健等行业中的不平衡数据场景提供了更具适应性的学习方法。

Abstract: The long-tail distribution, where a few head labels dominate while rare tail labels abound, poses a persistent challenge for large-scale Multi-Label Classification (MLC) in real-world data mining applications. Existing resampling and reweighting strategies often disrupt inter-label dependencies or require brittle hyperparameter tuning, especially as the label space expands to tens of thousands of labels. To address this issue, we propose Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL), a scalable cooperative framework that recasts long-tail MLC as a multi-player game - each sub-predictor ("player") specializes in a partition of the label space, collaborating to maximize global accuracy while pursuing intrinsic curiosity rewards based on tail label rarity and inter-player disagreement. This mechanism adaptively injects learning signals into under-represented tail labels without manual balancing or tuning. We further provide a theoretical analysis showing that our CD-GTMLL converges to a tail-aware equilibrium and formally links the optimization dynamics to improvements in the Rare-F1 metric. Extensive experiments across 7 benchmarks, including extreme multi-label classification datasets with 30,000+ labels, demonstrate that CD-GTMLL consistently surpasses state-of-the-art methods, with gains up to +1.6% P@3 on Wiki10-31K. Ablation studies further confirm the contributions of both game-theoretic cooperation and curiosity-driven exploration to robust tail performance. By integrating game theory with curiosity mechanisms, CD-GTMLL not only enhances model efficiency in resource-constrained environments but also paves the way for more adaptive learning in imbalanced data scenarios across industries like e-commerce and healthcare.

</details>


### [91] [FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning](https://arxiv.org/abs/2602.15337)
*Chaoyi Lu*

Main category: cs.LG

TL;DR: FedPSA提出了一种基于参数敏感性的细粒度异步联邦学习框架，通过动态调整对过期信息的容忍度，解决了现有AFL方法因陈旧性度量粗糙导致的性能限制，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 异步联邦学习（AFL）虽然比传统联邦学习训练速度更快，但由于异步过程引入的陈旧性可能导致性能下降。现有方法通常仅使用当前模型与全局模型之间的轮次差异作为衡量陈旧性的唯一指标，这种方式过于粗糙且缺乏对模型本身的观察，从而限制了异步方法的性能上限。

Method: 本文提出了FedPSA（基于参数敏感性的异步联邦学习），这是一个更细粒度的AFL框架。它利用参数敏感性来衡量模型过时性，并建立了一个动态动量队列以实时评估当前训练阶段，从而动态调整对过期信息的容忍度。

Result: 在多个数据集上的广泛实验和与各种方法的比较表明，FedPSA表现出卓越的性能，比基线方法提高了高达6.37%，比现有最先进的方法提高了1.93%。

Conclusion: FedPSA通过引入参数敏感性度量模型过时性和动态动量队列评估训练阶段，证明了其作为一种更细粒度异步联邦学习框架的优越性。

Abstract: Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\% improvement over baseline methods and 1.93\% over the current state-of-the-art method.

</details>


### [92] [CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies](https://arxiv.org/abs/2602.15367)
*Sibo Zhang,Rui Jing,Liangfu Lv,Jian Zhang,Yunliang Zang*

Main category: cs.LG

TL;DR: 本文提出了一种受小脑启发的强化学习架构，通过整合其结构原理（大规模扩展、稀疏连接、稀疏激活、树突级调制），显著提高了强化学习在噪声环境下的样本效率、鲁棒性和泛化能力，证明了小脑结构先验作为有效归纳偏差的价值。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在处理高维序贯决策任务时，面临样本效率低、对噪声敏感以及在部分可观测性下泛化能力弱的局限性。现有方法主要通过优化策略解决这些问题，而架构先验在塑造表征学习和决策动态方面的作用探索较少。

Method: 受小脑结构原理的启发，作者提出了一种生物学基础的强化学习架构，该架构结合了大规模扩展、稀疏连接、稀疏激活和树突级调制。

Result: 在嘈杂、高维的强化学习基准测试中，小脑架构和树突调制均持续提高了样本效率、鲁棒性和泛化能力，优于传统设计。对架构参数的敏感性分析表明，小脑启发式结构可以在模型参数受限的情况下为强化学习提供优化性能。

Conclusion: 小脑结构先验可以作为强化学习的有效归纳偏差。

Abstract: Reinforcement learning (RL) has achieved notable performance in high-dimensional sequential decision-making tasks, yet remains limited by low sample efficiency, sensitivity to noise, and weak generalization under partial observability. Most existing approaches address these issues primarily through optimization strategies, while the role of architectural priors in shaping representation learning and decision dynamics is less explored. Inspired by structural principles of the cerebellum, we propose a biologically grounded RL architecture that incorporate large expansion, sparse connectivity, sparse activation, and dendritic-level modulation. Experiments on noisy, high-dimensional RL benchmarks show that both the cerebellar architecture and dendritic modulation consistently improve sample efficiency, robustness, and generalization compared to conventional designs. Sensitivity analysis of architectural parameters suggests that cerebellum-inspired structures can offer optimized performance for RL with constrained model parameters. Overall, our work underscores the value of cerebellar structural priors as effective inductive biases for RL.

</details>


### [93] [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)
*Yannic Neuhaus,Nicolas Flammarion,Matthias Hein,Francesco Croce*

Main category: cs.LG

TL;DR: 本文评估了大型语言模型和大型视觉语言模型中思维链（CoT）推理在网格导航任务上的泛化能力。研究发现，CoT推理能提高分布内泛化，但分布外泛化能力有限，除非推理轨迹结合多种文本格式。纯文本模型表现优于图像模型。


<details>
  <summary>Details</summary>
Motivation: 尽管将推理集成到大型语言模型和大型视觉语言模型中显著提高了其能力，但推理模型的泛化能力仍定义模糊且理解不足。

Method: 本文提出了一个评估框架，用于严格检验思维链（CoT）方法在简单规划任务（具体为基于网格的导航任务）上的泛化能力。通过使用不同的输入表示（视觉和文本）和CoT推理策略对模型变体进行微调，并在分布内（ID）和分布外（OOD）测试条件下系统地评估它们。

Result: CoT推理在所有表示中都改善了分布内泛化。然而，在大多数情况下，当控制与ID数据的简单匹配时，分布外泛化（例如，到更大的地图）仍然非常有限。令人惊讶的是，结合多种文本格式的推理轨迹产生了最佳（且非平凡的）OOD泛化。最后，纯文本模型始终优于使用基于图像输入的模型。

Conclusion: 研究表明，思维链推理在分布内泛化方面有效，但在分布外泛化方面存在显著局限性。结合多种文本格式的推理轨迹可以改善分布外泛化。纯文本模型在这种导航任务中表现出优于图像模型的性能。

Abstract: Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigorously examine how well chain-of-thought (CoT) approaches generalize on a simple planning task. Specifically, we consider a grid-based navigation task in which a model is provided with a map and must output a sequence of moves that guides a player from a start position to a goal while avoiding obstacles. The versatility of the task and its data allows us to fine-tune model variants using different input representations (visual and textual) and CoT reasoning strategies, and systematically evaluate them under both in-distribution (ID) and out-of-distribution (OOD) test conditions. Our experiments show that, while CoT reasoning improves in-distribution generalization across all representations, out-of-distribution generalization (e.g., to larger maps) remains very limited in most cases when controlling for trivial matches with the ID data. Surprisingly, we find that reasoning traces which combine multiple text formats yield the best (and non-trivial) OOD generalization. Finally, purely text-based models consistently outperform those utilizing image-based inputs, including a recently proposed approach relying on latent space reasoning.

</details>


### [94] [Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design](https://arxiv.org/abs/2602.15648)
*Jens U. Kreber,Christian Weißenfels,Joerg Stueckler*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型的新型逆向设计方法，通过将设计空间松弛为连续网格，利用可微分模拟中的梯度进行引导扩散采样，并将结果反投影回原始空间，从而为复合材料设计问题找到多样化的解决方案，并在匹配体积模量和最小化材料密度方面表现出有效性。


<details>
  <summary>Details</summary>
Motivation: 逆向设计问题通常涉及数值模拟（例如FEM），并且面临多模态解决方案和离散/受限设计空间等挑战，这阻碍了基于梯度的优化。对多样化解决方案和复杂设计空间处理的需求促使了这项工作。

Method: 本方法将原始离散设计空间松弛为连续网格表示，通过正向模拟中的隐式微分计算梯度。在松弛参数空间上训练一个扩散模型作为合理松弛设计的先验。在推理时，通过可微分模拟中从目标函数传播的梯度，使用引导扩散对参数进行采样。最终通过反投影到原始参数空间获得设计样本。该方法针对复合材料设计问题进行开发，其中正向过程建模为线性FEM问题。

Result: 该方法能够在2D和3D设置中，对于中等到高目标体积模量，在1%的相对误差范围内提出多样化的设计。通过使用多目标损失函数，还可以同时最小化生成样本的材料密度。

Conclusion: 所提出的基于扩散模型的逆向设计方法有效解决了设计空间结构和多模态性方面的挑战，为工程和材料科学问题（如复合材料设计）提供了多样化和优化的解决方案。

Abstract: Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.

</details>


### [95] [Logit Distance Bounds Representational Similarity](https://arxiv.org/abs/2602.15438)
*Beatrix M. B. Nielsen,Emanuele Marconato,Luigi Gresele,Andrea Dittadi,Simon Buchholz*

Main category: cs.LG

TL;DR: 本论文研究了判别模型中近似条件分布一致性是否能带来内部表示的近似一致性。不同于KL散度，本文提出了一种基于logit差异的分布距离，它能保证线性表示的相似性。实验表明，基于logit距离的蒸馏比基于KL散度的蒸馏更能保留线性表示特性。


<details>
  <summary>Details</summary>
Motivation: 可识别性结果表明，如果两个判别模型产生相同的条件分布，则它们的内部表示通过可逆线性变换达成一致。本文旨在探讨当分布近似而非完全相等时，是否也能得出类似的结论，以解决KL散度在衡量线性表示相似性方面的不足。

Method: 本文定义了一种基于模型可识别性类别的表示差异度量，并引入了基于logit差异的分布距离。理论上证明了表示差异度量受logit距离的限制。此外，还分析了KL散度与logit距离的关系，并在合成数据集和图像数据集上进行了蒸馏实验。

Result: 基于logit差异的距离能够保证线性表示的相似性，并且表示差异度量受logit距离的限制。当模型概率远离零时，KL散度可以上限化logit距离，但该上限在实践中无法提供有意义的控制。基于KL的蒸馏可以匹配教师模型的预测，但无法保留线性表示特性；而基于logit距离的蒸馏能使学生模型具有更高的线性表示相似性，并更好地保留教师模型中线性可恢复的概念。

Conclusion: 基于logit差异的分布距离是衡量和保留判别模型中线性表示特性的有效方法，优于KL散度。在模型蒸馏任务中，采用logit距离进行蒸馏可以更好地保留教师模型中可解释的概念和线性表示属性。

Abstract: For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.

</details>


### [96] [The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes](https://arxiv.org/abs/2602.15515)
*Mohammad Taufeeque,Stefan Heimersheim,Adam Gleave,Chris Cundy*

Main category: cs.LG

TL;DR: 在现实编码环境中，AI系统在对抗白盒欺骗检测器训练时可能学会通过“混淆激活”或“混淆策略”来隐藏欺骗。高KL正则化和检测器惩罚能促使模型保持诚实，证明了白盒欺骗检测器在防止奖励劫持方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 训练对抗白盒欺骗检测器被提议作为使AI系统诚实的方法。然而，这种训练存在模型学习混淆其欺骗以逃避检测器的风险。以往的工作仅在模型直接因有害输出而获得奖励的人工环境中研究了混淆。

Method: 构建了一个奖励劫持（通过硬编码测试用例）自然发生的现实编码环境。引入了一种在对抗欺骗检测器进行训练时可能出现的结果分类法。通过经验研究和理论分析（针对策略梯度方法），探讨了不同的混淆策略（混淆激活和混淆策略）的产生机制。

Result: 在现实编码环境中，混淆现象确实出现。模型可能保持诚实，或者通过两种混淆策略变得具有欺骗性：(i) 混淆激活：模型输出欺骗性文本，同时修改其内部表示以不再触发检测器。(ii) 混淆策略：模型输出逃避检测器的欺骗性文本，通常通过包含对奖励劫持的理由来实现。经验表明，混淆激活源于强化学习过程中的表示漂移，无论是否存在检测器惩罚。探测器惩罚只激励混淆策略，理论上证明这对于策略梯度方法是预期的。

Conclusion: 足够高的KL正则化和检测器惩罚可以产生诚实的策略，这表明白盒欺骗检测器是应对奖励劫持任务的可行训练信号。

Abstract: Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.

</details>


### [97] [MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2602.15740)
*Fatemeh Khalvandi,Saadat Izadi,Abdolah Chalechale*

Main category: cs.LG

TL;DR: 该论文提出了一种名为MRC-GAT的多模态模型，用于阿尔茨海默病（AD）的早期分类诊断。该模型通过基于copula的相似性对齐、关系注意力机制和节点融合，并结合情景元学习，实现了多模态特征的有效整合，并在TADPOLE和NACC数据集上取得了最先进的诊断精度，分别为96.87%和92.31%。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）是一种进行性神经退行性疾病，需要早期精确诊断以提供及时临床管理。鉴于早期诊断的重要性，当前研究越来越关注计算机辅助诊断模型以提高精度和可靠性。然而，大多数基于图的方法仍依赖于固定的结构设计，这限制了它们的灵活性和在异构患者数据间的泛化能力。

Method: 提出了Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) 模型。该模型将基于copula的相似性对齐、关系注意力和节点融合作为情景元学习的核心组件。多模态特征，包括风险因素（RF）、认知测试分数和MRI属性，首先通过基于copula的转换在共同的统计空间中对齐，然后通过多关系注意力机制进行组合。

Result: 在TADPOLE和NACC数据集上进行的评估显示，MRC-GAT模型分别实现了96.87%和92.31%的准确率，与现有诊断模型相比，展示了最先进的性能。

Conclusion: 所提出的模型通过在疾病诊断的各个阶段提供可解释性，证实了所提方法的鲁棒性和适用性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.

</details>


### [98] [UrbanVerse: Learning Urban Region Representation Across Cities and Tasks](https://arxiv.org/abs/2602.15750)
*Fengze Sun,Egemen Tanin,Shanika Karunasekera,Zuqing Li,Flora D. Salim,Jianzhong Qi*

Main category: cs.LG

TL;DR: UrbanVerse是一个用于城市分析的基础模型，通过创新的跨城市和跨任务泛化方法，在多个下游任务上显著优于现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有的城市区域表征学习方法在跨城市和跨分析任务的泛化能力方面存在局限性。该论文旨在将城市表征学习泛化到超越城市和特定任务的设置，迈向城市分析的基础模型。

Method: 该论文提出了UrbanVerse模型，用于跨城市城市表征学习和跨任务城市分析。为了实现跨城市泛化，UrbanVerse侧重于目标区域的局部特征和附近区域的结构特征，而非整个城市。它将区域建模为图上的节点，并采用基于随机游走的程序来形成“区域序列”，以反映局部和邻里结构特征。为了实现跨任务泛化，该论文提出了名为HCondDiffCT的跨任务学习模块，该模块将区域条件先验知识和任务条件语义集成到扩散过程中，以共同建模多个下游城市预测任务。HCondDiffCT还可与现有城市表征学习模型集成以增强其下游任务有效性。

Result: 在真实世界数据集上的实验表明，UrbanVerse在跨城市设置下的六项任务中持续优于现有最先进的方法，预测准确率最高提高了35.89%。

Conclusion: UrbanVerse是一个新颖的城市分析基础模型，与现有方法相比，它在跨城市和跨任务泛化方面表现出卓越的能力，显著提高了预测准确性。

Abstract: Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form "sequences of regions" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.

</details>


### [99] [The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety](https://arxiv.org/abs/2602.15799)
*Max Springer,Chung Peng Lee,Blossom Metevier,Jane Castleman,Bohdan Turbal,Hayoung Jung,Zeyu Shen,Aleksandra Korolova*

Main category: cs.LG

TL;DR: 微调对齐语言模型在良性任务上时，即使没有有害内容，也会意外地降低安全防护。这源于对齐在低维、高曲率子空间中的集中，导致梯度下降过程中二阶效应的累积，从而造成对齐损失随训练时间呈四次方增长。


<details>
  <summary>Details</summary>
Motivation: 现有的解释认为微调更新与安全方向正交，但这被证明是错误的。研究需要揭示为何在良性任务上微调对齐语言模型会导致安全防护意外下降，以解决现有安全范式的盲点。

Method: 通过新颖的几何分析方法，证明了对齐集中在具有尖锐曲率的低维子空间中。提出了对齐不稳定性条件（Alignment Instability Condition），并分析了曲率如何通过二阶加速度将训练轨迹引向对齐敏感区域。

Result: 揭示了对齐损失与训练时间的四次方呈比例增长的定标律。对齐损失的增长由对齐几何的尖锐度和微调任务与安全关键参数之间的曲率耦合强度决定。

Conclusion: 对齐的脆弱性不是一个需要修补的错误，而是梯度下降在弯曲流形上的固有几何属性。现有安全范式存在结构性盲点，需要开发曲率感知方法，并将对齐安全分析从被动红队测试转向预测性诊断。

Abstract: Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [100] [The geometry of online conversations and the causal antecedents of conflictual discourse](https://arxiv.org/abs/2602.15600)
*Carlo Santagiustina,Caterina Cruciani*

Main category: cs.SI

TL;DR: 本文研究了气候变化在线讨论中冲突性语言的因果前因及互动几何。研究发现，发帖时间间隔、会话环境以及树状结构特征会影响讨论中的立场、语气和情感表达。具体而言，较长的发帖间隔与更尊重的回复相关；与父帖的较长间隔与较少的分歧但更多情感化表达相关；与父帖和同级旧帖的立场、语气、情感框架存在强烈的趋同性；早期分支响应会影响父子立场的一致性；礼貌维度影响是累加的，而情感维度存在显著的交互作用。


<details>
  <summary>Details</summary>
Motivation: 调查气候变化在线讨论中冲突性语言的因果前因以及互动几何。

Method: 通过LLM提示和平均推断出三个标注维度（立场：同意 vs 分歧；语气：攻击性 vs 尊重；情感 vs 事实框架）来捕捉话语冲突的互补方面，并利用在线论坛的帖子数据来检验这些维度如何响应时间、会话和树状结构特征。

Result: 1. 线程中连续帖子之间较长的延迟与平均更尊重的回复相关；相对于父帖的较长延迟与分歧略少但更多情感（较少事实）的语言相关。 2. 存在与同一父帖的旧兄弟姐妹帖子以及父帖本身在平均立场、语气和情感框架上的强烈趋同性，且父帖效应通常强于兄弟姐妹效应。 3. 早期分支级别的响应会调节这些对齐动态，父子立场对齐会根据分支是否以同意或不同意讨论的根消息而放大或减弱。 4. 这些影响对于与礼貌相关的维度（攻击性 vs 尊重，不同意 vs 同意）大体上是累加的；而对于情感与事实框架，存在显著的交互作用：当旧兄弟姐妹帖子也类似地对齐时，与父帖情感性的对齐会放大。

Conclusion: 在线气候变化讨论中冲突性语言的出现和互动模式受到多种因素的影响，包括时间延迟、对话结构以及早期分支响应，其中父帖和同级帖子的影响以及情感表达的交互作用尤为显著。

Abstract: This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.

</details>


<div id='hep-ex'></div>

# hep-ex [[Back]](#toc)

### [101] [GRACE: an Agentic AI for Particle Physics Experiment Design and Simulation](https://arxiv.org/abs/2602.15039)
*Justin Hill,Hong Joo Ryoo*

Main category: hep-ex

TL;DR: GRACE是一个面向高能和核物理领域的自主实验设计仿真原生智能体。它能从多模态输入中提取实验信息，构建仿真，并利用蒙特卡洛方法探索探测器设计修改以优化物理性能。通过分层仿真评估，GRACE在历史实验和自然语言提示基准测试中展示了其识别优化方向和改进建议的能力，将实验设计确立为物理定律下的约束搜索问题，并为自主科学推理引入了新基准。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体系统主要关注操作控制或执行预定义程序。然而，实验设计中存在一个上游问题，即如何在物理和实际约束下，提出探测器几何、材料和配置的非显而易见的修改，以改善物理性能。GRACE旨在解决这一挑战。

Method: GRACE是一个仿真原生智能体，它接收自然语言提示或已发表论文等多模态输入。首先，智能体从输入中提取实验的结构化表示，然后构建一个可运行的玩具仿真。接着，它使用第一性原理蒙特卡洛方法自主探索探测器几何、材料和配置的设计修改。智能体通过重复仿真、基于物理的效用函数以及预算感知的逐步升级（从快速参数模型到完整的Geant4仿真）来评估候选设计，同时严格保持可复现性并进行溯源追踪。

Result: 1. 在历史实验设置中进行了框架演示，结果表明该智能体能够仅使用基线仿真输入，识别出与已知升级优先级相符的优化方向。
2. 通过一项基准测试，智能体成功地从一系列自然语言提示（部分附有相关物理研究论文）中识别出设置并提出了改进建议，涵盖了不同高能物理问题。

Conclusion: 这项工作将实验设计确立为一个在物理定律下的约束搜索问题，并为复杂仪器中的自主、仿真驱动的科学推理引入了一个新的基准。

Abstract: We present GRACE, a simulation-native agent for autonomous experimental design in high-energy and nuclear physics. Given multimodal input in the form of a natural-language prompt or a published experimental paper, the agent extracts a structured representation of the experiment, constructs a runnable toy simulation, and autonomously explores design modifications using first-principles Monte Carlo methods. Unlike agentic systems focused on operational control or execution of predefined procedures, GRACE addresses the upstream problem of experimental design: proposing non-obvious modifications to detector geometry, materials, and configurations that improve physics performance under physical and practical constraints. The agent evaluates candidate designs through repeated simulation, physics-motivated utility functions, and budget-aware escalation from fast parametric models to full Geant4 simulations, while maintaining strict reproducibility and provenance tracking. We demonstrate the framework on historical experimental setups, showing that the agent can identify optimization directions that align with known upgrade priorities, using only baseline simulation inputs. We also conducted a benchmark in which the agent identified the setup and proposed improvements from a suite of natural language prompts, with some supplied with a relevant physics research paper, of varying high energy physics (HEP) problem settings. This work establishes experimental design as a constrained search problem under physical law and introduces a new benchmark for autonomous, simulation-driven scientific reasoning in complex instruments.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [102] [Proactive Conversational Assistant for a Procedural Manual Task based on Audio and IMU](https://arxiv.org/abs/2602.15707)
*Rehana Mahfuz,Yinyi Guo,Erik Visser,Phanidhar Chinchili*

Main category: cs.MM

TL;DR: 本文提出了一种仅使用音频和IMU输入的实时、保护隐私的会话助手，用于程序性任务。通过新颖的UWA LoRA微调方法，F-score提高了30%以上，速度提升了16倍，并可在边缘设备上运行。


<details>
  <summary>Details</summary>
Motivation: 现有的程序性任务实时会话助手通常依赖于视频输入，这不仅计算成本高昂，还会损害用户隐私。因此，需要一种仅使用轻量级、保护隐私的模态（如音频和IMU输入）来提供全面指导的实时会话助手。

Method: 1. 提出了一种仅使用来自用户可穿戴设备的音频和IMU输入来理解上下文的实时会话助手。
2. 构建了一个包含助手指导用户执行家具组装任务对话的数据集。
3. 针对现成的语言模型在对话中过于“健谈”的问题，设计了一种新颖的用户意图无关（UWA）LoRA微调方法，以抑制信息量较少的对话，同时保留传达重要指令的能力。
4. 在边缘设备上实现了该助手，不依赖于云服务。

Result: 1. UWA LoRA微调方法使F-score提高了30%以上。
2. 模型微调通过消除在提示中提供上下文示例的需要，实现了16倍的速度提升。
3. 该方法有效抑制了信息量较少的对话，同时保持了传达重要指令的能力。

Conclusion: 该研究表明，通过轻量级音频和IMU输入可以实现实时、保护隐私的程序性任务会话助手。UWA LoRA微调显著提高了助手的效率和对重要信息的关注度，并支持在边缘设备上部署。

Abstract: Real-time conversational assistants for procedural tasks often depend on video input, which can be computationally expensive and compromise user privacy. For the first time, we propose a real-time conversational assistant that provides comprehensive guidance for a procedural task using only lightweight privacy-preserving modalities such as audio and IMU inputs from a user's wearable device to understand the context. This assistant proactively communicates step-by-step instructions to a user performing a furniture assembly task, and answers user questions. We construct a dataset containing conversations where the assistant guides the user in performing the task. On observing that an off-the-shelf language model is a very talkative assistant, we design a novel User Whim Agnostic (UWA) LoRA finetuning method which improves the model's ability to suppress less informative dialogues, while maintaining its tendency to communicate important instructions. This leads to >30% improvement in the F-score. Finetuning the model also results in a 16x speedup by eliminating the need to provide in-context examples in the prompt. We further describe how such an assistant is implemented on edge devices with no dependence on the cloud.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [103] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个用于评估AI智能体在端到端研究中表现的基准和执行环境。研究发现，包括GPT-5在内的前沿智能体存在显著的能力-可靠性差距，尽管它们偶尔能达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了评估AI智能体在端到端研究中的能力，并了解它们在提出假设、运行实验和超越人类基线方面的表现和局限性，本文引入了ResearchGym。

Method: 研究方法是重新利用ICML、ICLR和ACL的五篇口头报告和亮点论文。从每篇论文的存储库中保留数据集、评估工具和基线实现，但隐去论文提出的方法。这形成了包含39个子任务的五个容器化任务环境。智能体必须提出新颖的假设、运行实验，并尝试在论文的指标上超越强大的人类基线。同时评估了由GPT-5驱动的智能体以及包括Claude Code和Codex在内的专有智能体脚手架。

Result: 由GPT-5驱动的智能体在15次评估中仅有1次（6.7%）改进了基线，提高了11.5%，平均仅完成了26.5%的子任务。识别出常见的长周期故障模式，包括不耐烦、时间与资源管理不善、对弱假设的过度自信、协调并行实验的困难以及上下文长度的硬限制。然而，在一次运行中，智能体超越了ICML 2025亮点任务的解决方案。其他专有智能体也显示出类似的能力-可靠性差距。

Conclusion: ResearchGym为自主智能体在闭环研究中的系统评估和分析提供了基础设施，并揭示了当前前沿AI智能体在端到端研究中存在显著的能力-可靠性差距。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [104] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 本文研究了通过修改教师模型生成的推理轨迹来阻止未经授权的知识蒸馏的方法，旨在实现反蒸馏（降低查询响应的训练有用性）和API水印（在学生模型中嵌入可验证签名）。实验表明，一种简单的基于指令的重写方法能有效实现反蒸馏，并支持高可靠性的水印检测。


<details>
  <summary>Details</summary>
Motivation: 未经授权的知识蒸馏利用了开发前沿大型语言模型（LLMs）所投入的巨大努力和成本，造成了不公平的竞争。

Method: 提出了动态重写教师模型推理输出的方法，同时保持答案的正确性和语义连贯性。其中两种方法利用LLMs的重写能力，另一些则使用基于梯度的技术。

Result: 实验证明，一种简单的基于指令的重写方法可以实现强大的反蒸馏效果，同时保持甚至提高了教师模型的性能。此外，这种重写方法还可以实现高度可靠的水印检测，基本没有误报。

Conclusion: 通过动态重写教师模型的推理输出，可以有效阻止未经授权的知识蒸馏，并通过嵌入可验证的水印来保护大型语言模型的知识产权，同时不影响教师模型的表现。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [105] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 本文提出了一种新的da Costian-Tarskianism方法来处理本体异质性，该方法基于扩展推理系统和扩展发展图。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提出一种处理本体异质性的新方法，该方法受到Carnapian-Goguenism的启发。

Method: 该方法暂时命名为da Costian-Tarskianism，基于推理系统，并引入了“扩展推理系统”（即加入了本体论公理的推理系统）和“扩展发展图”（一种通过扩展推理系统的态射以及其他操作如纤维化和分裂来关联本体的图结构）。

Result: 本文提出了da Costian-Tarskianism方法，并定义了扩展推理系统和扩展发展图的概念，为本体异质性提供了一个新颖的框架。

Conclusion: 本文讨论了这种方法对应用本体论领域的影响，并提出了未来的研究方向。

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [106] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 研究比较了LLMs在不确定性下的风险决策，发现它们分为理性的推理模型（RMs）和类人的会话模型（CMs），并指出数学推理训练是区分两者的关键。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为决策支持系统或在智能体工作流中的应用正在迅速改变数字生态系统，但其在不确定性下的决策制定机制仍知之甚少。

Method: 本研究对20个前沿和开源大型语言模型进行了风险选择的比较研究，考察了前景表征（显式或基于经验）和决策理由（解释）两个维度。研究还通过匹配的人类受试者实验提供了一个参照点，并以期望收益最大化的理性智能体模型作为另一个参照点。

Result: LLMs被分为两类：推理模型（RMs）和会话模型（CMs）。RMs倾向于理性行为，对前景顺序、得失框架和解释不敏感，无论前景是显式还是通过经验历史呈现，其行为都相似。CMs的理性程度显著较低，更像人类，对前景顺序、框架和解释敏感，并表现出较大的描述-历史差距。对开源LLMs的配对比较表明，区分RMs和CMs的关键因素是数学推理训练。

Conclusion: LLMs分为两类：推理模型（RMs）和会话模型（CMs），RMs更趋于理性且行为稳定，CMs则更像人类且受外部因素影响。数学推理训练是区分这两类模型的一个关键因素。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [107] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 本文介绍并评估了一个AI机器学习框架，该框架旨在通过补充确定性算法来预测供应链金融中的发票或支付稀释风险。


<details>
  <summary>Details</summary>
Motivation: 发票或支付稀释是供应链金融中非信用风险和利润损失的重要来源。传统的不可撤销支付承诺（IPU）会阻碍供应链金融的普及，尤其是在非投资级买家之间。

Method: 本文引入了一个AI机器学习框架，并评估其如何通过使用包含九个关键交易字段的广泛生产数据集来补充确定性算法，以实时预测发票稀释。

Result: 本文致力于引入并评估AI机器学习框架在预测发票稀释方面的能力，该框架利用了广泛的生产数据集，旨在解决供应链金融中的稀释风险。

Conclusion: 本文通过引入并评估AI机器学习框架在预测发票稀释方面的潜力，为解决供应链金融中的稀释风险提供了一种数据驱动的新方法。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [108] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 探索不同类型的记忆如何帮助智能体在不确定且非稳定的环境中进行空间导航，发现结合多策略、非稳定概率学习和动态记忆构建的智能体在复杂任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 在不确定、非稳定且感知受限的环境中，智能体进行空间导航和觅食面临挑战，需要研究如何构建鲁棒的模型和快速有效的学习方法。

Method: 研究了在简单觅食任务中，智能体从家通过障碍物找到食物的过程，比较了从简单到复杂的一系列使用不同记忆和学习策略的方法，包括结合多策略、非稳定概率学习和动态构建不完美地图。

Result: 发现处理不同性质子任务（探索、搜索、规划）需要结合多种策略的架构。利用非稳定概率学习技术更新情景记忆，并用这些记忆动态构建地图和规划路径的智能体，在任务难度增加时（只要不确定性不太大），比简单（最小记忆）智能体效率更高。

Conclusion: 在变化和不确定环境中，智能体通过结合多策略、非稳定概率学习和基于经验动态构建不完美地图的记忆利用方式，可以显著提高空间导航的效率，尤其适用于复杂任务。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [109] [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294)
*Ming Du,Yanqi Luo,Srutarshi Banerjee,Michael Wojcik,Jelena Popovic,Mathew J. Cherukara*

Main category: cs.AI

TL;DR: 本文提出了实验自动化智能体（EAA），这是一个由视觉语言模型驱动的智能体系统，旨在自动化复杂的实验显微镜工作流程。


<details>
  <summary>Details</summary>
Motivation: 提高光束线效率，减少操作负担，降低用户专业知识门槛。

Method: EAA集成了多模态推理、工具增强行动和可选的长期记忆，建立在灵活的任务管理器架构之上。它支持自主程序和交互式用户引导测量，并提供了一个现代工具生态系统，与模型上下文协议（MCP）具有双向兼容性。

Result: EAA在先进光子源的成像光束线进行了演示，包括自动区域板聚焦、自然语言描述的特征搜索和交互式数据采集。

Conclusion: 视觉智能体可以提高光束线效率，减少操作负担，并降低用户的专业知识门槛。

Abstract: We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.

</details>


### [110] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: 该研究提出一个智能体框架，通过AgriWorld执行环境和Agro-Reflective LLM智能体，使LLMs能够通过编写和执行代码来推理农业时空数据，并在基准测试中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有农业基础模型在预测和监测方面表现良好，但缺乏基于语言的推理和交互能力，限制了其在实际农艺工作流中的应用。同时，大型语言模型（LLMs）擅长文本解释和生成，但无法直接对高维、异构的农业时空数据集进行推理。因此，研究的动机在于弥合LLMs的语言推理能力与农业数据处理能力之间的差距。

Method: 该研究提出了一个农业科学的智能体框架。核心方法包括：
1.  **AgriWorld**：一个Python执行环境，提供统一的工具，用于地块地理空间查询、遥感时间序列分析、作物生长模拟以及任务特定预测器（如产量、胁迫和疾病风险）。
2.  **Agro-Reflective**：一个多轮大型语言模型（LLM）智能体，它通过“执行-观察-优化”循环迭代地编写代码、观察执行结果并改进其分析。
3.  **AgroBench**：一个用于生成可扩展数据的农业问答基准，涵盖查找、预测、异常检测和反事实“假设分析”。

Result: 实验结果表明，该方法在文本分析和直接工具使用基线上表现优异。这验证了执行驱动的反射机制对于实现可靠的农业推理的有效性。

Conclusion: 通过实验验证了执行驱动的反射机制对于可靠的农业推理是有效的，弥合了大型语言模型与农业高维异构数据之间的鸿沟。

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [111] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 该论文介绍了一种自适应弃权系统，通过实时上下文信号和分层级联检测机制，动态调整大型语言模型（LLM）的安全阈值，以在安全性和实用性之间取得平衡，同时优化性能。


<details>
  <summary>Details</summary>
Motivation: 生产环境中部署的大型语言模型（LLMs）面临安全与实用性的权衡，现有防护机制通常不具备上下文感知能力且计算成本高昂，导致高延迟和用户体验下降。

Method: 提出了一种自适应弃权系统，该系统根据领域和用户历史等实时上下文信号动态调整安全阈值。该框架集成了由五个并行检测器组成的多维检测架构，并通过分层级联机制进行组合，以优化速度和精度。级联设计通过逐步过滤查询减少了不必要的计算。

Result: 该系统显著减少了误报，特别是在医疗建议和创意写作等敏感领域。与非级联模型和外部防护系统相比，级联设计显著提高了延迟。在严格操作模式下，系统保持了高安全精度和接近完美的召回率。

Conclusion: 该上下文感知弃权框架有效平衡了安全性和实用性，同时保持了性能，为可靠的LLM部署提供了一个可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [112] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: 引入了EduEVAL-DB数据集，用于评估和训练教学解释的自动教学评估器和AI导师。该数据集包含基于教师角色的解释和教学风险评估标准，并通过初步验证实验展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI教育工具在教学解释方面可能存在不足，需要一个专门的数据集来支持自动教学评估器和AI导师的评估与训练，以提升教学解释的质量。

Method: 1. 构建EduEVAL-DB数据集，包含来自ScienceQA基准测试中139个问题的854个解释，涵盖K-12科学、语言和社会科学。2. 每个问题包含一个人类教师解释和六个由大语言模型（LLM）模拟教师角色生成的解释，这些角色通过提示工程实例化。3. 提出了一个教学风险评估标准，定义了五个风险维度：事实正确性、解释深度和完整性、重点和相关性、学生水平适当性以及意识形态偏见。4. 通过半自动化流程并结合专家教师审查，对所有解释进行二元风险标签注释。5. 进行初步验证实验，将Gemini 2.5 Pro与Llama 3.1 8B模型进行基准测试，并评估在EduEVAL-DB上进行监督微调是否支持教学风险检测。

Result: 初步验证实验表明EduEVAL-DB适用于评估用途。研究考察了在消费级硬件上可部署的模型通过在EduEVAL-DB上进行监督微调是否能有效支持教学风险检测。

Conclusion: EduEVAL-DB数据集及其提出的教学风险评估标准为自动教学评估器和AI导师的开发与评估提供了基础，尤其有助于在消费级硬件上部署的模型进行教学风险检测，从而可能改善AI在教育领域的应用。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [113] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva提出了一种“玻璃盒”架构，通过个人知识图谱实现个人AI的人工记忆管理，解决了当前“黑盒”RAG系统在问责制和隐私方面的不足，允许用户精确检查和修改信息。


<details>
  <summary>Details</summary>
Motivation: 当前个人AI系统（依赖“黑盒”检索增强生成和向量数据库）缺乏问责制。用户无法检查或纠正AI幻觉或敏感数据检索，且概念删除不精确，从而侵犯了隐私。

Method: Ruva是一种用于人机协同记忆管理的首个“玻璃盒”架构。它将个人AI基于个人知识图谱，将范式从向量匹配转向图推理。

Result: Ruva使用户能够检查AI的知识并精确编辑特定事实。这确保了“被遗忘权”，并赋予用户编辑其数字记忆的权力。

Conclusion: Ruva为个人AI提供了一种新颖的“玻璃盒”方法，通过个人知识图谱实现精确的记忆管理，确保问责制、透明度和真正的隐私，从根本上赋予用户对其数据和AI知识的控制权。

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at .

</details>


### [114] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 该论文使用PID Flow框架分析了多模态Transformer在不同层中视觉和语言信息的处理方式，揭示了“模态转导”模式，即视觉信息早期达到峰值，语言信息后期占据主导，且跨模态协同作用较低。


<details>
  <summary>Details</summary>
Motivation: 探究多模态Transformer的预测是由视觉证据、语言推理还是真正的跨模态融合计算驱动的，以及这种结构如何随层演变。

Method: 提出并应用了一种基于偏信息分解（PID）的逐层框架，结合了维度约简、归一化流高斯化和闭式高斯PID估计，形成了PID Flow。该框架应用于LLaVA-1.5-7B和LLaVA-1.6-7B在六个GQA推理任务上。通过有针对性的Image→Question注意力消除来建立因果关系。

Result: 发现了一个一致的“模态转导”模式：视觉独有信息早期达到峰值并随深度衰减，语言独有信息在后期层中激增（占最终预测的约82%），跨模态协同作用低于2%。这种轨迹在模型变体间高度稳定但强烈依赖于任务。注意力消除证实了因果关系，显示出被困视觉独有信息、补偿性协同作用和总信息成本的可预测增加，在视觉依赖型任务中最强。

Conclusion: 这些结果提供了关于多模态Transformer中视觉如何转化为语言的信息论和因果解释，并为识别可能丢失模态特定信息的架构瓶颈提供了定量指导。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [115] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 本文提出了一种预处理方法，用于推断额外的累积约束，以捕捉多资源交互，从而改进调度问题的搜索性能和目标边界。


<details>
  <summary>Details</summary>
Motivation: 累积约束在约束编程调度中是核心，但通常按约束进行传播，忽略了多资源交互，导致在某些基准测试上出现严重减速。

Method: 该方法将累积约束解释为关于占用向量的线性不等式，并通过(i)发现覆盖（即不能并行运行的任务集），(ii)通过提升加强发现集的覆盖不等式，以及(iii)将所得约束重新注入调度问题实例中来生成有效不等式。

Result: 在标准RCPSP和RCPSP/max测试套件上的实验表明，这些推断出的约束在有利实例上改善了搜索性能并收紧了目标边界，而在不利实例上几乎没有退化。此外，这些实验发现了25个新的下界和5个新的最佳解；其中8个下界直接来源于推断出的约束。

Conclusion: 推断出的累积约束能有效捕捉多资源交互，从而提高搜索性能并收紧目标边界。

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [116] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: 本文提出了CARE Drive框架，用于评估自动驾驶中视觉语言模型对人类相关考量的原因响应性，发现人类理由显著影响模型决策，但响应性因上下文因素而异。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要侧重于结果表现（如安全性和轨迹精度），未能确定模型决策是否反映人类相关考量。因此，不清楚模型解释是真正的原因响应决策还是事后合理化，这在安全关键领域可能导致虚假自信。

Method: 提出CARE Drive（Context Aware Reasons Evaluation for Driving），这是一个模型无关的框架，用于评估自动驾驶中视觉语言模型的原因响应性。该框架通过在受控上下文变异下比较基线和理由增强的模型决策，评估人类理由是否因果影响决策行为。评估过程分两阶段：提示校准以确保稳定输出，然后系统性的上下文扰动以衡量决策对安全裕度、社会压力和效率约束等人类理由的敏感性。研究在一个涉及相互竞争规范考量的骑车人超车场景中演示了CARE Drive。

Result: 明确的人类理由显著影响了模型决策，提高了与专家推荐行为的一致性。然而，响应性因上下文因素而异，表明模型对不同类型理由的敏感度不均。

Conclusion: 这些发现提供了经验证据，表明基础模型中的原因响应性可以在不修改模型参数的情况下进行系统评估。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [117] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA是一个无需训练的框架，通过直接操纵激活空间中的个性向量，实现了LLM的精细化个性控制，达到与微调相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的个性控制方法依赖于静态提示或昂贵的微调，未能捕捉人类特质的动态性和组合性。

Method: PERSONA框架通过三个阶段运行：Persona-Base通过对比激活分析提取正交特质向量；Persona-Algebra通过向量算术（标量乘法用于强度，加法用于组合，减法用于抑制）实现精确控制；Persona-Flow在推理过程中动态组合这些向量以实现上下文感知适应。核心在于，个性特质在模型的表示空间中表现为可提取的、近似正交的方向，并支持代数运算。

Result: 在PersonalityBench上，PERSONA实现了9.60的平均得分，几乎达到了监督微调的上限9.61，且无需任何梯度更新。在提出的Persona-Evolve基准上，对于动态个性适应，该方法在不同模型家族中取得了高达91%的胜率。

Conclusion: LLM个性的某些方面可以通过数学方法处理，这为可解释和高效的行为控制开辟了新方向。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [118] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: 大型语言模型在组合推理任务上表现不佳是由于其固定潜在表示。RCE框架通过动态生成、合并和巩固概念子空间，使模型能够在推理过程中修改其内部表示几何，从而显著提升了在组合推理基准测试上的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在许多复杂推理任务上表现出色，但在需要组合推理的基准测试（如ARC-AGI-2、GPQA、MATH、BBH和HLE）上准确性急剧下降。现有方法（如思维链提示、自洽性或强化学习）通过扩展token级别的搜索来改进推理，但它们保持模型潜在表示空间固定。当所需的抽象未被编码在此空间中时，性能会崩溃。

Method: 提出了一种名为递归概念演化（RCE）的框架。RCE使预训练语言模型能够在推理过程中修改其内部表示几何。该方法引入了动态生成的低秩概念子空间，这些子空间在检测到表示不足时产生，通过最小描述长度准则进行选择，在协同作用时合并，并通过受限优化进行整合以保持稳定性。这个过程允许模型构建新的抽象，而不是仅仅重组现有的抽象。该方法将RCE与Mistral-7B集成。

Result: RCE在ARC-AGI-2上取得了12-18点的性能提升，在GPQA和BBH上取得了8-14点的改进，并在MATH和HLE上持续减少了深度引起的错误。

Conclusion: RCE通过允许大型语言模型动态地演化其内部表示空间并构建新的抽象，显著提高了其在组合推理任务上的表现，解决了固定潜在表示的局限性。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [119] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: 针对多智能体系统中局部可观测性导致的协调和决策困难，本文提出GlobeDiff算法，通过将状态推断建模为多模态扩散过程，有效推断全局状态，并证明其估计误差有界。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，局部可观测性是有效协调和决策的关键障碍。现有方法如基于信念状态估计和智能体间通信，分别受限于仅利用过去经验而未能充分利用全局信息，以及缺乏有效利用辅助信息的鲁棒模型。

Method: 提出全局状态扩散算法（GlobeDiff），将状态推断过程表述为多模态扩散过程。该方法通过利用多模态扩散模型来整合局部观测，以高保真度推断全局状态。

Result: GlobeDiff在单模态和多模态分布下的估计误差均可被界定。实验结果表明，GlobeDiff表现出卓越的性能，并能准确推断全局状态。

Conclusion: GlobeDiff通过将状态推断建模为多模态扩散过程，在克服状态估计模糊性的同时，高保真地推断全局状态，并且其估计误差在单模态和多模态分布下均可被界定。这解决了多智能体系统中局部可观测性的关键挑战。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [120] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 本研究探讨了使用LLM作为社会科学实验中合成参与者时，如何通过启发式方法（适用于探索性研究）和统计校准（适用于确证性研究）来确保因果效应估计的有效性，并强调了LLM近似相关人群的重要性及避免狭隘替代人类参与者。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）作为合成参与者在社会科学实验中生成经济高效且即时响应的应用日益增多，但关于何时此类模拟可以支持对人类行为的有效推断的指导有限。

Method: 文章对比了两种获取因果效应有效估计的策略：
1. **启发式方法**：通过提示工程、模型微调等手段使模拟行为与观察到的人类行为互换，以减少LLM引入的不准确性。
2. **统计校准**：结合辅助人类数据和统计调整，以弥补观察到的和模拟的响应之间的差异。

Result: 1. **启发式方法**：适用于探索性任务，但缺乏确证性研究所需的正式统计保证。
2. **统计校准**：在明确假设下，能够保持有效性并以低于纯人类参与实验的成本提供更精确的因果效应估计。

Conclusion: 两种方法（启发式和统计校准）的潜力取决于LLM对相关人群的近似程度，并指出研究人员应避免狭隘地将LLM视为人类参与者的替代品，从而忽略了其他潜在机会。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [121] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 该研究提出了一种利用大型语言模型（LLM）嵌入来编码建筑语义的新方法，并通过GraphSAGE模型分类建筑对象子类型。结果表明，LLM编码（特别是llama-3压缩嵌入）在F1分数上优于传统独热编码，显著提升了AI对复杂建筑语义的理解能力。


<details>
  <summary>Details</summary>
Motivation: 在建筑、工程、施工和运营（AECO）行业中，准确表示建筑语义（包括通用对象类型和特定子类型）对于有效的人工智能模型训练至关重要。传统的编码方法（例如独热编码）往往无法传达密切相关的子类型之间细微的关系，从而限制了人工智能的语义理解能力。

Method: 该研究提出了一种新颖的训练方法，利用大型语言模型（LLM）嵌入（如OpenAI GPT和Meta LLaMA）作为编码，以保留建筑语义中更精细的区别。通过训练GraphSAGE模型对五个高层住宅建筑信息模型（BIM）中的42种建筑对象子类型进行分类，对所提出的方法进行了评估。测试了不同的嵌入维度，包括原始高维LLM嵌入（1,536、3,072或4,096）和通过Matryoshka表示模型生成的1,024维压缩嵌入。

Result: 实验结果表明，LLM编码优于传统的独热编码基线。其中，llama-3（压缩）嵌入实现了0.8766的加权平均F1分数，而独热编码为0.8475。

Conclusion: 研究结果强调了利用基于LLM的编码增强AI解释复杂领域特定建筑语义能力的潜力。随着LLM和降维技术的发展，该方法在整个AECO行业的语义细化任务中具有广阔的应用前景。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [122] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 由于数据量和质量不足是阻碍现代亚符号AI应用的关键因素，本章介绍了基于模拟的合成数据生成技术，包括其关键概念、益处、挑战，以及一个用于描述、设计和分析基于数字孪生的AI模拟解决方案的参考框架。


<details>
  <summary>Details</summary>
Motivation: 数据量和质量不足是现代亚符号AI应用的关键障碍，因此对合成数据生成技术有很高需求。模拟提供了一种生成多样化合成数据的合适且系统的方法。

Method: 本章向读者介绍了用于AI训练的基于模拟的合成数据生成的关键概念、益处和挑战，并提出了一个用于描述、设计和分析基于数字孪生的AI模拟解决方案的参考框架。

Result: 本章的结果是介绍了基于模拟的合成数据生成的关键概念、益处和挑战。

Conclusion: 本章总结并介绍了一个用于描述、设计和分析基于数字孪生的AI模拟解决方案的参考框架。

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [123] [Tomography by Design: An Algebraic Approach to Low-Rank Quantum States](https://arxiv.org/abs/2602.15202)
*Shakir Showkat Sofi,Charlotte Vermeylen,Lieven De Lathauwer*

Main category: quant-ph

TL;DR: 本文提出了一种用于量子态层析成像的代数算法，该算法利用某些可观测量的测量来估计底层密度矩阵的结构化条目。在低秩假设下，剩余条目仅使用标准数值线性代数运算即可获得。


<details>
  <summary>Details</summary>
Motivation: 提出一种计算效率高且提供确定性恢复保证的代数算法，用于估计低秩混合量子态。

Method: 一种用于量子态层析成像的代数算法，它利用某些可观测量的测量来估计密度矩阵的结构化条目，并通过标准的数值线性代数操作在低秩假设下完成剩余条目的恢复。该方法基于代数矩阵完备框架。

Result: 该代数矩阵完备框架适用于广泛的通用低秩混合量子态，与现有技术相比，计算效率高，并提供确定性恢复保证。

Conclusion: 所提出的代数矩阵完备框架为通用低秩混合量子态的量子态层析成像提供了一种计算高效且具有确定性恢复保证的方法。

Abstract: We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [124] [TokaMind: A Multi-Modal Transformer Foundation Model for Tokamak Plasma Dynamics](https://arxiv.org/abs/2602.15084)
*Tobia Boschi,Andrea Loreti,Nicola C. Amorisco,Rodrigo H. Ordonez-Hurtado,Cécile Rousseau,George K. Holt,Eszter Székely,Alexander Whittle,Samuel Jackson,Adriano Agnello,Stanislas Pamela,Alessandra Pascale,Robert Akers,Juan Bernabe Moreno,Vassil Alexandrov,Mykhaylo Zayats*

Main category: physics.plasm-ph

TL;DR: TokaMind是一个开源的多模态Transformer框架，用于融合等离子体建模，通过在异构托卡马克诊断数据上训练，在TokaMark基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个开源的基础模型框架，用于融合等离子体建模，能够处理来自托卡马克的异构诊断数据。

Method: TokaMind是一个基于多模态Transformer（MMT）的框架，利用公开的MAST数据集中的异构托卡马克诊断数据进行训练。它支持多种数据模态（时间序列、2D剖面、视频）、鲁棒的缺失信号处理和高效的任务适应。该模型采用免训练的离散余弦变换嵌入（DCT3D）来表示多模态信号。通过在TokaMark基准上评估，并比较了训练和嵌入策略。

Result: 微调后的TokaMind在除一项任务外所有任务上都优于基准线。对于多项任务，轻量级微调比在相同epoch预算下从头开始训练相同的架构表现更好。

Conclusion: 多模态预训练对托卡马克等离子体动力学有益，并为未来的聚变建模任务提供了实用且可扩展的基础。

Abstract: We present TokaMind, an open-source foundation model framework for fusion plasma modeling, based on a Multi-Modal Transformer (MMT) and trained on heterogeneous tokamak diagnostics from the publicly available MAST dataset. TokaMind supports multiple data modalities (time-series, 2D profiles, and videos) with different sampling rates, robust missing-signal handling, and efficient task adaptation via selectively loading and freezing four model components. To represent multi-modal signals, we use a training-free Discrete Cosine Transform embedding (DCT3D) and provide a clean interface for alternative embeddings (e.g., Variational Autoencoders - VAEs). We evaluate TokaMind on the recently introduced MAST benchmark TokaMark, comparing training and embedding strategies. Our results show that fine-tuned TokaMind outperforms the benchmark baseline on all but one task, and that, for several tasks, lightweight fine-tuning yields better performance than training the same architecture from scratch under a matched epoch budget. These findings highlight the benefits of multi-modal pretraining for tokamak plasma dynamics and provide a practical, extensible foundation for future fusion modeling tasks. Training code and model weights will be made publicly available.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [125] [CircuChain: Disentangling Competence and Compliance in LLM Circuit Analysis](https://arxiv.org/abs/2602.15037)
*Mayank Ravishankara*

Main category: cs.SE

TL;DR: 研究发现，在电路分析中，大型语言模型（LLMs）存在“依从性-能力分歧”：模型物理推理能力越强，可能越不遵循明确指令。CircuChain基准评估了这一现象，并指出需要新的评估框架来测试LLMs在严格数学领域中的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在工程领域性能不断提升，但用户指定约束下的可靠推理至关重要。在电路分析中，即便数值正确，若违反了网格方向或极性分配等既定方法论约定，仍是不足的。目前尚不清楚前沿模型是真正运用第一性原理推理，还是依赖与其明确指令相冲突的既定训练先验。

Method: 引入了CircuChain诊断基准，旨在区分电气电路分析中的指令依从性与物理推理能力。CircuChain包含五种典型电路拓扑的平衡对照/陷阱问题对，并系统地变动了符号约定、电流方向和极性定义。通过结合符号求解器、SPICE仿真和基于LLM的错误分类法，构建了多阶段验证流程，以细粒度地归因故障类型。

Result: 观察到一致的“依从性-能力分歧”。最强的模型表现出近乎完美的物理推理能力，但在“陷阱”条件下刻意反转自然符号模式时，却出现高比例的约定违规。相比之下，较弱的模型物理保真度较低，但却能更好地遵循明确指令。结果表明，模型能力的增强并不保证对约束的更好对齐。

Conclusion: 增强的模型能力不保证更好的约束对齐，需要新的评估框架来强调数学严格领域中的指令遵循。CircuChain为此提供了一个框架，并为工程教育和AI对齐研究提供了可操作的见解。

Abstract: As large language models (LLMs) advance toward expert-level performance in engineering domains, reliable reasoning under user-specified constraints becomes critical. In circuit analysis, for example, a numerically correct solution is insufficient if it violates established methodological conventions such as mesh directionality or polarity assignments, errors that can propagate in safety-critical systems. Yet it remains unclear whether frontier models truly apply first-principles reasoning or rely on entrenched training priors that conflict with explicit instructions. We introduce CircuChain, a diagnostic benchmark designed to disentangle instruction compliance from physical reasoning competence in electrical circuit analysis. CircuChain consists of counterbalanced Control/Trap problem pairs across five canonical circuit topologies, augmented with systematic variations in sign conventions, current orientations, and polarity definitions. A multi-stage verification pipeline, combining symbolic solvers, SPICE simulation, and an LLM-based error taxonomy, enables fine-grained attribution of failures to convention errors, physics errors, arithmetic mistakes, or hallucinations. Across 100 tasks per model, we observe a consistent Compliance-Competence Divergence. The strongest model evaluated exhibits near-perfect physical reasoning but a high rate of convention violations when Trap conditions deliberately invert natural sign patterns. Conversely, weaker models display lower physical fidelity yet superior adherence to explicit instructions. These results suggest that increased model capability does not guarantee improved constraint alignment and highlight the need for new evaluation frameworks that stress instruction-following under mathematically rigid domains. CircuChain provides one such framework and offers actionable insights for both engineering education and AI alignment research.

</details>


### [126] [GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon](https://arxiv.org/abs/2602.15241)
*Arya Tschand,Chenyu Wang,Zishen Wan,Andrew Cheng,Ioana Cristescu,Kevin He,Howard Huang,Alexander Ingare,Akseli Kangaslahti,Sara Kangaslahti,Theo Lebryk,Hongjin Lin,Jeffrey Jian Ma,Alexandru Meterez,Clara Mohri,Depen Morwani,Sunny Qin,Roy Rinberg,Paula Rodriguez-Diaz,Alyssa Mia Taliotis,Pernille Undrum Fathi,Rosie Zhao,Todd Zhou,Vijay Janapa Reddi*

Main category: cs.SE

TL;DR: 该论文从跨栈视角审视了生成式AI在计算系统设计、优化和构建中的应用，识别了五个重复出现的挑战和五个有效的设计原则，并强调了共享工程方法论的必要性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在重塑计算系统的设计，但研究分散于软件、架构和芯片设计社区，缺乏统一的跨栈视角。

Method: 本文分析了275篇论文，涵盖计算堆栈的三个层面的十一个应用领域，识别了跨堆栈的结构性难题和有效的应对措施，并将其组织成挑战-原则图。

Result: 论文发现领域中存在五大重复挑战（反馈循环危机、隐性知识问题、信任与验证、跨边界协同设计、从确定性到动态性的转变）和五项独立出现的有效设计原则（采用混合方法、设计持续反馈、按角色分离关注点、将方法与问题结构匹配、基于数十年的系统知识）。

Conclusion: 领域需要共享的工程方法论，包括通用词汇、跨层基准和系统设计实践，以促进社区间的协同进展，而不是重复发现。

Abstract: Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [127] [Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid](https://arxiv.org/abs/2602.15350)
*Mohamad Chehade,Hao Zhu*

Main category: eess.SY

TL;DR: 针对公共安全停电 (PSPS) 引起的电网拓扑变化，本文提出了一种可验证的多阶段适应性管道，通过微调大型语言模型 (LLM) 生成纠正性开关操作方案，显著提升了直流目标值，降低了交流潮流故障率，并改善了电压惩罚结果。


<details>
  <summary>Details</summary>
Motivation: 公共安全停电 (PSPS) 导致电网拓扑快速变化，使标准运行点不可行。运营商需要快速识别纠正性输电开关操作，以减少甩负荷并维持可接受的电压行为。

Method: 本文提出了一种可验证的多阶段适应性管道，用于微调指令调优的大型语言模型 (LLM)，以从紧凑的 PSPS 场景摘要中生成仅开放的纠正性开关方案。具体步骤包括：1. **监督微调**：将 DC-OPF MILP 预言机蒸馏为受约束的动作语法，以实现可靠的解析和可行性检查。2. **直接偏好优化 (DPO)**：使用基于交流评估的偏好对（根据电压惩罚度量排名）精炼策略，从而在直流模仿之外注入电压感知能力。3. **Best-of-N 选择**：在推理时选择根据目标度量表现最佳的可行候选方案。

Result: 在 IEEE 118-bus PSPS 场景中，微调相对于零样本生成显著改善了直流目标值，将交流潮流故障从 50% 降低到个位数，并在共同成功集上改善了电压惩罚结果。

Conclusion: 本文开发了一种可验证的多阶段适应性管道，通过微调大型语言模型，能够有效生成公共安全停电下的纠正性开关计划，显著提升了电网运行的鲁棒性和电压稳定性。

Abstract: Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [128] [An effective Genetic Programming Hyper-Heuristic for Uncertain Agile Satellite Scheduling](https://arxiv.org/abs/2602.15070)
*Yuning Chen,Junhua Xue,Wangqi Gu,Mingyan Shao*

Main category: cs.NE

TL;DR: 本文研究了不确定敏捷对地观测卫星调度问题（UAEOSSP），考虑了任务收益、资源消耗和任务可见性等不确定因素。提出了一种遗传编程超启发式（GPHH）方法来自动生成调度策略，该策略在实时调整计划方面表现出色，并显著优于现有启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有敏捷对地观测卫星调度问题（AEOSSP）是静态的，未能反映实际信息（如任务收益、资源消耗和任务可见性）在事前未知这一现实，因此需要解决考虑不确定因素的UAEOSSP问题。

Method: 设计了一种有效的遗传编程超启发式（GPHH）方法，以自动化生成调度策略。

Result: 演化出的调度策略能够实时调整计划并表现出色。实验结果表明，与设计良好的前瞻启发式（LAHs）和手动设计启发式（MDHs）相比，演化出的调度策略表现显著更优。具体而言，GPHH生成的策略比LAHs平均提高了5.03%，比MDHs平均提高了8.14%。

Conclusion: 遗传编程超启发式（GPHH）生成的调度策略在处理不确定敏捷对地观测卫星调度问题（UAEOSSP）方面，显著优于传统启发式方法，能够有效应对不确定性并提高调度性能。

Abstract: This paper investigates a novel problem, namely the Uncertain Agile Earth Observation Satellite Scheduling Problem (UAEOSSP). Unlike the static AEOSSP, it takes into account a range of uncertain factors (e.g., task profit, resource consumption, and task visibility) in order to reflect the reality that the actual information is inherently unknown beforehand. An effective Genetic Programming Hyper-Heuristic (GPHH) is designed to automate the generation of scheduling policies. The evolved scheduling policies can be utilized to adjust plans in real time and perform exceptionally well. Experimental results demonstrate that evolved scheduling policies significantly outperform both well-designed Look-Ahead Heuristics (LAHs) and Manually Designed Heuristics (MDHs). Specifically, the policies generated by GPHH achieve an average improvement of 5.03% compared to LAHs and 8.14% compared to MDHs.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [129] [Decision Making under Imperfect Recall: Algorithms and Benchmarks](https://arxiv.org/abs/2602.15252)
*Emanuel Tewolde,Brian Hu Zhang,Ioannis Anagnostides,Tuomas Sandholm,Vincent Conitzer*

Main category: cs.GT

TL;DR: 本文介绍了首个不完全记忆决策问题的基准测试套件，并首次证明了遗憾匹配（RM）算法在解决这类问题中的一阶最优策略方面，比其他常用的一阶优化器性能高出几个数量级。


<details>
  <summary>Details</summary>
Motivation: 不完全记忆决策问题模拟了智能体遗忘信息的场景，涵盖了AI系统隐私和AI安全等重要应用，但目前缺乏有效的基准和算法。本文旨在解决这一问题。

Method: 本文引入了首个不完全记忆决策问题的基准测试套件，并使用该套件生成了61个问题实例。作者评估了寻找一阶最优策略的各种算法的性能，并引入了遗憾匹配（RM）算法家族用于非线性约束优化，将其应用于不完全记忆决策问题。

Result: 遗憾匹配（RM）算法在性能上持续且显著（通常是几个数量级）优于常用的如投影梯度下降等一阶优化器。

Conclusion: 遗憾匹配（RM）算法家族首次被确立为解决大规模约束优化问题，特别是不完全记忆决策问题的强大方法。

Abstract: In game theory, imperfect-recall decision problems model situations in which an agent forgets information it held before. They encompass games such as the ``absentminded driver'' and team games with limited communication. In this paper, we introduce the first benchmark suite for imperfect-recall decision problems. Our benchmarks capture a variety of problem types, including ones concerning privacy in AI systems that elicit sensitive information, and AI safety via testing of agents in simulation. Across 61 problem instances generated using this suite, we evaluate the performance of different algorithms for finding first-order optimal strategies in such problems. In particular, we introduce the family of regret matching (RM) algorithms for nonlinear constrained optimization. This class of parameter-free algorithms has enjoyed tremendous success in solving large two-player zero-sum games, but, surprisingly, they were hitherto relatively unexplored beyond that setting. Our key finding is that RM algorithms consistently outperform commonly employed first-order optimizers such as projected gradient descent, often by orders of magnitude. This establishes, for the first time, the RM family as a formidable approach to large-scale constrained optimization problems.

</details>


### [130] [Outer Diversity of Structured Domains](https://arxiv.org/abs/2602.15708)
*Piotr Faliszewski,Krzysztof Sornat,Stanisław Szufa,Tomasz Wąs*

Main category: cs.GT

TL;DR: 本文介绍了序数偏好域的“外部多样性”概念，并评估了其在单峰、单交叉、组可分离和欧几里得等多种已知结构化域中的价值。


<details>
  <summary>Details</summary>
Motivation: 在选举中，序数偏好域是选民可以投票的偏好顺序的子集。该研究旨在引入并研究“领域外部多样性”这一概念。

Method: 引入并研究了“领域外部多样性”的概念，并评估了其对多种已知结构化领域（如单峰、单交叉、组可分离和欧几里得领域）的价值。

Result: 研究评估了“领域外部多样性”对单峰、单交叉、组可分离和欧几里得等多种知名结构化领域的价值。

Conclusion: 该研究评估了“领域外部多样性”对几种知名结构化领域（如单峰、单交叉、组可分离和欧几里得领域）的价值。

Abstract: An ordinal preference domain is a subset of preference orders that the voters are allowed to cast in an election. We introduce and study the notion of outer diversity of a domain and evaluate its value for a number of well-known structured domains, such as the single-peaked, single-crossing, group-separable, and Euclidean ones.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [131] [Algorithmic Approaches to Opinion Selection for Online Deliberation: A Comparative Study](https://arxiv.org/abs/2602.15439)
*Salim Hafid,Manon Berriche,Jean-Philippe Cointet*

Main category: cs.CY

TL;DR: 论文基准测试了在线审议中意见选择的算法，并提出了一种基于社会选择理论的新算法，以更好地平衡比例代表性和多样性。


<details>
  <summary>Details</summary>
Motivation: 在线审议平台中，算法选择意见用于报告可能导致少数声音被忽视、内容多样性降低，且现有选择策略对民主标准（如比例代表性）的影响尚不明确。

Method: 本文基准测试了几种现有的算法选择方法，并基于社会选择理论提出了一种新颖的算法，该算法在选择策略中同时考虑了多样性和平衡的代表性。

Result: 经验证明，虽然没有单一策略能在所有民主期望上占据主导地位，但论文提出的受社会选择启发的选择规则在比例代表性和多样性之间取得了最强的权衡。

Conclusion: 该研究通过基准测试现有算法并提出一种结合社会选择理论的新算法，解决了在线审议中意见选择算法对民主标准影响不明确的问题，特别是在平衡比例代表性和多样性方面提供了更优的解决方案。

Abstract: During deliberation processes, mediators and facilitators typically need to select a small and representative set of opinions later used to produce digestible reports for stakeholders. In online deliberation platforms, algorithmic selection is increasingly used to automate this process. However, such automation is not without consequences. For instance, enforcing consensus-seeking algorithmic strategies can imply ignoring or flattening conflicting preferences, which may lead to erasing minority voices and reducing content diversity. More generally, across the variety of existing selection strategies (e.g., consensus, diversity), it remains unclear how each approach influences desired democratic criteria such as proportional representation. To address this gap, we benchmark several algorithmic approaches in this context. We also build on social choice theory to propose a novel algorithm that incorporates both diversity and a balanced notion of representation in the selection strategy. We find empirically that while no single strategy dominates across all democratic desiderata, our social-choice-inspired selection rule achieves the strongest trade-off between proportional representation and diversity.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [132] [CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation](https://arxiv.org/abs/2602.15060)
*Tengjie Zhu,Guanyu Cai,Yang Zhaohui,Guanzhu Ren,Haohui Xie,ZiRui Wang,Junsong Wu,Jingbo Wang,Xiaokang Yang,Yao Mu,Yichao Yan,Yichao Yan*

Main category: cs.RO

TL;DR: 本文介绍了CLOT，一个通过高频定位反馈实现闭环全局运动跟踪的实时全身类人机器人遥操作系统，解决了长周期操作中的全局姿态漂移问题，通过数据驱动的随机化策略和对抗性运动先验实现了平稳、稳定和自然的运动，并在仿真和现实世界中验证了其高动态、高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 长周期全身类人机器人遥操作仍然具有挑战性，特别是对于全尺寸类人机器人，因为全局姿态会累积漂移。虽然最近基于学习的跟踪方法能够实现敏捷协调的运动，但它们通常在机器人的局部坐标系中操作，忽略全局姿态反馈，导致长时间执行期间的漂移和不稳定性。

Method: 本文提出了CLOT系统，一个通过高频定位反馈实现闭环全局运动跟踪的实时全身类人机器人遥操作系统，以同步操作员和机器人的姿态，消除长时间范围内的漂移。为避免强化学习中直接施加全局跟踪奖励导致的激进和脆弱修正，作者提出了一种数据驱动的随机化策略，将观测轨迹与奖励评估解耦，以实现平稳稳定的全局修正。此外，通过对抗性运动先验对策略进行正则化，以抑制不自然行为。为支持CLOT，收集了20小时的精心策划的人类运动数据用于训练，设计了一个基于Transformer的策略，并训练了超过1300个GPU小时。该策略被部署在一个31自由度（不含手部）的全尺寸类人机器人上。

Result: 模拟和现实世界实验均验证了CLOT系统在仿真到现实的类人机器人遥操作中实现了高动态运动、高精度跟踪和强大的鲁棒性。

Conclusion: CLOT系统通过解决长周期全身类人机器人遥操作中的全局姿态漂移问题，实现了高动态、高精度和强鲁棒性的仿真到现实的类人机器人遥操作。

Abstract: Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.

</details>


### [133] [Safe-SDL:Establishing Safety Boundaries and Control Mechanisms for AI-Driven Self-Driving Laboratories](https://arxiv.org/abs/2602.15061)
*Zihan Zhang,Haohui Que,Junhan Chang,Xin Zhang,Hao Wei,Tong Zhu*

Main category: cs.RO

TL;DR: 本文提出了Safe-SDL，一个用于在AI驱动的自主实验室中建立鲁棒安全边界和控制机制的框架。它通过形式化定义的运行设计域（ODDs）、控制障碍函数（CBFs）和新型事务性安全协议（CRUTD）来解决AI生成指令与物理安全影响之间的“语法到安全差距”，为安全部署自主科学系统提供了理论基础和实践指导。


<details>
  <summary>Details</summary>
Motivation: 自驾驶实验室（SDLs）通过AI与机器人自动化结合，加速科学发现，但其部署引入了与传统实验室或纯数字AI不同的前所未有的安全挑战。核心挑战在于AI生成的语法正确指令与其实际物理安全影响之间的“语法到安全差距”。

Method: Safe-SDL框架包含三个协同组件：形式化定义的运行设计域（ODDs）用于约束系统行为，控制障碍函数（CBFs）提供实时安全保障，以及新颖的事务性安全协议（CRUTD）确保数字规划与物理执行的原子一致性。通过分析现有实现（如UniLabOS和Osprey架构）来验证理论贡献，并通过LabSafety Bench进行评估。

Result: 针对LabSafety Bench的评估表明，当前的基座模型存在显著的安全缺陷，证明了架构安全机制是必不可少的。Safe-SDL框架提供了理论基础和实践指导，以实现自主科学系统的安全部署。

Conclusion: Safe-SDL为AI驱动的自主科学系统的安全部署奠定了理论基础和实践指导，从而负责任地加速科学发现。

Abstract: The emergence of Self-Driving Laboratories (SDLs) transforms scientific discovery methodology by integrating AI with robotic automation to create closed-loop experimental systems capable of autonomous hypothesis generation, experimentation, and analysis. While promising to compress research timelines from years to weeks, their deployment introduces unprecedented safety challenges differing from traditional laboratories or purely digital AI. This paper presents Safe-SDL, a comprehensive framework for establishing robust safety boundaries and control mechanisms in AI-driven autonomous laboratories. We identify and analyze the critical ``Syntax-to-Safety Gap'' -- the disconnect between AI-generated syntactically correct commands and their physical safety implications -- as the central challenge in SDL deployment. Our framework addresses this gap through three synergistic components: (1) formally defined Operational Design Domains (ODDs) that constrain system behavior within mathematically verified boundaries, (2) Control Barrier Functions (CBFs) that provide real-time safety guarantees through continuous state-space monitoring, and (3) a novel Transactional Safety Protocol (CRUTD) that ensures atomic consistency between digital planning and physical execution. We ground our theoretical contributions through analysis of existing implementations including UniLabOS and the Osprey architecture, demonstrating how these systems instantiate key safety principles. Evaluation against the LabSafety Bench reveals that current foundation models exhibit significant safety failures, demonstrating that architectural safety mechanisms are essential rather than optional. Our framework provides both theoretical foundations and practical implementation guidance for safe deployment of autonomous scientific systems, establishing the groundwork for responsible acceleration of AI-driven discovery.

</details>


### [134] [Augmenting Human Balance with Generic Supernumerary Robotic Limbs](https://arxiv.org/abs/2602.15092)
*Xuanyun Qiu,Dorian Verdel,Hector Cervantes-Culebro,Alexis Devillard,Etienne Burdet*

Main category: cs.RO

TL;DR: 超numerary机械臂（SLs）通过一个分层三层架构，显著提高了人机交互中的平衡性。


<details>
  <summary>Details</summary>
Motivation: 超numerary机械臂（SLs）的可用性受限于安全性和多功能控制等关键技术挑战，尤其是在确保人-SLs系统平衡方面，这是实现安全舒适增强任务的先决条件。与之前专为稳定性支持开发的SLs不同，本文提出一个通用框架，用于通过通用SLs保持平衡。

Method: 本文提出一个分层三层架构：(i) 预测层：估计人体躯干和质心（CoM）动态。(ii) 规划层：生成最优CoM轨迹以抵消躯干运动，并计算相应的SL控制输入。(iii) 控制层：在SL硬件上执行这些输入。

Result: 通过让十名参与者执行前屈和侧弯任务来评估该框架。结果显示，姿态不稳定性明显降低，证明了该框架在增强平衡方面的有效性。

Conclusion: 这项工作为人-SLs安全和多功能交互铺平了道路。

Abstract: Supernumerary robotic limbs (SLs) have the potential to transform a wide range of human activities, yet their usability remains limited by key technical challenges, particularly in ensuring safety and achieving versatile control. Here, we address the critical problem of maintaining balance in the human-SLs system, a prerequisite for safe and comfortable augmentation tasks. Unlike previous approaches that developed SLs specifically for stability support, we propose a general framework for preserving balance with SLs designed for generic use. Our hierarchical three-layer architecture consists of: (i) a prediction layer that estimates human trunk and center of mass (CoM) dynamics, (ii) a planning layer that generates optimal CoM trajectories to counteract trunk movements and computes the corresponding SL control inputs, and (iii) a control layer that executes these inputs on the SL hardware. We evaluated the framework with ten participants performing forward and lateral bending tasks. The results show a clear reduction in stance instability, demonstrating the framework's effectiveness in enhancing balance. This work paves the path towards safe and versatile human-SLs interactions. [This paper has been submitted for publication to IEEE.]

</details>


### [135] [A ROS2 Benchmarking Framework for Hierarchical Control Strategies in Mobile Robots for Mediterranean Greenhouses](https://arxiv.org/abs/2602.15162)
*Fernando Cañadas-Aránega,Francisco J. Mañas-Álvarez,José L- Guzmán,José C. Moreno,José L. Blanco-Claraco*

Main category: cs.RO

TL;DR: 针对温室环境下移动机器人控制器评估，本文提出了一个综合基准测试框架，该框架集成了三维模型、物理模拟器和分层控制架构，并考虑了多种扰动场景和标准化性能指标。


<details>
  <summary>Details</summary>
Motivation: 农业环境中移动机器人在恶劣条件下（如不平坦地形、变摩擦力、载荷变化、坡度）运行，其控制性能和稳定性受到显著影响。尽管农业机器人应用日益增多，但缺乏标准化、可重现的基准测试平台，阻碍了在实际操作条件下对控制策略进行公平比较和系统评估。

Method: 该论文提出了一个综合性的基准测试框架，用于评估温室环境中的移动机器人控制器。该框架整合了精确的三维环境模型、基于物理的模拟器以及包含低、中、高三层控制的分层控制架构。定义了三个基准类别，实现从执行器级控制到完全自主导航的模块化评估。此外，明确建模了三种扰动场景（载荷变化、地形类型和坡度），以复现实世界农业条件。引入了标准化性能指标（平方绝对误差SAE、平方控制输入SCI和复合性能指标）进行客观评估，并采用重复试验的统计分析来减弱传感器噪声和环境变异性的影响。该框架还通过插件式架构增强了可扩展性，便于集成用户自定义的控制器和规划器。

Result: 该框架提供了一个鲁棒且可扩展的工具，用于在现实条件下对经典、预测和基于规划的控制策略进行定量比较。

Conclusion: 该基准测试弥合了基于仿真分析与实际农业工业应用之间的鸿沟，为移动机器人控制策略的系统评估和比较提供了一个重要的工具。

Abstract: Mobile robots operating in agroindustrial environments, such as Mediterranean greenhouses, are subject to challenging conditions, including uneven terrain, variable friction, payload changes, and terrain slopes, all of which significantly affect control performance and stability. Despite the increasing adoption of robotic platforms in agriculture, the lack of standardized, reproducible benchmarks impedes fair comparisons and systematic evaluations of control strategies under realistic operating conditions. This paper presents a comprehensive benchmarking framework for evaluating mobile robot controllers in greenhouse environments. The proposed framework integrates an accurate three dimensional model of the environment, a physics based simulator, and a hierarchical control architecture comprising low, mid, and high level control layers. Three benchmark categories are defined to enable modular assessment, ranging from actuator level control to full autonomous navigation. Additionally, three disturbance scenarios payload variation, terrain type, and slope are explicitly modeled to replicate real world agricultural conditions. To ensure objective and reproducible evaluation, standardized performance metrics are introduced, including the Squared Absolute Error (SAE), the Squared Control Input (SCI), and composite performance indices. Statistical analysis based on repeated trials is employed to mitigate the influence of sensor noise and environmental variability. The framework is further enhanced by a plugin based architecture that facilitates seamless integration of user defined controllers and planners. The proposed benchmark provides a robust and extensible tool for the quantitative comparison of classical, predictive, and planning based control strategies in realistic conditions, bridging the gap between simulation based analysis and real world agroindustrial applications.

</details>


### [136] [DexEvolve: Evolutionary Optimization for Robust and Diverse Dexterous Grasp Synthesis](https://arxiv.org/abs/2602.15201)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种可扩展的生成-细化流程，用于合成大规模、多样化且物理可行的抓取。该流程利用高保真模拟器通过异步、无梯度演化算法优化抓取质量，而不是仅仅进行过滤。之后将细化后的抓取分布提炼成扩散模型。实验结果显示，该方法在每个物体上实现了120多个不同的稳定抓取，并优于现有的扩散模型方法。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的抓取预测依赖于大型多样化数据集，但这些数据集生成成本高昂且通常仅限于特定夹持器形态。分析抓取合成可用于扩大数据收集，但其简化假设常导致物理上不可行的抓取，需要在高保真模拟器中进行过滤，从而显著减少抓取数量和多样性。

Method: 该方法提出一个可扩展的生成-细化流程。首先，用一组分析生成的、可能次优的抓取作为种子集初始化演化搜索。然后，直接在高保真模拟器（Isaac Sim）中使用异步、无梯度演化算法对这些抓取进行细化，以提高稳定性并保持多样性。此外，细化阶段可以根据人类偏好或领域特定质量指标进行指导，无需可微分目标。最后，将细化后的抓取分布提炼成扩散模型，以实现鲁棒的实际部署。

Result: 在新的Handles数据集和DexGraspNet子集上的实验表明，该方法在每个物体上实现了超过120个不同的稳定抓取（比未细化的分析方法提高了1.7-6倍），并且在独特抓取覆盖率方面比基于扩散的替代方法高出46-60%。

Conclusion: 该生成-细化流程通过将高保真模拟器用作优化阶段，而不是单纯的验证和过滤，成功地合成出大规模、多样化且物理可行的抓取。这显著提高了稳定抓取的数量和多样性，并通过提炼成扩散模型支持了在现实世界中的鲁棒部署。

Abstract: Dexterous grasping is fundamental to robotics, yet data-driven grasp prediction heavily relies on large, diverse datasets that are costly to generate and typically limited to a narrow set of gripper morphologies. Analytical grasp synthesis can be used to scale data collection, but necessary simplifying assumptions often yield physically infeasible grasps that need to be filtered in high-fidelity simulators, significantly reducing the total number of grasps and their diversity. We propose a scalable generate-and-refine pipeline for synthesizing large-scale, diverse, and physically feasible grasps. Instead of using high-fidelity simulators solely for verification and filtering, we leverage them as an optimization stage that continuously improves grasp quality without discarding precomputed candidates. More specifically, we initialize an evolutionary search with a seed set of analytically generated, potentially suboptimal grasps. We then refine these proposals directly in a high-fidelity simulator (Isaac Sim) using an asynchronous, gradient-free evolutionary algorithm, improving stability while maintaining diversity. In addition, this refinement stage can be guided toward human preferences and/or domain-specific quality metrics without requiring a differentiable objective. We further distill the refined grasp distribution into a diffusion model for robust real-world deployment, and highlight the role of diversity for both effective training and during deployment. Experiments on a newly introduced Handles dataset and a DexGraspNet subset demonstrate that our approach achieves over 120 distinct stable grasps per object (a 1.7-6x improvement over unrefined analytical methods) while outperforming diffusion-based alternatives by 46-60\% in unique grasp coverage.

</details>


### [137] [OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy](https://arxiv.org/abs/2602.15309)
*Mostafa A. Atalla,Anand S. Sekar,Remi van Starkenburg,David J. Jager,Aimée Sakes,Michaël Wiertlewski,Paul Breedveld*

Main category: cs.RO

TL;DR: OSCAR是一种受产卵器启发的自推进胶囊机器人，通过相位编码摩擦各向异性实现结肠镜检查中可靠且可预测的运动，从而减少患者不适。


<details>
  <summary>Details</summary>
Motivation: 传统结肠镜检查会因轴环而导致患者不适。自推进机器人胶囊可以消除这个问题，但在结肠内湿滑、粘弹性的环境中可靠移动仍然是一个重大挑战。

Method: OSCAR通过弹簧加载凸轮系统驱动十二个周向滑块，以协调的、相移序列机械编码产卵器启发的运动模式。通过调整运动曲线以最大化回缩阶段相对于前进阶段，胶囊在界面处产生受控的摩擦各向异性，从而产生净向前推力。开发了一个结合了Kelvin-Voigt公式的分析模型来捕捉滑块和组织之间的粘弹性粘滑相互作用。

Result: 离体猪结肠的综合力学特性实验显示，平均稳态牵引力为0.85 N，与模型非常吻合。实验还证实，推力产生与速度无关，并与相位不对称性呈线性关系，与理论预测一致。在运动验证实验中，OSCAR表现出稳定的性能，平均速度达到3.08 mm/s，足以匹配传统结肠镜检查的盲肠插管时间。

Conclusion: OSCAR通过将相位编码摩擦各向异性与预测模型相结合，在低法向载荷下提供可控的推力产生，从而为机器人胶囊结肠镜检查实现更安全、更强大的自推进运动。

Abstract: Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.

</details>


### [138] [Feasibility-aware Imitation Learning from Observation with Multimodal Feedback](https://arxiv.org/abs/2602.15351)
*Kei Takahashi,Hikaru Sasaki,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文提出了一种名为Feasibility-Aware Behavior Cloning from Observation (FABCO) 的方法，通过整合基于观察的行为克隆与可行性估计和多模态反馈，解决了模仿学习中机器人动作缺失和演示动作不可行的问题，从而提高了模仿学习性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习框架在通过手持演示界面从演示者的动作中学习机器人控制策略时面临两个限制：1）演示数据不包含机器人动作，2）演示的动作可能对机器人不可行，这使得策略学习变得困难。

Method: FABCO将基于观察的行为克隆（BCO）与可行性估计相结合。可行性估计使用从机器人执行数据中学习到的机器人动力学模型来评估演示动作的可复现性。估计的可行性用于多模态反馈（通过视觉和触觉）以促进可行的演示动作，以及可行性感知策略学习以减少对机器人不可行的演示动作的影响。

Result: 在两项任务中对15名参与者进行的实验证实，与没有可行性反馈的情况相比，FABCO将模仿学习性能提高了3.2倍以上。

Conclusion: FABCO通过解决传统方法中机器人动作缺失和演示动作不可行的问题，有效地提高了模仿学习的性能，从而学习到鲁棒且可执行的策略。

Abstract: Imitation learning frameworks that learn robot control policies from demonstrators' motions via hand-mounted demonstration interfaces have attracted increasing attention. However, due to differences in physical characteristics between demonstrators and robots, this approach faces two limitations: i) the demonstration data do not include robot actions, and ii) the demonstrated motions may be infeasible for robots. These limitations make policy learning difficult. To address them, we propose Feasibility-Aware Behavior Cloning from Observation (FABCO). FABCO integrates behavior cloning from observation, which complements robot actions using robot dynamics models, with feasibility estimation. In feasibility estimation, the demonstrated motions are evaluated using a robot-dynamics model, learned from the robot's execution data, to assess reproducibility under the robot's dynamics. The estimated feasibility is used for multimodal feedback and feasibility-aware policy learning to improve the demonstrator's motions and learn robust policies. Multimodal feedback provides feasibility through the demonstrator's visual and haptic senses to promote feasible demonstrated motions. Feasibility-aware policy learning reduces the influence of demonstrated motions that are infeasible for robots, enabling the learning of policies that robots can execute stably. We conducted experiments with 15 participants on two tasks and confirmed that FABCO improves imitation learning performance by more than 3.2 times compared to the case without feasibility feedback.

</details>


### [139] [A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking](https://arxiv.org/abs/2602.15354)
*Jose Luis Peralta-Cabezas,Miguel Torres-Torriti,Marcelo Guarini-Hermann*

Main category: cs.RO

TL;DR: 本文比较了多种估计和预测技术在多机器人跟踪问题中的性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在比较不同估计和预测技术在多机器人跟踪问题中的性能，评估它们在估计/预测误差、计算开销和对非高斯噪声鲁棒性方面的表现。

Method: 本文通过比较多种估计和预测技术来解决多机器人跟踪问题。所比较的技术包括卡尔曼滤波器及其变体（如扩展卡尔曼滤波器和无迹卡尔曼滤波器），以及基于序贯蒙特卡洛采样方法的最新技术（如粒子滤波器和高斯混合Sigma点粒子滤波器）。性能评估标准包括估计或预测误差的大小、计算工作量以及每种方法对非高斯噪声的鲁棒性。

Result: 摘要中未明确给出具体的性能比较结果。

Conclusion: 摘要中未明确给出研究的结论。

Abstract: This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.

</details>


### [140] [Fluoroscopy-Constrained Magnetic Robot Control via Zernike-Based Field Modeling and Nonlinear MPC](https://arxiv.org/abs/2602.15357)
*Xinhao Chen,Hongkun Yao,Anuruddha Bhattacharjee,Suraj Raval,Lamar O. Mair,Yancy Diaz-Mercado,Axel Krieger*

Main category: cs.RO

TL;DR: 该论文提出了一种在低帧率和噪声荧光图像反馈下仍能保持精确和稳定的磁驱动手术机器人控制框架，通过结合非线性模型预测控制（NMPC）、基于Zernike多项式的可微分磁场模型和卡尔曼滤波器实现，并在体外实验中验证了其在复杂解剖路径中的导航和药物递送能力。


<details>
  <summary>Details</summary>
Motivation: 磁驱动手术机器人虽能减少组织创伤并提高手术精度，但其在荧光成像下控制受限，因为荧光成像提供低帧率且嘈杂的姿态反馈，这限制了其临床应用。

Method: 该论文提出一个控制框架，包含直接输出线圈电流的非线性模型预测控制（NMPC）框架、基于Zernike多项式的解析可微分磁场模型以及用于估计机器人状态的卡尔曼滤波器。

Result: 实验结果表明，在反馈降采样至3 Hz并添加高斯噪声（sigma = 2 mm）的情况下，所提出的控制方法仍然保持高精度。在脊柱模型实验中，该方法成功执行了药物递送轨迹，均方根（RMS）位置误差为1.18 mm，同时保持了与关键解剖边界的安全距离。

Conclusion: 该控制框架有效地解决了磁驱动手术机器人在临床荧光成像条件下的控制挑战，显著提高了其在复杂解剖结构中导航和执行精密任务的精度和稳定性，为未来的临床应用奠定了基础。

Abstract: Magnetic actuation enables surgical robots to navigate complex anatomical pathways while reducing tissue trauma and improving surgical precision. However, clinical deployment is limited by the challenges of controlling such systems under fluoroscopic imaging, which provides low frame rate and noisy pose feedback. This paper presents a control framework that remains accurate and stable under such conditions by combining a nonlinear model predictive control (NMPC) framework that directly outputs coil currents, an analytically differentiable magnetic field model based on Zernike polynomials, and a Kalman filter to estimate the robot state. Experimental validation is conducted with two magnetic robots in a 3D-printed fluid workspace and a spine phantom replicating drug delivery in the epidural space. Results show the proposed control method remains highly accurate when feedback is downsampled to 3 Hz with added Gaussian noise (sigma = 2 mm), mimicking clinical fluoroscopy. In the spine phantom experiments, the proposed method successfully executed a drug delivery trajectory with a root mean square (RMS) position error of 1.18 mm while maintaining safe clearance from critical anatomical boundaries.

</details>


### [141] [ActionCodec: What Makes for Good Action Tokenizers](https://arxiv.org/abs/2602.15397)
*Zibin Dong,Yicheng Liu,Shiduo Zhang,Baijun Ye,Yifu Yuan,Fei Ni,Jingjing Gong,Xipeng Qiu,Hang Zhao,Yinchuan Li,Jianye Hao*

Main category: cs.RO

TL;DR: 本文提出了一套针对VLA优化设计的动作分词器设计原则，并基于这些原则开发了ActionCodec，显著提高了VLA模型的训练效率和性能，在多个基准测试中达到了SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在指令遵循和训练效率方面表现出色，但其核心的动作分词设计主要侧重于重建保真度，未能解决其对VLA优化的直接影响。因此，“什么是好的动作分词器”这一基本问题仍未得到解答。

Method: 作者通过建立从VLA优化角度出发的设计原则来弥补现有研究的不足。这些原则基于信息论见解，包括最大化时间令牌重叠、最小化词汇冗余、增强多模态互信息和令牌独立性。在此指导下，作者引入了高性能动作分词器ActionCodec。

Result: ActionCodec显著提高了VLA的训练效率和性能，在LIBERO上，经过ActionCodec微调的SmolVLM2-2.2B模型在没有机器人预训练的情况下实现了95.5%的成功率。通过先进的架构改进，成功率达到97.4%，为没有机器人预训练的VLA模型树立了新的SOTA。

Conclusion: 本文建立的设计原则和发布的模型将为社区开发更有效的动作分词器提供清晰的路线图。

Abstract: Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.

</details>


### [142] [Hybrid F' and ROS2 Architecture for Vision-Based Autonomous Flight: Design and Experimental Validation](https://arxiv.org/abs/2602.15398)
*Abdelrahman Metwally,Monijesu James,Aleksey Fedoseev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Andrey Somov*

Main category: cs.RO

TL;DR: 该论文提出了一种结合NASA F'飞行软件框架和ROS2中间件的集成系统，通过Protocol Buffers桥接，以平衡确定性实时控制和先进感知能力，并通过四旋翼飞行测试进行了验证。


<details>
  <summary>Details</summary>
Motivation: 自主航空航天系统需要一种能够平衡确定性实时控制和先进感知能力的架构。

Method: 论文提出了一种将NASA F'飞行软件框架与ROS2中间件通过Protocol Buffers桥接的集成系统。该架构通过一次32.25分钟的室内四旋翼飞行测试进行了评估，使用了基于视觉的导航。

Result: 视觉系统实现了87.19 Hz的位置估计，数据连续性为99.90%，平均延迟为11.47毫秒。所有15个地面命令以100%的成功率执行。系统资源利用率保持较低（CPU 15.19%，RAM 1,244 MB），且没有过时遥测消息。

Conclusion: 结果验证了结合认证级确定性和灵活自主性的混合飞行软件架构在自主飞行器上的可行性。

Abstract: Autonomous aerospace systems require architectures that balance deterministic real-time control with advanced perception capabilities. This paper presents an integrated system combining NASA's F' flight software framework with ROS2 middleware via Protocol Buffers bridging. We evaluate the architecture through a 32.25-minute indoor quadrotor flight test using vision-based navigation. The vision system achieved 87.19 Hz position estimation with 99.90\% data continuity and 11.47 ms mean latency, validating real-time performance requirements. All 15 ground commands executed successfully with 100 % success rate, demonstrating robust F'--PX4 integration. System resource utilization remained low (15.19 % CPU, 1,244 MB RAM) with zero stale telemetry messages, confirming efficient operation on embedded platforms. Results validate the feasibility of hybrid flight-software architectures combining certification-grade determinism with flexible autonomy for autonomous aerial vehicles.

</details>


### [143] [One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](https://arxiv.org/abs/2602.15400)
*Zerui Li,Hongpei Zheng,Fangguo Zhao,Aidan Chan,Jian Zhou,Sihao Lin,Shijie Li,Qi Wu*

Main category: cs.RO

TL;DR: 本文提出了一种针对具身视觉与语言导航的解耦设计，通过交互式度量世界表示和反事实推理，实现了在模拟和真实世界环境中的零样本SOTA性能和鲁棒的模拟到现实迁移。


<details>
  <summary>Details</summary>
Motivation: 导航智能体需要理解高级语义指令和精确的空间感知。以多模态大语言模型（MLLMs）为核心构建导航智能体展现出巨大潜力，但当前紧密耦合的设计严重限制了系统性能。

Method: 本文提出了一种解耦设计，将低级空间状态估计与高级语义规划分离。引入了交互式度量世界表示，以维护丰富一致的信息，并允许多模态大语言模型（MLLMs）进行交互和推理决策。此外，还引入了反事实推理来进一步激发MLLMs的能力，同时度量世界表示确保了生成动作的物理有效性。在模拟和真实世界环境中进行了综合实验。

Result: 本文方法在R2R-CE基准上达到了48.8%的成功率（SR），在RxR-CE基准上达到了42.2%的成功率，建立了零样本的最新技术水平。同时，展示了度量表示在不同具身（包括轮式TurtleBot 4和定制无人机）之间的零样本模拟到现实迁移能力。

Conclusion: 该解耦框架为具身视觉与语言导航提供了一个鲁棒且领域无关的接口。

Abstract: A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\% Success Rate (SR) in R2R-CE and 42.2\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.

</details>


### [144] [Lyapunov-Based $\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot](https://arxiv.org/abs/2602.15424)
*Branimir Ćaran,Vladimir Milić,Bojan Jerbić*

Main category: cs.RO

TL;DR: 本文提出了一种基于Lyapunov的PI类控制器，用于独立驱动和转向的四轮移动机器人的$\mathcal{L}_2$稳定运动控制，并通过实验验证了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是为独立驱动和转向的四轮移动机器人提供一种具有稳定性、性能保证和适用于实时操作的系统化控制器设计方法，并减少配置依赖效应。

Method: 该研究通过以下方法进行：1) 采用Lyapunov方法合成PI类控制器；2) 使用明确、经过结构验证的模型进行控制器设计；3) 构建Lyapunov函数以得到明确的界限和$\mathcal{L}_2$稳定性结果；4) 通过反馈合成减少配置依赖效应。

Result: 研究结果表明：1) 所得控制律保持了PI类形式；2) 保留了严格的稳定性特性；3) 在真实的四轮移动机器人平台上通过实验证明了其有效性和鲁棒性。

Conclusion: 本文提出了一种基于Lyapunov的PI类控制器，用于独立驱动和转向的四轮移动机器人的$\mathcal{L}_2$稳定运动控制。该控制器具有系统的设计方法、严格的稳定性保证和实时操作适用性，并通过实验验证了其有效性和鲁棒性。

Abstract: In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.

</details>


### [145] [Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling](https://arxiv.org/abs/2602.15513)
*Ji Li,Jing Xia,Mingyi Li,Shiyan Hu*

Main category: cs.RO

TL;DR: 本文提出了一种非参数记忆框架，该框架明确分离了具身探索和问答中的偶发记忆和语义记忆，以解决多模态大语言模型在长程观察和有限上下文下的具身智能体部署挑战，并通过检索和推理实现经验的鲁棒重用和跨环境泛化，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 将多模态大语言模型（MLLMs）部署为具身智能体的大脑仍然面临挑战，尤其是在长程观察和有限上下文预算下。现有的记忆辅助方法通常依赖于文本摘要，这会丢失丰富的视觉和空间细节，并且在非稳态环境中表现脆弱。

Method: 本文提出了一种非参数记忆框架，明确区分了具身探索和问答中的偶发记忆和语义记忆。其方法采用“检索优先，推理辅助”的范式，通过语义相似性召回偶发经验，并通过视觉推理进行验证，从而实现对过去观察的鲁棒重用，无需严格的几何对齐。同时，引入了一种程序风格的规则提取机制，将经验转化为结构化、可重用的语义记忆，以促进跨环境泛化。

Result: 在具身问答和探索基准测试中取得了最先进的性能，在A-EQA上LLM-Match提高了7.3%，LLM MatchXSPL提高了11.4%。在GOAT-Bench上，成功率提高了7.7%，SPL提高了6.8%。分析表明，偶发记忆主要提高了探索效率，而语义记忆增强了具身智能体的复杂推理。

Conclusion: 偶发记忆提高了探索效率，而语义记忆增强了具身智能体的复杂推理能力。

Abstract: Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.

</details>


### [146] [VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing](https://arxiv.org/abs/2602.15549)
*Guoqin Tang,Qingxuan Jia,Gang Chen,Tong Li,Zeyuan Huang,Zihang Lv,Ning Ji*

Main category: cs.RO

TL;DR: VLM-DEWM是一种认知架构，通过将VLM推理与动态外部世界模型（DEWM）分离，并使用可外部化的推理跟踪（ERT）进行验证，从而解决了动态制造环境中VLM在状态跟踪和故障恢复方面的挑战，显著提高了状态跟踪准确性和恢复成功率。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在智能制造的高级规划中具有潜力，但在动态工作单元中部署面临两大挑战：一是无状态操作导致世界状态漂移，无法持续跟踪视线外的状态；二是推理不透明，难以诊断故障，导致代价高昂的盲目重试。

Method: 本文提出了VLM-DEWM认知架构，通过一个持久的、可查询的动态外部世界模型（DEWM）将VLM推理与世界状态管理解耦。每个VLM决策都被构建成一个可外部化的推理跟踪（ERT），包含动作提议、世界信念和因果假设，并在执行前根据DEWM进行验证。当发生故障时，通过预测状态与观察状态之间的差异分析，实现有针对性的恢复，而非全局重新规划。

Result: VLM-DEWM在多站装配、大规模设施探索和真实机器人诱导故障恢复方面进行了评估。与基线内存增强VLM系统相比，VLM-DEWM将状态跟踪准确率从56%提高到93%，恢复成功率从低于5%提高到95%，并通过结构化内存显著降低了计算开销。

Conclusion: 这些结果表明，VLM-DEWM是动态制造环境中长周期机器人操作的一种可验证且具有弹性的解决方案。

Abstract: Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.

</details>


### [147] [Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions](https://arxiv.org/abs/2602.15567)
*Jieting Long,Dechuan Liu,Weidong Cai,Ian Manchester,Weiming Zhi*

Main category: cs.RO

TL;DR: 提出了一种名为约束感知流（CASF）的新框架，该框架通过增加约束依赖度量来增强流策略，从而在执行过程中实时调整机器人轨迹，以确保安全性和任务特定约束，同时保持流策略的多模态和反应性。


<details>
  <summary>Details</summary>
Motivation: 机器人运动分布通常表现出多模态，需要灵活的生成模型进行准确表示。现有流策略（SFPs）虽能生成平滑且反应迅速的轨迹，但缺乏在训练后调整轨迹以强制执行安全和任务特定约束的机制。

Method: CASF将每个约束（在机器人工作空间或配置空间中定义）建模为可微分距离函数。该函数被转换为局部度量，并拉回机器人的控制空间，在执行过程中重塑学习到的速度场。在远离受限区域时，所得度量会还原为恒等变换；在接近约束边界时，它会平滑地衰减或重定向运动，从而有效地变形底层流以维持安全性。

Result: CASF使轨迹能够实时调整，确保机器人动作遵守关节限制、避免碰撞并保持在可行工作空间内，同时保留流策略的多模态和反应性。它生成满足约束、平滑、可行且动态一致的轨迹。在模拟和真实世界的操控任务中，CASF表现优于标准的后处理投影基线方法。

Conclusion: CASF通过引入约束依赖度量，有效地解决了现有流策略在实时约束感知轨迹适应方面的局限性，从而在不牺牲流策略优势的情况下，实现更安全、更可靠的机器人控制。

Abstract: Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajectories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot's workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot's control space. Far from restricted regions, the resulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines.

</details>


### [148] [Grip as Needed, Glide on Demand: Ultrasonic Lubrication for Robotic Locomotion](https://arxiv.org/abs/2602.15608)
*Mostafa A. Atalla,Daan van Bemmel,Jack Cummings,Paul Breedveld,Michaël Wiertlewski,Aimée Sakes*

Main category: cs.RO

TL;DR: 本研究引入超声波润滑，通过激发共振结构主动控制机器人运动中的摩擦，实现了高效率的双向运动，并在多种表面和条件下有效降低摩擦。


<details>
  <summary>Details</summary>
Motivation: 摩擦是陆地运动的关键，但在机器人系统中，摩擦几乎总是被视为由表面材料和条件决定的被动特性，因此需要一种主动控制摩擦的方法。

Method: 通过超声频率激励共振结构，使接触界面动态切换“抓取”和“滑动”状态以实现运动。开发了两种摩擦控制模块（圆柱形和平板式），并将其集成到仿生尺蠖和黄蜂产卵器运动系统中。

Result: 两种系统都实现了双向运动，运动效率接近完美，超过90%。摩擦特性实验进一步证明，在干燥和潮湿条件下以及不同粗糙度的表面上，包括刚性、软性、颗粒状和生物组织界面，摩擦显著降低。

Conclusion: 超声波润滑是一种可行的机器人运动主动摩擦控制机制，有望降低设计复杂性并提高机器人运动系统的效率。

Abstract: Friction is the essential mediator of terrestrial locomotion, yet in robotic systems it is almost always treated as a passive property fixed by surface materials and conditions. Here, we introduce ultrasonic lubrication as a method to actively control friction in robotic locomotion. By exciting resonant structures at ultrasonic frequencies, contact interfaces can dynamically switch between "grip" and "slip" states, enabling locomotion. We developed two friction control modules, a cylindrical design for lumen-like environments and a flat-plate design for external surfaces, and integrated them into bio-inspired systems modeled after inchworm and wasp ovipositor locomotion. Both systems achieved bidirectional locomotion with nearly perfect locomotion efficiencies that exceeded 90%. Friction characterization experiments further demonstrated substantial friction reduction across various surfaces, including rigid, soft, granular, and biological tissue interfaces, under dry and wet conditions, and on surfaces with different levels of roughness, confirming the broad applicability of ultrasonic lubrication to locomotion tasks. These findings establish ultrasonic lubrication as a viable active friction control mechanism for robotic locomotion, with the potential to reduce design complexity and improve efficiency of robotic locomotion systems.

</details>


### [149] [SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms](https://arxiv.org/abs/2602.15633)
*Haichao Liu,Yufeng Hu,Shuang Wang,Kangjun Guo,Jun Ma,Jinni Zhou*

Main category: cs.RO

TL;DR: 该论文提出SpecFuse，一个频谱-时间融合预测控制框架，用于无人机在摇摆海洋平台上的自主着陆，实现了高精度和高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在无人机在摇摆海洋平台上的自主着陆方面面临挑战，包括波浪引起的多频振荡、风扰动和运动预测中的预测相位滞后。这些方法将平台运动视为一般随机过程或缺乏波浪谱特征的显式建模，导致在动态海洋条件下性能不佳。

Method: 本文提出了SpecFuse，一个新颖的频谱-时间融合预测控制框架。该框架将频域波浪分解与时域递归状态估计相结合，用于无人艇（USVs）的高精度6-DoF运动预测。它显式建模了主导波浪谐波以减轻相位滞后，并通过IMU数据实时改进预测。此外，还设计了一个分层控制架构，采用基于采样的HPO-RRT*算法进行非凸约束下的动态轨迹规划，以及一个学习增强的预测控制器，融合数据驱动的扰动补偿与基于优化的执行。

Result: 通过广泛验证（2,000次模拟 + 8次湖泊实验），该方法实现了3.2厘米的预测误差、4.46厘米的着陆偏差、98.7% / 87.5%的成功率（模拟/真实世界），以及在嵌入式硬件上82毫秒的延迟。在精度上优于现有最新方法44%-48%，并且对波浪-风耦合扰动具有鲁棒性。

Conclusion: SpecFuse为无人机在摇摆海洋平台上的自主着陆提供了一个鲁棒且高精度的解决方案，支持了搜索与救援、环境监测等关键海上任务。所有代码、实验配置和数据集将开源以促进可重现性。

Abstract: Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.

</details>


### [150] [Spatially-Aware Adaptive Trajectory Optimization with Controller-Guided Feedback for Autonomous Racing](https://arxiv.org/abs/2602.15642)
*Alexander Wachter,Alexander Willert,Marc-Philip Ecker,Christian Hartl-Nesic*

Main category: cs.RO

TL;DR: 本文提出了一种结合NURBS轨迹表示、CMA-ES全局轨迹优化和控制器引导空间反馈的闭环自动赛车线优化框架。该方法通过卡尔曼启发式空间更新，将跟踪误差作为局部赛道特征的信息信号，构建自适应的基于加速度的约束图，迭代优化轨迹。在仿真中，圈速减少了17.38%；在真实硬件上，实现了7.60%的圈速提升，并对抓地力变化表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将跟踪误差视为瞬态扰动。本文的动机是利用跟踪误差作为局部赛道特征的信息信号，以构建一个自适应的加速度约束图，从而在空间变化的赛道和车辆行为下，迭代地将轨迹优化到接近最佳性能。

Method: 该框架是一个闭环系统，结合了基于NURBS的轨迹表示、CMA-ES全局轨迹优化和控制器引导的空间反馈。它通过卡尔曼启发式空间更新，将跟踪误差作为局部赛道特征的信息信号。这使得能够构建一个自适应的、基于加速度的约束图，该图迭代地细化轨迹。

Result: 在仿真中，与使用最大静态加速度参数化的控制器相比，本文方法实现了17.38%的圈速减少。在真实硬件上，使用不同摩擦系数的轮胎进行测试，在不明确参数化摩擦的情况下，获得了7.60%的圈速提升。

Conclusion: 本文提出的自动赛车线优化闭环框架，通过利用跟踪误差作为空间反馈，在仿真和真实硬件上均实现了显著的圈速提升，并对现实世界中变化的抓地力条件表现出鲁棒性。

Abstract: We present a closed-loop framework for autonomous raceline optimization that combines NURBS-based trajectory representation, CMA-ES global trajectory optimization, and controller-guided spatial feedback. Instead of treating tracking errors as transient disturbances, our method exploits them as informative signals of local track characteristics via a Kalman-inspired spatial update. This enables the construction of an adaptive, acceleration-based constraint map that iteratively refines trajectories toward near-optimal performance under spatially varying track and vehicle behavior. In simulation, our approach achieves a 17.38% lap time reduction compared to a controller parametrized with maximum static acceleration. On real hardware, tested with different tire compounds ranging from high to low friction, we obtain a 7.60% lap time improvement without explicitly parametrizing friction. This demonstrates robustness to changing grip conditions in real-world scenarios.

</details>


### [151] [MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction](https://arxiv.org/abs/2602.15733)
*Qiang Zhang,Jiahao Ma,Peiran Liu,Shuai Shi,Zeran Su,Zifan Wang,Jingkai Sun,Wei Cui,Jialin Yu,Gang Han,Wen Zhao,Pihai Sun,Kangning Yin,Jiaxu Wang,Jiahang Cao,Lingfeng Zhang,Hao Cheng,Xiaoshuai Hao,Yiding Ji,Junwei Liang,Jian Tang,Renjing Xu,Yijie Guo*

Main category: cs.RO

TL;DR: MeshMimic是一个创新框架，它通过从视频中重建3D场景和人体轨迹，并优化运动数据及重新定位人机交互特征，使仿人机器人能够学习“运动-地形”耦合交互，从而在不同地形上实现鲁棒、高动态的性能，且仅需低成本的单目传感器。


<details>
  <summary>Details</summary>
Motivation: 由于仿人机器人的高维度和复杂动力学特性，手动运动设计不切实际，导致过度依赖昂贵的动作捕捉（MoCap）数据。现有MoCap数据集通常缺乏周围物理环境的几何上下文，导致在地形感知任务中出现物理不一致（如接触滑动或网格穿透），即运动与场景脱耦。

Method: MeshMimic框架将3D场景重建与具身智能相结合。它利用先进的3D视觉模型，从视频中精确分割并重建人体轨迹以及地形和物体的3D几何结构。该方法引入了一种基于运动学一致性的优化算法，从嘈杂的视觉重建中提取高质量运动数据，并提出了一种接触不变的重定向方法，将人与环境的交互特征转移到仿人机器人智能体。

Result: 实验结果表明，MeshMimic在多样化和具有挑战性的地形上实现了鲁棒、高动态的性能。该方法证明，利用消费级单目传感器的低成本管道可以促进复杂物理交互的训练。

Conclusion: MeshMimic为非结构化环境中仿人机器人的自主进化提供了一条可扩展的路径，通过使其能够直接从视频中学习耦合的“运动-地形”交互，并且仅使用低成本传感器。

Abstract: Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled "motion-terrain" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.

</details>


### [152] [Robot-Assisted Social Dining as a White Glove Service](https://arxiv.org/abs/2602.15767)
*Atharva S Kashyap,Ugne Aleksandra Morkute,Patricia Alves-Oliveira*

Main category: cs.RO

TL;DR: 本研究通过与残疾人进行参与式设计，探讨了机器人在“野外”社交用餐环境中的理想应用，提出机器人应提供“白手套服务”，包括多模态交互、情境化社交行为、扩展角色及适应餐桌关系。


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助进食系统仅限于实验室或家庭测试，忽略了餐馆等“野外”社交用餐环境。设计此类机器人面临动态、无人监督环境等独特挑战，需要机器人进行适应和响应。

Method: 研究方法包括与残疾人进行的推测性参与式设计，辅以半结构化访谈和定制的基于AI的视觉故事板工具，以发现“野外”社交用餐的理想场景。

Result: 研究核心见解是，机器人辅助进食系统应遵循“白手套服务”原则，具体包括：1) 支持多模态输入和不显眼的输出；2) 具有情境敏感的社交行为并优先考虑用户；3) 具备超越进食的扩展角色；4) 适应餐桌上的其他人际关系。

Conclusion: 该研究对机器人辅助进食的“野外”和团体环境具有重要意义，为未来设计提供了指导。

Abstract: Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.

</details>


### [153] [Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching](https://arxiv.org/abs/2602.15827)
*Zhen Wu,Xiaoyu Huang,Lujie Yang,Yuanhang Zhang,Koushil Sreenath,Xi Chen,Pieter Abbeel,Rocky Duan,Angjoo Kanazawa,Carmelo Sferrazza,Guanya Shi,C. Karen Liu*

Main category: cs.RO

TL;DR: 本文提出了感知类人机器人跑酷（PHP），这是一个模块化框架，使类人机器人在复杂障碍环境中自主执行长距离、基于视觉的跑酷。该框架结合了运动匹配进行技能组合，并利用基于感知的强化学习进行自主决策，并在Unitree G1机器人上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 当前的类人机器人运动在捕捉高度动态人类动作的敏捷性和适应性方面面临挑战，特别是在复杂环境中的敏捷跑酷，这需要低级鲁棒性、类人动作表达性、长距离技能组合和感知驱动的决策。

Method: PHP框架首先利用运动匹配（在特征空间中进行最近邻搜索）将重新定位的原子级人类技能组合成长时间运动轨迹。接着，为这些组合运动训练运动跟踪强化学习（RL）专家策略，并结合DAgger和RL将其提炼成一个单一的基于深度感知、多技能的学生策略。通过板载深度传感和离散的2D速度指令，机器人能够选择并执行跨越、攀爬、跳跃或滚下不同几何形状和高度障碍物的动作。

Result: 在Unitree G1类人机器人上进行了广泛的真实世界实验验证。实验展示了高动态跑酷技能，例如攀爬高达1.25米（机器人高度的96%）的障碍物，以及在实时障碍物扰动下进行闭环适应的长距离多障碍物穿越。

Conclusion: 该框架通过结合运动匹配和感知驱动的强化学习，使类人机器人能够自主执行复杂的敏捷跑酷，展示了令人印象深刻的真实世界能力。

Abstract: While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.

</details>


### [154] [Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828)
*Yuxuan Kuang,Sungjae Park,Katerina Fragkiadaki,Shubham Tulsiani*

Main category: cs.RO

TL;DR: Dex4D是一个基于模拟的框架，用于学习任务无关的灵巧操作策略，该策略可以通过3D点轨迹零样本迁移到各种现实世界任务中。


<details>
  <summary>Details</summary>
Motivation: 学习能够完成大量日常任务的通用策略在灵巧操作中仍是一个开放的挑战。通过真实世界远程操作收集大规模操作数据既昂贵又难以扩展。虽然在模拟中学习提供了一个可行的替代方案，但为训练设计多个特定任务的环境和奖励同样具有挑战性。

Method: Dex4D利用模拟来学习任务无关的灵巧技能。它学习了一个领域无关的3D点轨迹条件策略，称为“任意姿态到任意姿态”策略，能够将任何物体操作到任何期望的姿态。该策略在模拟中通过数千个具有不同姿态配置的物体进行训练。在部署时，通过使用从生成视频中提取的以物体为中心的点轨迹进行提示，实现零样本迁移到现实世界任务。在执行过程中，Dex4D使用在线点跟踪进行闭环感知和控制。

Result: 该方法实现了各种灵巧操作任务的零样本部署，并比现有基线有显著改进。此外，它对新颖物体、场景布局、背景和轨迹表现出强大的泛化能力，突出了所提出框架的鲁棒性和可扩展性。

Conclusion: Dex4D提供了一个强大且可扩展的框架，用于学习通用灵巧操作策略，该策略可以从模拟零样本迁移到各种现实世界任务中，克服了数据收集和特定任务训练的局限性。

Abstract: Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [155] [Reconstructing Carbon Monoxide Reanalysis with Machine Learning](https://arxiv.org/abs/2602.15056)
*Paula Harder,Johannes Flemming*

Main category: physics.ao-ph

TL;DR: 该研究探索机器学习方法，以预测一氧化碳（CO）再分析结果，旨在弥补因卫星观测数据（如MOPITT CO）停用而造成的数据损失。


<details>
  <summary>Details</summary>
Motivation: 大气成分再分析产品的质量高度依赖观测数据，但这些数据的可用性会随时间变化，例如MOPITT卫星的一氧化碳（CO）观测数据将于2025年初停止。机器学习提供了一种有前景的方法来弥补此类数据损失，通过学习模型配置之间的系统差异。

Method: 本研究调查机器学习方法，旨在从控制模型模拟中预测月平均一氧化碳总柱再分析。

Result: 该摘要未提及具体的实验结果。

Conclusion: 该摘要未提及明确的结论。

Abstract: The Copernicus Atmospheric Monitoring Service provides reanalysis products for atmospheric composition by combining model simulations with satellite observations. The quality of these products depends strongly on the availability of the observational data, which can vary over time as new satellite instruments become available or are discontinued, such as Carbon Monoxide (CO) observations of the Measurements Of Pollution In The Troposphere (MOPITT) satellite in early 2025. Machine learning offers a promising approach to compensate for such data losses by learning systematic discrepancies between model configurations. In this study, we investigate machine learning methods to predict monthly-mean total column of Carbon Monoxide re-analysis from a control model simulation.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [156] [MyoInteract: A Framework for Fast Prototyping of Biomechanical HCI Tasks using Reinforcement Learning](https://arxiv.org/abs/2602.15245)
*Ankit Bhattarai,Hannah Selder,Florian Fischer,Arthur Fleig,Per Ola Kristensson*

Main category: cs.HC

TL;DR: MyoInteract是一个基于强化学习的生物力学人机交互任务快速原型框架，显著减少了设置和训练时间，使生物力学强化学习对交互设计师更易于使用。


<details>
  <summary>Details</summary>
Motivation: 基于强化学习的生物力学模拟在人机交互研究和交互设计中具有革命性潜力，但目前缺乏可用性和可解释性，阻碍了其广泛应用和快速原型开发。

Method: 开发了MyoInteract框架，该框架以人类行动周期为设计视角，提供了一个易于使用的图形用户界面，允许设计师在几分钟内设置任务、用户模型和训练参数，并对肌肉驱动的模拟用户进行训练和评估。

Result: MyoInteract将训练时间缩短了高达98%（从数天缩短至数分钟）。一项对12位交互设计师的研讨会研究表明，生物力学强化学习新手可以在一个会话中成功设置、训练和评估目标导向的用户运动。

Conclusion: 这项工作通过将生物力学强化学习从一个耗时数天的专家任务转变为一个易于访问的、耗时一小时的工作流程，显著降低了人机交互生物力学研究的进入门槛，并加速了迭代周期。

Abstract: Reinforcement learning (RL)-based biomechanical simulations have the potential to revolutionise HCI research and interaction design, but currently lack usability and interpretability. Using the Human Action Cycle as a design lens, we identify key limitations of biomechanical RL frameworks and develop MyoInteract, a novel framework for fast prototyping of biomechanical HCI tasks. MyoInteract allows designers to setup tasks, user models, and training parameters from an easy-to-use GUI within minutes. It trains and evaluates muscle-actuated simulated users within minutes, reducing training times by up to 98%. A workshop study with 12 interaction designers revealed that MyoInteract allowed novices in biomechanical RL to successfully setup, train, and assess goal-directed user movements within a single session. By transforming biomechanical RL from a days-long expert task into an accessible hour-long workflow, this work significantly lowers barriers to entry and accelerates iteration cycles in HCI biomechanics research.

</details>


### [157] [From Diagnosis to Inoculation: Building Cognitive Resistance to AI Disempowerment](https://arxiv.org/abs/2602.15265)
*Aleksey Komissarov*

Main category: cs.HC

TL;DR: 本研究提出了一个AI素养框架，通过一个案例研究展示了其在AI共同指导的在线课程中的应用。该框架与现有AI导致人类“剥夺权力”的分类法一致，并运用免疫理论论证了AI素养需通过暴露于AI失败模式而非仅靠陈述性知识来培养。此独立方法间的契合强化了诊断与教育应对方案的有效性。


<details>
  <summary>Details</summary>
Motivation: Sharma等人（2026）的研究揭示了AI助手交互可能导致人类在情境中被剥夺权力（包括现实扭曲、价值判断扭曲和行动扭曲），但具体的教学干预措施尚未得到充分探索。

Method: 该研究开发了一个围绕八个跨领域学习成果的AI素养框架，并通过一个以AI作为共同指导者的在线课程案例研究来交付此框架。它借鉴了免疫理论（Inoculation Theory），主张AI素养不能仅通过陈述性知识获得，而需要指导性地暴露于AI的失败模式。

Result: 所提出的AI素养框架与Sharma等人识别的“剥夺权力”分类法相符。免疫理论在AI特定扭曲方面的应用是新颖的。 pedagogically-derived 框架与 empirically-derived 分类法之间的趋同加强了对问题诊断和所提议教育应对方案的论证。

Conclusion: 此项研究通过独立开发的教学框架与Sharma等人实证分类法的契合，强化了对AI潜在负面影响的诊断及其教育应对方案的有效性。它强调了AI素养教育应包含指导性暴露于AI失败模式的重要性，而非仅限于陈述性知识。

Abstract: Recent empirical research by Sharma et al. (2026) demonstrated that AI assistant interactions carry meaningful potential for situational human disempowerment, including reality distortion, value judgment distortion, and action distortion. While this work provides a critical diagnosis of the problem, concrete pedagogical interventions remain underexplored. I present an AI literacy framework built around eight cross-cutting Learning Outcomes (LOs), developed independently through teaching practice and subsequently found to align with Sharma et al.'s disempowerment taxonomy. I report a case study from a publicly available online course, where a co-teaching methodology--with AI serving as an active voice co-instructor--was used to deliver this framework. Drawing on inoculation theory (McGuire, 1961)--a well-established persuasion research framework recently applied to misinformation prebunking by the Cambridge school (van der Linden, 2022; Roozenbeek & van der Linden, 2019)--I argue that AI literacy cannot be acquired through declarative knowledge alone, but requires guided exposure to AI failure modes, including the sycophantic validation and authority projection patterns identified by Sharma et al. This application of inoculation theory to AI-specific distortion is, to my knowledge, novel. I discuss the convergence between the pedagogically-derived framework and Sharma et al.'s empirically-derived taxonomy, and argue that this convergence--two independent approaches arriving at similar problem descriptions--strengthens the case for both the diagnosis and the proposed educational response.

</details>


### [158] [How to Disclose? Strategic AI Disclosure in Crowdfunding](https://arxiv.org/abs/2602.15698)
*Ning Wang,Chen Liang*

Main category: cs.HC

TL;DR: 在众筹中，强制性AI披露会显著降低项目表现（资金和支持者数量），但通过战略性披露（高真实性、高明确性，避免过度积极情绪）可以缓解负面影响。其机制涉及创作者能力感知和AI洗白担忧。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能日益融入众筹实践，人工智能参与的战略性披露变得至关重要，但关于不同披露策略如何影响投资者决策的实证见解仍然有限。

Method: 该研究利用Kickstarter强制性人工智能披露政策作为自然实验，并辅以四项在线实验进行分析。

Result: 强制性人工智能披露显著降低了众筹表现：人工智能项目筹集的资金下降了39.8%，支持者数量下降了23.9%。然而，这种不利影响受到披露策略的系统性调节。人工智能参与程度越高，人工智能披露的负面影响越大；而高真实性和高明确性则能减轻这些负面影响。过度积极的情感语调（创作者可能直观地采用以对抗人工智能怀疑论的策略）会适得其反，加剧负面结果。研究通过随机实验确定了两个潜在机制：感知到的创作者能力和对“AI洗白”的担忧。实质性信号主要影响能力判断，而修辞信号则通过不同的途径（单独中介或两者顺序）发挥作用。

Conclusion: 这些发现为企业家、平台和政策制定者在高风险投资环境中战略性地管理人工智能透明度提供了理论和实践见解。

Abstract: As artificial intelligence (AI) increasingly integrates into crowdfunding practices, strategic disclosure of AI involvement has become critical. Yet, empirical insights into how different disclosure strategies influence investor decisions remain limited. Drawing on signaling theory and Aristotle's rhetorical framework, we examine how mandatory AI disclosure affects crowdfunding performance and how substantive signals (degree of AI involvement) and rhetorical signals (logos/explicitness, ethos/authenticity, pathos/emotional tone) moderate these effects. Leveraging Kickstarter's mandatory AI disclosure policy as a natural experiment and four supplementary online experiments, we find that mandatory AI disclosure significantly reduces crowdfunding performance: funds raised decline by 39.8% and backer counts by 23.9% for AI-involved projects. However, this adverse effect is systematically moderated by disclosure strategy. Greater AI involvement amplifies the negative effects of AI disclosure, while high authenticity and high explicitness mitigate them. Interestingly, excessive positive emotional tone (a strategy creators might intuitively adopt to counteract AI skepticism) backfires and exacerbates negative outcomes. Supplementary randomized experiments identify two underlying mechanisms: perceived creator competence and AI washing concerns. Substantive signals primarily affect competence judgments, whereas rhetorical signals operate through varied pathways: either mediator alone or both in sequence. These findings provide theoretical and practical insights for entrepreneurs, platforms, and policymakers strategically managing AI transparency in high-stakes investment contexts.

</details>
