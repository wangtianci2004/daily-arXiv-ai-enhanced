<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 40]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.HC](#cs.HC) [Total: 4]
- [q-bio.OT](#q-bio.OT) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.SE](#cs.SE) [Total: 4]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [eess.SY](#eess.SY) [Total: 2]
- [math.NA](#math.NA) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.OS](#cs.OS) [Total: 1]
- [physics.acc-ph](#physics.acc-ph) [Total: 1]
- [cs.AI](#cs.AI) [Total: 46]
- [eess.SP](#eess.SP) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 37]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Three-dimensional Damage Visualization of Civil Structures via Gaussian Splatting-enabled Digital Twins](https://arxiv.org/abs/2602.16713)
*Shuo Wang,Shuo Wang,Xin Nie,Yasutaka Narazaki,Thomas Matiki,Billie F. Spencer Jr*

Main category: cs.CV

TL;DR: 该研究提出了一种基于高斯泼溅（GS）的数字孪生方法，用于土木基础设施的精确三维（3D）损伤可视化，该方法通过利用GS进行3D重建来可视化并减少2D损伤分割误差，开发多尺度重建策略以平衡效率和细节，并支持损伤随时间演变的数字孪生更新。


<details>
  <summary>Details</summary>
Motivation: 土木基础设施检查需要超越传统的二维（2D）图像损伤识别，实现数字孪生上精确的三维（3D）损伤可视化。

Method: 本研究引入了一种基于高斯泼溅（GS）的数字孪生方法，专为有效的三维损伤可视化而设计。该方法的主要贡献包括：1）利用基于GS的3D重建来可视化2D损伤分割结果，同时减少分割误差；2）开发一种多尺度重建策略，以平衡效率和损伤细节；3）使数字孪生能够随着损伤随时间演变而更新。

Result: 该方法在一个用于震后检查的开源合成数据集上进行了演示，结果表明所提出的方法为土木基础设施数字孪生中的综合3D损伤可视化提供了一个有前景的解决方案。

Conclusion: 所提出的基于高斯泼溅（GS）的数字孪生方法为土木基础设施中的综合3D损伤可视化提供了一个有前景的解决方案，解决了传统2D方法的局限性，并支持损伤的动态更新。

Abstract: Recent advancements in civil infrastructure inspections underscore the need for precise three-dimensional (3D) damage visualization on digital twins, transcending traditional 2D image-based damage identifications. Compared to conventional photogrammetric 3D reconstruction techniques, modern approaches such as Neural Radiance Field (NeRF) and Gaussian Splatting (GS) excel in scene representation, rendering quality, and handling featureless regions. Among them, GS stands out for its efficiency, leveraging discrete anisotropic 3D Gaussians to represent radiance fields, unlike NeRF's continuous implicit model. This study introduces a GS-enabled digital twin method tailored for effective 3D damage visualization. The method's key contributions include: 1) utilizing GS-based 3D reconstruction to visualize 2D damage segmentation results while reducing segmentation errors; 2) developing a multi-scale reconstruction strategy to balance efficiency and damage detail; 3) enabling digital twin updates as damage evolves over time. Demonstrated on an open-source synthetic dataset for post-earthquake inspections, the proposed approach offers a promising solution for comprehensive 3D damage visualization in civil infrastructure digital twins.

</details>


### [2] [3D Scene Rendering with Multimodal Gaussian Splatting](https://arxiv.org/abs/2602.17124)
*Chi-Shiang Gau,Konstantinos D. Polyzos,Athanasios Bacharis,Saketh Madhuvarasu,Tara Javidi*

Main category: cs.CV

TL;DR: 该论文提出了一种将射频传感（如雷达）与3D高斯溅射（GS）结合的多模态框架，以克服传统视觉GS在恶劣条件下的局限性。通过RF信号进行深度预测，生成高质量点云来初始化GS，从而实现更高效、更鲁棒的高保真3D场景渲染。


<details>
  <summary>Details</summary>
Motivation: 传统的基于视觉的3D高斯溅射（GS）方法在初始化高斯基元和训练参数时需要足够多的相机视图，这会产生额外的处理成本。此外，在恶劣天气、低光照或部分遮挡等视觉线索不可靠的条件下，其性能会显著下降。为了解决这些挑战，并借鉴了射频信号对天气、光照和遮挡的鲁棒性，研究者寻求一种更高效、更鲁棒的替代方案。

Method: 该研究提出了一种多模态框架，将射频（RF）传感（如汽车雷达）与GS渲染相结合。此方法通过稀疏的RF深度测量实现高效深度预测，生成高质量的3D点云，用于初始化各种GS架构中的高斯函数。

Result: 数值测试表明，将射频传感整合到GS管线中是有效的。该方法通过射频信息增强的结构准确性，实现了高保真度的3D场景渲染。

Conclusion: 该研究证明，将射频传感审慎地整合到GS管线中具有显著优势，为仅依赖视觉的GS渲染提供了一种更高效、更鲁棒的替代方案，特别是在视觉线索不可靠的条件下。

Abstract: 3D scene reconstruction and rendering are core tasks in computer vision, with applications spanning industrial monitoring, robotics, and autonomous driving. Recent advances in 3D Gaussian Splatting (GS) and its variants have achieved impressive rendering fidelity while maintaining high computational and memory efficiency. However, conventional vision-based GS pipelines typically rely on a sufficient number of camera views to initialize the Gaussian primitives and train their parameters, typically incurring additional processing cost during initialization while falling short in conditions where visual cues are unreliable, such as adverse weather, low illumination, or partial occlusions. To cope with these challenges, and motivated by the robustness of radio-frequency (RF) signals to weather, lighting, and occlusions, we introduce a multimodal framework that integrates RF sensing, such as automotive radar, with GS-based rendering as a more efficient and robust alternative to vision-only GS rendering. The proposed approach enables efficient depth prediction from only sparse RF-based depth measurements, yielding a high-quality 3D point cloud for initializing Gaussian functions across diverse GS architectures. Numerical tests demonstrate the merits of judiciously incorporating RF sensing into GS pipelines, achieving high-fidelity 3D scene rendering driven by RF-informed structural accuracy.

</details>


### [3] [NRGS-SLAM: Monocular Non-Rigid SLAM for Endoscopy via Deformation-Aware 3D Gaussian Splatting](https://arxiv.org/abs/2602.17182)
*Jiwei Shan,Zeyu Cai,Yirui Li,Yongbo Chen,Lijun Han,Yun-hui Liu,Hesheng Wang,Shing Shin Cheng*

Main category: cs.CV

TL;DR: NRGS-SLAM是一种基于3D高斯泼溅的单目非刚性SLAM系统，通过引入形变感知3D高斯图和鲁棒的几何损失，解决了内窥镜场景中的耦合模糊性和低重建质量问题，在姿态估计和重建方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜场景中的软组织形变违反了视觉SLAM的刚性假设，导致相机自我运动和内部形变之间存在强耦合模糊性。现有单目非刚性SLAM方法通常缺乏有效的解耦机制，且依赖稀疏或低保真场景表示，这导致跟踪漂移和重建质量受限。

Method: NRGS-SLAM是一个基于3D高斯泼溅的单目非刚性SLAM系统。为解决耦合模糊性，它引入了形变感知3D高斯图，通过贝叶斯自监督策略优化每个高斯基元的形变概率。该系统包含一个可形变跟踪模块，通过优先处理低形变区域实现鲁棒的粗到细姿态估计，并进行高效的逐帧形变更新。一个精心设计的可形变映射模块逐步扩展和细化地图。此外，统一的鲁棒几何损失结合外部几何先验以缓解单目非刚性SLAM的病态性。

Result: 在多个公共内窥镜数据集上，NRGS-SLAM实现了更精确的相机姿态估计（RMSE降低高达50%）和比现有技术更高质量的真实感重建。综合消融研究进一步验证了关键设计选择的有效性。

Conclusion: NRGS-SLAM通过引入形变感知3D高斯图和鲁棒的几何损失，有效解决了内窥镜场景下单目非刚性SLAM中的耦合模糊性和病态性问题，在相机姿态估计和重建质量方面显著优于现有技术。

Abstract: Visual simultaneous localization and mapping (V-SLAM) is a fundamental capability for autonomous perception and navigation. However, endoscopic scenes violate the rigidity assumption due to persistent soft-tissue deformations, creating a strong coupling ambiguity between camera ego-motion and intrinsic deformation. Although recent monocular non-rigid SLAM methods have made notable progress, they often lack effective decoupling mechanisms and rely on sparse or low-fidelity scene representations, which leads to tracking drift and limited reconstruction quality. To address these limitations, we propose NRGS-SLAM, a monocular non-rigid SLAM system for endoscopy based on 3D Gaussian Splatting. To resolve the coupling ambiguity, we introduce a deformation-aware 3D Gaussian map that augments each Gaussian primitive with a learnable deformation probability, optimized via a Bayesian self-supervision strategy without requiring external non-rigidity labels. Building on this representation, we design a deformable tracking module that performs robust coarse-to-fine pose estimation by prioritizing low-deformation regions, followed by efficient per-frame deformation updates. A carefully designed deformable mapping module progressively expands and refines the map, balancing representational capacity and computational efficiency. In addition, a unified robust geometric loss incorporates external geometric priors to mitigate the inherent ill-posedness of monocular non-rigid SLAM. Extensive experiments on multiple public endoscopic datasets demonstrate that NRGS-SLAM achieves more accurate camera pose estimation (up to 50\% reduction in RMSE) and higher-quality photo-realistic reconstructions than state-of-the-art methods. Comprehensive ablation studies further validate the effectiveness of our key design choices. Source code will be publicly available upon paper acceptance.

</details>


### [4] [When Vision Overrides Language: Evaluating and Mitigating Counterfactual Failures in VLAs](https://arxiv.org/abs/2602.17659)
*Yu Fang,Yuchun Feng,Dong Jing,Jiaqi Liu,Yue Yang,Zhenyu Wei,Daniel Szafir,Mingyu Ding*

Main category: cs.CV

TL;DR: 本文提出LIBERO-CF基准以评估视觉-语言-行动（VLA）模型的反事实失败，并引入反事实行动指导（CAG）方法。CAG通过双分支推理明确规范语言条件作用，显著提高了VLA在遵循语言指令方面的准确性和鲁棒性，尤其是在减少视觉捷径方面，且无需额外训练或模型修改。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-行动（VLA）模型在实际应用中常无法忠实遵循语言指令，特别是在缺乏强场景特定监督的情况下。它们容易出现反事实失败，即因数据集偏差导致的视觉捷径，重复执行训练中频繁出现的行为和选择物体，而忽略语言意图。

Method: 1. 引入LIBERO-CF：首个VLA反事实基准，通过在视觉上合理的环境中分配替代指令来评估语言遵循能力。
2. 提出反事实行动指导（CAG）：一种双分支推理方案，通过将标准VLA策略与语言非条件视觉-行动（VA）模块结合，在动作选择期间进行反事实比较，从而明确地规范VLA中的语言条件作用。CAG旨在减少对视觉捷径的依赖。

Result: 1. LIBERO-CF评估：揭示了最先进VLA模型中反事实失败的普遍性。
2. CAG在LIBERO-CF上的表现：
    * 训练无关策略：语言遵循准确率提升9.7%（π0.5），任务成功率在未充分观察任务上提升3.6%。
    * 结合VA模型：语言遵循准确率进一步提升15.5%，任务成功率提升8.5%。
3. 真实世界评估：反事实失败减少9.4%，任务成功率平均提升17.2%。
4. CAG的优势：无需额外演示、无需修改现有架构或预训练模型，即插即用，跨多样VLA模型表现出持续改进。

Conclusion: 反事实行动指导（CAG）通过引入明确的语言条件作用机制，显著提高了最先进视觉-语言-行动（VLA）模型在遵循语言指令方面的鲁棒性和准确性，解决了视觉捷径问题，且无需额外训练或模型修改。

Abstract: Vision-Language-Action models (VLAs) promise to ground language instructions in robot control, yet in practice often fail to faithfully follow language. When presented with instructions that lack strong scene-specific supervision, VLAs suffer from counterfactual failures: they act based on vision shortcuts induced by dataset biases, repeatedly executing well-learned behaviors and selecting objects frequently seen during training regardless of language intent. To systematically study it, we introduce LIBERO-CF, the first counterfactual benchmark for VLAs that evaluates language following capability by assigning alternative instructions under visually plausible LIBERO layouts. Our evaluation reveals that counterfactual failures are prevalent yet underexplored across state-of-the-art VLAs. We propose Counterfactual Action Guidance (CAG), a simple yet effective dual-branch inference scheme that explicitly regularizes language conditioning in VLAs. CAG combines a standard VLA policy with a language-unconditioned Vision-Action (VA) module, enabling counterfactual comparison during action selection. This design reduces reliance on visual shortcuts, improves robustness on under-observed tasks, and requires neither additional demonstrations nor modifications to existing architectures or pretrained models. Extensive experiments demonstrate its plug-and-play integration across diverse VLAs and consistent improvements. For example, on LIBERO-CF, CAG improves $\pi_{0.5}$ by 9.7% in language following accuracy and 3.6% in task success on under-observed tasks using a training-free strategy, with further gains of 15.5% and 8.5%, respectively, when paired with a VA model. In real-world evaluations, CAG reduces counterfactual failures of 9.4% and improves task success by 17.2% on average.

</details>


### [5] [Analytic Score Optimization for Multi Dimension Video Quality Assessment](https://arxiv.org/abs/2602.16856)
*Boda Lin,Yongjie Zhu,Wenyu Qin,Meng Wang,Pengfei Wan*

Main category: cs.CV

TL;DR: 本文提出了UltraVQA，一个用于用户生成内容（UGC）的大规模多维度视频质量评估（VQA）数据集，其包含详细的人工和GPT标注，涵盖五个关键质量维度。此外，本文还引入了分析分数优化（ASO），一种用于多维度VQA的理论基础后训练目标，该方法在实验中优于大多数基线。


<details>
  <summary>Details</summary>
Motivation: 视频质量评估（VQA）正在从单一数字的平均意见得分发展到更丰富、多方面的视频内容评估。因此，需要更丰富的数据集和方法来利用多维度标注。

Method: 1. 数据集创建：UltraVQA，一个大规模多维度VQA数据集，用于用户生成内容（UGC），包含五个关键质量维度（运动质量、运动幅度、美学质量、内容质量和清晰度质量）的标注。每个视频由超过3个人类评估员进行评分，并附有细粒度的子属性标签和基于集体人类判断生成的GPT解释性理由。
2. 提出方法：分析分数优化（ASO），这是一种为多维度VQA导出的理论基础后训练目标。它将质量评估重新定义为正则化决策过程，获得了自然捕获人类评分序数性质的闭合形式解，确保与人类排名偏好对齐。

Result: 所提出的ASO方法优于大多数基线，包括闭源API和开源模型。它还降低了质量预测中的平均绝对误差（MAE）。

Conclusion: 多维度、可解释的标注和基于强化的对齐对于推动视频质量评估至关重要。

Abstract: Video Quality Assessment (VQA) is evolving beyond single-number mean opinion score toward richer, multi-faceted evaluations of video content. In this paper, we present a large-scale multi-dimensional VQA dataset UltraVQA that encompasses diverse User-Generated Content~(UGC) annotated across five key quality dimensions: Motion Quality, Motion Amplitude, Aesthetic Quality, Content Quality, and Clarity Quality. Each video in our dataset is scored by over 3 human raters on these dimensions, with fine-grained sub-attribute labels, and accompanied by an explanatory rationale generated by GPT based on the collective human judgments. To better leverage these rich annotations and improve discrete quality score assessment, we introduce Analytic Score Optimization (ASO), a theoretically grounded post-training objective derived for multi-dimensional VQA. By reframing quality assessment as a regularized decision-making process, we obtain a closed-form solution that naturally captures the ordinal nature of human ratings, ensuring alignment with human ranking preferences. In experiments, our method outperforms most baselines including closed-source APIs and open-source models, while also reducing mean absolute error (MAE) in quality prediction. Our work highlights the importance of multi-dimensional, interpretable annotations and reinforcement-based alignment in advancing video quality assessment.

</details>


### [6] [DODO: Discrete OCR Diffusion Models](https://arxiv.org/abs/2602.16872)
*Sean Man,Roy Ganz,Roi Ronen,Shahar Tsiper,Shai Mazor,Niv Nayman*

Main category: cs.CV

TL;DR: 当前VLM在OCR中依赖自回归解码，效率低。DODO引入块离散扩散模型，实现并行解码，显著提高OCR速度并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 光学字符识别（OCR）是数字化信息的关键任务，但现代视觉语言模型（VLM）在处理长文档时，其自回归解码方式计算成本高且速度慢。尽管OCR的确定性特征理论上允许通过扩散模型进行高效并行解码，但现有掩码扩散模型存在结构不稳定性，不适用于OCR的严格匹配要求。

Method: 提出DODO，这是首个利用块离散扩散（block discrete diffusion）的VLM，旨在解决OCR任务的同步错误。它通过将生成分解为块来缓解全局扩散的同步错误。

Result: DODO在OCR任务中实现了接近最先进的准确性，并将推理速度比自回归基线提高了3倍。

Conclusion: DODO成功地将块离散扩散应用于OCR，解决了现有方法的效率瓶颈，在保持高准确性的同时显著提升了推理速度，从而释放了并行解码在确定性OCR任务中的潜力。

Abstract: Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge between visual data and textual understanding. While modern Vision-Language Models (VLM) have achieved high accuracy in this domain, they predominantly rely on autoregressive decoding, which becomes computationally expensive and slow for long documents as it requires a sequential forward pass for every generated token. We identify a key opportunity to overcome this bottleneck: unlike open-ended generation, OCR is a highly deterministic task where the visual input strictly dictates a unique output sequence, theoretically enabling efficient, parallel decoding via diffusion models. However, we show that existing masked diffusion models fail to harness this potential; those introduce structural instabilities that are benign in flexible tasks, like captioning, but catastrophic for the rigid, exact-match requirements of OCR. To bridge this gap, we introduce DODO, the first VLM to utilize block discrete diffusion and unlock its speedup potential for OCR. By decomposing generation into blocks, DODO mitigates the synchronization errors of global diffusion. Empirically, our method achieves near state-of-the-art accuracy while enabling up to 3x faster inference compared to autoregressive baselines.

</details>


### [7] [StereoAdapter-2: Globally Structure-Consistent Underwater Stereo Depth Estimation](https://arxiv.org/abs/2602.16915)
*Zeyu Ren,Xiang Li,Yiran Wang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出了StereoAdapter-2，通过引入基于选择性状态空间模型的ConvSS2D算子替代传统的ConvGRU，以实现水下立体深度估计中高效的长距离视差传播。结合大规模合成数据集UW-StereoDepth-80K和动态LoRA自适应，该方法在水下基准测试中达到了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 水下立体深度估计受波长依赖的光衰减、散射和折射引起的严重领域偏移影响。现有的基于GRU的迭代细化方法在长距离视差传播方面效率低下，尤其是在大视差和无纹理的水下区域，需要多次迭代。

Method: StereoAdapter-2用基于选择性状态空间模型的新型ConvSS2D算子取代了传统的ConvGRU更新器。该算子采用四向扫描策略，与极线几何对齐，同时捕获垂直结构一致性，从而在一个更新步骤内实现高效的长距离空间传播，计算复杂度为线性。此外，构建了大规模合成水下立体数据集UW-StereoDepth-80K，并结合了从StereoAdapter继承的动态LoRA自适应。

Result: 该框架在水下基准测试中实现了最先进的零样本性能，在TartanAir-UW上提高了17%，在SQUID上提高了7.2%。并通过BlueROV2平台上的真实世界验证证明了其鲁棒性。

Conclusion: StereoAdapter-2通过创新的ConvSS2D算子和大规模数据集，显著提升了水下立体深度估计的性能和效率，有效解决了长距离视差传播的挑战，并展现出强大的泛化能力和鲁棒性。

Abstract: Stereo depth estimation is fundamental to underwater robotic perception, yet suffers from severe domain shifts caused by wavelength-dependent light attenuation, scattering, and refraction. Recent approaches leverage monocular foundation models with GRU-based iterative refinement for underwater adaptation; however, the sequential gating and local convolutional kernels in GRUs necessitate multiple iterations for long-range disparity propagation, limiting performance in large-disparity and textureless underwater regions. In this paper, we propose StereoAdapter-2, which replaces the conventional ConvGRU updater with a novel ConvSS2D operator based on selective state space models. The proposed operator employs a four-directional scanning strategy that naturally aligns with epipolar geometry while capturing vertical structural consistency, enabling efficient long-range spatial propagation within a single update step at linear computational complexity. Furthermore, we construct UW-StereoDepth-80K, a large-scale synthetic underwater stereo dataset featuring diverse baselines, attenuation coefficients, and scattering parameters through a two-stage generative pipeline combining semantic-aware style transfer and geometry-consistent novel view synthesis. Combined with dynamic LoRA adaptation inherited from StereoAdapter, our framework achieves state-of-the-art zero-shot performance on underwater benchmarks with 17% improvement on TartanAir-UW and 7.2% improvment on SQUID, with real-world validation on the BlueROV2 platform demonstrates the robustness of our approach. Code: . Website: .

</details>


### [8] [Xray-Visual Models: Scaling Vision models on Industry Scale Data](https://arxiv.org/abs/2602.16918)
*Shlok Mishra,Tsung-Yu Lin,Linda Wang,Hongli Xu,Yimin Liu,Michael Hsu,Chaitanya Ahuja,Hao Yuan,Jianpeng Cheng,Hong-You Chen,Haoyuan Xu,Chao Li,Abhijeet Awasthi,Jihye Moon,Don Husa,Michael Ge,Sumedha Singla,Arkabandhu Chowdhury,Phong Dingh,Satya Narayan Shukla,Yonghuan Yang,David Jacobs,Qi Guo,Jun Xiao,Xiangjun Fan,Aashu Singh*

Main category: cs.CV

TL;DR: Xray-Visual是一个统一的视觉模型，在海量社交媒体数据上进行训练，结合MAE、半监督和CLIP风格学习，通过EViT增强ViT，并在多个基准测试中达到SOTA性能，引入LLM2CLIP进一步提升检索和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 需要一个统一的视觉模型架构，用于大规模图像和视频理解，并能有效利用工业级社交媒体数据。

Method: Xray-Visual是一个统一的视觉模型架构，利用Facebook和Instagram上超过150亿的图像-文本对和100亿的视频-标签对进行训练。数据处理包括平衡和噪声抑制策略。训练采用三阶段流水线：自监督MAE、半监督标签分类和CLIP风格的对比学习。模型基于Vision Transformer主干，通过高效的令牌重组（EViT）增强计算效率。此外，还集成了大型语言模型作为文本编码器（LLM2CLIP）以提升检索性能。

Result: Xray-Visual在ImageNet（图像分类）、Kinetics和HMDB51（视频理解）以及MSCOCO（跨模态检索）等多个基准测试中取得了最先进的性能。模型对领域偏移和对抗性扰动表现出强大的鲁棒性。通过将大型语言模型作为文本编码器（LLM2CLIP）集成，显著增强了检索性能和泛化能力，尤其是在真实世界环境中。

Conclusion: Xray-Visual为可扩展多模态视觉模型树立了新基准，同时保持了卓越的准确性和计算效率。

Abstract: We present Xray-Visual, a unified vision model architecture for large-scale image and video understanding trained on industry-scale social media data. Our model leverages over 15 billion curated image-text pairs and 10 billion video-hashtag pairs from Facebook and Instagram, employing robust data curation pipelines that incorporate balancing and noise suppression strategies to maximize semantic diversity while minimizing label noise. We introduce a three-stage training pipeline that combines self-supervised MAE, semi-supervised hashtag classification, and CLIP-style contrastive learning to jointly optimize image and video modalities. Our architecture builds on a Vision Transformer backbone enhanced with efficient token reorganization (EViT) for improved computational efficiency. Extensive experiments demonstrate that Xray-Visual achieves state-of-the-art performance across diverse benchmarks, including ImageNet for image classification, Kinetics and HMDB51 for video understanding, and MSCOCO for cross-modal retrieval. The model exhibits strong robustness to domain shift and adversarial perturbations. We further demonstrate that integrating large language models as text encoders (LLM2CLIP) significantly enhances retrieval performance and generalization capabilities, particularly in real-world environments. Xray-Visual establishes new benchmarks for scalable, multimodal vision models, while maintaining superior accuracy and computational efficiency.

</details>


### [9] [HS-3D-NeRF: 3D Surface and Hyperspectral Reconstruction From Stationary Hyperspectral Images Using Multi-Channel NeRFs](https://arxiv.org/abs/2602.16950)
*Kibon Ku,Talukder Z. Jubery,Adarsh Krishnamurthy,Baskar Ganapathysubramanian*

Main category: cs.CV

TL;DR: 本文提出了一种名为HSI-SC-NeRF的固定相机多通道神经辐射场（NeRF）框架，用于高通量高光谱3D重建农产品，以克服现有方法在集成高光谱成像和3D数据方面的局限性，并在实验中展现出高精度和光谱保真度。


<details>
  <summary>Details</summary>
Motivation: 将高光谱成像（HSI）和3D几何数据大规模集成仍然具有挑战性，因为传统方法涉及复杂的硬件设置，不兼容自动化表型系统。最近的神经辐射场（NeRF）技术提供了计算高效的3D重建，但通常需要移动相机设置，这限制了标准室内农业环境中的吞吐量和可重复性。

Method: 本文提出了HSI-SC-NeRF，一个用于高通量高光谱3D重建的固定相机多通道NeRF框架。该方法通过一个定制的特氟龙成像腔，在物体旋转时使用固定相机捕捉多视角高光谱数据，提供漫射均匀照明。物体姿态通过ArUco校准标记估计，并通过模拟姿态变换转换到相机坐标系。多通道NeRF公式使用复合光谱损失联合优化所有高光谱波段的重建，并采用两阶段训练协议，将几何初始化与辐射校正解耦。

Result: 在三种农产品样本上的实验表明，该方法在可见光和近红外光谱范围内具有高空间重建精度和强大的光谱保真度。

Conclusion: HSI-SC-NeRF在可见光和近红外光谱范围内实现了高空间重建精度和强大的光谱保真度，证明了其适用于集成到自动化农业工作流程中。

Abstract: Advances in hyperspectral imaging (HSI) and 3D reconstruction have enabled accurate, high-throughput characterization of agricultural produce quality and plant phenotypes, both essential for advancing agricultural sustainability and breeding programs. HSI captures detailed biochemical features of produce, while 3D geometric data substantially improves morphological analysis. However, integrating these two modalities at scale remains challenging, as conventional approaches involve complex hardware setups incompatible with automated phenotyping systems. Recent advances in neural radiance fields (NeRF) offer computationally efficient 3D reconstruction but typically require moving-camera setups, limiting throughput and reproducibility in standard indoor agricultural environments. To address these challenges, we introduce HSI-SC-NeRF, a stationary-camera multi-channel NeRF framework for high-throughput hyperspectral 3D reconstruction targeting postharvest inspection of agricultural produce. Multi-view hyperspectral data is captured using a stationary camera while the object rotates within a custom-built Teflon imaging chamber providing diffuse, uniform illumination. Object poses are estimated via ArUco calibration markers and transformed to the camera frame of reference through simulated pose transformations, enabling standard NeRF training on stationary-camera data. A multi-channel NeRF formulation optimizes reconstruction across all hyperspectral bands jointly using a composite spectral loss, supported by a two-stage training protocol that decouples geometric initialization from radiometric refinement. Experiments on three agricultural produce samples demonstrate high spatial reconstruction accuracy and strong spectral fidelity across the visible and near-infrared spectrum, confirming the suitability of HSI-SC-NeRF for integration into automated agricultural workflows.

</details>


### [10] [DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.16968)
*Dahye Kim,Deepti Ghadiyaram,Raghudeep Gadde*

Main category: cs.CV

TL;DR: 扩散Transformer（DiTs）在图像和视频生成中表现出色但计算成本高昂，原因是固定的分词过程。本文提出了一种动态分词策略，根据内容复杂度和去噪时间步动态调整补丁大小，从而显著提高了推理速度，同时保持了生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer（DiTs）在图像和视频生成中取得了最先进的性能，但由于固定的分词过程，即在整个去噪阶段使用恒定大小的补丁，导致计算成本过高。

Method: 提出了一种动态分词（dynamic tokenization）策略。这是一种高效的测试时间策略，根据内容复杂度和去噪时间步动态调整补丁大小。核心思想是，早期时间步只需要粗糙的补丁来建模全局结构，而后续迭代需要更精细（更小）的补丁来细化局部细节。在推理过程中，该方法动态地重新分配去噪步骤中的补丁大小。

Result: 该方法在 和 Wan 2.1 上分别实现了高达 3.52 倍和 3.2 倍的加速，同时没有损害生成质量和提示依从性。

Conclusion: 动态分词策略通过根据内容复杂度和去噪时间步动态调整补丁大小，有效降低了扩散Transformer的计算成本，显著提升了推理速度，同时保持了感知生成质量。

Abstract: Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to $3.52\times$ and $3.2\times$ speedup on and Wan $2.1$, respectively, without compromising the generation quality and prompt adherence.

</details>


### [11] [Characterizing the Predictive Impact of Modalities with Supervised Latent-Variable Modeling](https://arxiv.org/abs/2602.16979)
*Divyam Madaan,Sumit Chopra,Kyunghyun Cho*

Main category: cs.CV

TL;DR: PRIMO是一种有监督的潜在变量插补模型，用于处理多模态大语言模型（MLLMs）中缺失模态的问题。它在训练和推理过程中处理不完整数据，实现了与基线相当的性能，并量化了缺失模态的预测影响。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）取得了成功，但现有方法大多假设训练和推理过程中模态是完整的。然而，在实际应用中，由于模态缺失、异步收集或仅适用于部分样本，多模态数据常常是不完整的。

Method: 本文提出了PRIMO模型，它通过一个潜在变量来建模缺失的模态，该变量捕获了缺失模态与观测模态在预测上下文中的关系。PRIMO能够利用所有可用的训练样本，无论是模态完整还是部分缺失。在推理过程中，模型从学习到的缺失模态分布中抽取多个样本，以获取边际预测分布并分析缺失模态对每个实例预测的影响。它使用从潜在补全预测中计算出的基于方差的指标，在实例级别量化模态的预测影响。

Result: PRIMO在合成XOR数据集、Audio-Vision MNIST和MIMIC-III数据集上进行了评估。在所有数据集上，当模态完全缺失时，PRIMO的性能与单模态基线相当；当所有模态都可用时，其性能与多模态基线相当。PRIMO使用从潜在补全预测中计算出的基于方差的指标，量化了模态在实例级别的预测影响。研究还通过可视化展示了缺失模态的不同补全如何导致一组合理的标签。

Conclusion: PRIMO模型有效地解决了多模态大语言模型中模态缺失的问题，在保持性能的同时，还提供了一种量化和可视化缺失数据对预测影响的方法。

Abstract: Despite the recent success of Multimodal Large Language Models (MLLMs), existing approaches predominantly assume the availability of multiple modalities during training and inference. In practice, multimodal data is often incomplete because modalities may be missing, collected asynchronously, or available only for a subset of examples. In this work, we propose PRIMO, a supervised latent-variable imputation model that quantifies the predictive impact of any missing modality within the multimodal learning setting. PRIMO enables the use of all available training examples, whether modalities are complete or partial. Specifically, it models the missing modality through a latent variable that captures its relationship with the observed modality in the context of prediction. During inference, we draw many samples from the learned distribution over the missing modality to both obtain the marginal predictive distribution (for the purpose of prediction) and analyze the impact of the missing modalities on the prediction for each instance. We evaluate PRIMO on a synthetic XOR dataset, Audio-Vision MNIST, and MIMIC-III for mortality and ICD-9 prediction. Across all datasets, PRIMO obtains performance comparable to unimodal baselines when a modality is fully missing and to multimodal baselines when all modalities are available. PRIMO quantifies the predictive impact of a modality at the instance level using a variance-based metric computed from predictions across latent completions. We visually demonstrate how varying completions of the missing modality result in a set of plausible labels.

</details>


### [12] [PartRAG: Retrieval-Augmented Part-Level 3D Generation and Editing](https://arxiv.org/abs/2602.17033)
*Peize Li,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: PartRAG是一个检索增强的扩散框架，用于单幅图像的3D部分级结构生成。它通过分层对比检索模块整合外部零件数据库以解决零件几何多样性问题，并通过掩码部分级编辑器实现精确的局部编辑，从而在Objave等数据集上取得了有竞争力的结果并支持交互式编辑。


<details>
  <summary>Details</summary>
Motivation: 单幅图像的3D部分级生成面临挑战：学习到的先验难以覆盖零件几何形状的长尾分布并保持多视图一致性；现有系统对精确的局部编辑支持有限。

Method: 本文提出了PartRAG，一个将外部零件数据库与扩散转换器相结合的检索增强框架。为解决第一个挑战，引入了分层对比检索模块，该模块在零件和对象粒度上将密集图像块与3D零件潜在空间对齐，从包含1,236个带零件注释的资产库中检索，将多样化、物理上合理的样本注入去噪过程。为解决第二个挑战，添加了一个在共享规范空间中操作的掩码部分级编辑器，允许进行交换、属性细化和组合更新，而无需重新生成整个对象，同时保留非目标零件和多视图一致性。

Result: PartRAG在Objaverse、ShapeNet和ABO数据集上取得了有竞争力的结果。在Objaverse上，Chamfer距离从0.1726降低到0.1528，F-Score从0.7472提高到0.844。推理时间为38秒，交互式编辑可在5-8秒内完成。定性上，PartRAG生成更清晰的零件边界、更好的薄结构保真度，并对铰接对象表现出鲁棒性。

Conclusion: PartRAG通过结合检索增强生成和部分级编辑，有效解决了单幅图像3D生成中零件几何多样性和局部编辑的挑战，从而在定量和定性上都取得了改进的结果，并提供了高效的编辑能力。

Abstract: Single-image 3D generation with part-level structure remains challenging: learned priors struggle to cover the long tail of part geometries and maintain multi-view consistency, and existing systems provide limited support for precise, localized edits. We present PartRAG, a retrieval-augmented framework that integrates an external part database with a diffusion transformer to couple generation with an editable representation. To overcome the first challenge, we introduce a Hierarchical Contrastive Retrieval module that aligns dense image patches with 3D part latents at both part and object granularity, retrieving from a curated bank of 1,236 part-annotated assets to inject diverse, physically plausible exemplars into denoising. To overcome the second challenge, we add a masked, part-level editor that operates in a shared canonical space, enabling swaps, attribute refinements, and compositional updates without regenerating the whole object while preserving non-target parts and multi-view consistency. PartRAG achieves competitive results on Objaverse, ShapeNet, and ABO-reducing Chamfer Distance from 0.1726 to 0.1528 and raising F-Score from 0.7472 to 0.844 on Objaverse-with inference of 38s and interactive edits in 5-8s. Qualitatively, PartRAG produces sharper part boundaries, better thin-structure fidelity, and robust behavior on articulated objects. Code: . Website: .

</details>


### [13] [Amber-Image: Efficient Compression of Large-Scale Diffusion Transformers](https://arxiv.org/abs/2602.17047)
*Chaojie Yang,Tian Li,Yue Zhang,Jun Gao*

Main category: cs.CV

TL;DR: 本文提出了一种高效压缩框架，将大型扩散Transformer（DiT）模型Qwen-Image转换为轻量级Text-to-Image（T2I）模型Amber-Image系列，通过时间步敏感深度剪枝、混合流架构、层级蒸馏和微调，实现了70%的参数缩减，显著降低了计算成本和部署门槛，同时保持了高保真合成和卓越的文本渲染能力。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer（DiT）架构在Text-to-Image（T2I）生成方面取得了显著进展，但其计算成本过高且存在部署障碍。

Method: 本研究提出一个高效压缩框架，将60层双流MMDiT-based Qwen-Image转换为轻量级模型。首先，通过时间步敏感的深度剪枝策略得到Amber-Image-10B，其中保留层通过局部权重平均重新初始化，并通过层级蒸馏和全参数微调进行优化。在此基础上，通过引入混合流架构，将深层双流转换为从图像分支初始化的单流，并通过渐进式蒸馏和轻量级微调进一步完善，开发出Amber-Image-6B。

Result: 该方法将参数减少了70%，并消除了对大规模数据工程的需求。整个压缩和训练流程（从10B到6B变体）所需的GPU小时数少于2,000，与从头开始训练相比，显示出卓越的成本效率。在DPG-Bench和LongText-Bench等基准测试中，Amber-Image实现了高保真合成和卓越的文本渲染，与大得多的模型相媲美。

Conclusion: Amber-Image系列模型通过高效的压缩框架，成功解决了DiT架构在T2I生成中的计算成本和部署障碍问题，在显著降低模型规模和训练成本的同时，保持了与大型模型相当的性能。

Abstract: Diffusion Transformer (DiT) architectures have significantly advanced Text-to-Image (T2I) generation but suffer from prohibitive computational costs and deployment barriers. To address these challenges, we propose an efficient compression framework that transforms the 60-layer dual-stream MMDiT-based Qwen-Image into lightweight models without training from scratch. Leveraging this framework, we introduce Amber-Image, a series of streamlined T2I models. We first derive Amber-Image-10B using a timestep-sensitive depth pruning strategy, where retained layers are reinitialized via local weight averaging and optimized through layer-wise distillation and full-parameter fine-tuning. Building on this, we develop Amber-Image-6B by introducing a hybrid-stream architecture that converts deep-layer dual streams into a single stream initialized from the image branch, further refined via progressive distillation and lightweight fine-tuning. Our approach reduces parameters by 70% and eliminates the need for large-scale data engineering. Notably, the entire compression and training pipeline-from the 10B to the 6B variant-requires fewer than 2,000 GPU hours, demonstrating exceptional cost-efficiency compared to training from scratch. Extensive evaluations on benchmarks like DPG-Bench and LongText-Bench show that Amber-Image achieves high-fidelity synthesis and superior text rendering, matching much larger models.

</details>


### [14] [StructCore: Structure-Aware Image-Level Scoring for Training-Free Unsupervised Anomaly Detection](https://arxiv.org/abs/2602.17048)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: StructCore是一种无需训练、结构感知的图像级评分方法，通过捕获分布和空间特征并使用对角马哈拉诺比斯校准来改进图像级异常检测，优于最大池化，并在MVTec AD和VisA上实现了高AUROC分数。


<details>
  <summary>Details</summary>
Motivation: 现有的最大池化方法在将异常分数图转换为图像级决策时，由于仅依赖单一极端响应，会丢失异常证据的分布和结构信息，导致正常和异常分数重叠。

Method: 提出StructCore方法。该方法无需训练，接收异常分数图后，计算一个低维结构描述符phi(S)以捕获分布和空间特征。然后，通过从训练良好样本估计的对角马哈拉诺比斯校准来优化图像级评分，且不修改像素级定位。

Result: StructCore在MVTec AD数据集上实现了99.6%的图像级AUROC分数，在VisA数据集上实现了98.4%的图像级AUROC分数，表明它通过利用最大池化忽略的结构特征实现了鲁棒的图像级异常检测。

Conclusion: StructCore通过利用传统最大池化方法所忽略的结构特征，显著提升了图像级异常检测的鲁棒性和准确性。

Abstract: Max pooling is the de facto standard for converting anomaly score maps into image-level decisions in memory-bank-based unsupervised anomaly detection (UAD). However, because it relies on a single extreme response, it discards most information about how anomaly evidence is distributed and structured across the image, often causing normal and anomalous scores to overlap. We propose StructCore, a training-free, structure-aware image-level scoring method that goes beyond max pooling. Given an anomaly score map, StructCore computes a low-dimensional structural descriptor phi(S) that captures distributional and spatial characteristics, and refines image-level scoring via a diagonal Mahalanobis calibration estimated from train-good samples, without modifying pixel-level localization. StructCore achieves image-level AUROC scores of 99.6% on MVTec AD and 98.4% on VisA, demonstrating robust image-level anomaly detection by exploiting structural signatures missed by max pooling.

</details>


### [15] [Cholec80-port: A Geometrically Consistent Trocar Port Segmentation Dataset for Robust Surgical Scene Understanding](https://arxiv.org/abs/2602.17060)
*Shunsuke Kikuchi,Atsushi Kouno,Hiroki Matsuzaki*

Main category: cs.CV

TL;DR: 本研究提出了Ch_olec80-port数据集和几何一致的套管针端口分割SOP，以解决腹腔镜视觉任务中端口造成的几何管道问题，并通过实验证明了其在提高跨数据集鲁棒性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 套管针端口在腹腔镜视图中会持续遮挡，并因其镜面和纹理表面而吸引过多的特征点，这严重影响了图像拼接、3D重建和视觉SLAM等基于几何的下游管道，导致对齐和跟踪稳定性下降。公共外科数据集中缺乏明确的端口标签，且现有注释常常通过遮蔽中心腔体而违反几何一致性，即便解剖区域透过腔体可见。

Method: 研究人员创建了Ch_olec80-port，这是一个高保真套管针端口分割数据集，源自Ch_olec80。同时，他们定义了一个严格的标准操作程序（SOP），用于生成不包含中心开口的端口套管掩模。此外，他们还根据相同的SOP清理并统一了现有的公共数据集。

Result: 实验证明，几何一致的注释显著提高了跨数据集的鲁棒性，其改进程度超越了单纯增加数据集大小所能带来的效果。

Conclusion: 在腹腔镜手术视觉任务中，几何一致的套管针端口分割注释对于提高跨数据集的鲁棒性至关重要。

Abstract: Trocar ports are camera-fixed, pseudo-static structures that can persistently occlude laparoscopic views and attract disproportionate feature points due to specular, textured surfaces. This makes ports particularly detrimental to geometry-based downstream pipelines such as image stitching, 3D reconstruction, and visual SLAM, where dynamic or non-anatomical outliers degrade alignment and tracking stability. Despite this practical importance, explicit port labels are rare in public surgical datasets, and existing annotations often violate geometric consistency by masking the central lumen (opening), even when anatomical regions are visible through it. We present Cholec80-port, a high-fidelity trocar port segmentation dataset derived from Cholec80, together with a rigorous standard operating procedure (SOP) that defines a port-sleeve mask excluding the central opening. We additionally cleanse and unify existing public datasets under the same SOP. Experiments demonstrate that geometrically consistent annotations substantially improve cross-dataset robustness beyond what dataset size alone provides.

</details>


### [16] [Cross Pseudo Labeling For Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2602.17077)
*Lee Dayeon,Kim Dongheyong,Park Chaewon,Woo Sungmin,Lee Sangyoun*

Main category: cs.CV

TL;DR: CPL-VAD提出了一种带有交叉伪标签的双分支框架，用于弱监督视频异常检测，通过结合时间精度和语义区分，实现了最先进的异常检测和异常类别分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督视频异常检测方法需要同时检测异常并识别异常类别，且仅依赖视频级标签。该方法旨在解决视频异常检测中的时间定位精度和语义识别能力问题。

Method: CPL-VAD是一个带有交叉伪标签的双分支框架。一个分支负责片段级异常定位（二值异常检测），另一个分支利用视觉-语言对齐识别异常事件类别（类别分类）。两个分支通过交换伪标签来传递互补优势。

Result: 在XD-Violence和UCF-Crime数据集上的实验表明，CPL-VAD在异常检测和异常类别分类方面均达到了最先进的性能。

Conclusion: CPL-VAD通过结合时间精度和语义区分，在弱监督视频异常检测中取得了最先进的性能，特别是在异常检测和异常类别分类方面。

Abstract: Weakly supervised video anomaly detection aims to detect anomalies and identify abnormal categories with only video-level labels. We propose CPL-VAD, a dual-branch framework with cross pseudo labeling. The binary anomaly detection branch focuses on snippet-level anomaly localization, while the category classification branch leverages vision-language alignment to recognize abnormal event categories. By exchanging pseudo labels, the two branches transfer complementary strengths, combining temporal precision with semantic discrimination. Experiments on XD-Violence and UCF-Crime demonstrate that CPL-VAD achieves state-of-the-art performance in both anomaly detection and abnormal category classification.

</details>


### [17] [ComptonUNet: A Deep Learning Model for GRB Localization with Compton Cameras under Noisy and Low-Statistic Conditions](https://arxiv.org/abs/2602.17085)
*Shogo Sato,Kazuo Tanaka,Shojun Ogasawara,Kazuki Yamamoto,Kazuhiko Murasaki,Ryuichi Tanida,Jun Kataoka*

Main category: cs.CV

TL;DR: ComptonUNet是一个混合深度学习框架，用于在低光子统计和强背景噪声条件下，实现微弱伽马射线暴的鲁棒定位，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 微弱的伽马射线暴（GRBs）可能为早期恒星形成提供独特见解，但由于光子统计量低和背景噪声大，检测和定位这些微弱源极具挑战性。现有机器学习模型难以平衡统计鲁棒性和噪声抑制。

Method: ComptonUNet是一个混合深度学习框架，它结合了直接重建模型的统计效率和基于图像架构的去噪能力，共同处理原始数据并重建图像。该模型旨在有限光子统计和强背景污染条件下有效运行，并通过模拟伽马射线暴事件在低地球轨道任务背景环境中进行性能评估。

Result: ComptonUNet在各种低统计量和高背景场景下，其定位精度显著优于现有方法。

Conclusion: ComptonUNet显著优于现有方法，在低统计量和高背景噪声场景下均能提高定位精度。这表明ComptonUNet为微弱伽马射线暴的鲁棒定位提供了一种有效方案，有助于深入理解早期恒星形成。

Abstract: Gamma-ray bursts (GRBs) are among the most energetic transient phenomena in the universe and serve as powerful probes for high-energy astrophysical processes. In particular, faint GRBs originating from a distant universe may provide unique insights into the early stages of star formation. However, detecting and localizing such weak sources remains challenging owing to low photon statistics and substantial background noise. Although recent machine learning models address individual aspects of these challenges, they often struggle to balance the trade-off between statistical robustness and noise suppression. Consequently, we propose ComptonUNet, a hybrid deep learning framework that jointly processes raw data and reconstructs images for robust GRB localization. ComptonUNet was designed to operate effectively under conditions of limited photon statistics and strong background contamination by combining the statistical efficiency of direct reconstruction models with the denoising capabilities of image-based architectures. We perform realistic simulations of GRB-like events embedded in background environments representative of low-Earth orbit missions to evaluate the performance of ComptonUNet. Our results demonstrate that ComptonUNet significantly outperforms existing approaches, achieving improved localization accuracy across a wide range of low-statistic and high-background scenarios.

</details>


### [18] [B$^3$-Seg: Camera-Free, Training-Free 3DGS Segmentation via Analytic EIG and Beta-Bernoulli Bayesian Updates](https://arxiv.org/abs/2602.17134)
*Hiromichi Kamata,Samuel Arthur Munro,Fuminori Homma*

Main category: cs.CV

TL;DR: B$^3$-Seg是一种快速、理论性强的开放词汇3DGS分割方法，它在无相机和免训练条件下，通过序列Beta-Bernoulli贝叶斯更新和基于预期信息增益的主动视图选择，实现了与高成本监督方法相当的性能，并在几秒内完成端到端分割，适用于实时交互式编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式3D高斯飞溅（3DGS）分割方法依赖于预定义相机视角、真实标签或高成本的再训练，这使得它们在电影和游戏制作中对低延迟实时编辑的应用不切实际。

Method: 本文提出B$^3$-Seg，一种将分割重构为序列Beta-Bernoulli贝叶斯更新的方法。它通过分析预期信息增益（EIG）主动选择下一个视图。这种贝叶斯公式保证了EIG的自适应单调性和次模性，从而为最优视图采样策略提供了贪婪的$(1{-}1/e)$近似。

Result: 在多个数据集上的实验表明，B$^3$-Seg在几秒钟内完成了端到端分割，并取得了与高成本监督方法相当的竞争性结果。

Conclusion: 实验结果表明，B$^3$-Seg能够实现实用、交互式的3DGS分割，并具有可证明的信息效率。

Abstract: Interactive 3D Gaussian Splatting (3DGS) segmentation is essential for real-time editing of pre-reconstructed assets in film and game production. However, existing methods rely on predefined camera viewpoints, ground-truth labels, or costly retraining, making them impractical for low-latency use. We propose B$^3$-Seg (Beta-Bernoulli Bayesian Segmentation for 3DGS), a fast and theoretically grounded method for open-vocabulary 3DGS segmentation under camera-free and training-free conditions. Our approach reformulates segmentation as sequential Beta-Bernoulli Bayesian updates and actively selects the next view via analytic Expected Information Gain (EIG). This Bayesian formulation guarantees the adaptive monotonicity and submodularity of EIG, which produces a greedy $(1{-}1/e)$ approximation to the optimal view sampling policy. Experiments on multiple datasets show that B$^3$-Seg achieves competitive results to high-cost supervised methods while operating end-to-end segmentation within a few seconds. The results demonstrate that B$^3$-Seg enables practical, interactive 3DGS segmentation with provable information efficiency.

</details>


### [19] [BadCLIP++: Stealthy and Persistent Backdoors in Multimodal Contrastive Learning](https://arxiv.org/abs/2602.17168)
*Siyuan Liang,Yongcheng Jing,Yingjie Wang,Jiaxing Huang,Ee-chien Chang,Dacheng Tao*

Main category: cs.CV

TL;DR: BadCLIP++是一个统一框架，通过引入语义融合QR微触发器和稳定触发器嵌入与模型参数，解决了多模态对比学习模型后门攻击中的隐蔽性和持久性挑战，并在低中毒率下实现了高攻击成功率和对防御的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对多模态对比学习模型的后门攻击研究面临两个关键挑战：隐蔽性（stealthiness）和持久性（persistence）。现有方法在强检测或持续微调下常失败，主要原因包括：1) 暴露触发模式的跨模态不一致性；2) 低中毒率下加速后门遗忘的梯度稀释。这些相互关联的原因尚未得到充分建模和解决。

Method: BadCLIP++框架通过以下方式解决挑战：1. 隐蔽性：引入语义融合QR微触发器，在任务相关区域嵌入不可感知的模式，保持干净数据统计量，并生成紧凑的触发器分布；应用目标对齐子集选择以在低注入率下增强信号。2. 持久性：通过半径收缩和质心对齐稳定触发器嵌入；通过曲率控制和弹性权重整合稳定模型参数，使解决方案保持在低曲率宽域内以抵抗微调。该方法还首次提供了理论分析，表明在信任区域内，干净微调和后门目标的梯度是同向的，从而提供攻击成功率下降的非递增上限。

Result: 在数字环境中，仅使用0.3%的中毒率，BadCLIP++实现了99.99%的攻击成功率（ASR），超越基线11.4个百分点。在19种防御机制下，ASR仍保持在99.90%以上，干净准确率下降不到0.8%。该方法在物理攻击中也达到了65.03%的成功率，并对水印移除防御显示出鲁棒性。

Conclusion: BadCLIP++通过解决多模态对比学习模型后门攻击中的隐蔽性和持久性挑战，显著提高了攻击成功率，并在各种防御机制下保持了鲁棒性，同时对攻击成功率的衰减提供了理论分析。

Abstract: Research on backdoor attacks against multimodal contrastive learning models faces two key challenges: stealthiness and persistence. Existing methods often fail under strong detection or continuous fine-tuning, largely due to (1) cross-modal inconsistency that exposes trigger patterns and (2) gradient dilution at low poisoning rates that accelerates backdoor forgetting. These coupled causes remain insufficiently modeled and addressed. We propose BadCLIP++, a unified framework that tackles both challenges. For stealthiness, we introduce a semantic-fusion QR micro-trigger that embeds imperceptible patterns near task-relevant regions, preserving clean-data statistics while producing compact trigger distributions. We further apply target-aligned subset selection to strengthen signals at low injection rates. For persistence, we stabilize trigger embeddings via radius shrinkage and centroid alignment, and stabilize model parameters through curvature control and elastic weight consolidation, maintaining solutions within a low-curvature wide basin resistant to fine-tuning. We also provide the first theoretical analysis showing that, within a trust region, gradients from clean fine-tuning and backdoor objectives are co-directional, yielding a non-increasing upper bound on attack success degradation. Experiments demonstrate that with only 0.3% poisoning, BadCLIP++ achieves 99.99% attack success rate (ASR) in digital settings, surpassing baselines by 11.4 points. Across nineteen defenses, ASR remains above 99.90% with less than 0.8% drop in clean accuracy. The method further attains 65.03% success in physical attacks and shows robustness against watermark removal defenses.

</details>


### [20] [Selective Training for Large Vision Language Models via Visual Information Gain](https://arxiv.org/abs/2602.17186)
*Seulbi Lee,Sangheum Hwang*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLMs）存在语言偏差问题，即回答不依赖视觉证据。本文引入了视觉信息增益（VIG），这是一种基于困惑度的指标，用于量化视觉输入对预测不确定性的降低。VIG可以进行样本和token级别的细粒度分析。基于VIG，我们提出了一种VIG引导的选择性训练方案，优先处理高VIG的样本和token，从而在显著减少监督的情况下，通过专注于视觉信息丰富的样本和token来提高视觉基础能力并缓解语言偏差，实现卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）尽管取得了显著进展，但常常受到语言偏差的困扰，即在生成答案时不依赖视觉证据。现有工作试图通过解码策略、架构修改或精选指令数据来缓解此问题，但它们通常缺乏对单个训练样本或token从图像中实际受益程度的定量度量。

Method: 本文引入了视觉信息增益（VIG），这是一种基于困惑度的指标，用于衡量视觉输入提供的预测不确定性的降低。VIG支持在样本和token级别进行细粒度分析，有效突出视觉基础元素（如颜色、空间关系和属性）。利用VIG，我们提出了一种VIG引导的选择性训练方案，优先处理高VIG的样本和token。

Result: VIG引导的选择性训练方案提高了视觉基础能力并缓解了语言偏差。

Conclusion: 通过专注于视觉信息丰富的样本和token，该方法在显著减少监督的情况下实现了卓越的性能。

Abstract: Large Vision Language Models (LVLMs) have achieved remarkable progress, yet they often suffer from language bias, producing answers without relying on visual evidence. While prior work attempts to mitigate this issue through decoding strategies, architectural modifications, or curated instruction data, they typically lack a quantitative measure of how much individual training samples or tokens actually benefit from the image. In this work, we introduce Visual Information Gain (VIG), a perplexity-based metric that measures the reduction in prediction uncertainty provided by visual input. VIG enables fine-grained analysis at both sample and token levels, effectively highlighting visually grounded elements such as colors, spatial relations, and attributes. Leveraging this, we propose a VIG-guided selective training scheme that prioritizes high-VIG samples and tokens. This approach improves visual grounding and mitigates language bias, achieving superior performance with significantly reduced supervision by focusing exclusively on visually informative samples and tokens.

</details>


### [21] [EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models](https://arxiv.org/abs/2602.17196)
*Yahong Wang,Juncheng Wu,Zhangkai Ni,Chengmei Yang,Yihang Liu,Longzhen Yang,Yuyin Zhou,Ying Wen,Lianghua He*

Main category: cs.CV

TL;DR: 该论文提出EntropyPrune，一种矩阵熵引导的令牌剪枝框架，用于加速多模态大语言模型（MLLMs）的推理，通过识别“熵坍塌层”（ECL）提供了一种有原则的剪枝标准，并在准确性和效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）由于每张图像处理数百个视觉令牌而导致推理成本高昂。现有的令牌剪枝方法大多是启发式的，依赖于静态、经验选择的层，这限制了解释性和模型间的可迁移性。

Method: 引入了矩阵熵视角来识别“熵坍塌层”（ECL），在该层视觉表示的信息内容出现急剧且一致的下降，从而为选择剪枝阶段提供了原则性标准。在此观察基础上，提出了EntropyPrune，一种新型的矩阵熵引导令牌剪枝框架，该框架量化了单个视觉令牌的信息价值，并在不依赖注意力图的情况下剪枝冗余令牌。为了实现高效计算，利用了对偶Gram矩阵的谱等价性，降低了熵计算的复杂性，理论上实现了高达64倍的加速。

Result: 在各种多模态基准上的大量实验表明，EntropyPrune在准确性和效率方面均持续优于最先进的剪枝方法。在LLaVA-1.5-7B模型上，该方法实现了68.2%的FLOPs减少，同时保留了96.0%的原始性能。此外，EntropyPrune能够有效地泛化到高分辨率和基于视频的模型，突显了其在实际MLLM加速中的强大鲁棒性和可扩展性。

Conclusion: EntropyPrune通过基于信息熵高效剪枝视觉令牌，为加速MLLMs提供了一个有原则、鲁棒且可扩展的解决方案，与现有方法相比，显著提高了效率和准确性。

Abstract: Multimodal large language models (MLLMs) incur substantial inference cost due to the processing of hundreds of visual tokens per image. Although token pruning has proven effective for accelerating inference, determining when and where to prune remains largely heuristic. Existing approaches typically rely on static, empirically selected layers, which limit interpretability and transferability across models. In this work, we introduce a matrix-entropy perspective and identify an "Entropy Collapse Layer" (ECL), where the information content of visual representations exhibits a sharp and consistent drop, which provides a principled criterion for selecting the pruning stage. Building on this observation, we propose EntropyPrune, a novel matrix-entropy-guided token pruning framework that quantifies the information value of individual visual tokens and prunes redundant ones without relying on attention maps. Moreover, to enable efficient computation, we exploit the spectral equivalence of dual Gram matrices, reducing the complexity of entropy computation and yielding up to a 64x theoretical speedup. Extensive experiments on diverse multimodal benchmarks demonstrate that EntropyPrune consistently outperforms state-of-the-art pruning methods in both accuracy and efficiency. On LLaVA-1.5-7B, our method achieves a 68.2% reduction in FLOPs while preserving 96.0% of the original performance. Furthermore, EntropyPrune generalizes effectively to high-resolution and video-based models, highlighting the strong robustness and scalability in practical MLLM acceleration. The code will be publicly available at .

</details>


### [22] [A Multi-modal Detection System for Infrastructure-based Freight Signal Priority](https://arxiv.org/abs/2602.17252)
*Ziyan Zhang,Chuheng Wei,Xuanpeng Zhao,Siyan Li,Will Snyder,Mike Stas,Peng Hao,Kanok Boriboonsomsin,Guoyuan Wu*

Main category: cs.CV

TL;DR: 本文设计并评估了一个基于基础设施的多模态LiDAR-摄像头系统，用于在信号交叉口可靠地检测和估计货运车辆的运动，以支持货运信号优先（FSP）应用。


<details>
  <summary>Details</summary>
Motivation: 货运车辆在接近信号交叉口时，需要可靠的检测和运动估计来支持基于基础设施的货运信号优先（FSP）系统。准确及时地感知车辆类型、位置和速度对于实现有效的优先控制策略至关重要。

Method: 本文设计、部署并评估了一个基于基础设施的多模态货运车辆检测系统，该系统集成了LiDAR和摄像头传感器。系统采用混合传感架构，包括路口子系统和路段子系统，通过无线通信实现同步数据传输。感知管线结合了基于聚类和基于深度学习的检测方法，并采用卡尔曼滤波器进行跟踪，以实现稳定的实时性能。LiDAR测量数据被注册到大地参考系中，以支持车道级定位和一致的车辆跟踪。

Result: 现场评估表明，该系统能够以高时空分辨率可靠地监测货运车辆的运动。

Conclusion: 该设计和部署为开发支持FSP应用的基于基础设施的传感系统提供了实践经验。

Abstract: Freight vehicles approaching signalized intersections require reliable detection and motion estimation to support infrastructure-based Freight Signal Priority (FSP). Accurate and timely perception of vehicle type, position, and speed is essential for enabling effective priority control strategies. This paper presents the design, deployment, and evaluation of an infrastructure-based multi-modal freight vehicle detection system integrating LiDAR and camera sensors. A hybrid sensing architecture is adopted, consisting of an intersection-mounted subsystem and a midblock subsystem, connected via wireless communication for synchronized data transmission. The perception pipeline incorporates both clustering-based and deep learning-based detection methods with Kalman filter tracking to achieve stable real-time performance. LiDAR measurements are registered into geodetic reference frames to support lane-level localization and consistent vehicle tracking. Field evaluations demonstrate that the system can reliably monitor freight vehicle movements at high spatio-temporal resolution. The design and deployment provide practical insights for developing infrastructure-based sensing systems to support FSP applications.

</details>


### [23] [EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection](https://arxiv.org/abs/2602.17260)
*Hung Mai,Loi Dinh,Duc Hai Nguyen,Dat Do,Luong Doan,Khanh Nguyen Quoc,Huan Vu,Phong Ho,Naeem Ul Islam,Tuan Do*

Main category: cs.CV

TL;DR: EA-Swin是一种嵌入无关的Swin Transformer，通过因子化窗口注意力设计，直接在预训练视频嵌入上建模时空依赖性，以检测由Sora2、Veo3等生成的高度逼真的合成视频。该研究还构建了EA-Video数据集，并在主要生成器上取得了0.97-0.99的准确率，超越了现有SOTA方法，并具有强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法依赖浅层嵌入轨迹、基于图像的适应或计算量大的MLLM，在检测Sora2、Veo3等基础视频生成器产生的高度逼真合成视频时存在局限性。

Method: 提出了一种名为EA-Swin的嵌入无关Swin Transformer，它通过因子化窗口注意力设计直接在预训练视频嵌入上建模时空依赖性，使其与通用的ViT风格的基于patch的编码器兼容。此外，构建了EA-Video数据集，该数据集包含13万个视频，整合了新收集的样本和现有数据集，涵盖了各种商业和开源生成器，并包括用于严格跨分布评估的未见生成器划分。

Result: EA-Swin在主要生成器上实现了0.97-0.99的准确率，比之前的SoTA方法（通常为0.8-0.9）高出5-20%，同时对未见分布保持强大的泛化能力。

Conclusion: EA-Swin为现代AI生成视频检测提供了一个可扩展且稳健的解决方案，在准确性和泛化能力方面均表现出色。

Abstract: Recent advances in foundation video generators such as Sora2, Veo3, and other commercial systems have produced highly realistic synthetic videos, exposing the limitations of existing detection methods that rely on shallow embedding trajectories, image-based adaptation, or computationally heavy MLLMs. We propose EA-Swin, an Embedding-Agnostic Swin Transformer that models spatiotemporal dependencies directly on pretrained video embeddings via a factorized windowed attention design, making it compatible with generic ViT-style patch-based encoders. Alongside the model, we construct the EA-Video dataset, a benchmark dataset comprising 130K videos that integrates newly collected samples with curated existing datasets, covering diverse commercial and open-source generators and including unseen-generator splits for rigorous cross-distribution evaluation. Extensive experiments show that EA-Swin achieves 0.97-0.99 accuracy across major generators, outperforming prior SoTA methods (typically 0.8-0.9) by a margin of 5-20%, while maintaining strong generalization to unseen distributions, establishing a scalable and robust solution for modern AI-generated video detection.

</details>


### [24] [Attachment Anchors: A Novel Framework for Laparoscopic Grasping Point Prediction in Colorectal Surgery](https://arxiv.org/abs/2602.17310)
*Dennis N. Schneider,Lars Wagner,Daniel Rueckert,Dirk Wilhelm*

Main category: cs.CV

TL;DR: 该研究引入了“附着锚点”——一种编码结直肠手术中组织与其解剖附着点之间局部几何和机械关系的结构化表示，以提高自主组织操作中抓取点预测的准确性，尤其是在未见过的情况下。


<details>
  <summary>Details</summary>
Motivation: 在结直肠手术等复杂多变的微创手术中，准确的抓取点预测对于自主组织操作是一个关键挑战。结直肠手术因其复杂性和持续时间长，在现有研究中代表性不足，但其重复性的组织操作使其成为自主机器学习驱动支持的良好切入点。

Method: 引入了“附着锚点”（attachment anchors）作为一种结构化表示，编码组织与其解剖附着点在结直肠手术中的局部几何和机械关系。这种表示通过将手术场景归一化到一致的局部参考系中，减少了抓取点预测的不确定性。附着锚点可以从腹腔镜图像中预测，并整合到基于机器学习的抓取框架中。

Result: 在包含90例结直肠手术的数据集上的实验表明，与仅使用图像的基线相比，附着锚点显著改善了抓取点预测，尤其在包括未见过手术和外科医生在内的分布外设置中表现出强大的增益。

Conclusion: 附着锚点是结直肠手术中基于学习的组织操作的一种有效中间表示。

Abstract: Accurate grasping point prediction is a key challenge for autonomous tissue manipulation in minimally invasive surgery, particularly in complex and variable procedures such as colorectal interventions. Due to their complexity and prolonged duration, colorectal procedures have been underrepresented in current research. At the same time, they pose a particularly interesting learning environment due to repetitive tissue manipulation, making them a promising entry point for autonomous, machine learning-driven support. Therefore, in this work, we introduce attachment anchors, a structured representation that encodes the local geometric and mechanical relationships between tissue and its anatomical attachments in colorectal surgery. This representation reduces uncertainty in grasping point prediction by normalizing surgical scenes into a consistent local reference frame. We demonstrate that attachment anchors can be predicted from laparoscopic images and incorporated into a grasping framework based on machine learning. Experiments on a dataset of 90 colorectal surgeries demonstrate that attachment anchors improve grasping point prediction compared to image-only baselines. There are particularly strong gains in out-of-distribution settings, including unseen procedures and operating surgeons. These results suggest that attachment anchors are an effective intermediate representation for learning-based tissue manipulation in colorectal surgery.

</details>


### [25] [Polaffini: A feature-based approach for robust affine and polyaffine image registration](https://arxiv.org/abs/2602.17337)
*Antoine Legouhy,Cosimo Campo,Ross Callaghan,Hojjat Azadbakht,Hui Zhang*

Main category: cs.CV

TL;DR: Polaffini是一种稳健、多功能的医学图像解剖学配准框架，它利用深度学习分割模型进行基于特征的配准。与传统的基于强度的方法相比，Polaffini在结构对齐方面表现更优，并能为后续的非线性配准提供更好的初始化。


<details>
  <summary>Details</summary>
Motivation: 医学图像配准主要依赖于基于强度的方法，这些方法依赖于对齐质量的替代度量。理论上，基于特征的方法更理想，但因特征提取的可靠性挑战而未能广泛应用。然而，深度学习的最新进展克服了这些挑战，提供了能够可靠、精细解剖学描绘的预训练分割模型。本文旨在利用这些进展来创建新的基于解剖学的图像配准算法。

Method: 本文提出了Polaffini框架。它利用预训练的深度学习分割模型获取分割区域，并从这些区域中以特别简单的方式提取它们的质心，作为具有一对一对应关系的基于解剖学的特征点。这些特征点通过闭式解实现高效的全局和局部仿射匹配。这些匹配用于生成从仿射到具有可调平滑度的多仿射的整体变换。多仿射变换比仿射变换具有更多的自由度，可以在对数欧几里德框架中嵌入以确保微分同胚特性。

Result: Polaffini在结构对齐方面优于竞争的基于强度的方法。它为下游的非线性配准提供了改进的初始化。Polaffini快速、稳健、准确。

Conclusion: Polaffini是一款快速、稳健、准确的框架，特别适用于集成到医学图像处理流程中。它在结构对齐方面表现出色，并能为后续的非线性配准提供更好的初始化，证明了利用深度学习进展进行基于解剖学配准的有效性。

Abstract: In this work we present Polaffini, a robust and versatile framework for anatomically grounded registration. Medical image registration is dominated by intensity-based registration methods that rely on surrogate measures of alignment quality. In contrast, feature-based approaches that operate by identifying explicit anatomical correspondences, while more desirable in theory, have largely fallen out of favor due to the challenges of reliably extracting features. However, such challenges are now significantly overcome thanks to recent advances in deep learning, which provide pre-trained segmentation models capable of instantly delivering reliable, fine-grained anatomical delineations. We aim to demonstrate that these advances can be leveraged to create new anatomically-grounded image registration algorithms. To this end, we propose Polaffini, which obtains, from these segmented regions, anatomically grounded feature points with 1-to-1 correspondence in a particularly simple way: extracting their centroids. These enable efficient global and local affine matching via closed-form solutions. Those are used to produce an overall transformation ranging from affine to polyaffine with tunable smoothness. Polyaffine transformations can have many more degrees of freedom than affine ones allowing for finer alignment, and their embedding in the log-Euclidean framework ensures diffeomorphic properties. Polaffini has applications both for standalone registration and as pre-alignment for subsequent non-linear registration, and we evaluate it against popular intensity-based registration techniques. Results demonstrate that Polaffini outperforms competing methods in terms of structural alignment and provides improved initialisation for downstream non-linear registration. Polaffini is fast, robust, and accurate, making it particularly well-suited for integration into medical image processing pipelines.

</details>


### [26] [Tree crop mapping of South America reveals links to deforestation and conservation](https://arxiv.org/abs/2602.17372)
*Yuchang Jiang,Anton Raichuk,Xiaoye Tong,Vivien Sainte Fare Garnot,Daniel Ortiz-Gonzalo,Dan Morris,Konrad Schindler,Jan Dirk Wegner,Maxim Neumann*

Main category: cs.CV

TL;DR: 本研究利用多模态深度学习和卫星影像数据，生成了南美洲首个10米分辨率树木作物地图，发现现有监管地图将农业错误识别为森林，可能导致小农面临不公平惩罚，为零毁林政策提供了高分辨率基线。


<details>
  <summary>Details</summary>
Motivation: 监测树木作物扩张对于零毁林政策（如欧盟的《无毁林产品条例》(EUDR)）至关重要。然而，现有努力因缺乏能区分不同农业系统与森林的高分辨率数据而受阻。

Method: 使用多模态、时空深度学习模型，并结合Sentinel-1和Sentinel-2卫星影像时间序列进行训练，生成了南美洲首个10米分辨率的树木作物地图。

Result: 绘制了南美洲约1100万公顷的树木作物地图，其中23%与2000-2020年森林覆盖损失相关。分析发现，支持EUDR的现有监管地图常将既有农业（特别是小农农林业）错误分类为“森林”。

Conclusion: 本研究通过提供高分辨率基线，有助于制定有效、包容和公平的保护政策，以减轻现有监管地图可能导致虚假毁林警报和对小农不公平惩罚的风险。

Abstract: Monitoring tree crop expansion is vital for zero-deforestation policies like the European Union's Regulation on Deforestation-free Products (EUDR). However, these efforts are hindered by a lack of highresolution data distinguishing diverse agricultural systems from forests. Here, we present the first 10m-resolution tree crop map for South America, generated using a multi-modal, spatio-temporal deep learning model trained on Sentinel-1 and Sentinel-2 satellite imagery time series. The map identifies approximately 11 million hectares of tree crops, 23% of which is linked to 2000-2020 forest cover loss. Critically, our analysis reveals that existing regulatory maps supporting the EUDR often classify established agriculture, particularly smallholder agroforestry, as "forest". This discrepancy risks false deforestation alerts and unfair penalties for small-scale farmers. Our work mitigates this risk by providing a high-resolution baseline, supporting conservation policies that are effective, inclusive, and equitable.

</details>


### [27] [SpectralGCD: Spectral Concept Selection and Cross-modal Representation Learning for Generalized Category Discovery](https://arxiv.org/abs/2602.17395)
*Lorenzo Caselli,Marco Mistretta,Simone Magistri,Andrew D. Bagdanov*

Main category: cs.CV

TL;DR: SpectralGCD是一种高效的多模态广义类别发现（GCD）方法，通过利用CLIP跨模态图像-概念相似性作为统一表示，并通过谱过滤和知识蒸馏来提高语义质量和对齐，以较低的计算成本实现了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现（GCD）中，仅使用图像特征训练分类器易过拟合旧类别，而现有多模态方法虽有所改进但独立处理模态且计算成本高。

Method: 提出SpectralGCD，一种高效且有效的多模态GCD方法，使用CLIP跨模态图像-概念相似性作为统一的跨模态表示。将每张图像表示为大型任务无关字典中语义概念的混合，通过引入Spectral Filtering，利用强教师模型测量的softmaxed相似度上的跨模态协方差矩阵，自动保留字典中相关的概念。通过同一教师模型进行前向和反向知识蒸馏，确保学生模型的跨模态表示在语义上充分且对齐良好。

Result: 在六个基准测试中，SpectralGCD的准确性与最先进的方法相当或显著优于它们，且计算成本仅为一小部分。

Conclusion: SpectralGCD作为一种高效且有效的新型多模态方法，显著提升了广义类别发现的性能，同时大幅降低了计算成本。

Abstract: Generalized Category Discovery (GCD) aims to identify novel categories in unlabeled data while leveraging a small labeled subset of known classes. Training a parametric classifier solely on image features often leads to overfitting to old classes, and recent multimodal approaches improve performance by incorporating textual information. However, they treat modalities independently and incur high computational cost. We propose SpectralGCD, an efficient and effective multimodal approach to GCD that uses CLIP cross-modal image-concept similarities as a unified cross-modal representation. Each image is expressed as a mixture over semantic concepts from a large task-agnostic dictionary, which anchors learning to explicit semantics and reduces reliance on spurious visual cues. To maintain the semantic quality of representations learned by an efficient student, we introduce Spectral Filtering which exploits a cross-modal covariance matrix over the softmaxed similarities measured by a strong teacher model to automatically retain only relevant concepts from the dictionary. Forward and reverse knowledge distillation from the same teacher ensures that the cross-modal representations of the student remain both semantically sufficient and well-aligned. Across six benchmarks, SpectralGCD delivers accuracy comparable to or significantly superior to state-of-the-art methods at a fraction of the computational cost. The code is publicly available at: .

</details>


### [28] [A High-Level Survey of Optical Remote Sensing](https://arxiv.org/abs/2602.17397)
*Panagiotis Koletsis,Vasilis Efthymiou,Maria Vakalopoulou,Nikos Komodakis,Anastasios Doulamis,Georgios Th. Papadopoulos*

Main category: cs.CV

TL;DR: 该论文全面概述了使用RGB摄像头的无人机进行光学遥感的能力，旨在为进入该领域的研究人员提供指导，并提供数据集和见解等关键信息。


<details>
  <summary>Details</summary>
Motivation: 近年来，计算机视觉和无人机技术（通常配备RGB摄像头）的进步推动了遥感领域的发展。现有光学遥感文献内容丰富，但缺乏一个从整体视角全面概述该领域能力的综述，以指导新研究人员。

Method: 本文提供了一个全面的概述，介绍了使用无人机进行光学遥感的能力，并提供了数据集和见解等关键信息。

Result: 这项工作旨在作为新研究人员进入该领域的指南，提供高层次的见解，并帮助他们专注于与其兴趣最相关的领域。据作者所知，目前没有其他综述从这种整体视角来解决这个问题。

Conclusion: 该论文提供了一个急需的、全面的、整体的无人机光学遥感概述，旨在作为新研究人员的指导。

Abstract: In recent years, significant advances in computer vision have also propelled progress in remote sensing. Concurrently, the use of drones has expanded, with many organizations incorporating them into their operations. Most drones are equipped by default with RGB cameras, which are both robust and among the easiest sensors to use and interpret. The body of literature on optical remote sensing is vast, encompassing diverse tasks, capabilities, and methodologies. Each task or methodology could warrant a dedicated survey. This work provides a comprehensive overview of the capabilities of the field, while also presenting key information, such as datasets and insights. It aims to serve as a guide for researchers entering the field, offering high-level insights and helping them focus on areas most relevant to their interests. To the best of our knowledge, no existing survey addresses this holistic perspective.

</details>


### [29] [EAGLE: Expert-Augmented Attention Guidance for Tuning-Free Industrial Anomaly Detection in Multimodal Large Language Models](https://arxiv.org/abs/2602.17419)
*Xiaomeng Peng,Xilang Huang,Seon Han Choi*

Main category: cs.CV

TL;DR: 提出EAGLE框架，一个免微调的专家增强注意力引导MMLMs方法，用于工业异常检测，实现了准确检测和可解释描述，并通过鼓励MMLMs将注意力集中在异常区域来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习工业异常检测方法只能提供二元决策且解释性有限；多模态大语言模型（MLLMs）虽有潜力，但现有方法通常需要昂贵的微调，且与轻量级专家检测器相比，异常检测准确性提升不一致。

Method: 提出EAGLE（expert-augmented attention guidance for industrial anomaly detection in MLLMs）框架，这是一个免微调的框架，它集成专家模型的输出，以引导MLLMs实现准确的检测和可解释的异常描述。

Result: EAGLE在不更新任何参数的情况下，显著提高了MVTec-AD和VisA数据集上多个MLLMs的异常检测性能，并取得了与基于微调方法相当的结果。研究还发现，成功的异常检测与异常区域的注意力集中度增加有关，而EAGLE倾向于促进这种对齐。

Conclusion: EAGLE提供了一种免微调且有效的方法来提升MLLMs在工业异常检测中的性能和可解释性，通过引导注意力机制，使其在准确性和解释性上达到与微调方法相当甚至更好的水平。

Abstract: Industrial anomaly detection is important for smart manufacturing, but many deep learning approaches produce only binary decisions and provide limited semantic explanations. Multimodal large language models (MLLMs) can potentially generate fine-grained, language-based analyses, yet existing methods often require costly fine-tuning and do not consistently improve anomaly detection accuracy compared to lightweight specialist detectors. We propose expert-augmented attention guidance for industrial anomaly detection in MLLMs (EAGLE), a tuning-free framework that integrates outputs from expert model to guide MLLMs toward both accurate detection and interpretable anomaly descriptions. We further study how EAGLE affects MLLMs internals by examining the attention distribution of MLLMs to the anomalous image regions in the intermediate layers. We observe that successful anomaly detection is associated with increased attention concentration on anomalous regions, and EAGLE tends to encourage this alignment. Experiments on MVTec-AD and VisA show that EAGLE improves anomaly detection performance across multiple MLLMs without any parameter updates, achieving results comparable to fine-tuning based methods. Code is available at \href{ }{ }

</details>


### [30] [4D Monocular Surgical Reconstruction under Arbitrary Camera Motions](https://arxiv.org/abs/2602.17473)
*Jiwei Shan,Zeyu Cai,Cheng-Tai Hsieh,Yirui Li,Hao Liu,Lijun Han,Hesheng Wang,Shing Shin Cheng*

Main category: cs.CV

TL;DR: Local-EndoGS是一个用于单目内窥镜视频的高质量4D重建框架，能处理任意相机运动。它采用渐进式、基于窗口的全局表示和粗到精的初始化策略，并结合2D像素轨迹和物理运动先验，在外观和几何方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从内窥镜视频重建可变形手术场景具有挑战性且临床重要。现有最先进的方法大多针对固定内窥镜视角的变形场景，并依赖立体深度先验或精确的运动结构进行初始化和优化，这限制了它们处理真实临床环境中具有大相机运动的单目序列的能力。

Method: 提出Local-EndoGS，一个高质量的4D重建框架，用于任意相机运动的单目内窥镜序列。它引入了渐进式、基于窗口的全局表示，为每个观察到的窗口分配局部可变形场景模型，以处理长序列和大运动。为解决缺乏立体深度或精确运动结构时的不可靠初始化问题，设计了一种结合多视角几何、跨窗口信息和单目深度先验的粗到精策略。此外，还结合了长距离2D像素轨迹约束和物理运动先验以提高变形的合理性。

Result: 在三个公共内窥镜数据集上的实验表明，Local-EndoGS在外观质量和几何精度方面持续优于现有最先进的方法。消融研究验证了其关键设计的有效性。

Conclusion: Local-EndoGS通过其创新性的窗口化表示、鲁棒的初始化策略以及运动先验，成功解决了从单目内窥镜视频重建可变形手术场景的挑战，并在质量上超越了现有技术。

Abstract: Reconstructing deformable surgical scenes from endoscopic videos is challenging and clinically important. Recent state-of-the-art methods based on implicit neural representations or 3D Gaussian splatting have made notable progress. However, most are designed for deformable scenes with fixed endoscope viewpoints and rely on stereo depth priors or accurate structure-from-motion for initialization and optimization, limiting their ability to handle monocular sequences with large camera motion in real clinical settings. To address this, we propose Local-EndoGS, a high-quality 4D reconstruction framework for monocular endoscopic sequences with arbitrary camera motion. Local-EndoGS introduces a progressive, window-based global representation that allocates local deformable scene models to each observed window, enabling scalability to long sequences with substantial motion. To overcome unreliable initialization without stereo depth or accurate structure-from-motion, we design a coarse-to-fine strategy integrating multi-view geometry, cross-window information, and monocular depth priors, providing a robust foundation for optimization. We further incorporate long-range 2D pixel trajectory constraints and physical motion priors to improve deformation plausibility. Experiments on three public endoscopic datasets with deformable scenes and varying camera motions show that Local-EndoGS consistently outperforms state-of-the-art methods in appearance quality and geometry. Ablation studies validate the effectiveness of our key designs. Code will be released upon acceptance at: .

</details>


### [31] [QuPAINT: Physics-Aware Instruction Tuning Approach to Quantum Material Discovery](https://arxiv.org/abs/2602.17478)
*Xuan-Bac Nguyen,Hoang-Quan Nguyen,Sankalp Pandey,Tim Faltermeier,Nicholas Borys,Hugh Churchill,Khoa Luu*

Main category: cs.CV

TL;DR: 本文提出了一个物理感知多模态框架，通过合成数据生成器（Synthia）、大规模指令数据集（QMat-Instruct）和物理感知指令微调架构（QuPAINT），解决了二维量子材料表征中标签数据有限和泛化性差的问题，并建立了全面的评估基准（QF-Bench）。


<details>
  <summary>Details</summary>
Motivation: 表征二维量子材料面临挑战，包括微妙的层依赖对比度、有限的标注数据以及不同实验室和成像设置间的显著差异。现有视觉模型缺乏物理先验，难以泛化到新材料或硬件条件。

Method: 1. Synthia：一个基于物理的合成数据生成器，模拟薄膜干涉下量子材料薄片的真实光学响应，生成多样化高质量的样本以减少人工标注依赖。
2. QMat-Instruct：首个用于量子材料的大规模指令数据集，包含多模态、物理信息问答对，旨在训练多模态大型语言模型（MLLMs）理解薄片的外观和厚度。
3. Physics-Aware Instruction Tuning (QuPAINT)：一种多模态架构，融合了物理信息注意力模块，将视觉嵌入与光学先验结合，实现更鲁棒和有区分性的薄片表征。
4. QF-Bench：一个全面的基准测试，涵盖多种材料、衬底和成像设置，为公平和可重现的评估提供标准化协议。

Result: 1. Synthia：生成多样化高质量的合成数据，减少了对专家手动标注的依赖。
2. QMat-Instruct：提供了大规模指令数据集，有效训练MLLMs理解薄片的外观和厚度。
3. QuPAINT：通过融合光学先验，实现了更鲁棒和有区分性的薄片表征。
4. QF-Bench：建立了用于标准化、公平和可复现评估的综合基准。

Conclusion: 该工作通过物理感知多模态框架、合成数据生成器、大规模指令数据集和评估基准，显著提高了2D量子材料表征的准确性和泛化能力，为该领域提供了标准化工具和方法。

Abstract: Characterizing two-dimensional quantum materials from optical microscopy images is challenging due to the subtle layer-dependent contrast, limited labeled data, and significant variation across laboratories and imaging setups. Existing vision models struggle in this domain since they lack physical priors and cannot generalize to new materials or hardware conditions. This work presents a new physics-aware multimodal framework that addresses these limitations from both the data and model perspectives. We first present Synthia, a physics-based synthetic data generator that simulates realistic optical responses of quantum material flakes under thin-film interference. Synthia produces diverse and high-quality samples, helping reduce the dependence on expert manual annotation. We introduce QMat-Instruct, the first large-scale instruction dataset for quantum materials, comprising multimodal, physics-informed question-answer pairs designed to teach Multimodal Large Language Models (MLLMs) to understand the appearance and thickness of flakes. Then, we propose Physics-Aware Instruction Tuning (QuPAINT), a multimodal architecture that incorporates a Physics-Informed Attention module to fuse visual embeddings with optical priors, enabling more robust and discriminative flake representations. Finally, we establish QF-Bench, a comprehensive benchmark spanning multiple materials, substrates, and imaging settings, offering standardized protocols for fair and reproducible evaluation.

</details>


### [32] [Tracing Copied Pixels and Regularizing Patch Affinity in Copy Detection](https://arxiv.org/abs/2602.17484)
*Yichen Lu,Siwei Nie,Minlong Lu,Xudong Yang,Xiaobo Zhang,Peng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为PixTrace的像素坐标跟踪模块和几何引导对比损失CopyNCE，以解决图像复制检测(ICD)中现有自监督学习方法对复杂编辑的不足，实现了最先进的性能和更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 图像复制检测（ICD）旨在通过鲁棒的特征表示学习来识别图像对之间被篡改的内容。尽管自监督学习（SSL）改进了ICD系统，但现有的视图级对比方法由于细粒度对应学习不足，在处理复杂编辑时表现不佳。

Method: 本文通过利用编辑内容固有的几何可追溯性来解决这一限制。具体地，提出了两个关键创新点：1. PixTrace——一个像素坐标跟踪模块，用于在编辑转换中保持显式空间映射。2. CopyNCE——一种几何引导的对比损失，它利用从PixTrace验证映射中导出的重叠比率来规范补丁亲和性。该方法将像素级可追溯性与补丁级相似性学习相结合，抑制了SSL训练中的监督噪声。

Result: 广泛的实验证明，该方法不仅实现了最先进的性能（在DISC21数据集上，匹配器达到88.7% uAP / 83.9% RP90，描述符达到72.6% uAP / 68.4% RP90），而且比现有方法具有更好的可解释性。

Conclusion: 本文提出的方法通过将像素级可追溯性与补丁级相似性学习相结合，有效地解决了图像复制检测中复杂编辑的挑战，显著提高了性能和可解释性。

Abstract: Image Copy Detection (ICD) aims to identify manipulated content between image pairs through robust feature representation learning. While self-supervised learning (SSL) has advanced ICD systems, existing view-level contrastive methods struggle with sophisticated edits due to insufficient fine-grained correspondence learning. We address this limitation by exploiting the inherent geometric traceability in edited content through two key innovations. First, we propose PixTrace - a pixel coordinate tracking module that maintains explicit spatial mappings across editing transformations. Second, we introduce CopyNCE, a geometrically-guided contrastive loss that regularizes patch affinity using overlap ratios derived from PixTrace's verified mappings. Our method bridges pixel-level traceability with patch-level similarity learning, suppressing supervision noise in SSL training. Extensive experiments demonstrate not only state-of-the-art performance (88.7% uAP / 83.9% RP90 for matcher, 72.6% uAP / 68.4% RP90 for descriptor on DISC21 dataset) but also better interpretability over existing methods.

</details>


### [33] [FoundationPose-Initialized 3D-2D Liver Registration for Surgical Augmented Reality](https://arxiv.org/abs/2602.17517)
*Hanyuan Zhang,Lucas He,Runlong He,Abdolrahim Kadkhodamohammadi,Danail Stoyanov,Brian R. Davidson,Evangelos B. Mazomenos,Matthew J. Clarkson*

Main category: cs.CV

TL;DR: 增强现实技术可以改善腹腔镜肝脏手术中的肿瘤定位。本文提出了一种轻量级的注册流程，结合了腹腔镜深度图和基础姿态估计器进行相机-肝脏姿态估计，并使用非刚性迭代最近点（NICP）代替有限元（FE）模型进行形变对齐。该方法在真实患者数据上实现了临床相关的精度（平均注册误差9.91毫米），同时降低了工程/建模复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有的腹腔镜肝脏手术增强现实注册流程通常依赖器官轮廓，并使用有限元（FE）模型结合降维或机器学习组件来处理可变形（非刚性）对齐，这增加了工程/建模的复杂性和专业知识要求。本文旨在通过简化方法来提高肿瘤定位，并降低这些要求。

Method: 该研究将腹腔镜深度图与基础姿态估计器相结合，用于相机-肝脏姿态估计。同时，用非刚性迭代最近点（NICP）取代了基于有限元的形变处理，以降低工程/建模复杂性和专业知识要求。

Result: 在3个真实患者数据案例中，深度增强的基础姿态方法实现了9.91毫米的平均注册误差。结合刚性-NICP注册比单独的刚性注册表现更好，证明NICP是有限元可变形模型的有效替代品。

Conclusion: 该流程在腹腔镜肝脏手术中实现了临床相关的增强现实注册精度，并提供了一种轻量级、工程友好的替代方案，取代了基于有限元的形变方法。NICP被证明是有限元可变形模型的一种高效替代品。

Abstract: Augmented reality can improve tumor localization in laparoscopic liver surgery. Existing registration pipelines typically depend on organ contours; deformable (non-rigid) alignment is often handled with finite-element (FE) models coupled to dimensionality-reduction or machine-learning components. We integrate laparoscopic depth maps with a foundation pose estimator for camera-liver pose estimation and replace FE-based deformation with non-rigid iterative closest point (NICP) to lower engineering/modeling complexity and expertise requirements. On real patient data, the depth-augmented foundation pose approach achieved 9.91 mm mean registration error in 3 cases. Combined rigid-NICP registration outperformed rigid-only registration, demonstrating NICP as an efficient substitute for finite-element deformable models. This pipeline achieves clinically relevant accuracy while offering a lightweight, engineering-friendly alternative to FE-based deformation.

</details>


### [34] [LATA: Laplacian-Assisted Transductive Adaptation for Conformal Uncertainty in Medical VLMs](https://arxiv.org/abs/2602.17535)
*Behzad Bozorgtabar,Dwarikanath Mahapatra,Sudipta Roy,Muzammal Naseer,Imran Razzak,Zongyuan Ge*

Main category: cs.CV

TL;DR: 本文提出了LATA，一种无需训练和标签的精炼方法，通过图平滑和故障感知共形分数来提高医用VLM的预测集效率和类别平衡性，同时保持理论保证。


<details>
  <summary>Details</summary>
Motivation: 医用视觉-语言模型（VLM）在医学影像方面具有强大的零样本识别能力，但其在领域漂移下的可靠性取决于经过校准且具有保证的不确定性。分裂共形预测（SCP）提供了有限样本覆盖，但预测集通常较大（效率低）且类别覆盖不平衡（高类别条件覆盖差距，CCV），尤其是在少样本、不平衡的情况下。此外，天真地适应校准标签会破坏可交换性并使保证失效。

Method: 本文提出了LATA（Laplacian-Assisted Transductive Adaptation），这是一种无需训练和标签的精炼方法。LATA通过在图像-图像k-NN图上平滑零样本概率来操作联合校准和测试池，并使用少量CCCP均场更新。它通过确定性变换保持了SCP的有效性。此外，本文引入了一种“故障感知”共形分数，将其嵌入到视觉-语言不确定性（ViLU）框架中，以提供实例级难度和标签合理性，从而在固定覆盖率下提高预测集效率和类别平衡性。LATA具有黑盒（不更新VLM）、计算量轻（窗口式转导，无反向传播）的特点，并包含一个可选的先验旋钮，可严格无标签运行，或根据需要使用校准边际进行一次标签信息变体。

Result: LATA在三个医用VLM和九个下游任务中进行了评估，结果表明它始终能减少预测集大小和CCV，同时匹配或收紧目标覆盖率，优于先前的转导基线，并缩小了与使用标签方法之间的差距，同时计算量大大减少。全面的消融实验和定性分析表明，LATA在不损害可交换性的前提下锐化了零样本预测。

Conclusion: LATA是一种黑盒、计算量轻、无需训练和标签的医疗VLM改进方法，它显著提高了预测集效率和类别平衡性，同时保持了保形预测的保证，并优于现有方法。它在不损害可交换性的前提下，锐化了零样本预测。

Abstract: Medical vision-language models (VLMs) are strong zero-shot recognizers for medical imaging, but their reliability under domain shift hinges on calibrated uncertainty with guarantees. Split conformal prediction (SCP) offers finite-sample coverage, yet prediction sets often become large (low efficiency) and class-wise coverage unbalanced-high class-conditioned coverage gap (CCV), especially in few-shot, imbalanced regimes; moreover, naively adapting to calibration labels breaks exchangeability and voids guarantees. We propose \texttt{\textbf{LATA}} (Laplacian-Assisted Transductive Adaptation), a \textit{training- and label-free} refinement that operates on the joint calibration and test pool by smoothing zero-shot probabilities over an image-image k-NN graph using a small number of CCCP mean-field updates, preserving SCP validity via a deterministic transform. We further introduce a \textit{failure-aware} conformal score that plugs into the vision-language uncertainty (ViLU) framework, providing instance-level difficulty and label plausibility to improve prediction set efficiency and class-wise balance at fixed coverage. \texttt{\textbf{LATA}} is black-box (no VLM updates), compute-light (windowed transduction, no backprop), and includes an optional prior knob that can run strictly label-free or, if desired, in a label-informed variant using calibration marginals once. Across \textbf{three} medical VLMs and \textbf{nine} downstream tasks, \texttt{\textbf{LATA}} consistently reduces set size and CCV while matching or tightening target coverage, outperforming prior transductive baselines and narrowing the gap to label-using methods, while using far less compute. Comprehensive ablations and qualitative analyses show that \texttt{\textbf{LATA}} sharpens zero-shot predictions without compromising exchangeability.

</details>


### [35] [GraphThinker: Reinforcing Video Reasoning with Event Graph Thinking](https://arxiv.org/abs/2602.17555)
*Zixu Cheng,Da Li,Jian Hu,Ziquan Liu,Wei Li,Shaogang Gong*

Main category: cs.CV

TL;DR: GraphThinker是一种基于强化微调的方法，通过构建事件级场景图并增强视觉基础，以显式建模事件内外关系和引入视觉注意力奖励，从而减少视频推理中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 视频推理需要理解事件间的因果关系，但这种关系通常是隐式的且手动标注成本高。现有的多模态大型语言模型（MLLMs）在视频推理中缺乏显式的因果结构建模，导致幻觉问题。

Method: 提出GraphThinker，该方法首先利用MLLM构建事件视频场景图（EVSG），显式建模事件内部和事件间的关系，并将这些场景图作为中间思维过程整合到MLLM中。其次，在强化微调过程中引入视觉注意力奖励，以增强视频基础并进一步减轻幻觉。

Result: GraphThinker在RexTime和VidHalluc两个数据集上进行了评估，结果显示它在捕获对象和事件关系、实现更精确的事件定位方面表现出卓越的能力，并与现有方法相比，显著减少了视频推理中的幻觉。

Conclusion: GraphThinker通过引入显式的事件级场景图建模和强化微调中的视觉注意力奖励，有效解决了视频推理中的幻觉问题，提升了模型对事件关系和定位的理解能力。

Abstract: Video reasoning requires understanding the causal relationships between events in a video. However, such relationships are often implicit and costly to annotate manually. While existing multimodal large language models (MLLMs) often infer event relations through dense captions or video summaries for video reasoning, such modeling still lacks causal understanding. Without explicit causal structure modeling within and across video events, these models suffer from hallucinations during the video reasoning. In this work, we propose GraphThinker, a reinforcement finetuning-based method that constructs structural event-level scene graphs and enhances visual grounding to jointly reduce hallucinations in video reasoning. Specifically, we first employ an MLLM to construct an event-based video scene graph (EVSG) that explicitly models both intra- and inter-event relations, and incorporate these formed scene graphs into the MLLM as an intermediate thinking process. We also introduce a visual attention reward during reinforcement finetuning, which strengthens video grounding and further mitigates hallucinations. We evaluate GraphThinker on two datasets, RexTime and VidHalluc, where it shows superior ability to capture object and event relations with more precise event localization, reducing hallucinations in video reasoning compared to prior methods.

</details>


### [36] [Art2Mus: Artwork-to-Music Generation via Visual Conditioning and Large-Scale Cross-Modal Alignment](https://arxiv.org/abs/2602.17599)
*Ivan Rinaldi,Matteo Mendula,Nicola Fanelli,Florence Levé,Matteo Testi,Giovanna Castellano,Gennaro Vessio*

Main category: cs.CV

TL;DR: ArtSound是一个包含艺术作品-音乐对的数据集。ArtToMus是一个无需文本转换即可直接进行艺术作品到音乐生成的框架。它生成了能反映视觉线索的连贯音乐，并将直接视觉到音乐生成确立为一个新的研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有的图像条件音乐生成系统存在两个基本限制：一是它们通常在自然照片上训练，限制了捕捉艺术作品中更丰富的语义、风格和文化内容的能力；二是大多数系统依赖于图像到文本的转换阶段，使用语言作为语义捷径，这简化了条件设置但阻止了直接的视觉到音频学习。

Method: 研究引入了ArtSound，一个包含105,884个艺术作品-音乐对的大规模多模态数据集，并富含双模态字幕，该数据集扩展自ArtGraph和Free Music Archive。此外，研究提出了ArtToMus，这是首个专门为直接艺术作品到音乐生成设计的框架，它在没有图像到文本翻译或基于语言的语义监督的情况下，将数字化艺术作品映射到音乐。该框架将视觉嵌入投影到潜在扩散模型的条件空间中，从而实现仅由视觉信息指导的音乐合成。

Result: 实验结果表明，ArtToMus生成的音乐在音乐上连贯且风格一致，反映了源艺术作品的显著视觉线索。尽管由于去除语言监督导致难度大幅增加，绝对对齐分数低于文本条件系统（符合预期），但ArtToMus仍实现了有竞争力的感知质量和有意义的跨模态对应。

Conclusion: 这项工作将直接视觉到音乐生成确立为一个独特且具有挑战性的研究方向，并提供了支持多媒体艺术、文化遗产和人工智能辅助创作实践应用的资源。

Abstract: Music generation has advanced markedly through multimodal deep learning, enabling models to synthesize audio from text and, more recently, from images. However, existing image-conditioned systems suffer from two fundamental limitations: (i) they are typically trained on natural photographs, limiting their ability to capture the richer semantic, stylistic, and cultural content of artworks; and (ii) most rely on an image-to-text conversion stage, using language as a semantic shortcut that simplifies conditioning but prevents direct visual-to-audio learning. Motivated by these gaps, we introduce ArtSound, a large-scale multimodal dataset of 105,884 artwork-music pairs enriched with dual-modality captions, obtained by extending ArtGraph and the Free Music Archive. We further propose ArtToMus, the first framework explicitly designed for direct artwork-to-music generation, which maps digitized artworks to music without image-to-text translation or language-based semantic supervision. The framework projects visual embeddings into the conditioning space of a latent diffusion model, enabling music synthesis guided solely by visual information. Experimental results show that ArtToMus generates musically coherent and stylistically consistent outputs that reflect salient visual cues of the source artworks. While absolute alignment scores remain lower than those of text-conditioned systems-as expected given the substantially increased difficulty of removing linguistic supervision-ArtToMus achieves competitive perceptual quality and meaningful cross-modal correspondence. This work establishes direct visual-to-music generation as a distinct and challenging research direction, and provides resources that support applications in multimedia art, cultural heritage, and AI-assisted creative practice. Code and dataset will be publicly released upon acceptance.

</details>


### [37] [Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery](https://arxiv.org/abs/2602.17605)
*Jowaria Khan,Anindya Sarkar,Yevgeniy Vorobeychik,Elizabeth Bondi-Kelly*

Main category: cs.CV

TL;DR: 本文提出了一个统一的地理空间发现框架，该框架结合了主动学习、在线元学习和概念引导推理，通过概念加权不确定性采样和相关性感知元批次形成策略，解决了在数据稀疏和动态环境中高效发现隐藏目标的问题，并在PFAS污染的真实数据集上验证了其可靠性。


<details>
  <summary>Details</summary>
Motivation: 在环境监测、灾害响应、公共卫生等现实场景中，数据收集成本高、难度大，且环境动态变化。在资源紧张的情况下，有效地从未知区域进行战略性采样以发现隐藏目标至关重要。然而，稀疏且有偏差的地理空间真实数据限制了现有学习方法（如强化学习）的适用性。

Method: 本文提出了一个统一的地理空间发现框架，该框架整合了主动学习、在线元学习和概念引导推理。主要创新包括：概念加权不确定性采样策略（不确定性由基于领域特定概念学习到的相关性调节）和相关性感知元批次形成策略（在在线元更新期间促进语义多样性，提高动态环境下的泛化能力）。

Result: 在致癌PFAS污染的真实数据集上的实验表明，该方法在有限数据和动态环境下能够可靠地发现目标。

Conclusion: 该方法在有限数据和动态环境下，能够可靠地发现目标。

Abstract: In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tight resource constraints. Yet, sparse and biased geospatial ground truth limits the applicability of existing learning-based methods, such as reinforcement learning. To address this, we propose a unified geospatial discovery framework that integrates active learning, online meta-learning, and concept-guided reasoning. Our approach introduces two key innovations built on a shared notion of *concept relevance*, which captures how domain-specific factors influence target presence: a *concept-weighted uncertainty sampling strategy*, where uncertainty is modulated by learned relevance based on readily-available domain-specific concepts (e.g., land cover, source proximity); and a *relevance-aware meta-batch formation strategy* that promotes semantic diversity during online-meta updates, improving generalization in dynamic environments. Our experiments include testing on a real-world dataset of cancer-causing PFAS (Per- and polyfluoroalkyl substances) contamination, showcasing our method's reliability at uncovering targets with limited data and a varying environment.

</details>


### [38] [CORAL: Correspondence Alignment for Improved Virtual Try-On](https://arxiv.org/abs/2602.17636)
*Jiyoung Kim,Youngjin Shin,Siyoon Jin,Dahyun Chung,Jisu Nam,Tongmin Kim,Jongjae Park,Hyeonwoo Kang,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出了CORAL，一个基于Diffusion Transformer（DiT）的虚拟试穿（VTON）框架，通过显式对齐查询-键匹配与外部对应关系来解决现有方法在保留服装细节和人-服装对应方面的问题。CORAL通过对应蒸馏损失和熵最小化损失来增强性能，并通过VLM评估协议验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿（VTON）方法在保留服装精细细节方面表现不佳，尤其是在需要精确人-服装对应关系的非配对设置中。这些方法未明确强制执行人-服装对齐，也未能解释对应关系如何在Diffusion Transformers (DiTs) 中产生。本文首先分析了DiT架构中的全3D注意力，并发现人-服装对应关系关键取决于全3D注意力中精确的人-服装查询-键匹配。

Method: 本文提出了基于DiT的CORrespondence ALignment (CORAL) 框架。该框架通过引入两项互补组件来显式对齐查询-键匹配与鲁棒的外部对应关系：1) 对应蒸馏损失，用于将可靠匹配与人-服装注意力对齐；2) 熵最小化损失，用于锐化注意力分布。此外，本文还提出了一种基于VLM的评估协议。

Result: CORAL始终优于基线方法，在增强全局形状传输和局部细节保留方面均有提升。广泛的消融实验验证了所提出的设计选择。新的VLM评估协议能更好地反映人类偏好。

Conclusion: CORAL在虚拟试穿任务中显著优于现有基线，提高了全局形状传输和局部细节保留能力。该方法通过VLM评估协议进一步验证了其对人类偏好的良好匹配。

Abstract: Existing methods for Virtual Try-On (VTON) often struggle to preserve fine garment details, especially in unpaired settings where accurate person-garment correspondence is required. These methods do not explicitly enforce person-garment alignment and fail to explain how correspondence emerges within Diffusion Transformers (DiTs). In this paper, we first analyze full 3D attention in DiT-based architecture and reveal that the person-garment correspondence critically depends on precise person-garment query-key matching within the full 3D attention. Building on this insight, we then introduce CORrespondence ALignment (CORAL), a DiT-based framework that explicitly aligns query-key matching with robust external correspondences. CORAL integrates two complementary components: a correspondence distillation loss that aligns reliable matches with person-garment attention, and an entropy minimization loss that sharpens the attention distribution. We further propose a VLM-based evaluation protocol to better reflect human preference. CORAL consistently improves over the baseline, enhancing both global shape transfer and local detail preservation. Extensive ablations validate our design choices.

</details>


### [39] [IntRec: Intent-based Retrieval with Contrastive Refinement](https://arxiv.org/abs/2602.17639)
*Pourya Shamsolmoali,Masoumeh Zareapoor,Eric Granger,Yue Lu*

Main category: cs.CV

TL;DR: 本文提出了IntRec，一个交互式目标检索框架，它利用意图状态（IS）中的正向锚点和负向约束双重记忆集，根据用户反馈优化预测，从而显著提高了在LVIS和LVIS-Ambiguous基准测试上的检索准确性。


<details>
  <summary>Details</summary>
Motivation: 从复杂场景中检索用户指定对象，尤其是当查询模糊或涉及多个相似对象时，仍然是一项具有挑战性的任务。现有的开放词汇检测器以一次性方式操作，缺乏根据用户反馈细化预测的能力。

Method: 本文提出了IntRec，一个基于用户反馈细化预测的交互式目标检索框架。其核心是一个意图状态（IS），它为正向锚点（已确认的线索）和负向约束（已拒绝的假设）维护双重记忆集。一个对比对齐函数通过最大化与正向线索的相似性同时惩罚被拒绝的线索来对候选对象进行排序，从而在杂乱场景中实现细粒度消歧。

Result: 在LVIS数据集上，IntRec取得了35.4 AP的成绩，分别比OVMR、CoDet和CAKE高出+2.3、+3.7和+0.5 AP。在具有挑战性的LVIS-Ambiguous基准测试上，经过一次纠正性反馈后，其性能比其一次性基线提高了+7.9 AP，每次交互的额外延迟低于30毫秒。

Conclusion: 该交互式框架在没有额外监督的情况下，大幅提高了检索准确性，并在具有挑战性的基准测试上展现出更好的性能。

Abstract: Retrieving user-specified objects from complex scenes remains a challenging task, especially when queries are ambiguous or involve multiple similar objects. Existing open-vocabulary detectors operate in a one-shot manner, lacking the ability to refine predictions based on user feedback. To address this, we propose IntRec, an interactive object retrieval framework that refines predictions based on user feedback. At its core is an Intent State (IS) that maintains dual memory sets for positive anchors (confirmed cues) and negative constraints (rejected hypotheses). A contrastive alignment function ranks candidate objects by maximizing similarity to positive cues while penalizing rejected ones, enabling fine-grained disambiguation in cluttered scenes. Our interactive framework provides substantial improvements in retrieval accuracy without additional supervision. On LVIS, IntRec achieves 35.4 AP, outperforming OVMR, CoDet, and CAKE by +2.3, +3.7, and +0.5, respectively. On the challenging LVIS-Ambiguous benchmark, it improves performance by +7.9 AP over its one-shot baseline after a single corrective feedback, with less than 30 ms of added latency per interaction.

</details>


### [40] [OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents](https://arxiv.org/abs/2602.17665)
*Akashah Shabbir,Muhammad Umer Sheikh,Muhammad Akhtar Munir,Hiyam Debary,Mustansar Fiaz,Muhammad Zaigham Zaheer,Paolo Fraccaro,Fahad Shahbaz Khan,Muhammad Haris Khan,Xiao Xiang Zhu,Salman Khan*

Main category: cs.CV

TL;DR: OpenEarthAgent是一个统一框架，用于训练工具增强的地理空间智能体，该智能体通过监督微调结构化推理轨迹，在遥感领域实现了多模态推理，并展现出良好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理能力难以扩展到遥感领域，因为模型必须在保持连贯多步逻辑的同时，处理空间尺度、地理结构和多光谱指数。

Method: 提出OpenEarthAgent框架，用于开发工具增强的地理空间智能体，该智能体通过对卫星图像、自然语言查询和详细推理轨迹进行监督微调来训练。训练管道将模型与跨分析上下文的已验证多步工具交互对齐。构建了一个包含14,538个训练实例和1,169个评估实例的语料库，涵盖城市、环境、灾害和基础设施领域，并结合了GIS操作和NDVI、NBR、NDBI等指数分析。

Result: 所学习的智能体通过工具驱动的地理空间交互，在不同条件下展现出结构化推理、稳定的空间理解和可解释行为。与强基线模型相比，实现了持续改进；与最近的开源和闭源模型相比，性能具有竞争力。

Conclusion: OpenEarthAgent框架成功地将多模态推理能力扩展到遥感领域，通过显式推理轨迹训练的工具增强型地理空间智能体，在多样化场景下实现了稳定且可解释的地理空间分析，并在性能上超越了现有模型。

Abstract: Recent progress in multimodal reasoning has enabled agents that can interpret imagery, connect it with language, and perform structured analytical tasks. Extending such capabilities to the remote sensing domain remains challenging, as models must reason over spatial scale, geographic structures, and multispectral indices while maintaining coherent multi-step logic. To bridge this gap, OpenEarthAgent introduces a unified framework for developing tool-augmented geospatial agents trained on satellite imagery, natural-language queries, and detailed reasoning traces. The training pipeline relies on supervised fine-tuning over structured reasoning trajectories, aligning the model with verified multistep tool interactions across diverse analytical contexts. The accompanying corpus comprises 14,538 training and 1,169 evaluation instances, with more than 100K reasoning steps in the training split and over 7K reasoning steps in the evaluation split. It spans urban, environmental, disaster, and infrastructure domains, and incorporates GIS-based operations alongside index analyses such as NDVI, NBR, and NDBI. Grounded in explicit reasoning traces, the learned agent demonstrates structured reasoning, stable spatial understanding, and interpretable behaviour through tool-driven geospatial interactions across diverse conditions. We report consistent improvements over a strong baseline and competitive performance relative to recent open and closed-source models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [41] [References Improve LLM Alignment in Non-Verifiable Domains](https://arxiv.org/abs/2602.16802)
*Kejian Shi,Yixin Liu,Peifeng Wang,Alexander R. Fabbri,Shafiq Joty,Arman Cohan*

Main category: cs.CL

TL;DR: 本研究提出利用参考指导的LLM评估器作为非可验证领域LLM对齐的软“验证器”。该方法显著提高了LLM评审的准确性，并且通过参考指导的自我改进，在AlpacaEval和Arena-Hard等基准测试上，相对于直接SFT和无参考自我改进取得了显著性能提升，性能可与强大的奖励模型相媲美。


<details>
  <summary>Details</summary>
Motivation: 尽管可验证奖励强化学习（RLVR）在推理任务中表现出强大的有效性，但由于缺乏真实世界的验证器，它无法直接应用于LLM对齐等非可验证领域。本研究旨在探究参考指导的LLM评估器是否可以通过充当软“验证器”来弥补这一差距。

Method: 1. 设计了利用参考输出来增强用于LLM对齐的LLM评估器的评估协议。2. 综合实验表明，参考指导的方法显著提高了能力较弱的LLM评审的准确性，并能增强较强的LLM评审。3. 基于这些改进的评审，研究展示了高质量参考在对齐调整中的效用，其中LLM在参考指导下充当评审进行自我改进。

Result: 1. 参考指导的方法显著提高了使用前沿模型参考的LLM评审的准确性；高质量（即人工编写）参考也能增强更强的LLM评审。2. 参考指导的自我改进在性能上明显优于直接在参考输出上进行SFT以及使用无参考评审的自我改进，达到了与使用ArmoRM（一种强大的微调奖励模型）进行训练相当的性能。3. 具体而言，在AlpacaEval和Arena-Hard上，Llama-3-8B-Instruct分别达到73.1%和58.7%；Qwen2.5-7B分别达到70.0%和74.1%。4. 相对于SFT蒸馏，在AlpacaEval / Arena-Hard上平均绝对增益为+20.2 / +17.1点；相对于无参考自我改进，平均绝对增益为+5.3 / +3.6点。

Conclusion: 本研究强调了使用参考指导的LLM评估器在非可验证领域实现有效LLM后期训练的潜力。

Abstract: While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-evaluators can bridge this gap by serving as soft "verifiers". First, we design evaluation protocols that enhance LLM-based evaluators for LLM alignment using reference outputs. Through comprehensive experiments, we show that a reference-guided approach substantially improves the accuracy of less capable LLM-judges using references from frontier models; stronger LLM-judges can also be enhanced by high-quality (i.e., human-written) references. Building on these improved judges, we demonstrate the utility of high-quality references in alignment tuning, where LLMs guided with references are used as judges to self-improve. We show that reference-guided self-improvement yields clear gains over both direct SFT on reference outputs and self-improvement with reference-free judges, achieving performance comparable to training with ArmoRM, a strong finetuned reward model. Specifically, our method achieves 73.1% and 58.7% on AlpacaEval and Arena-Hard with Llama-3-8B-Instruct, and 70.0% and 74.1% with Qwen2.5-7B, corresponding to average absolute gains of +20.2 / +17.1 points over SFT distillation and +5.3 / +3.6 points over reference-free self-improvement on AlpacaEval / Arena-Hard. These results highlight the potential of using reference-guided LLM-evaluators to enable effective LLM post-training in non-verifiable domains.

</details>


### [42] [Evaluating Monolingual and Multilingual Large Language Models for Greek Question Answering: The DemosQA Benchmark](https://arxiv.org/abs/2602.16811)
*Charalampos Mastrokostas,Nikolaos Giarelis,Nikos Karacapilidis*

Main category: cs.CL

TL;DR: 本研究通过创建新的希腊语问答数据集DemosQA、开发内存高效的评估框架以及对11个单语和多语LLM进行广泛评估，解决了希腊语问答领域中LLM的资源不足和评估不足问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在问答等任务上取得了显著进展，但其研究主要集中在高资源语言（如英语）。多语言模型存在训练数据偏见，倾向于少数流行语言，或者依赖于从高资源语言到低资源语言的迁移学习，这可能导致社会、文化和历史方面的误解。为低资源语言开发的单语LLMs，其有效性在特定语言任务上与多语言模型相比，研究较少。本研究旨在弥补希腊语问答领域的这一研究空白。

Method: 1. 构建了DemosQA数据集，该数据集利用社交媒体用户问题和社区评审答案，以更好地捕捉希腊社会的文化精神。
2. 开发了一个内存高效的LLM评估框架，该框架可适应不同的问答数据集和语言。
3. 使用3种不同的提示策略，对6个由人工整理的希腊语问答数据集上的11个单语和多语LLM进行了广泛评估。
4. 发布了代码和数据以促进可复现性。

Result: 本研究提供了DemosQA，这是一个新颖的希腊语问答数据集；开发了一个内存高效的LLM评估框架；并对11个单语和多语LLM在6个希腊语问答数据集上进行了广泛评估，使用了3种不同的提示策略。所有代码和数据均已发布，以确保可复现性。

Conclusion: 本研究通过提供新的数据集、内存高效的评估框架以及对希腊语问答的广泛评估，弥补了该领域的研究空白，并促进了可复现性。

Abstract: Recent advancements in Natural Language Processing and Deep Learning have enabled the development of Large Language Models (LLMs), which have significantly advanced the state-of-the-art across a wide range of tasks, including Question Answering (QA). Despite these advancements, research on LLMs has primarily targeted high-resourced languages (e.g., English), and only recently has attention shifted toward multilingual models. However, these models demonstrate a training data bias towards a small number of popular languages or rely on transfer learning from high- to under-resourced languages; this may lead to a misrepresentation of social, cultural, and historical aspects. To address this challenge, monolingual LLMs have been developed for under-resourced languages; however, their effectiveness remains less studied when compared to multilingual counterparts on language-specific tasks. In this study, we address this research gap in Greek QA by contributing: (i) DemosQA, a novel dataset, which is constructed using social media user questions and community-reviewed answers to better capture the Greek social and cultural zeitgeist; (ii) a memory-efficient LLM evaluation framework adaptable to diverse QA datasets and languages; and (iii) an extensive evaluation of 11 monolingual and multilingual LLMs on 6 human-curated Greek QA datasets using 3 different prompting strategies. We release our code and data to facilitate reproducibility.

</details>


### [43] [One-step Language Modeling via Continuous Denoising](https://arxiv.org/abs/2602.16813)
*Chanhyuk Lee,Jaehoon Yoo,Manan Agarwal,Sheel Shah,Jerry Huang,Aditi Raghunathan,Seunghoon Hong,Nicholas M. Boffi,Jinwoo Kim*

Main category: cs.CL

TL;DR: 本研究提出了一种基于流的连续去噪语言模型（FLM），并通过蒸馏得到FMLM，在少步生成任务上，FMLM的生成质量和速度均超越了离散扩散模型，挑战了离散扩散在离散模态生成建模中的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于离散扩散的语言模型在少步生成时样本质量急剧下降，未能实现其比自回归模型更快生成的潜力。因此，需要一种能够同时提高生成质量和速度的新方法。

Method: 本文通过重新审视离散模态上的流基础，构建了一个流式语言模型（FLM），该模型对one-hot token编码进行欧几里得去噪。模型通过交叉熵目标预测干净数据进行训练，并引入了一个简单的时间重参数化来提高训练稳定性和生成质量。通过将FLM蒸馏成其关联的流映射，得到一个蒸馏流映射语言模型（FMLM），支持少步生成。

Result: 在LM1B和OWT语言数据集上，FLM达到了与最先进离散扩散模型相当的生成质量。FMLM在所有少步语言模型中表现优异，其一步生成质量甚至超过了其他模型的八步质量。

Conclusion: 本研究质疑了离散扩散过程对于离散模态生成建模的必要性，并为大规模加速流式语言模型铺平了道路。

Abstract: Language models based on discrete diffusion have attracted widespread interest for their potential to provide faster generation than autoregressive models. In practice, however, they exhibit a sharp degradation of sample quality in the few-step regime, failing to realize this promise. Here we show that language models leveraging flow-based continuous denoising can outperform discrete diffusion in both quality and speed. By revisiting the fundamentals of flows over discrete modalities, we build a flow-based language model (FLM) that performs Euclidean denoising over one-hot token encodings. We show that the model can be trained by predicting the clean data via a cross entropy objective, where we introduce a simple time reparameterization that greatly improves training stability and generation quality. By distilling FLM into its associated flow map, we obtain a distilled flow map language model (FMLM) capable of few-step generation. On the LM1B and OWT language datasets, FLM attains generation quality matching state-of-the-art discrete diffusion models. With FMLM, our approach outperforms recent few-step language models across the board, with one-step generation exceeding their 8-step quality. Our work calls into question the widely held hypothesis that discrete diffusion processes are necessary for generative modeling over discrete modalities, and paves the way toward accelerated flow-based language modeling at scale. Code is available at .

</details>


### [44] [Claim Automation using Large Language Model](https://arxiv.org/abs/2602.16836)
*Zhengda Mo,Zhiyu Quan,Eli O'Donohue,Kaiwen Zhong*

Main category: cs.CL

TL;DR: 通过LoRA对大型语言模型进行领域特定微调，以处理保险索赔中的非结构化叙述，生成结构化纠正措施建议，显著优于通用LLM，并实现约80%的案例与真实纠正措施几乎一致。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在通用语言任务上表现出色，但在保险等受监管和数据敏感领域的部署有限。本研究旨在利用LLM从非结构化索赔叙述中生成结构化纠正措施建议，以加速索赔理赔员的决策。

Method: 研究利用数百万历史保修索赔，通过低秩适应（LoRA）技术对预训练的LLM进行微调，将其应用于索赔处理流程中的初始决策模块。评估采用结合自动化语义相似性指标和人工评估的多维度框架。

Result: 领域特定的微调显著优于商用通用和基于提示的LLM，约80%的评估案例与真实纠正措施达到近乎一致的匹配。

Conclusion: 领域自适应微调能够使模型输出分布与实际操作数据更紧密地对齐，证明了其作为保险应用中可靠且可治理的构建模块的潜力。

Abstract: While Large Language Models (LLMs) have achieved strong performance on general-purpose language tasks, their deployment in regulated and data-sensitive domains, including insurance, remains limited. Leveraging millions of historical warranty claims, we propose a locally deployed governance-aware language modeling component that generates structured corrective-action recommendations from unstructured claim narratives. We fine-tune pretrained LLMs using Low-Rank Adaptation (LoRA), scoping the model to an initial decision module within the claim processing pipeline to speed up claim adjusters' decisions. We assess this module using a multi-dimensional evaluation framework that combines automated semantic similarity metrics with human evaluation, enabling a rigorous examination of both practical utility and predictive accuracy. Our results show that domain-specific fine-tuning substantially outperforms commercial general-purpose and prompt-based LLMs, with approximately 80% of the evaluated cases achieving near-identical matches to ground-truth corrective actions. Overall, this study provides both theoretical and empirical evidence to prove that domain-adaptive fine-tuning can align model output distributions more closely with real-world operational data, demonstrating its promise as a reliable and governable building block for insurance applications.

</details>


### [45] [BanglaSummEval: Reference-Free Factual Consistency Evaluation for Bangla Summarization](https://arxiv.org/abs/2602.16843)
*Ahmed Rafid,Rumman Adib,Fariya Ahmed,Ajwad Abrar,Mohammed Saidul Islam*

Main category: cs.CL

TL;DR: BanglaSummEval是一个无参考、基于问答的框架，用于评估孟加拉语摘要的事实一致性，并显示出与人类判断的高度相关性，为低资源语言提供实用解决方案。


<details>
  <summary>Details</summary>
Motivation: 评估事实一致性对于可靠的文本摘要至关重要，尤其是在医疗保健和新闻等高风险领域。然而，大多数现有评估指标忽略了孟加拉语这一广泛使用但资源匮乏的语言，并且通常依赖于参考摘要。

Method: 该方法名为BanglaSummEval，是一个无参考、基于问答（QA）的框架，用于评估孟加拉语摘要的事实准确性和内容覆盖率。它通过从源文档和摘要中自动生成问题和答案来实现。一个单一的多语言指令调优语言模型负责处理问题生成、问题回答、候选答案提取和问题重要性加权，从而降低了系统复杂性和计算成本。为了捕捉超越表面重叠的语义一致性，该方法使用BERTScore-Recall进行答案比较。

Result: BanglaSummEval在来自教育和医疗领域的300份人工编写摘要上进行了验证，结果表明与专家人工判断具有很强的相关性（Pearson's r = 0.694，Spearman's ρ = 0.763）。

Conclusion: BanglaSummEval为低资源语言环境下的事实一致性评估提供了一个实用且透明的解决方案，它能提供可解释的、分步诊断的评估结果和可靠的评估分数。

Abstract: Evaluating factual consistency is essential for reliable text summarization, particularly in high-stakes domains such as healthcare and news. However, most existing evaluation metrics overlook Bangla, a widely spoken yet under-resourced language, and often depend on reference summaries. We introduce BanglaSummEval, a reference-free, question-answering-based framework for evaluating factual consistency in Bangla summarization. The proposed method assesses both factual accuracy and content coverage through automatically generated questions and answers derived from the source document and the summary. A single multilingual instruction-tuned language model handles question generation, question answering, candidate answer extraction, and question importance weighting. This unified design reduces system complexity and computational cost. To capture semantic consistency beyond surface-level overlap, we use BERTScore-Recall for answer comparison. We validate BanglaSummEval on 300 human-written summaries from educational and medical domains, demonstrating strong correlation with expert human judgments (Pearson's $r = 0.694$, Spearman's $\rho = 0.763$). By providing interpretable, step-wise diagnostics alongside reliable evaluation scores, BanglaSummEval offers a practical and transparent solution for factual consistency evaluation in low-resource language settings.

</details>


### [46] [Meenz bleibt Meenz, but Large Language Models Do Not Speak Its Dialect](https://arxiv.org/abs/2602.16852)
*Minh Duc Bui,Manuel Mager,Peter Herbert Kann,Katharina von der Wense*

Main category: cs.CL

TL;DR: 本研究首次对濒危的美因茨方言Meenzerisch进行了NLP探索。我们创建了一个包含2,351个方言词汇的数字词典，并用它来测试LLMs生成方言定义和词汇的能力。结果显示，即使采用少量样本学习和规则提取，LLMs的准确率也低于10%，表明急需更多资源和对德国方言的深入研究。


<details>
  <summary>Details</summary>
Motivation: Meenzerisch是德国美因茨市的方言，也是美因茨狂欢节的传统语言，但它正濒临消亡，许多其他德国方言也面临同样命运。自然语言处理（NLP）有潜力帮助语言和方言的保护与复兴，然而此前没有任何NLP研究关注过Meenzerisch。本工作旨在首次将NLP研究明确聚焦于美因茨方言。

Method: 1. 构建了一个数字词典，这是一个基于现有资源（Schramm，1966）的NLP就绪数据集，包含2,351个方言词汇及其标准德语释义。
2. 使用该数据集评估了最先进的大型语言模型（LLMs）生成方言词汇定义以及根据定义生成方言词汇的能力。
3. 进行了额外实验，探究少量样本学习（few-shot learning）和从训练集中提取规则并传递给LLM是否能提高准确性。

Result: 1. LLMs在生成方言定义和方言词汇方面表现不佳：最佳定义模型的准确率仅为6.27%，最佳词汇生成模型的准确率为1.51%。
2. 少量样本学习和规则提取虽然能改善结果，但准确率仍低于10%。
3. 这表明LLMs在低资源方言处理方面存在显著局限性。

Conclusion: 急需更多资源和针对德国方言的研究投入。

Abstract: Meenzerisch, the dialect spoken in the German city of Mainz, is also the traditional language of the Mainz carnival, a yearly celebration well known throughout Germany. However, Meenzerisch is on the verge of dying out-a fate it shares with many other German dialects. Natural language processing (NLP) has the potential to help with the preservation and revival efforts of languages and dialects. However, so far no NLP research has looked at Meenzerisch. This work presents the first research in the field of NLP that is explicitly focused on the dialect of Mainz. We introduce a digital dictionary-an NLP-ready dataset derived from an existing resource (Schramm, 1966)-to support researchers in modeling and benchmarking the language. It contains 2,351 words in the dialect paired with their meanings described in Standard German. We then use this dataset to answer the following research questions: (1) Can state-of-the-art large language models (LLMs) generate definitions for dialect words? (2) Can LLMs generate words in Meenzerisch, given their definitions? Our experiments show that LLMs can do neither: the best model for definitions reaches only 6.27% accuracy and the best word generation model's accuracy is 1.51%. We then conduct two additional experiments in order to see if accuracy is improved by few-shot learning and by extracting rules from the training set, which are then passed to the LLM. While those approaches are able to improve the results, accuracy remains below 10%. This highlights that additional resources and an intensification of research efforts focused on German dialects are desperately needed.

</details>


### [47] [A Conceptual Hybrid Framework for Post-Quantum Security: Integrating BB84 QKD, AES, and Bio-inspired Mechanisms](https://arxiv.org/abs/2602.16922)
*Md. Ismiel Hossen Abir*

Main category: cs.CL

TL;DR: 该研究提出了一个混合安全框架，结合经典和量子技术（如AES、BB84 QKD、量子态比较和生物启发免疫系统），以应对量子计算对RSA的威胁，旨在后量子时代提供可扩展和自适应的数据保护。


<details>
  <summary>Details</summary>
Motivation: 量子计算对经典密码学（特别是RSA）构成重大风险，因为Shor算法能够以多项式时间有效破解RSA。为了确保后量子时代的数据保护，需要应对RSA在经典和量子攻击下的漏洞。

Method: 该研究设计了一个混合安全框架，结合了以下技术：AES加密（用于经典安全）、BB84量子密钥分发（用于安全密钥交换和窃听检测）、量子态比较（用于轻量级认证）以及受生物启发的免疫系统（用于自适应威胁检测）。

Result: 研究发现RSA易受Shor算法攻击；BB84在理想条件下能实现完整的密钥协商，并能高精度检测窃听。所提出的概念模型结合了经典和量子安全方法，提供了一种可扩展和自适应的后量子加密数据保护解决方案。

Conclusion: 该工作主要提出了一个概念性框架，详细的实现、安全证明和广泛的实验验证被认为是未来的工作。

Abstract: Quantum computing is a significant risk to classical cryptographic, especially RSA, which depends on the difficulty of factoring large numbers. Classical factorization methods, such as Trial Division and Pollard's Rho, are inefficient for large keys, while Shor's quantum algorithm can break RSA efficiently in polynomial time. This research studies RSA's vulnerabilities under both classical and quantum attacks and designs a hybrid security framework to ensure data protection in the post-quantum era. The conceptual framework combines AES encryption for classical security, BB84 Quantum Key Distribution (QKD) for secure key exchange with eavesdropping detection, quantum state comparison for lightweight authentication, and a bio-inspired immune system for adaptive threat detection. RSA is vulnerable to Shor's algorithm, BB84 achieves full key agreement in ideal conditions, and it detects eavesdropping with high accuracy. The conceptual model includes both classical and quantum security methods, providing a scalable and adaptive solution for Post-Quantum encryption data protection. This work primarily proposes a conceptual framework. Detailed implementation, security proofs, and extensive experimental validation are considered future work.

</details>


### [48] [ConvApparel: A Benchmark Dataset and Validation Framework for User Simulators in Conversational Recommenders](https://arxiv.org/abs/2602.16938)
*Ofer Meshi,Krisztian Balog,Sally Goldman,Avi Caciularu,Guy Tennenholtz,Jihwan Jeong,Amir Globerson,Craig Boutilier*

Main category: cs.CL

TL;DR: 该研究通过引入ConvApparel数据集和综合验证框架，解决了LLM用户模拟器存在的“真实性差距”问题。结果显示，所有模拟器都存在真实性差距，但数据驱动的模拟器在适应未见行为方面表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM用户模拟器存在“真实性差距”，导致其优化系统在真实世界中表现不佳。

Method: 引入了ConvApparel数据集，采用双智能体数据收集协议（包含“好”和“坏”推荐器），并结合统计对齐、人类相似度分数和反事实验证的综合验证框架。

Result: 所有模拟器都存在显著的真实性差距。然而，数据驱动的模拟器优于提示基线，尤其是在反事实验证中，它们能更真实地适应未见行为。

Conclusion: 尽管数据驱动的模拟器仍然不完美，但它们在适应未见行为方面表现出更强的鲁棒性，预示着更接近真实世界的用户模型。

Abstract: The promise of LLM-based user simulators to improve conversational AI is hindered by a critical "realism gap," leading to systems that are optimized for simulated interactions, but may fail to perform well in the real world. We introduce ConvApparel, a new dataset of human-AI conversations designed to address this gap. Its unique dual-agent data collection protocol -- using both "good" and "bad" recommenders -- enables counterfactual validation by capturing a wide spectrum of user experiences, enriched with first-person annotations of user satisfaction. We propose a comprehensive validation framework that combines statistical alignment, a human-likeness score, and counterfactual validation to test for generalization. Our experiments reveal a significant realism gap across all simulators. However, the framework also shows that data-driven simulators outperform a prompted baseline, particularly in counterfactual validation where they adapt more realistically to unseen behaviors, suggesting they embody more robust, if imperfect, user models.

</details>


### [49] [When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism Transfer Between Turkish and English](https://arxiv.org/abs/2602.16957)
*Hasan Can Biyik,Libby Barak,Jing Peng,Anna Feldman*

Main category: cs.CL

TL;DR: 研究发现跨语言委婉语检测存在迁移不对称性，语义重叠不足以保证正向迁移，尤其在低资源语言对中。标签分布差异和领域特定对齐影响迁移效果。


<details>
  <summary>Details</summary>
Motivation: 委婉语的跨文化和语用依赖性使得跨语言建模复杂化。本研究旨在探讨跨语言等效性如何影响多语言委婉语检测中的迁移学习。

Method: 研究将土耳其语和英语中的潜在委婉语术语（PETs）根据功能、语用和语义对齐分为重叠（OPETs）和非重叠（NOPETs）子集，以调查跨语言等效性如何影响多语言委婉语检测中的迁移学习。

Result: 研究发现迁移不对称性：语义重叠不足以保证正向迁移，尤其是在资源匮乏的土耳其语到英语方向，性能甚至可能下降，而在某些情况下，基于NOPET的训练可以改善性能。标签分布差异有助于解释这些反直觉结果。类别级别分析表明迁移可能受领域特定对齐的影响。

Conclusion: 跨语言等效性会影响多语言委婉语检测中的迁移学习，语义重叠不足以保证正向迁移，尤其是在资源匮乏的语言对中。标签分布差异和领域特定对齐是解释观察结果的关键因素。

Abstract: Euphemisms substitute socially sensitive expressions, often softening or reframing meaning, and their reliance on cultural and pragmatic context complicates modeling across languages. In this study, we investigate how cross-lingual equivalence influences transfer in multilingual euphemism detection. We categorize Potentially Euphemistic Terms (PETs) in Turkish and English into Overlapping (OPETs) and Non-Overlapping (NOPETs) subsets based on their functional, pragmatic, and semantic alignment. Our findings reveal a transfer asymmetry: semantic overlap is insufficient to guarantee positive transfer, particularly in low-resource Turkish-to-English direction, where performance can degrade even for overlapping euphemisms, and in some cases, improve under NOPET-based training. Differences in label distribution help explain these counterintuitive results. Category-level analysis suggests that transfer may be influenced by domain-specific alignment, though evidence is limited by sparsity.

</details>


### [50] [Eigenmood Space: Uncertainty-Aware Spectral Graph Analysis of Psychological Patterns in Classical Persian Poetry](https://arxiv.org/abs/2602.16959)
*Kourosh Shahnazari,Seyed Moein Ayyoubzadeh,Mohammadali Keshtparvar*

Main category: cs.CL

TL;DR: 本文提出了一种不确定性感知的计算框架，用于对古典波斯诗歌进行诗人层面的心理分析。该框架采用大规模自动多标签标注，将每节诗与心理概念、置信度分数和弃权标志关联起来，并通过聚合、散度测量和特征情感嵌入来量化诗人的个性和概念关系。结果表明，该框架支持可扩展、可审计的数字人文分析，同时通过传播不确定性来保持解释的谨慎性。


<details>
  <summary>Details</summary>
Motivation: 古典波斯诗歌通过隐喻、互文惯例和修辞间接性表达情感生活，这使得细读必不可少，但限制了大规模可重现的比较。本文的动机是开发一种计算框架来克服这一限制，同时保留解释的谨慎性。

Method: 1. 大规模自动多标签标注：将每节诗与一套心理概念、每个标签的置信度分数和指示证据不足的弃权标志相关联。
2. 聚合：将置信度加权的证据聚合成一个“诗人 × 概念”矩阵。
3. 个性量化：将每位诗人解释为概念上的概率分布，并使用詹森-香农散度（Jensen-Shannon divergence）和库尔巴克-莱布勒散度（Kullback-Leibler divergence）量化诗人与语料库基线的差异，从而衡量诗歌的个性。
4. 关系结构捕捉：构建一个概念上的置信度加权共现图，并通过拉普拉斯谱分解定义特征情感（Eigenmood）嵌入。
5. 不确定性处理：在包含10位诗人的61,573节诗歌语料库中，22.2%的诗节被弃权。进一步报告了在置信度阈值下的敏感性分析、将弃权视为一类的选择偏差诊断，以及沿特征情感轴检索诗节级示例的从远到近的工作流程。

Result: 该框架支持可扩展、可审计的数字人文分析，同时通过将不确定性从诗节级证据传播到诗人级推断来保留解释的谨慎性。22.2%的诗节被弃权，这强调了不确定性在分析中的重要性。

Conclusion: 本文开发的不确定性感知计算框架能够对古典波斯诗歌进行可扩展、可审计的心理分析，并通过在整个分析过程中明确处理和传播不确定性来保持解释的谨慎性。

Abstract: Classical Persian poetry is a historically sustained archive in which affective life is expressed through metaphor, intertextual convention, and rhetorical indirection. These properties make close reading indispensable while limiting reproducible comparison at scale. We present an uncertainty-aware computational framework for poet-level psychological analysis based on large-scale automatic multi-label annotation. Each verse is associated with a set of psychological concepts, per-label confidence scores, and an abstention flag that signals insufficient evidence. We aggregate confidence-weighted evidence into a Poet $\times$ Concept matrix, interpret each poet as a probability distribution over concepts, and quantify poetic individuality as divergence from a corpus baseline using Jensen--Shannon divergence and Kullback--Leibler divergence. To capture relational structure beyond marginals, we build a confidence-weighted co-occurrence graph over concepts and define an Eigenmood embedding through Laplacian spectral decomposition. On a corpus of 61{,}573 verses across 10 poets, 22.2\% of verses are abstained, underscoring the analytical importance of uncertainty. We further report sensitivity analysis under confidence thresholding, selection-bias diagnostics that treat abstention as a category, and a distant-to-close workflow that retrieves verse-level exemplars along Eigenmood axes. The resulting framework supports scalable, auditable digital-humanities analysis while preserving interpretive caution by propagating uncertainty from verse-level evidence to poet-level inference.

</details>


### [51] [Evaluating Cross-Lingual Classification Approaches Enabling Topic Discovery for Multilingual Social Media Data](https://arxiv.org/abs/2602.17051)
*Deepak Uniyal,Md Abul Bashar,Richi Nayak*

Main category: cs.CL

TL;DR: 本研究分析了不同的跨语言文本分类方法，用于大规模多语言社交媒体讨论中的内容过滤和主题发现，以氢能推文为例。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理在分析多语言社交媒体讨论方面面临巨大挑战，尤其是在大型公共辩论跨越多种语言时。本研究旨在探讨跨语言文本分类方法如何支持对全球对话进行可靠分析。

Method: 研究使用了一个长达十年（2013-2022年）的、包含超过九百万条关于氢能的英文、日文、印地文和韩文推文数据集。针对关键词驱动数据收集导致的无关内容问题，探索了四种内容过滤方法：1）将英文标注数据翻译成目标语言以构建特定语言模型；2）将所有语言的未标注数据翻译成英文，基于英文标注创建单一模型；3）将英文微调的多语言Transformer直接应用于各目标语言数据；4）结合翻译标注和多语言训练的混合策略。每种方法都通过过滤噪声数据中与氢能相关的推文的能力进行评估。随后，对相关子集进行主题建模以提取主要主题。

Result: 结果揭示了翻译方法和多语言方法之间的关键权衡。

Conclusion: 研究为优化大规模社交媒体分析的跨语言管道提供了可行的见解。

Abstract: Analysing multilingual social media discourse remains a major challenge in natural language processing, particularly when large-scale public debates span across diverse languages. This study investigates how different approaches for cross-lingual text classification can support reliable analysis of global conversations. Using hydrogen energy as a case study, we analyse a decade-long dataset of over nine million tweets in English, Japanese, Hindi, and Korean (2013--2022) for topic discovery. The online keyword-driven data collection results in a significant amount of irrelevant content. We explore four approaches to filter relevant content: (1) translating English annotated data into target languages for building language-specific models for each target language, (2) translating unlabelled data appearing from all languages into English for creating a single model based on English annotations, (3) applying English fine-tuned multilingual transformers directly to each target language data, and (4) a hybrid strategy that combines translated annotations with multilingual training. Each approach is evaluated for its ability to filter hydrogen-related tweets from noisy keyword-based collections. Subsequently, topic modeling is performed to extract dominant themes within the relevant subsets. The results highlight key trade-offs between translation and multilingual approaches, offering actionable insights into optimising cross-lingual pipelines for large-scale social media analysis.

</details>


### [52] [ALPS: A Diagnostic Challenge Set for Arabic Linguistic & Pragmatic Reasoning](https://arxiv.org/abs/2602.17054)
*Hussein S. Al-Olimat,Ahmad Alshareef*

Main category: cs.CL

TL;DR: 本研究引入了ALPS，一个专注于深层语义和语用学的阿拉伯语诊断基准，解决了现有基准数据合成或翻译的问题。通过评估23个模型，发现模型在形态句法依赖性方面存在明显不足，尽管顶级商业模型超越了人类平均水平，但与阿拉伯语原生模型仍有差距。


<details>
  <summary>Details</summary>
Motivation: 现有的阿拉伯语NLP基准虽然规模大，但常依赖合成或翻译数据，缺乏深层语言验证。研究旨在创建一个关注语言深度理解、探究深层语义和语用学的诊断挑战集，以弥补现有基准的不足。

Method: 研究引入了ALPS（Arabic Linguistic & Pragmatic Suite）诊断挑战集，该数据集是原生的、由专家策划，旨在探测深层语义和语用学。ALPS包含531个精心设计的问题，涵盖15个任务和47个子任务，强调语言理解的深度。数据集的开发结合了阿拉伯语语言学专业知识，确保了文化真实性并消除了翻译痕迹。研究评估了23种不同的模型（商业、开源和阿拉伯语原生模型），并将其表现与单次人类表现（平均84.6%准确率）以及专家裁定的Oracle（99.2%）进行对比。

Result: 模型展现出高流畅性，但在基本的形态句法依赖性上表现不佳。在依赖变音符号的任务中，形态句法依赖性的错误率较高（36.5%），远高于组合语义。顶级商业模型（Gemini-3-flash，94.2%）超越了平均单次人类表现。然而，商业巨头与阿拉伯语原生模型之间存在显著差距，其中最好的阿拉伯语特定模型（Jais-2-70B，83.6%）接近但未能达到人类表现。

Conclusion: 现有模型在深层阿拉伯语语言理解，特别是形态句法依赖性方面仍有显著不足。虽然顶级商业模型表现优异，但阿拉伯语原生模型与人类表现之间仍存在差距，表明需要进一步研究和提升其在文化真实性和语言深度方面的性能。

Abstract: While recent Arabic NLP benchmarks focus on scale, they often rely on synthetic or translated data which may benefit from deeper linguistic verification. We introduce ALPS (Arabic Linguistic & Pragmatic Suite), a native, expert-curated diagnostic challenge set probing Deep Semantics and Pragmatics, capabilities that complement specialized large-scale benchmarks. While broad-coverage benchmarks prioritize scale and multi-task coverage, ALPS targets the depth of linguistic understanding through 531 rigorously crafted questions across 15 tasks and 47 subtasks. We developed the dataset with deep expertise in Arabic linguistics, guaranteeing cultural authenticity and eliminating translation artifacts. Evaluating 23 diverse models (commercial, open-source, and Arabic-native) against a single-pass human performance (avg. 84.6% accuracy) and an expert-adjudicated oracle (99.2%), we reveal a critical dissociation: models achieve high fluency but fail on fundamental morpho-syntactic dependencies, with elevated error rates on morpho-syntactic dependencies (36.5% across diacritics-reliant tasks) compared to compositional semantics. While top commercial models (Gemini-3-flash at 94.2%) surpass the average single human, a substantial gap persists between commercial giants and Arabic-native models, with the best Arabic-specific model (Jais-2-70B at 83.6%) approaching but not matching human performance.

</details>


### [53] [BankMathBench: A Benchmark for Numerical Reasoning in Banking Scenarios](https://arxiv.org/abs/2602.17072)
*Yunseung Lee,Subin Kim,Youngjun Kwak,Jaegul Choo*

Main category: cs.CL

TL;DR: 本文提出了BankMathBench，一个针对金融领域LLM数值推理的银行任务数据集，旨在解决现有模型在核心银行计算中准确性低且现有基准不足的问题。通过在该数据集上训练并进行工具增强微调，LLM在公式生成和数值推理准确性上取得了显著提升，证明了BankMathBench在评估和推进LLM银行领域数值推理能力方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在核心银行计算（如总支付估算、不同利率产品比较和提前还款利息计算）中准确性较低，且现有基准未能充分捕捉这些错误。数学数据集侧重基础数学问题，金融基准主要针对金融文档，导致日常银行场景未被充分探索。

Method: 提出了BankMathBench，一个反映真实银行任务的领域特定数据集，并根据单产品推理、多产品比较和多条件场景将其分为基本、中级和高级三个难度级别。通过在该数据集上训练开源LLM并进行工具增强微调。

Result: 在BankMathBench上训练后，开源LLM在公式生成和数值推理准确性方面均有显著提高。通过工具增强微调，模型在基本、中级和高级难度上，相对于零样本基线，平均准确率分别提高了57.6%p、75.1%p和62.9%p。

Conclusion: BankMathBench是评估和提升LLM在实际银行场景中数值推理能力的可靠基准。

Abstract: Large language models (LLMs)-based chatbots are increasingly being adopted in the financial domain, particularly in digital banking, to handle customer inquiries about products such as deposits, savings, and loans. However, these models still exhibit low accuracy in core banking computations-including total payout estimation, comparison of products with varying interest rates, and interest calculation under early repayment conditions. Such tasks require multi-step numerical reasoning and contextual understanding of banking products, yet existing LLMs often make systematic errors-misinterpreting product types, applying conditions incorrectly, or failing basic calculations involving exponents and geometric progressions. However, such errors have rarely been captured by existing benchmarks. Mathematical datasets focus on fundamental math problems, whereas financial benchmarks primarily target financial documents, leaving everyday banking scenarios underexplored. To address this limitation, we propose BankMathBench, a domain-specific dataset that reflects realistic banking tasks. BankMathBench is organized in three levels of difficulty-basic, intermediate, and advanced-corresponding to single-product reasoning, multi-product comparison, and multi-condition scenarios, respectively. When trained on BankMathBench, open-source LLMs exhibited notable improvements in both formula generation and numerical reasoning accuracy, demonstrating the dataset's effectiveness in enhancing domain-specific reasoning. With tool-augmented fine-tuning, the models achieved average accuracy increases of 57.6%p (basic), 75.1%p (intermediate), and 62.9%p (advanced), representing significant gains over zero-shot baselines. These findings highlight BankMathBench as a reliable benchmark for evaluating and advancing LLMs' numerical reasoning in real-world banking scenarios.

</details>


### [54] [The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI](https://arxiv.org/abs/2602.17127)
*Dusan Bosnjakovic*

Main category: cs.CL

TL;DR: 本论文提出了一个基于心理测量理论的新审计框架，用于量化大型语言模型中持久的、提供者级别的行为签名（如优化偏见、奉承等），发现即使在项目层面的高变异性下，模型行为也存在显著的“实验室信号”聚类，表明潜在偏见可能在AI架构中形成递归的意识形态回音室。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）从独立的聊天界面转变为多智能体系统和递归评估循环（LLM即评判者）中的基础推理层，检测持久的、提供者级别的行为特征对于安全和治理至关重要。传统的基准测试衡量瞬态任务准确性，但未能捕捉稳定的、潜在的响应策略——即在训练和对齐过程中嵌入的、超越单个模型版本的“普遍心态”。

Method: 该研究引入了一个新颖的审计框架，利用心理测量理论（特别是序数不确定性下的潜在特质估计）来量化LLM的行为倾向，而不依赖于真实标签。具体方法包括使用强制选择序数小插曲，这些小插曲被语义正交诱饵掩盖，并受密码学置换不变性控制。审计了九个领先模型，评估了优化偏见、奉承和现状合法化等维度。使用混合线性模型（MixedLM）和组内相关系数（ICC）分析。

Result: 研究发现，虽然项目层面的框架导致了高变异性，但持久的“实验室信号”解释了显著的行为聚类。

Conclusion: 在“锁定”的供应商生态系统中，潜在偏见并非静态错误，而是复合变量，可能在多层AI架构中创建递归的意识形态回音室，从而带来风险。

Abstract: As Large Language Models (LLMs) transition from standalone chat interfaces to foundational reasoning layers in multi-agent systems and recursive evaluation loops (LLM-as-a-judge), the detection of durable, provider-level behavioral signatures becomes a critical requirement for safety and governance. Traditional benchmarks measure transient task accuracy but fail to capture stable, latent response policies -- the ``prevailing mindsets'' embedded during training and alignment that outlive individual model versions. This paper introduces a novel auditing framework that utilizes psychometric measurement theory -- specifically latent trait estimation under ordinal uncertainty -- to quantify these tendencies without relying on ground-truth labels. Utilizing forced-choice ordinal vignettes masked by semantically orthogonal decoys and governed by cryptographic permutation-invariance, the research audits nine leading models across dimensions including Optimization Bias, Sycophancy, and Status-Quo Legitimization. Using Mixed Linear Models (MixedLM) and Intraclass Correlation Coefficient (ICC) analysis, the research identifies that while item-level framing drives high variance, a persistent ``lab signal'' accounts for significant behavioral clustering. These findings demonstrate that in ``locked-in'' provider ecosystems, latent biases are not merely static errors but compounding variables that risk creating recursive ideological echo chambers in multi-layered AI architectures.

</details>


### [55] [Quantifying and Mitigating Socially Desirable Responding in LLMs: A Desirability-Matched Graded Forced-Choice Psychometric Study](https://arxiv.org/abs/2602.17262)
*Kensuke Okada,Yui Furukawa,Kyosuke Bunji*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在自呈问卷中存在社会期望反应（SDR），这会偏倚评估结果。本文提出了一个心理测量学框架来量化和缓解LLMs问卷评估中的SDR，通过指令对比和匹配期望度的等级强制选择（GFC）格式，研究表明GFC能显著降低SDR，同时保持对预期角色画像的恢复。


<details>
  <summary>Details</summary>
Motivation: 人类自呈问卷在大型语言模型（LLMs）的基准测试和审计中应用日益广泛，但LLMs倾向于给出社会偏好的答案，即社会期望反应（SDR），这会偏倚问卷得分和后续结论。因此，需要一个方法来量化和缓解LLMs问卷评估中的SDR。

Method: 1. **量化SDR：** 在“诚实”与“假装表现良好”的指令下进行相同的问卷测试，SDR通过项目反应理论（IRT）估计的潜在分数计算为方向校正的标准化效应大小，以实现跨构念和反应格式的比较，并与人类模拟作弊基准进行对照。2. **缓解SDR：** 通过约束优化，从项目库中选择30对跨领域项目，构建了一个匹配期望度的等级强制选择（GFC）大五人格问卷。

Result: 1. 在对具有已知目标画像的合成角色进行评估时，九个经过指令微调的LLMs在李克特式问卷中始终表现出较大的SDR。2. 匹配期望度的GFC问卷能显著减弱SDR。3. GFC在很大程度上保留了对预期角色画像的恢复。4. 结果揭示了一个模型依赖的SDR-恢复权衡。

Conclusion: 大型语言模型在基于问卷的评估中表现出社会期望反应（SDR）。本文提出的等级强制选择（GFC）格式能有效缓解SDR，同时保持角色画像的恢复。这些结果强调了在LLMs问卷基准测试和审计中，需要采用SDR感知（SDR-aware）的报告实践。

Abstract: Human self-report questionnaires are increasingly used in NLP to benchmark and audit large language models (LLMs), from persona consistency to safety and bias assessments. Yet these instruments presume honest responding; in evaluative contexts, LLMs can instead gravitate toward socially preferred answers-a form of socially desirable responding (SDR)-biasing questionnaire-derived scores and downstream conclusions. We propose a psychometric framework to quantify and mitigate SDR in questionnaire-based evaluation of LLMs. To quantify SDR, the same inventory is administered under HONEST versus FAKE-GOOD instructions, and SDR is computed as a direction-corrected standardized effect size from item response theory (IRT)-estimated latent scores. This enables comparisons across constructs and response formats, as well as against human instructed-faking benchmarks. For mitigation, we construct a graded forced-choice (GFC) Big Five inventory by selecting 30 cross-domain pairs from an item pool via constrained optimization to match desirability. Across nine instruction-tuned LLMs evaluated on synthetic personas with known target profiles, Likert-style questionnaires show consistently large SDR, whereas desirability-matched GFC substantially attenuates SDR while largely preserving the recovery of the intended persona profiles. These results highlight a model-dependent SDR-recovery trade-off and motivate SDR-aware reporting practices for questionnaire-based benchmarking and auditing of LLMs.

</details>


### [56] [Towards Cross-lingual Values Assessment: A Consensus-Pluralism Perspective](https://arxiv.org/abs/2602.17283)
*Yukun Chen,Xinyu Zhang,Jialong Tang,Yu Wan,Baosong Yang,Yiming Li,Zhan Qin,Kui Ren*

Main category: cs.CL

TL;DR: 本研究引入了X-Value，一个跨语言价值观评估基准，以弥补当前LLM内容安全评估中对深层价值观维度的忽视。评估结果表明，当前SOTA LLM在跨语言价值观评估中表现不足且存在显著的语言差异，凸显了提升LLM价值观感知能力的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在内容安全方面发挥着关键作用，但当前的评估范式主要侧重于检测显式危害（例如暴力或仇恨言论），而忽视了数字内容中传达的更微妙的价值观维度。为了弥补这一差距，本研究旨在评估LLM对内容深层价值观进行全球视角评估的能力。

Method: 引入了X-Value，这是一个新颖的跨语言价值观评估基准，旨在评估LLM从全球视角评估内容深层价值观的能力。X-Value包含超过5,000个跨18种语言的问答对，系统地组织成7个核心领域，这些领域基于Schwartz基本人类价值观理论，并分为简单和困难级别。此外，提出了一种独特的两阶段标注框架：首先识别问题属于全球共识（如人权）还是多元主义（如宗教），随后对内容中隐含的潜在价值观进行多方评估。

Result: 对X-Value的系统评估显示，当前最先进的LLM在跨语言价值观评估方面表现出不足（准确率低于77%），并且在不同语言之间存在显著的性能差异（准确率差异超过20%）。

Conclusion: 这项工作强调了LLM迫切需要提升其细致入微、具备价值观意识的内容评估能力。

Abstract: While large language models (LLMs) have become pivotal to content safety, current evaluation paradigms primarily focus on detecting explicit harms (e.g., violence or hate speech), neglecting the subtler value dimensions conveyed in digital content. To bridge this gap, we introduce X-Value, a novel Cross-lingual Values Assessment Benchmark designed to evaluate LLMs' ability to assess deep-level values of content from a global perspective. X-Value consists of more than 5,000 QA pairs across 18 languages, systematically organized into 7 core domains grounded in Schwartz's Theory of Basic Human Values and categorized into easy and hard levels for discriminative evaluation. We further propose a unique two-stage annotation framework that first identifies whether an issue falls under global consensus (e.g., human rights) or pluralism (e.g., religion), and subsequently conducts a multi-party evaluation of the latent values embedded within the content. Systematic evaluations on X-Value reveal that current SOTA LLMs exhibit deficiencies in cross-lingual values assessment ($Acc < 77\%$), with significant performance disparities across different languages ($\Delta Acc > 20\%$). This work highlights the urgent need to improve the nuanced, values-aware content assessment capability of LLMs. Our X-Value is available at: .

</details>


### [57] [Representation Collapse in Machine Translation Through the Lens of Angular Dispersion](https://arxiv.org/abs/2602.17287)
*Evgeniia Tokarchuk,Maya K. Nachesa,Sergey Troshin,Vlad Niculae*

Main category: cs.CL

TL;DR: 本文分析了Transformer架构下神经机器翻译模型中的表征坍塌现象，并提出了一种基于角离散的正则化方法，该方法不仅能缓解坍塌，还能提高翻译质量，且在量化模型中依然有效。


<details>
  <summary>Details</summary>
Motivation: 现代基于Transformer架构的神经翻译模型在标准下一词预测训练策略下可能出现表征坍塌，特别是在深层和连续输出的神经机器翻译中更为明显，导致几何空间利用效率低下。

Method: 本文分析了离散和连续NMT Transformer在训练过程中不同层级的表征坍塌动态。研究中整合了一种基于角离散的现有正则化方法。

Result: 经验证明，基于角离散的正则化方法不仅能缓解表征坍塌，还能提高翻译质量。此外，量化模型也表现出类似的坍塌行为，并且正则化的益处在量化后依然得以保留。

Conclusion: 通过引入角离散正则化方法，可以有效缓解Transformer架构下的神经机器翻译模型的表征坍塌问题，从而提高翻译质量，并且该方法在离散、连续及量化模型中均能保持其有效性。

Abstract: Modern neural translation models based on the Transformer architecture are known for their high performance, particularly when trained on high-resource datasets. A standard next-token prediction training strategy, while widely adopted in practice, may lead to overlooked artifacts such as representation collapse. Previous works have shown that this problem is especially pronounced in the representation of the deeper Transformer layers, where it often fails to efficiently utilize the geometric space. Representation collapse is even more evident in end-to-end training of continuous-output neural machine translation, where the trivial solution would be to set all vectors to the same value. In this work, we analyze the dynamics of representation collapse at different levels of discrete and continuous NMT transformers throughout training. We incorporate an existing regularization method based on angular dispersion and demonstrate empirically that it not only mitigates collapse but also improves translation quality. Furthermore, we show that quantized models exhibit similar collapse behavior and that the benefits of regularization are preserved even after quantization.

</details>


### [58] [Same Meaning, Different Scores: Lexical and Syntactic Sensitivity in LLM Evaluation](https://arxiv.org/abs/2602.17316)
*Bogdan Kostić,Conor Fallon,Julian Risch,Alexander Löser*

Main category: cs.CL

TL;DR: LLMs对输入提示中的词汇和句法扰动高度敏感，词汇扰动导致性能显著下降，句法扰动效果不一。这表明LLMs更依赖表层模式而非抽象语言能力，强调了鲁棒性测试在LLM评估中的必要性。


<details>
  <summary>Details</summary>
Motivation: 尽管标准化评估基准是LLM模型比较的主要工具，但其可靠性因模型对输入提示中浅层变化的敏感性而受到质疑。

Method: 本研究采用两种语言学原理驱动的管道来生成语义不变的变体：一种使用同义词替换进行词汇变化，另一种使用依存句法分析确定适用的句法转换。研究了这些扰动对23个LLM在MMLU、SQuAD和AMEGA三个基准上的绝对性能和相对排名的影响。

Result: 1. 词汇扰动在几乎所有模型和任务中持续导致显著的性能下降。
2. 句法扰动具有异质性效应，有时会提高结果。
3. 两种扰动类型都动摇了复杂任务上的模型排行榜。
4. 模型鲁棒性与模型大小之间没有持续的正相关性，显示出强烈的任务依赖性。

Conclusion: LLMs更多地依赖于表层词汇模式而非抽象语言能力，这凸显了在LLM评估中将鲁棒性测试作为标准组成部分的必要性。

Abstract: The rapid advancement of Large Language Models (LLMs) has established standardized evaluation benchmarks as the primary instrument for model comparison. Yet, their reliability is increasingly questioned due to sensitivity to shallow variations in input prompts. This paper examines how controlled, truth-conditionally equivalent lexical and syntactic perturbations affect the absolute performance and relative ranking of 23 contemporary LLMs across three benchmarks: MMLU, SQuAD, and AMEGA. We employ two linguistically principled pipelines to generate meaning-preserving variations: one performing synonym substitution for lexical changes, and another using dependency parsing to determine applicable syntactic transformations. Results show that lexical perturbations consistently induce substantial, statistically significant performance degradation across nearly all models and tasks, while syntactic perturbations have more heterogeneous effects, occasionally improving results. Both perturbation types destabilize model leaderboards on complex tasks. Furthermore, model robustness did not consistently scale with model size, revealing strong task dependence. Overall, the findings suggest that LLMs rely more on surface-level lexical patterns than on abstract linguistic competence, underscoring the need for robustness testing as a standard component of LLM evaluation.

</details>


### [59] [RPDR: A Round-trip Prediction-Based Data Augmentation Framework for Long-Tail Question Answering](https://arxiv.org/abs/2602.17366)
*Yiming Zhang,Siyue Zhang,Junbo Zhao,Chen Zhao*

Main category: cs.CL

TL;DR: 本研究提出了 RPDR，一个新颖的数据增强框架，通过选择高质量的易学训练数据来增强密集检索器，显著提升了大型语言模型在长尾问答任务中的表现，尤其是在极端长尾类别上。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长尾问答中面临重大挑战，因为它们获取和准确回忆不常见知识的能力有限。尽管检索增强生成（RAG）系统在缓解这一限制方面显示出巨大潜力，但密集检索模型在泛化到稀有或小众知识时常常面临相同的困难。

Method: RPDR 方法包含三个核心组件：合成数据生成、使用“往返预测”（Round-Trip prediction）进行数据选择以识别易学实例，以及使用这些实例进行检索器训练。

Result: RPDR 在两个长尾检索基准 PopQA 和 EntityQuestion 上进行了评估，结果表明其比现有检索器（如 BM25 和 Contriver）有显著改进，尤其是在极端长尾类别上。

Conclusion: 通过详细的人工分析，我们确定了 RPDR 的优势和局限性，并提出了一个动态路由机制，以将查询动态路由到专门的检索模块，从而进一步提高检索性能。

Abstract: Long-tail question answering presents significant challenges for large language models (LLMs) due to their limited ability to acquire and accurately recall less common knowledge. Retrieval-augmented generation (RAG) systems have shown great promise in mitigating this limitation by integrating external retrieval mechanisms. However, dense retrieval models often face the same difficulties when generalizing to rare or niche knowledge. In this study, we introduce RPDR, a novel data augmentation framework that selects high-quality easy-to-learn training data, to enhance dense retrievers. Our approach is built around three core components: synthetic data generation, data selection with Round-Trip prediction to identify easy-to-learn instances, and retriever training with these instances. We evaluate RPDR on two long-tail retrieval benchmarks, PopQA and EntityQuestion, demonstrating substantial improvements over existing retrievers like BM25 and Contriver, especially on extremely long-tail categories. We identify the strengths and limitations of RPDR through detailed human analysis and propose a dynamic routing mechanism to dynamically route queries to specialized retrieval modules to further improve retrieval performance.

</details>


### [60] [The Role of the Availability Heuristic in Multiple-Choice Answering Behaviour](https://arxiv.org/abs/2602.17377)
*Leonidas Zotos,Hedderik van Rijn,Malvina Nissim*

Main category: cs.CL

TL;DR: 本文研究多项选择题中“可用性启发式”策略，发现正确答案在大型语料库中显著更普遍。选择最可用的选项可显著提高分数（13.5%-32.9%高于随机猜测），且此模式在LLM生成的选项中也存在。


<details>
  <summary>Details</summary>
Motivation: 当学生不确定多项选择题（MCQ）的正确答案时，通常会进行猜测。本文旨在探讨“可用性启发式”（Availability heuristic）——即选择最容易想到的选项（通过概念在大型语料库中的普遍性来操作化），是否是回答多项选择题的有效策略。

Method: 本文提出了一种计算方法，通过概念在大型语料库（如维基百科）中的普遍性来评估多项选择题选项的认知可用性。该方法在三个大型问题集上进行了测试，并分析了大型语言模型（LLM）生成的选择题选项。

Result: 研究发现，正确答案（独立于问题干）比不正确的选择题选项具有显著更高的可用性。具体而言，使用维基百科作为检索语料库时，始终选择最可用的选项可以将分数提高到比随机猜测基线高出13.5%到32.9%。此外，大型语言模型（LLM）生成的选择题选项显示出与专家创建的选项相似的可用性模式。

Conclusion: 在当前和未来的学生行为计算建模工作中，应考虑可用性（availability）这一因素。

Abstract: When students are unsure of the correct answer to a multiple-choice question (MCQ), guessing is common practice. The availability heuristic, proposed by A. Tversky and D. Kahneman in 1973, suggests that the ease with which relevant instances come to mind, typically operationalised by the mere frequency of exposure, can offer a mental shortcut for problems in which the test-taker does not know the exact answer. Is simply choosing the option that comes most readily to mind a good strategy for answering MCQs? We propose a computational method of assessing the cognitive availability of MCQ options operationalised by concepts' prevalence in large corpora. The key finding, across three large question sets, is that correct answers, independently of the question stem, are significantly more available than incorrect MCQ options. Specifically, using Wikipedia as the retrieval corpus, we find that always selecting the most available option leads to scores 13.5% to 32.9% above the random-guess baseline. We further find that LLM-generated MCQ options show similar patterns of availability compared to expert-created options, despite the LLMs' frequentist nature and their training on large collections of textual data. Our findings suggest that availability should be considered in current and future work when computationally modelling student behaviour.

</details>


### [61] [Diverse Word Choices, Same Reference: Annotating Lexically-Rich Cross-Document Coreference](https://arxiv.org/abs/2602.17424)
*Anastasia Zhukova,Felix Hamborg,Karsten Donnay,Norman Meuschke,Bela Gipp*

Main category: cs.CL

TL;DR: 本文提出了一种修订的NewsWCL50数据集的跨文档共指消解（CDCR）标注方案，将共指链视为语篇元素，以处理新闻语篇中词汇多样性和框架变化，并通过重新标注数据集验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的CDCR数据集主要关注事件消解，并采用狭义的共指定义，限制了它们在分析词汇差异大且极化的新闻报道中的有效性。

Method: 提出了一种修订的CDCR标注方案，将共指链视为语篇元素（DEs）和概念分析单元，以适应同一性和近同一性关系。使用统一的编码本重新标注了NewsWCL50和ECB+的一个子集。通过词汇多样性指标和同头词引理基线评估了新数据集。

Result: 重新标注的数据集紧密对齐，介于原始ECB+和NewsWCL50之间。

Conclusion: 重新标注的数据集紧密对齐，介于原始ECB+和NewsWCL50之间，支持新闻领域中平衡且注重语篇的跨文档共指消解研究。

Abstract: Cross-document coreference resolution (CDCR) identifies and links mentions of the same entities and events across related documents, enabling content analysis that aggregates information at the level of discourse participants. However, existing datasets primarily focus on event resolution and employ a narrow definition of coreference, which limits their effectiveness in analyzing diverse and polarized news coverage where wording varies widely. This paper proposes a revised CDCR annotation scheme of the NewsWCL50 dataset, treating coreference chains as discourse elements (DEs) and conceptual units of analysis. The approach accommodates both identity and near-identity relations, e.g., by linking "the caravan" - "asylum seekers" - "those contemplating illegal entry", allowing models to capture lexical diversity and framing variation in media discourse, while maintaining the fine-grained annotation of DEs. We reannotate the NewsWCL50 and a subset of ECB+ using a unified codebook and evaluate the new datasets through lexical diversity metrics and a same-head-lemma baseline. The results show that the reannotated datasets align closely, falling between the original ECB+ and NewsWCL50, thereby supporting balanced and discourse-aware CDCR research in the news domain.

</details>


### [62] [Evaluating Extremely Low-Resource Machine Translation: A Comparative Study of ChrF++ and BLEU Metrics](https://arxiv.org/abs/2602.17425)
*Sanjeev Kumar,Preethi Jyothi,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本研究比较了BLEU和ChrF++在极低资源语言（ELRL）机器翻译（MT）评估中的表现，发现尽管ChrF++常被使用，但BLEU能提供有价值的互补词汇精度见解，提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 在极低资源语言（ELRL）场景中评估机器翻译（MT）质量面临独特挑战，因为广泛使用的BLEU等指标在高资源环境下有效，但在数据稀缺背景下常错误地代表质量。

Method: 比较了基于n-gram的BLEU和基于字符的ChrF++，评估其在马加希语、博杰普尔语和恰蒂斯加尔语这三种极低资源语言中对幻觉、重复、原文复制和变音符号（matra）变体等翻译伪影的响应，重点关注大型语言模型（LLMs）和神经机器翻译（NMT）系统的输出。

Result: 尽管BLEU的绝对分数较低，但它提供了互补的词汇精度见解，从而提高了可解释性。

Conclusion: 在极低资源语言机器翻译评估中，尽管ChrF++常被依赖，但BLEU提供互补的词汇精度见解，提高了评估的可解释性。

Abstract: Evaluating machine translation (MT) quality in extremely low-resource language (ELRL) scenarios poses unique challenges, as widely used metrics such as BLEU, effective in high-resource settings, often misrepresent quality in data-scarce contexts. This work presents a comparative analysis of BLEU, an n-gram-based metric, and ChrF++, a character-based metric, for MT evaluation in ELRL settings. We examine how each metric responds to translation artifacts, including hallucinations, repetition, source-text copying, and diacritic (\textit{matra}) variations across three ELRLs: Magahi, Bhojpuri, and Chhattisgarhi, with a focus on outputs from large language models (LLMs) and neural MT (NMT) systems. While recent work often relies solely on ChrF++, our findings show that BLEU, despite its lower absolute scores, provides complementary lexical-precision insights that improve interpretability.

</details>


### [63] [Fine-Grained Uncertainty Quantification for Long-Form Language Model Outputs: A Comparative Study](https://arxiv.org/abs/2602.17431)
*Dylan Bouchard,Mohit Singh Chauhan,Viren Bajaj,David Skarbrevik*

Main category: cs.CL

TL;DR: 针对LLMs长文本输出的幻觉检测问题，本文提出了一种细粒度不确定性量化分类法，并实验验证了不同评分策略和不确定性感知解码的有效性，为提升长文本事实性提供了实践指导。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型语言模型（LLMs）闭卷幻觉检测的不确定性量化方法主要为短文本输出设计，不适用于长文本生成。

Method: 引入了一种针对长文本LLM输出进行细粒度不确定性量化的分类法，该分类法在响应分解、单元级别评分和响应级别聚合三个阶段区分设计选择。同时，形式化了几种基于一致性的黑盒评分器，对现有方法进行了推广和扩展。

Result: 1) “主张-响应蕴涵”（claim-response entailment）表现始终优于或与更复杂的主张级别评分器持平。2) 主张级别评分通常比句子级别评分效果更好。3) 不确定性感知解码对于提高长文本输出的事实性非常有效。

Conclusion: 该框架阐明了现有方法之间的关系，实现了公平比较，并为选择细粒度不确定性量化（UQ）组件提供了实用指导。

Abstract: Uncertainty quantification has emerged as an effective approach to closed-book hallucination detection for LLMs, but existing methods are largely designed for short-form outputs and do not generalize well to long-form generation. We introduce a taxonomy for fine-grained uncertainty quantification in long-form LLM outputs that distinguishes methods by design choices at three stages: response decomposition, unit-level scoring, and response-level aggregation. We formalize several families of consistency-based black-box scorers, providing generalizations and extensions of existing methods. In our experiments across multiple LLMs and datasets, we find 1) claim-response entailment consistently performs better or on par with more complex claim-level scorers, 2) claim-level scoring generally yields better results than sentence-level scoring, and 3) uncertainty-aware decoding is highly effective for improving the factuality of long-form outputs. Our framework clarifies relationships between prior methods, enables apples-to-apples comparisons, and provides practical guidance for selecting components for fine-grained UQ.

</details>


### [64] [AIDG: Evaluating Asymmetry Between Information Extraction and Containment in Multi-Turn Dialogue](https://arxiv.org/abs/2602.17443)
*Adib Sakhawat,Fardeen Sadab,Rakin Shahriar*

Main category: cs.CL

TL;DR: 本研究引入了对抗性信息推理游戏 (AIDG) 框架，用于评估大型语言模型 (LLMs) 在动态多轮交互中的战略推理能力。研究发现 LLMs 在信息遏制方面明显优于信息推理，并确定了信息动态和约束遵守是导致这种差距的主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型 (LLMs) 的战略推理能力需要超越静态基准测试，转向动态、多轮交互。本文旨在探究对话中信息提取（主动推理）和信息遏制（状态维护）之间的不对称性。

Method: 研究引入了 AIDG（对抗性信息推理游戏），这是一个博弈论框架，用于探究对话中信息提取和信息遏制之间的不对称性。研究提出了两个互补任务：AIDG-I（测量社交推理中的语用策略）和 AIDG-II（测量结构化“20个问题”设置中的约束满足）。研究对六个前沿 LLM 进行了 439 场游戏。

Result: 研究观察到明显的能力不对称：模型在信息遏制方面的表现明显优于信息推理，防御方面有 350 ELO 的优势 (Cohen's d = 5.47)。研究确定了导致这一差距的两个瓶颈：1) 信息动态，其中确认策略比盲目推理有效 7.75 倍 (p < 0.00001)；2) 约束遵守，其中指令遵循在对话负载下会下降，占推理失败的 41.3%。

Conclusion: 研究结果表明，尽管 LLMs 在局部防御连贯性方面表现出色，但它们在战略性探究所需的全局状态跟踪方面存在困难。

Abstract: Evaluating the strategic reasoning capabilities of Large Language Models (LLMs) requires moving beyond static benchmarks to dynamic, multi-turn interactions. We introduce AIDG (Adversarial Information Deduction Game), a game-theoretic framework that probes the asymmetry between information extraction (active deduction) and information containment (state maintenance) in dialogue. We propose two complementary tasks: AIDG-I, measuring pragmatic strategy in social deduction, and AIDG-II, measuring constraint satisfaction in a structured "20 Questions" setting. Across 439 games with six frontier LLMs, we observe a clear capability asymmetry: models perform substantially better at containment than deduction, with a 350 ELO advantage on defense;(Cohen's d = 5.47). We identify two bottlenecks driving this gap: (1) Information Dynamics, where confirmation strategies are 7.75x more effective than blind deduction (p < 0.00001), and (2) Constraint Adherence, where instruction-following degrades under conversational load, accounting for 41.3% of deductive failures. These findings suggest that while LLMs excel at local defensive coherence, they struggle with the global state tracking required for strategic inquiry.

</details>


### [65] [ABCD: All Biases Come Disguised](https://arxiv.org/abs/2602.17445)
*Mateusz Nowak,Xavier Cadet,Peter Chin*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在多项选择题（MCQ）评估中存在标签-位置-少样本提示偏差。本文提出了一种简化的去偏差评估协议，通过使用统一、无序的标签并提示LLM使用完整的答案来提高评估的鲁棒性，并显著降低了答案排列的平均准确性方差。


<details>
  <summary>Details</summary>
Motivation: 多项选择题（MCQ）基准是衡量大型语言模型（LLMs）推理和回答知识问题的标准评估方法。通过合成的NonsenseQA基准测试，我们观察到不同的LLMs表现出不同程度的标签-位置-少样本提示偏差，即模型在回答每个MCQ问题时会利用答案位置、答案前的标签、少样本提示中正确答案的分布或它们的组合。

Method: 我们提出了一种简单的去偏差评估协议，该协议用统一、无序的标签替换每个问题的标签，并提示LLM使用整个呈现的答案。然后，我们使用一个简单的句子相似性模型来评估LLM的答案。

Result: 该协议在LLM性能下降最小的情况下，展示了改进的鲁棒性和不同答案排列之间更低的标准差，揭示了LLM在减少评估伪影下的能力，而无需提示示例或选项标签的帮助。在多个基准测试和模型中，该协议显著提高了答案排列的鲁棒性，将平均准确性方差降低了3倍，而平均模型性能仅有微小的下降。通过对各种嵌入模型和相似性函数的消融研究，我们表明该方法比标准方法更具鲁棒性。

Conclusion: 本文提出的去偏差评估协议有效地减轻了LLMs在MCQ评估中的标签-位置-少样本提示偏差，从而在性能下降最小的情况下，对LLMs的真实能力进行了更鲁棒和准确的评估。

Abstract: Multiple-choice question (MCQ) benchmarks have been a standard evaluation practice for measuring LLMs' ability to reason and answer knowledge-based questions. Through a synthetic NonsenseQA benchmark, we observe that different LLMs exhibit varying degrees of label-position-few-shot-prompt bias, where the model either uses the answer position, the label in front of the answer, the distributions of correct answers present in the few-shot prompt, or a combination of all to answer each MCQ question. We propose a simple bias-reduced evaluation protocol that replaces the labels of each question with uniform, unordered labels and prompts the LLM to use the whole answer presented. With a simple sentence similarity model, we demonstrate improved robustness and lower standard deviation between different permutations of answers with a minimal drop in LLM's performance, exposing the LLM's capabilities under reduced evaluation artifacts, without any help from the prompt examples or the option labels. Across multiple benchmarks and models, this protocol substantially improves the robustness to answer permutations, reducing mean accuracy variance $3\times$ with only a minimal decrease in the mean model's performance. Through ablation studies on various embedding models and similarity functions, we show that the method is more robust than the standard ones.

</details>


### [66] [Entropy-Based Data Selection for Language Models](https://arxiv.org/abs/2602.17465)
*Hongming Li,Yang Liu,Chao Huang*

Main category: cs.CL

TL;DR: 本文提出了一种基于熵的无监督数据选择（EUDS）框架，用于在计算资源受限场景下高效微调语言模型，显著降低了计算成本并提高了训练效率。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型微调对计算和数据资源需求巨大，现有数据选择技术计算成本高昂。尽管大型语言模型能缓解数据稀缺，但数据可用性评估仍具挑战，因此高效数据选择必不可少。

Method: 本文提出了基于熵的无监督数据选择（EUDS）框架。

Result: EUDS在情感分析、主题分类和问答任务上被证实有效。它建立了一个计算高效的数据过滤机制，显著降低了计算成本，提高了训练时间效率，并减少了数据需求。

Conclusion: EUDS为计算受限场景下语言模型的有效微调提供了一种创新解决方案。

Abstract: Modern language models (LMs) increasingly require two critical resources: computational resources and data resources. Data selection techniques can effectively reduce the amount of training data required for fine-tuning LMs. However, their effectiveness is closely related to computational resources, which always require a high compute budget. Owing to the resource limitations in practical fine-tuning scenario, we systematically reveal the relationship between data selection and uncertainty estimation of selected data. Although large language models (LLMs) exhibit exceptional capabilities in language understanding and generation, which provide new ways to alleviate data scarcity, evaluating data usability remains a challenging task. This makes efficient data selection indispensable. To mitigate these issues, we propose Entropy-Based Unsupervised Data Selection (EUDS) framework. Empirical experiments on sentiment analysis (SA), topic classification (Topic-CLS), and question answering (Q&A) tasks validate its effectiveness. EUDS establishes a computationally efficient data-filtering mechanism. Theoretical analysis and experimental results confirm the effectiveness of our approach. EUDS significantly reduces computational costs and improves training time efficiency with less data requirement. This provides an innovative solution for the efficient fine-tuning of LMs in the compute-constrained scenarios.

</details>


### [67] [PEACE 2.0: Grounded Explanations and Counter-Speech for Combating Hate Expressions](https://arxiv.org/abs/2602.17467)
*Greta Damo,Stéphane Petiot,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: PEACE 2.0是一个新颖的工具，它利用检索增强生成（RAG）管道来分析仇恨言论并解释其原因，同时生成基于证据的反驳言论。


<details>
  <summary>Details</summary>
Motivation: 仇恨言论在在线平台日益增多，对社会构成重大挑战。尽管自然语言处理领域在检测仇恨言论方面取得了进展，但如何有效回应仇恨言论（即反驳言论）仍是一个开放性问题。

Method: 论文提出了PEACE 2.0工具。该工具利用检索增强生成（RAG）管道，实现了三项主要功能：i) 将仇恨言论的解释建立在证据和事实之上；ii) 自动生成基于证据的反驳言论；iii) 探索反驳言论回复的特征。

Result: PEACE 2.0通过整合其能力，能够对显性及隐性仇恨信息进行深入分析并生成回应。

Conclusion: PEACE 2.0提供了一个全面的解决方案，用于分析和回应在线平台上的仇恨言论，特别是在生成基于证据的反驳言论方面具有创新性。

Abstract: The increasing volume of hate speech on online platforms poses significant societal challenges. While the Natural Language Processing community has developed effective methods to automatically detect the presence of hate speech, responses to it, called counter-speech, are still an open challenge. We present PEACE 2.0, a novel tool that, besides analysing and explaining why a message is considered hateful or not, also generates a response to it. More specifically, PEACE 2.0 has three main new functionalities: leveraging a Retrieval-Augmented Generation (RAG) pipeline i) to ground HS explanations into evidence and facts, ii) to automatically generate evidence-grounded counter-speech, and iii) exploring the characteristics of counter-speech replies. By integrating these capabilities, PEACE 2.0 enables in-depth analysis and response generation for both explicit and implicit hateful messages.

</details>


### [68] [Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dialect Representation and Intent Misalignment in Transformers](https://arxiv.org/abs/2602.17469)
*Nusrat Jahan Lia,Shubhashis Roy Dipta*

Main category: cs.CL

TL;DR: 本研究揭示了孟加拉语和英语之间的跨语言情感错位问题，指出当前AI对齐范式存在严重的安全和表征失败，尤其是在压缩模型和区域模型中。研究强调需要多元化、文化根植的对齐方式，以尊重语言和方言多样性，而非普遍压缩。


<details>
  <summary>Details</summary>
Motivation: 双向对齐的核心主题是确保AI系统准确理解人类意图以及人类信任AI行为，但这种循环在语言障碍下严重受损。本研究旨在解决孟加拉语和英语之间的跨语言情感错位问题。

Method: 通过对四种Transformer架构进行基准测试来解决孟加拉语和英语之间的跨语言情感错位问题。

Result: 压缩模型（mDistilBERT）表现出28.7%的“情感反转率”，从根本上误解了用户的积极意图。研究发现“不对称同理心”现象，即某些模型系统性地削弱或放大了孟加拉语文本相对于英语文本的情感权重。区域模型（IndicBERT）在处理正式（Sadhu）孟加拉语时，对齐错误增加了57%，显示出“现代偏见”。

Conclusion: 公平的人机协同进化需要多元化、文化根植的对齐方式，以尊重语言和方言多样性，而非普遍压缩。建议对齐基准应纳入“情感稳定性”指标，明确惩罚低资源和方言语境下的极性反转。

Abstract: The core theme of bidirectional alignment is ensuring that AI systems accurately understand human intent and that humans can trust AI behavior. However, this loop fractures significantly across language barriers. Our research addresses Cross-Lingual Sentiment Misalignment between Bengali and English by benchmarking four transformer architectures. We reveal severe safety and representational failures in current alignment paradigms. We demonstrate that compressed model (mDistilBERT) exhibits 28.7% "Sentiment Inversion Rate," fundamentally misinterpreting positive user intent as negative (or vice versa). Furthermore, we identify systemic nuances affecting human-AI trust, including "Asymmetric Empathy" where some models systematically dampen and others amplify the affective weight of Bengali text relative to its English counterpart. Finally, we reveal a "Modern Bias" in the regional model (IndicBERT), which shows a 57% increase in alignment error when processing formal (Sadhu) Bengali. We argue that equitable human-AI co-evolution requires pluralistic, culturally grounded alignment that respects language and dialectal diversity over universal compression, which fails to preserve the emotional fidelity required for reciprocal human-AI trust. We recommend that alignment benchmarks incorporate "Affective Stability" metrics that explicitly penalize polarity inversions in low-resource and dialectal contexts.

</details>


### [69] [Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian](https://arxiv.org/abs/2602.17475)
*Pietro Ferrazzi,Mattia Franzin,Alberto Lavelli,Bernardo Magnini*

Main category: cs.CL

TL;DR: 小型大型语言模型（LLMs）在医学NLP任务中表现出色，通过微调等适应策略，可以与大型模型媲美甚至超越，尤其是Qwen3-1.7B模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在医学自然语言处理（NLP）任务中表现优异，但其庞大的计算需求限制了在实际医疗环境中的部署。本研究旨在探讨参数量约十亿的“小型”大型语言模型是否能有效执行医学任务，并保持具有竞争力的准确性。

Method: 本研究评估了来自Llama-3、Gemma-3和Qwen3三个主要家族的“小型”LLMs（约十亿参数），涵盖命名实体识别、关系抽取、病例报告表填充、问答和论点挖掘等20项临床NLP任务。系统比较了多种适应策略，包括推理时的少样本提示和约束解码，以及训练时的监督微调和持续预训练。此外，发布了所有公开可用的意大利医学NLP数据集的综合集合，以及用于持续预训练的来自意大利医院急诊科的1.26亿词和来自各种来源的1.75亿词的意大利数据集，并发布了表现最佳的模型。

Result: 微调被证明是最有效的适应方法，而少样本提示和约束解码的结合则提供了强大的低资源替代方案。研究结果表明，小型LLMs可以与大型基线模型匹配甚至超越。基于Qwen3-1.7B的最佳配置比Qwen3-32B的平均得分高出9.2分。

Conclusion: 小型大型语言模型，特别是通过微调等适应策略，在医学NLP任务中表现出高效性，能够匹配甚至超越大型基线模型，使其成为实际医疗部署的可行选择。本研究发布的模型和数据集将进一步推动相关研究。

Abstract: Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether "small" LLMs (around one billion parameters) can effectively perform medical tasks while maintaining competitive accuracy. We evaluate models from three major families-Llama-3, Gemma-3, and Qwen3-across 20 clinical NLP tasks among Named Entity Recognition, Relation Extraction, Case Report Form Filling, Question Answering, and Argument Mining. We systematically compare a range of adaptation strategies, both at inference time (few-shot prompting, constraint decoding) and at training time (supervised fine-tuning, continual pretraining). Fine-tuning emerges as the most effective approach, while the combination of few-shot prompting and constraint decoding offers strong lower-resource alternatives. Our results show that small LLMs can match or even surpass larger baselines, with our best configuration based on Qwen3-1.7B achieving an average score +9.2 points higher than Qwen3-32B. We release a comprehensive collection of all the publicly available Italian medical datasets for NLP tasks, together with our top-performing models. Furthermore, we release an Italian dataset of 126M words from the Emergency Department of an Italian Hospital, and 175M words from various sources that we used for continual pre-training.

</details>


### [70] [Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to Obstetrics](https://arxiv.org/abs/2602.17513)
*Baris Karacan,Barbara Di Eugenio,Patrick Thornton*

Main category: cs.CL

TL;DR: 该论文引入了一个新的妇产科笔记数据集，并评估了基于Transformer的监督模型和零样本大型语言模型在临床文本分段方面的性能。研究发现，监督模型在域内表现出色，但在域外性能显著下降；而零样本模型在纠正幻觉节标题后，展现出强大的域外适应性。


<details>
  <summary>Details</summary>
Motivation: 临床自由文本笔记中包含重要的患者信息，识别这些笔记中的分段已被证明可以支持临床决策和下游NLP任务。然而，现有的大多数分段方法都在MIMIC-III等公共语料库上进行训练，未能覆盖所有医学领域。

Method: 1. 整理了一个新的去识别化、已标注分段的妇产科笔记数据集。
2. 在MIMIC-III的精选子集（域内）和新的妇产科数据集（域外）上，系统性地评估了基于Transformer的监督模型在分段任务上的性能。
3. 首次对用于医学分段的监督模型与零样本大型语言模型进行了直接比较。

Result: 1. 监督模型在域内表现强劲，但在域外性能显著下降。
2. 零样本模型在纠正幻觉节标题后，展现出强大的域外适应性。

Conclusion: 1. 强调了开发特定领域临床资源的重要性。
2. 零样本分段是将在医疗NLP应用于除已充分研究的语料库之外的领域的一个有前景的方向，前提是需要适当管理幻觉问题。

Abstract: Clinical free-text notes contain vital patient information. They are structured into labelled sections; recognizing these sections has been shown to support clinical decision-making and downstream NLP tasks. In this paper, we advance clinical section segmentation through three key contributions. First, we curate a new de-identified, section-labeled obstetrics notes dataset, to supplement the medical domains covered in public corpora such as MIMIC-III, on which most existing segmentation approaches are trained. Second, we systematically evaluate transformer-based supervised models for section segmentation on a curated subset of MIMIC-III (in-domain), and on the new obstetrics dataset (out-of-domain). Third, we conduct the first head-to-head comparison of supervised models for medical section segmentation with zero-shot large language models. Our results show that while supervised models perform strongly in-domain, their performance drops substantially out-of-domain. In contrast, zero-shot models demonstrate robust out-of-domain adaptability once hallucinated section headers are corrected. These findings underscore the importance of developing domain-specific clinical resources and highlight zero-shot segmentation as a promising direction for applying healthcare NLP beyond well-studied corpora, as long as hallucinations are appropriately managed.

</details>


### [71] [Using LLMs for Knowledge Component-level Correctness Labeling in Open-ended Coding Problems](https://arxiv.org/abs/2602.17542)
*Zhangqi Duan,Arnav Kankaria,Dhruv Kartik,Andrew Lan*

Main category: cs.CL

TL;DR: 本研究提出了一个基于LLM的自动化框架，用于从学生代码中标记知识组件（KC）级别的正确性，从而改进学习曲线拟合和预测性能。


<details>
  <summary>Details</summary>
Motivation: 在真实世界数据集中，特别是对于涉及多个知识组件（KC）的开放式编程任务，KC级别的正确性标签很少可用。将问题级别的正确性简单地传播到所有相关KC会掩盖部分掌握情况，并常常导致学习曲线拟合不佳。

Method: 提出一个自动化框架，利用大型语言模型（LLMs）直接从学生编写的代码中标记知识组件（KC）级别的正确性。该方法评估每个KC是否被正确应用，并引入一个时间上下文感知的Code-KC映射机制，以更好地将KC与个体学生代码对齐。

Result: 该框架产生的学习曲线与认知理论更加一致，并相对于基线提高了预测性能（通过练习幂律和加性因素模型评估）。人类评估进一步表明LLM标注与专家标注之间存在实质性一致。

Conclusion: 本研究提出的基于LLM的框架能有效生成准确的KC级正确性标签，从而改进编程任务中的学生建模和学习分析。

Abstract: Fine-grained skill representations, commonly referred to as knowledge components (KCs), are fundamental to many approaches in student modeling and learning analytics. However, KC-level correctness labels are rarely available in real-world datasets, especially for open-ended programming tasks where solutions typically involve multiple KCs simultaneously. Simply propagating problem-level correctness to all associated KCs obscures partial mastery and often leads to poorly fitted learning curves. To address this challenge, we propose an automated framework that leverages large language models (LLMs) to label KC-level correctness directly from student-written code. Our method assesses whether each KC is correctly applied and further introduces a temporal context-aware Code-KC mapping mechanism to better align KCs with individual student code. We evaluate the resulting KC-level correctness labels in terms of learning curve fit and predictive performance using the power law of practice and the Additive Factors Model. Experimental results show that our framework leads to learning curves that are more consistent with cognitive theory and improves predictive performance, compared to baselines. Human evaluation further demonstrates substantial agreement between LLM and expert annotations.

</details>


### [72] [Learning to Stay Safe: Adaptive Regularization Against Safety Degradation during Fine-Tuning](https://arxiv.org/abs/2602.17546)
*Jyotin Goel,Souvik Maji,Pratik Mazumder*

Main category: cs.CL

TL;DR: 本文介绍了一个自适应正则化训练框架，该框架通过在训练过程中响应安全风险来保持语言模型在微调过程中的安全性，且不牺牲实用性。


<details>
  <summary>Details</summary>
Motivation: 指令遵循语言模型在良性微调下安全行为会恶化，在对抗性更新下会更糟。现有防御措施通常保护有限，或需要在安全性和实用性之间进行权衡。

Method: 本文引入了一个训练框架，该框架能根据安全风险自适应地调整正则化，使模型在微调过程中保持对齐。为评估训练时的安全风险，探索了两种方法：1) 基于法官的Safety Critic，它为训练批次分配高级危害分数；2) 基于激活的风险预测器，它使用轻量级分类器在中间模型激活上训练，以估计有害意图。每种方法都提供一个风险信号，用于约束被认定为高风险的更新，使其保持接近安全的参考策略，而较低风险的更新则按标准训练进行。

Result: 经验证，有害意图信号可以从生成前激活中预测，且法官分数提供了有效的高召回率安全指导。在多种模型家族和攻击场景下，无论采用哪种风险估计方法，自适应正则化都比标准微调显著降低了攻击成功率，同时保持了下游性能，并且没有增加推理时间成本。

Conclusion: 这项工作展示了一种在不牺牲实用性的前提下保持模型安全性的原则性机制。

Abstract: Instruction-following language models are trained to be helpful and safe, yet their safety behavior can deteriorate under benign fine-tuning and worsen under adversarial updates. Existing defenses often offer limited protection or force a trade-off between safety and utility. We introduce a training framework that adapts regularization in response to safety risk, enabling models to remain aligned throughout fine-tuning. To estimate safety risk at training time, we explore two distinct approaches: a judge-based Safety Critic that assigns high-level harm scores to training batches, and an activation-based risk predictor built with a lightweight classifier trained on intermediate model activations to estimate harmful intent. Each approach provides a risk signal that is used to constrain updates deemed higher risk to remain close to a safe reference policy, while lower-risk updates proceed with standard training. We empirically verify that harmful intent signals are predictable from pre-generation activations and that judge scores provide effective high-recall safety guidance. Across multiple model families and attack scenarios, adaptive regularization with either risk estimation approach consistently lowers attack success rate compared to standard fine-tuning, preserves downstream performance, and adds no inference-time cost. This work demonstrates a principled mechanism for maintaining safety without sacrificing utility.

</details>


### [73] [The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\rightarrow$LLM Pipelines?](https://arxiv.org/abs/2602.17598)
*Jayadev Billa*

Main category: cs.CL

TL;DR: 大多数现有语音大模型在行为和机制上等同于简单的ASR-LLM级联，特别是在处理无噪声任务时。它们在有噪声环境下表现更差，但Qwen2-Audio是一个例外，表明级联等效性取决于架构。


<details>
  <summary>Details</summary>
Motivation: 理解当前语音大模型（Speech LLMs）的实际工作机制，特别是它们在多大程度上等同于显式的ASR转录后再接LLM的级联系统，以及这种等效性是否普遍存在，并评估其在不同条件下的性能表现（尤其是在噪声环境中）。

Method: 1. **匹配骨干测试 (Matched-backbone testing):** 首次通过控制LLM骨干，在四种语音大模型和六项任务上进行测试，比较语音大模型与其对应的ASR-LLM级联系统的性能。
2. **Logit Lens分析 (Logit lens analysis):** 检查模型隐藏状态中是否出现字面文本，以探究其内部表示。
3. **LEACE概念擦除 (LEACE concept erasure):** 确认文本表示在所测试的两种架构中是否是因果必要的，通过擦除概念后准确率的下降来验证。

Result: 1. **行为和机制等效性 (Behavioral and mechanistic equivalence):** 在可从转录文本解决的任务上，大多数语音大模型在行为和机制上与简单的Whisper→LLM级联系统等同。
2. **Ultravox等效性 (Ultravox equivalence):** Ultravox与其匹配的级联系统在统计学上无法区分（Kappa值为0.93）。
3. **内部文本表示 (Internal text representation):** Logit lens分析揭示隐藏状态中出现了字面文本。
4. **文本表示的因果必要性 (Causal necessity of text representations):** LEACE概念擦除实验证实文本表示在所测试的两种架构中是因果必要的，擦除后准确率几乎降至零。
5. **Qwen2-Audio的差异性 (Qwen2-Audio divergence):** Qwen2-Audio展现出真正的分歧，表明级联等效性是架构依赖的，而非普遍现象。
6. **噪声环境下的性能 (Performance under noise):** 在大多数实际应用场景中，当前的语音大模型是昂贵的级联系统，并且在噪声环境下表现更差，在0 dB时，其在无噪声条件下的优势反而逆转高达7.6%。

Conclusion: 大多数当前的语音大模型在行为和机制上等同于显式的ASR-LLM级联系统，尤其是在非噪声环境下。它们在噪声环境下表现更差，且成本更高。然而，这种等效性并非普遍适用，而是取决于模型架构（如Qwen2-Audio所示）。因此，在大多数部署场景中，应谨慎评估当前语音大模型的实际效用和成本效益。

Abstract: Current speech LLMs largely perform implicit ASR: on tasks solvable from a transcript, they are behaviorally and mechanistically equivalent to simple Whisper$\to$LLM cascades. We show this through matched-backbone testing across four speech LLMs and six tasks, controlling for the LLM backbone for the first time. Ultravox is statistically indistinguishable from its matched cascade ($\kappa{=}0.93$); logit lens reveals literal text emerging in hidden states; LEACE concept erasure confirms text representations are causally necessary in both architectures tested, collapsing accuracy to near-zero. Qwen2-Audio genuinely diverges, revealing cascade equivalence is architecture-dependent, not universal. For most deployed use cases, current speech LLMs are expensive cascades, and under noise, they are worse ones, with clean-condition advantages reversing by up to 7.6% at 0 dB.

</details>


### [74] [Unmasking the Factual-Conceptual Gap in Persian Language Models](https://arxiv.org/abs/2602.17623)
*Alireza Sakhaeirad,Ali Ma'manpoosh,Arshia Hemmat*

Main category: cs.CL

TL;DR: DivanBench是一个诊断波斯语LLM文化能力的基准，发现模型存在顺从偏见、预训练加剧偏见以及事实检索与应用之间存在差距，表明文化理解需要超越简单的多语种数据扩展。


<details>
  <summary>Details</summary>
Motivation: 现有的波斯语自然语言处理基准很少区分记忆的文化事实和推理隐含社会规范的能力，缺乏对武断的、依赖上下文的规则的评估。

Method: 引入了DivanBench诊断基准，该基准专注于迷信和习俗，包含315个问题，分为三种任务类型（事实检索、配对情景验证和情景推理），并评估了七个波斯语大型语言模型。

Result: 模型表现出严重的顺从偏见，能够识别适当行为但未能拒绝明显违规；连续的波斯语预训练放大了这种偏见，常常降低模型识别矛盾的能力；所有模型在检索事实知识和将其应用于情景之间存在21%的性能差距。

Conclusion: 文化能力不仅仅是扩展单语数据，因为当前模型只学习模仿文化模式，而未能内化其底层图式。

Abstract: While emerging Persian NLP benchmarks have expanded into pragmatics and politeness, they rarely distinguish between memorized cultural facts and the ability to reason about implicit social norms. We introduce DivanBench, a diagnostic benchmark focused on superstitions and customs, arbitrary, context-dependent rules that resist simple logical deduction. Through 315 questions across three task types (factual retrieval, paired scenario verification, and situational reasoning), we evaluate seven Persian LLMs and reveal three critical failures: most models exhibit severe acquiescence bias, correctly identifying appropriate behaviors but failing to reject clear violations; continuous Persian pretraining amplifies this bias rather than improving reasoning, often degrading the model's ability to discern contradictions; and all models show a 21\% performance gap between retrieving factual knowledge and applying it in scenarios. These findings demonstrate that cultural competence requires more than scaling monolingual data, as current models learn to mimic cultural patterns without internalizing the underlying schemas.

</details>


### [75] [Differences in Typological Alignment in Language Models' Treatment of Differential Argument Marking](https://arxiv.org/abs/2602.17653)
*Iskar Deng,Nathalia Xu,Shane Steinert-Threlkeld*

Main category: cs.CL

TL;DR: 本研究将语言模型在合成语料库上展现的类人句法类型学偏好扩展到差异论元标记（DAM）。通过在18个不同DAM系统上训练GPT-2模型，发现模型能可靠地展现对自然标记方向的类人偏好（偏向标记语义非典型论元），但未能重现人类语言中对宾语的强烈偏好，这表明不同的类型学倾向可能源于不同的底层机制。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明，在合成语料库上训练的语言模型可以展现出与人类语言中跨语言规律相似的类型学偏好，尤其是在词序等句法现象上。本文旨在将这一范式扩展到差异论元标记（DAM），这是一个基于语义显赫度的形态标记系统，以探究模型能否在DAM中也展现出类人的类型学偏好。

Method: 采用受控的合成学习方法。在实现18种不同DAM系统的语料库上训练GPT-2模型。使用最小对进行泛化能力评估。

Result: 模型揭示了DAM的两个类型学维度之间的分离。模型可靠地展现出对自然标记方向的类人偏好，偏向于在语义上非典型的论元上使用显性标记的系统。然而，模型未能重现人类语言中显性DAM标记更常针对宾语而非主语的强烈宾语偏好。

Conclusion: 这些发现表明，不同的类型学倾向可能源于不同的底层机制。

Abstract: Recent work has shown that language models (LMs) trained on synthetic corpora can exhibit typological preferences that resemble cross-linguistic regularities in human languages, particularly for syntactic phenomena such as word order. In this paper, we extend this paradigm to differential argument marking (DAM), a semantic licensing system in which morphological marking depends on semantic prominence. Using a controlled synthetic learning method, we train GPT-2 models on 18 corpora implementing distinct DAM systems and evaluate their generalization using minimal pairs. Our results reveal a dissociation between two typological dimensions of DAM. Models reliably exhibit human-like preferences for natural markedness direction, favoring systems in which overt marking targets semantically atypical arguments. In contrast, models do not reproduce the strong object preference in human languages, in which overt marking in DAM more often targets objects rather than subjects. These findings suggest that different typological tendencies may arise from distinct underlying sources.

</details>


### [76] [What Language is This? Ask Your Tokenizer](https://arxiv.org/abs/2602.17655)
*Clara Meister,Ahmetcan Yavuz,Pietro Lesci,Tiago Pimentel*

Main category: cs.CL

TL;DR: UniLID是一种基于UnigramLM分词算法的语言识别方法，解决了低资源和近源语言识别的挑战，并在样本效率和方言识别上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别系统在高资源语言上表现良好，但在低资源和密切相关语言设置中仍存在脆弱性。

Method: 本文提出UniLID，一种简单高效的语言识别方法。它基于UnigramLM分词算法的概率框架、参数估计技术和推理策略，通过共享的分词词汇表学习语言条件的一元语法分布，并将分词视为语言特有现象。该方法数据和计算高效，支持不重新训练现有模型即可增量添加新语言，并且可以自然地集成到现有语言模型分词流水线中。

Result: 经验评估显示，UniLID在标准基准测试中能与广泛使用的基线（包括fastText、GlotLID和CLD3）达到具有竞争力的性能。它显著提高了低资源设置下的样本效率，每种语言只需五个标记样本即可超过70%的准确率。此外，在细粒度方言识别方面也取得了巨大提升。

Conclusion: UniLID有效解决了低资源和近源语言识别的难题，并在效率和性能上展现出优越性，特别是在低资源和方言识别场景中具有显著优势。

Abstract: Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite near-perfect performance on high-resource languages, existing systems remain brittle in low-resource and closely related language settings. We introduce UniLID, a simple and efficient LID method based on the UnigramLM tokenization algorithm, leveraging its probabilistic framing, parameter estimation technique and inference strategy. In short, we learn language-conditional unigram distributions over a shared tokenizer vocabulary but treat segmentation as a language-specific phenomenon. Our formulation is data- and compute-efficient, supports incremental addition of new languages without retraining existing models, and can naturally be integrated into existing language model tokenization pipelines. Empirical evaluations against widely used baselines, including fastText, GlotLID, and CLD3, show that UniLID achieves competitive performance on standard benchmarks, substantially improves sample efficiency in low-resource settings - surpassing 70% accuracy with as few as five labeled samples per language - and delivers large gains on fine-grained dialect identification.

</details>


### [77] [Sink-Aware Pruning for Diffusion Language Models](https://arxiv.org/abs/2602.17664)
*Aidar Myrzakhan,Tianyi Li,Bowei Guo,Shengkun Tang,Zhiqiang Shen*

Main category: cs.CL

TL;DR: 扩散语言模型（DLM）推理成本高，现有剪枝方法不适用于DLM中不稳定的注意力汇聚点。本文提出Sink-Aware Pruning方法，自动识别并剪枝DLM中不稳定的汇聚点，在不重新训练的情况下，提升了质量-效率，并优于现有剪枝基线。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型由于迭代去噪导致高昂的推理成本，因此需要高效剪枝。现有剪枝启发式方法大多继承自自回归语言模型，通常会保留注意力汇聚点，因为在自回归模型中它们是稳定的全局锚点。然而，本研究发现这一假设不适用于扩散语言模型，其注意力汇聚点位置在生成轨迹上表现出更高的方差，表明这些汇聚点通常是瞬态的，不如自回归模型中那样具有结构性重要性。

Method: 基于对扩散语言模型中注意力汇聚点位置在生成轨迹上高方差的观察，本文提出了“Sink-Aware Pruning”方法，该方法能自动识别并剪枝扩散语言模型中不稳定的注意力汇聚点。

Result: 在无需重新训练的情况下，我们的方法实现了更好的质量-效率权衡，并在相同计算资源下，性能优于强大的现有剪枝基线。

Conclusion: 我们提出的Sink-Aware Pruning方法通过识别扩散语言模型中注意力汇聚点（attention sink）的瞬态特性，有效解决了扩散语言模型的剪枝挑战，在无需重新训练的情况下提高了效率和质量。

Abstract: Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks serve as stable global anchors. We show that this assumption does not hold for DLMs: the attention-sink position exhibits substantially higher variance over the full generation trajectory (measured by how the dominant sink locations shift across timesteps), indicating that sinks are often transient and less structurally essential than in AR models. Based on this observation, we propose ${\bf \texttt{Sink-Aware Pruning}}$, which automatically identifies and prunes unstable sinks in DLMs (prior studies usually keep sinks for AR LLMs). Without retraining, our method achieves a better quality-efficiency trade-off and outperforms strong prior pruning baselines under matched compute. Our code is available at .

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [78] ["It's like a pet...but my pet doesn't collect data about me": Multi-person Households' Privacy Design Preferences for Household Robots](https://arxiv.org/abs/2602.16975)
*Jennica Li,Shirley Zhang,Dakota Sullivan,Bengisu Cagiltay,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz*

Main category: cs.HC

TL;DR: 家用机器人日益普及，但其先进功能带来了隐私风险。现有研究在多用户视角下，对用户偏好的隐私设计和缓解策略的探讨有限。本研究通过与15个家庭进行参与式设计，发现用户不信任机器人制造商会尊重数据隐私，并提出用户期望拥有数据权限、易于访问的控制和通知系统以及可定制的隐私设计。


<details>
  <summary>Details</summary>
Motivation: 目前关于家用机器人隐私的研究，在探讨用户偏好的隐私设计、缓解策略以及多用户视角方面存在空白。

Method: 通过与15个家庭进行面对面的参与式设计会议，探讨他们如何基于自身的担忧和期望来设计一个隐私感知的家用机器人。

Result: 参与者不信任机器人及其制造商会尊重家庭成员的数据隐私，或在多用户生态系统中运行而不损害个人数据。基于这些担忧，他们提出了赋予用户数据权限、包含可访问的控制和通知系统，并可随时间推移根据每个用户的需求和偏好进行定制的设计方案。

Conclusion: 本文将研究结果综合为可操作的设计建议，供机器人制造商和开发人员参考。

Abstract: Household robots boasting mobility, more sophisticated sensors, and powerful processing models have become increasingly prevalent in the commercial market. However, these features may expose users to unwanted privacy risks, including unsolicited data collection and unauthorized data sharing. While security and privacy researchers thus far have explored people's privacy concerns around household robots, literature investigating people's preferred privacy designs and mitigation strategies is still limited. Additionally, the existing literature has not yet accounted for multi-user perspectives on privacy design and household robots. We aimed to fill this gap by conducting in-person participatory design sessions with 15 households to explore how they would design a privacy-aware household robot based on their concerns and expectations. We found that participants did not trust that robots, or their respective manufacturers, would respect the data privacy of household members or operate in a multi-user ecosystem without jeopardizing users' personal data. Based on these concerns, they generated designs that gave them authority over their data, contained accessible controls and notification systems, and could be customized and tailored to suit the needs and preferences of each user over time. We synthesize our findings into actionable design recommendations for robot manufacturers and developers.

</details>


### [79] [AI-Mediated Feedback Improves Student Revisions: A Randomized Trial with FeedbackWriter in a Large Undergraduate Course](https://arxiv.org/abs/2602.16820)
*Xinyi Lu,Kexin Phyllis Ju,Mitchell Dudley,Larissa Sano,Xu Wang*

Main category: cs.HC

TL;DR: 本研究发现，与传统手写反馈相比，学生收到人工智能辅助反馈后，修订稿的质量显著提高。助教也认为人工智能建议有助于发现学生作业中的不足和澄清评分标准。


<details>
  <summary>Details</summary>
Motivation: 尽管使用大型语言模型（LLMs）为学生写作提供反馈的兴趣日益增长，但目前对学生如何回应人工智能辅助反馈与人工反馈知之甚少。本研究旨在填补这一空白。

Method: 研究在一个大型经济学入门课程中进行了一项随机对照试验（N=354）。研究部署了FeedbackWriter系统，该系统在助教为学生的知识密集型论文提供反馈时，向助教生成人工智能建议。助教拥有采纳、编辑或驳回这些建议的完全权力。学生被随机分配到两个组：一个接收助教手写反馈的基线组，另一个接收由助教根据FeedbackWriter建议提供的人工智能辅助反馈组。学生根据反馈修改他们的草稿，修订稿随后被评分。总共有1,366篇论文通过该系统进行评分。

Result: 研究发现，收到人工智能辅助反馈的学生产出了显著更高质量的修订稿，且随着助教采纳更多人工智能建议，质量提升更为显著。助教认为人工智能建议有助于发现不足之处和澄清评分标准。

Conclusion: 人工智能辅助反馈，通过向助教提供建议，能够显著提高学生修订作业的质量，并受到助教的认可。这表明人工智能在教育反馈过程中具有积极的应用潜力。

Abstract: Despite growing interest in using LLMs to generate feedback on students' writing, little is known about how students respond to AI-mediated versus human-provided feedback. We address this gap through a randomized controlled trial in a large introductory economics course (N=354), where we introduce and deploy FeedbackWriter - a system that generates AI suggestions to teaching assistants (TAs) while they provide feedback on students' knowledge-intensive essays. TAs have the full capacity to adopt, edit, or dismiss the suggestions. Students were randomly assigned to receive either handwritten feedback from TAs (baseline) or AI-mediated feedback where TAs received suggestions from FeedbackWriter. Students revise their drafts based on the feedback, which is further graded. In total, 1,366 essays were graded using the system. We found that students receiving AI-mediated feedback produced significantly higher-quality revisions, with gains increasing as TAs adopted more AI suggestions. TAs found the AI suggestions useful for spotting gaps and clarifying rubrics.

</details>


### [80] [What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data](https://arxiv.org/abs/2602.17483)
*Dimitri Staufer,Kirsten Morehouse*

Main category: cs.HC

TL;DR: 大型语言模型在预训练和用户交互中会接触并生成个人数据。本研究通过LMP2工具审计了八种LLM，发现模型能自信地生成个人数据，且普通用户对GPT-4o生成的数据准确性较高（如性别、发色等）。72%的参与者希望控制模型生成的与其姓名相关的联想，引发了对个人数据定义和数据隐私权是否应延伸至LLM的讨论。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在预训练和用户交互中会接触个人数据，且个人数据可能重新浮现，但用户不了解模型如何强烈地将特定信息与其身份关联。

Method: 研究审计了八种大型语言模型（3个开源，5个基于API，包括GPT-4o）中的个人数据。引入了LMP2（大型语言模型隐私探测器），这是一个以人为本、保护隐私的审计工具，通过两次形成性研究（N=20）进行了完善。对欧盟居民进行了两项研究，以获取（i）对LLM生成个人数据的直觉（N1=155）和（ii）对工具输出的反应（N2=303）。

Result: 实证表明，模型能自信地为知名人士生成多个个人数据类别。对于普通用户，GPT-4o能以60%或更高的准确率生成11项特征（例如，性别、发色，语言）。

Conclusion: 72%的参与者希望控制模型生成的与其姓名相关的联想，这引发了关于何为个人数据以及数据隐私权是否应延伸到大型语言模型的问题。

Abstract: Large language models (LLMs), and conversational agents based on them, are exposed to personal data (PD) during pre-training and during user interactions. Prior work shows that PD can resurface, yet users lack insight into how strongly models associate specific information to their identity. We audit PD across eight LLMs (3 open-source; 5 API-based, including GPT-4o), introduce LMP2 (Language Model Privacy Probe), a human-centered, privacy-preserving audit tool refined through two formative studies (N=20), and run two studies with EU residents to capture (i) intuitions about LLM-generated PD (N1=155) and (ii) reactions to tool output (N2=303). We show empirically that models confidently generate multiple PD categories for well-known individuals. For everyday users, GPT-4o generates 11 features with 60% or more accuracy (e.g., gender, hair color, languages). Finally, 72% of participants sought control over model-generated associations with their name, raising questions about what counts as PD and whether data privacy rights should extend to LLMs.

</details>


### [81] [Say It My Way: Exploring Control in Conversational Visual Question Answering with Blind Users](https://arxiv.org/abs/2602.16930)
*Farnaz Zamiri Zeraati,Yang Trista Cao,Yuehan Qiao,Hal Daumé III,Hernisa Kacorri*

Main category: cs.HC

TL;DR: 本研究调查了11名盲人用户如何通过提示工程定制与VQA系统的交互，发现现有系统存在冗长、时空距离估计不准和相机指导不足等问题，并提出了改进交互设计的见解。


<details>
  <summary>Details</summary>
Motivation: 现有的盲人辅助VQA工具交互模式僵化，定制机会有限。当系统响应与用户目标和上下文不符时，用户控制尤为重要，对于依赖这些系统获取信息的盲人用户来说，这一差距尤其严重。

Method: 研究邀请了11位盲人用户与一个真实世界的对话式VQA系统进行交互定制。通过分析418次交互、反思和访谈，研究分析了参与者采用的基于提示的技术，包括研究中引入的和用户独立开发的。

Result: VQA交互通常冗长（平均3轮，最多21轮），输入文本通常比听到的响应短十倍。基于先进LLM的系统缺乏冗长控制，在估计时空距离方面存在局限性，依赖于难以访问的图像取景，且相机指导不足。

Conclusion: 本研究讨论了提示工程等定制技术如何帮助参与者解决VQA系统在冗长性控制、时空距离估计、图像取景和相机指导方面的局限性。研究为查询和系统层面的交互设计提供了见解，并发布了一个新的公共数据集。

Abstract: Prompting and steering techniques are well established in general-purpose generative AI, yet assistive visual question answering (VQA) tools for blind users still follow rigid interaction patterns with limited opportunities for customization. User control can be helpful when system responses are misaligned with their goals and contexts, a gap that becomes especially consequential for blind users that may rely on these systems for access. We invite 11 blind users to customize their interactions with a real-world conversational VQA system. Drawing on 418 interactions, reflections, and post-study interviews, we analyze prompting-based techniques participants adopted, including those introduced in the study and those developed independently in real-world settings. VQA interactions were often lengthy: participants averaged 3 turns, sometimes up to 21, with input text typically tenfold shorter than the responses they heard. Built on state-of-the-art LLMs, the system lacked verbosity controls, was limited in estimating distance in space and time, relied on inaccessible image framing, and offered little to no camera guidance. We discuss how customization techniques such as prompt engineering can help participants work around these limitations. Alongside a new publicly available dataset, we offer insights for interaction design at both query and system levels.

</details>


<div id='q-bio.OT'></div>

# q-bio.OT [[Back]](#toc)

### [82] [PREFER: An Ontology for the PREcision FERmentation Community](https://arxiv.org/abs/2602.16755)
*Txell Amigó,Shawn Zheng Kai Tan,Angel Luu Phanthanourak,Sebastian Schulz,Pasquale D. Colaianni,Dominik M. Maszczyk,Ester Milesi,Ivan Schlembach,Mykhaylo Semenov Petrov,Marta Reventós Montané,Lars K. Nielsen,Jochen Förster,Bernhard Ø. Palsson,Suresh Sudarsan,Alberto Santos*

Main category: q-bio.OT

TL;DR: 该论文介绍了PREFER，一个开源本体，旨在标准化精密发酵中的生物过程数据，以提高数据可访问性、互操作性，并支持机器学习模型的训练。


<details>
  <summary>Details</summary>
Motivation: 精密发酵中缺乏社区标准限制了数据可访问性和互操作性，阻碍了高通量生物反应器平台之间的数据整合，并妨碍了预测性机器学习模型的训练。

Method: 引入PREFER，一个与BFO及其他社区本体对齐的开源本体，覆盖整个精密发酵过程。

Result: PREFER能够实现结构化元数据，支持自动化跨平台执行、高保真数据捕获，并连接不同的数据孤岛，生成可供训练机器学习模型的机器可操作数据集。

Conclusion: PREFER为可扩展、可互操作的生物过程系统奠定了基础，并支持向数据驱动的生物生产转型。

Abstract: Precision fermentation relies on microbial cell factories to produce sustainable food, pharmaceuticals, chemicals, and biofuels. Specialized laboratories such as biofoundries are advancing these processes using high-throughput bioreactor platforms, which generate vast datasets. However, the lack of community standards limits data accessibility and interoperability, preventing integration across platforms. In order to address this, we introduce PREFER, an open-source ontology designed to establish a unified standard for bioprocess data. Built in alignment with the widely adopted Basic Formal Ontology (BFO) and connecting with several other community ontologies, PREFER ensures consistency and cross-domain compatibility and covers the whole precision fermentation process. Integrating PREFER into high-throughput bioprocess development workflows enables structured metadata that supports automated cross-platform execution and high-fidelity data capture. Furthermore, PREFER's standardization has the potential to bridge disparate data silos, generating machine-actionable datasets critical for training predictive, robust machine learning models in synthetic biology. This work provides the foundation for scalable, interoperable bioprocess systems and supports the transition toward more data-driven bioproduction.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [83] [GPU-Accelerated Algorithms for Graph Vector Search: Taxonomy, Empirical Study, and Research Directions](https://arxiv.org/abs/2602.16719)
*Yaowen Liu,Xuejia Chen,Anxin Tian,Haoyang Li,Qinbin Li,Xin Zhang,Alexander Zhou,Chen Jason Zhang,Qing Li,Lei Chen*

Main category: cs.DB

TL;DR: 该论文对GPU加速的图基近似最近邻搜索（ANNS）进行了全面调查和实验研究，揭示了距离计算和数据传输是主要瓶颈，并为设计可扩展的GPU ANNS系统提供了指导。


<details>
  <summary>Details</summary>
Motivation: 尽管图基方法在近似最近邻搜索中代表了最先进水平，但对于其在现代GPU架构上的优化以及在实际场景中的端到端有效性缺乏系统理解。

Method: 本文进行了一项全面的调查和实验研究，建立了GPU优化策略的详细分类法，阐明了算法任务与GPU硬件执行单元之间的映射，并对六种领先算法在八个大规模基准数据集上的图索引构建和查询搜索性能进行了评估。

Result: 分析显示，距离计算仍然是主要的计算瓶颈，而主机CPU和GPU之间的数据传输是影响大规模实际延迟的主导因素。研究还强调了不同系统设计在可扩展性和内存使用方面的关键权衡。

Conclusion: 研究结果为设计可扩展和稳健的GPU驱动近似最近邻搜索系统提供了明确的指导，并为知识发现和数据挖掘社区提供了全面的基准。

Abstract: Approximate Nearest Neighbor Search (ANNS) underpins many large-scale data mining and machine learning applications, with efficient retrieval increasingly hinging on GPU acceleration as dataset sizes grow. Although graph-based approaches represent the state of the art in approximate nearest neighbor search, there is a lack of systematic understanding regarding their optimization for modern GPU architectures and their end-to-end effectiveness in practical scenarios. In this work, we present a comprehensive survey and experimental study of GPU-accelerated graph-based vector search algorithms. We establish a detailed taxonomy of GPU optimization strategies and clarify the mapping between algorithmic tasks and hardware execution units within GPUs. Through a thorough evaluation of six leading algorithms on eight large-scale benchmark datasets, we assess both graph index construction and query search performance. Our analysis reveals that distance computation remains the primary computational bottleneck, while data transfer between the host CPU and GPU emerges as the dominant factor influencing real-world latency at large scale. We also highlight key trade-offs in scalability and memory usage across different system designs. Our findings offer clear guidelines for designing scalable and robust GPU-powered approximate nearest neighbor search systems, and provide a comprehensive benchmark for the knowledge discovery and data mining community.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [84] [A Reversible Semantics for Janus](https://arxiv.org/abs/2602.16913)
*Ivan Lanese,Germán Vidal*

Main category: cs.PL

TL;DR: Janus语言的现有小步语义缺乏可逆性，本文提出了一种新的可逆小步语义，且与现有语义等价。


<details>
  <summary>Details</summary>
Motivation: Janus是一种可逆编程语言，但其现有的小步语义在正向计算时会丢失信息，导致不可逆，不满足Loop Lemma，这限制了其在调试和并发扩展中的应用。

Method: 本文提出了一种新的小步语义，并通过为高级编程语言定义基于“程序计数器”的语义来解决这一非平凡的挑战。

Result: 成功实现了一种真正可逆的小步语义。

Conclusion: 本文提出了一种新的小步语义，该语义是可逆的，并且与Janus语言原有的语义等价。

Abstract: Janus is a paradigmatic example of reversible programming language. Indeed, Janus programs can be executed backwards as well as forwards. However, its small-step semantics (useful, e.g., for debugging or as a basis for extensions with concurrency primitives) is not reversible, since it loses information while computing forwards. E.g., it does not satisfy the Loop Lemma, stating that any reduction has an inverse, a main property of reversibility in process calculi, where small-step semantics is commonly used. We present here a novel small-step semantics which is actually reversible, while remaining equivalent to the previous one. It involves the non-trivial challenge of defining a semantics based on a "program counter" for a high-level programming language.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [85] [Intent Laundering: AI Safety Datasets Are Not What They Seem](https://arxiv.org/abs/2602.16729)
*Shahriar Golchin,Marc Wetter*

Main category: cs.CR

TL;DR: AI安全数据集过度依赖“触发性线索”，使其不切实际。通过“意图清洗”移除这些线索后，被认为是“安全”的模型变得脆弱（攻击成功率达90-98%），揭示了当前安全评估与真实世界威胁之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 系统评估现有AI安全数据集的质量，以确定它们是否能准确反映真实世界的攻击并衡量实际的安全风险，而不是仅仅通过“触发性线索”引起拒绝，从而揭示模型安全评估与真实世界对抗行为之间可能存在的脱节。

Method: 1. 从孤立角度评估数据集质量：考察数据集反映真实世界攻击的程度，依据三个关键特性（恶意意图驱动、精心构造、离群）。特别关注数据集对“触发性线索”的过度依赖。2. 从实践角度评估数据集：引入“意图清洗”（intent laundering）程序，该程序旨在抽象掉攻击中的触发性线索，同时严格保留恶意意图和所有相关细节。3. 将“意图清洗”应用于已评估的“安全”模型，并作为越狱技术进行测试。

Result: 1. 现有AI安全数据集过度依赖“触发性线索”（具有明显负面/敏感含义的词语或短语），这与真实世界的攻击不符。2. 一旦通过“意图清洗”移除这些触发性线索，所有先前被评估为“相当安全”的模型（包括Gemini 3 Pro和Claude Sonnet 3.7）都变得不安全。3. “意图清洗”作为一种越狱技术，在完全黑盒访问下，能持续达到90%至超过98%的高攻击成功率。4. 模型安全评估方式与真实世界对手行为之间存在显著脱节。

Conclusion: 目前的AI安全数据集由于过度依赖触发性线索，未能忠实地反映真实世界的攻击，导致模型安全评估与真实世界对抗行为之间存在显著脱节。需要重新审视并改进AI安全评估方法。

Abstract: We systematically evaluate the quality of widely used AI safety datasets from two perspectives: in isolation and in practice. In isolation, we examine how well these datasets reflect real-world attacks based on three key properties: driven by ulterior intent, well-crafted, and out-of-distribution. We find that these datasets overrely on "triggering cues": words or phrases with overt negative/sensitive connotations that are intended to trigger safety mechanisms explicitly, which is unrealistic compared to real-world attacks. In practice, we evaluate whether these datasets genuinely measure safety risks or merely provoke refusals through triggering cues. To explore this, we introduce "intent laundering": a procedure that abstracts away triggering cues from attacks (data points) while strictly preserving their malicious intent and all relevant details. Our results indicate that current AI safety datasets fail to faithfully represent real-world attacks due to their overreliance on triggering cues. In fact, once these cues are removed, all previously evaluated "reasonably safe" models become unsafe, including Gemini 3 Pro and Claude Sonnet 3.7. Moreover, when intent laundering is adapted as a jailbreaking technique, it consistently achieves high attack success rates, ranging from 90% to over 98%, under fully black-box access. Overall, our findings expose a significant disconnect between how model safety is evaluated and how real-world adversaries behave.

</details>


### [86] [Can Adversarial Code Comments Fool AI Security Reviewers -- Large-Scale Empirical Study of Comment-Based Attacks and Defenses Against LLM Code Analysis](https://arxiv.org/abs/2602.16741)
*Scott Thornton*

Main category: cs.CR

TL;DR: 对抗性注释对大型语言模型（LLM）的漏洞检测准确性影响不显著，与在代码生成任务中的表现不同，LLM对此类攻击具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明，对抗性提示操纵会降低大型语言模型（LLM）在代码生成中的性能。本研究旨在测试类似的基于注释的操纵是否会在漏洞检测过程中误导LLM。

Method: 构建了一个包含Python、JavaScript和Java的100个样本的基准，每个样本配有8种注释变体（从无注释到对抗性策略，如权限欺骗和技术欺骗）。评估了8个前沿模型（5个商业模型和3个开源模型），进行了9,366次试验。此外，还测试了4种自动化防御措施，进行了4,646次额外试验。

Result: 对抗性注释对检测准确性产生了微小且统计上不显著的影响（McNemar精确p > 0.21；所有95%置信区间均包含零）。商业模型（基线检测率为89%至96%）和开源模型（基线检测率为53%至72%）均如此。与注释操纵在代码生成设置中能实现高攻击成功率不同，漏洞检测性能并未显著下降。更复杂的对抗性策略并未比简单的操纵性注释提供任何优势。静态分析交叉引用防御效果最佳，检测率为96.9%，并恢复了47%的基线遗漏。失败主要集中在固有的高难度漏洞类别上（如竞态条件、时序侧信道和复杂授权逻辑），而非对抗性注释。

Conclusion: LLM在漏洞检测方面对基于注释的对抗性操纵具有鲁棒性，这与代码生成任务不同。漏洞检测的失败主要集中在固有的高难度漏洞类别上，而不是对抗性注释。

Abstract: AI-assisted code review is widely used to detect vulnerabilities before production release. Prior work shows that adversarial prompt manipulation can degrade large language model (LLM) performance in code generation. We test whether similar comment-based manipulation misleads LLMs during vulnerability detection. We build a 100-sample benchmark across Python, JavaScript, and Java, each paired with eight comment variants ranging from no comments to adversarial strategies such as authority spoofing and technical deception. Eight frontier models, five commercial and three open-source, are evaluated in 9,366 trials. Adversarial comments produce small, statistically non-significant effects on detection accuracy (McNemar exact p > 0.21; all 95 percent confidence intervals include zero). This holds for commercial models with 89 to 96 percent baseline detection and open-source models with 53 to 72 percent, despite large absolute performance gaps. Unlike generation settings where comment manipulation achieves high attack success, detection performance does not meaningfully degrade. More complex adversarial strategies offer no advantage over simple manipulative comments. We test four automated defenses across 4,646 additional trials (14,012 total). Static analysis cross-referencing performs best at 96.9 percent detection and recovers 47 percent of baseline misses. Comment stripping reduces detection for weaker models by removing helpful context. Failures concentrate on inherently difficult vulnerability classes, including race conditions, timing side channels, and complex authorization logic, rather than on adversarial comments.

</details>


### [87] [Large-scale online deanonymization with LLMs](https://arxiv.org/abs/2602.16800)
*Simon Lermen,Daniel Paleka,Joshua Swanson,Michael Aerni,Nicholas Carlini,Florian Tramèr*

Main category: cs.CR

TL;DR: 大型语言模型可用于大规模去匿名化，通过分析在线匿名资料和对话，能以高精度识别用户，并在封闭世界设置下，通过LLM提取特征、语义匹配和推理，直接处理原始用户内容，效果远超传统方法。研究结果表明在线匿名用户的实际隐蔽性不复存在，需重新考虑在线隐私威胁模型。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探讨大型语言模型在去匿名化方面的能力，解决传统去匿名化方法对结构化数据或手动特征工程的依赖，并评估在线匿名性面临的新威胁。

Method: 研究展示了具有完整互联网访问权限的智能体能高精度重新识别Hacker News用户和Anthropic Interviewer参与者。针对封闭世界设置，设计了一个可扩展的攻击管道，利用LLM提取身份相关特征、通过语义嵌入搜索候选匹配项、并对最佳候选进行推理以验证匹配并减少假阳性。该方法直接处理任意平台上的原始用户内容，无需结构化数据或手动特征工程。研究构建了三个具有已知真实数据的数据集进行评估：连接Hacker News和LinkedIn资料、匹配Reddit电影讨论社区用户、以及匹配同一用户的Reddit历史记录。

Result: 在所有评估设置中，基于LLM的方法均显著优于传统基线方法。与最佳非LLM方法接近0%的性能相比，LLM方法在90%的精度下实现了高达68%的召回率。

Conclusion: 研究结果表明，保护在线匿名用户的实际隐蔽性已不复存在。因此，需要重新审视在线隐私的威胁模型。

Abstract: We show that large language models can be used to perform at-scale deanonymization. With full Internet access, our agent can re-identify Hacker News users and Anthropic Interviewer participants at high precision, given pseudonymous online profiles and conversations alone, matching what would take hours for a dedicated human investigator. We then design attacks for the closed-world setting. Given two databases of pseudonymous individuals, each containing unstructured text written by or about that individual, we implement a scalable attack pipeline that uses LLMs to: (1) extract identity-relevant features, (2) search for candidate matches via semantic embeddings, and (3) reason over top candidates to verify matches and reduce false positives. Compared to prior deanonymization work (e.g., on the Netflix prize) that required structured data or manual feature engineering, our approach works directly on raw user content across arbitrary platforms. We construct three datasets with known ground-truth data to evaluate our attacks. The first links Hacker News to LinkedIn profiles, using cross-platform references that appear in the profiles. Our second dataset matches users across Reddit movie discussion communities; and the third splits a single user's Reddit history in time to create two pseudonymous profiles to be matched. In each setting, LLM-based methods substantially outperform classical baselines, achieving up to 68% recall at 90% precision compared to near 0% for the best non-LLM method. Our results show that the practical obscurity protecting pseudonymous users online no longer holds and that threat models for online privacy need to be reconsidered.

</details>


### [88] [DAVE: A Policy-Enforcing LLM Spokesperson for Secure Multi-Document Data Sharing](https://arxiv.org/abs/2602.17413)
*René Brinkhege,Prahlad Menon*

Main category: cs.CR

TL;DR: DAVE是一个LLM发言人，它通过受策略约束的自然语言接口安全地回答关于私有文档的问题，无需直接共享文档或手动编辑，而是通过在查询时进行“虚拟编辑”来保护敏感信息。


<details>
  <summary>Details</summary>
Motivation: 在当前的组织间数据空间中，使用策略主要在资产层面执行，导致共享粒度粗糙（整个文档或数据集共享或不共享）。当文档只有部分内容敏感时，为避免信息泄露，数据提供者通常需要手动编辑文档，这既昂贵又难以维护。

Method: 本文提出了DAVE，一个执行使用策略的LLM发言人，它通过自然语言接口回答关于私有文档的问题。DAVE通过“虚拟编辑”在查询时抑制敏感信息，而无需修改源文档。该方法将策略违规信息披露形式化，并描述了一个将发言人与Eclipse Dataspace Components和ODRL风格策略集成的架构。作者还概述了一个初步的提供者侧集成原型。

Result: 本文的主要贡献是架构性的，它提出并描述了一个用于将LLM发言人与Eclipse Dataspace Components和ODRL风格策略集成的架构，并提供了一个初步的提供者侧集成原型。它形式化了在此设置中的策略违规信息披露，并引入了虚拟编辑概念。由于尚未实现或全面评估整个执行流程，本文还概述了一个评估方法。

Conclusion: 本文为未来在系统化管理的LLM多方数据空间中评估安全性、实用性和性能权衡的实证工作奠定了基础，并概述了评估方法。

Abstract: In current inter-organizational data spaces, usage policies are enforced mainly at the asset level: a whole document or dataset is either shared or withheld. When only parts of a document are sensitive, providers who want to avoid leaking protected information typically must manually redact documents before sharing them, which is costly, coarse-grained, and hard to maintain as policies or partners change. We present DAVE, a usage policy-enforcing LLM spokesperson that answers questions over private documents on behalf of a data provider. Instead of releasing documents, the provider exposes a natural language interface whose responses are constrained by machine-readable usage policies. We formalize policy-violating information disclosure in this setting, drawing on usage control and information flow security, and introduce virtual redaction: suppressing sensitive information at query time without modifying source documents. We describe an architecture for integrating such a spokesperson with Eclipse Dataspace Components and ODRL-style policies, and outline an initial provider-side integration prototype in which QA requests are routed through a spokesperson service instead of triggering raw document transfer. Our contribution is primarily architectural: we do not yet implement or empirically evaluate the full enforcement pipeline. We therefore outline an evaluation methodology to assess security, utility, and performance trade-offs under benign and adversarial querying as a basis for future empirical work on systematically governed LLM access to multi-party data spaces.

</details>


### [89] [What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?](https://arxiv.org/abs/2602.17345)
*Boyang Ma,Hechuan Guo,Peizhuo Lv,Minghui Xu,Xuelong Dai,YeChao Zhang,Yijun Yang,Yue Zhang*

Main category: cs.CR

TL;DR: 具身AI系统在现实部署中面临不可逆的物理后果，但现有研究视角不足。本文提出具身AI的故障源于系统级不匹配，而非孤立缺陷，并阐明了四个核心见解，强调需从系统层面而非组件层面保障具身AI安全。


<details>
  <summary>Details</summary>
Motivation: 具身AI系统正从受控环境快速转向安全关键的现实世界部署，其故障可能导致不可逆的物理后果，引发了对安全性、保障性和可靠性的基本问题。现有研究主要通过LLM漏洞或经典CPS故障来分析具身AI，但这些视角不足以解释现代具身系统中的许多故障。因此，需要更深入地理解具身AI故障的根本原因。

Method: 本文通过一项调查（survey）指出，现有分析具身AI的视角（LLM漏洞或经典CPS故障）不足。作者提出，一类重要的故障源于具身引起的系统级不匹配，而非孤立的模型缺陷或传统CPS攻击。文章通过识别并阐述了四个核心见解来解释具身AI为何更难保障。

Result: 具身AI更难保障的原因在于：
(i) 语义正确性不意味着物理安全，因为语言级推理抽象掉了几何、动力学和接触约束。
(ii) 由于非线性动力学和状态不确定性，相同的动作在不同物理状态下可能导致截然不同的结果。
(iii) 微小误差会在紧密耦合的感知-决策-行动循环中传播和放大。
(iv) 安全在时间或系统层面上不具组合性，局部安全的决策可能累积成全局不安全的行为。

Conclusion: 确保具身AI的安全需要超越组件级防御，转向对物理风险、不确定性和故障传播进行系统级推理。

Abstract: Embodied AI systems (e.g., autonomous vehicles, service robots, and LLM-driven interactive agents) are rapidly transitioning from controlled environments to safety critical real-world deployments. Unlike disembodied AI, failures in embodied intelligence lead to irreversible physical consequences, raising fundamental questions about security, safety, and reliability. While existing research predominantly analyzes embodied AI through the lenses of Large Language Model (LLM) vulnerabilities or classical Cyber-Physical System (CPS) failures, this survey argues that these perspectives are individually insufficient to explain many observed breakdowns in modern embodied systems. We posit that a significant class of failures arises from embodiment-induced system-level mismatches, rather than from isolated model flaws or traditional CPS attacks. Specifically, we identify four core insights that explain why embodied AI is fundamentally harder to secure: (i) semantic correctness does not imply physical safety, as language-level reasoning abstracts away geometry, dynamics, and contact constraints; (ii) identical actions can lead to drastically different outcomes across physical states due to nonlinear dynamics and state uncertainty; (iii) small errors propagate and amplify across tightly coupled perception-decision-action loops; and (iv) safety is not compositional across time or system layers, enabling locally safe decisions to accumulate into globally unsafe behavior. These insights suggest that securing embodied AI requires moving beyond component-level defenses toward system-level reasoning about physical risk, uncertainty, and failure propagation.

</details>


### [90] [Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge](https://arxiv.org/abs/2602.17452)
*Wyatt Benno,Alberto Centelles,Antoine Douchet,Khalil Gibran*

Main category: cs.CR

TL;DR: Jolt Atlas是一个基于Jolt证明系统和ONNX张量操作的zkML框架，通过查找中心方法和优化实现了在内存受限环境下对机器学习模型推理的零知识证明，具有实际的证明时间，适用于隐私保护和对抗环境。


<details>
  <summary>Details</summary>
Motivation: 现有的零知识虚拟机（zkVMs）需要模拟CPU指令执行。Jolt Atlas旨在提供一个更直接、高效且适用于非线性函数的zkML框架，以解决现有zkVMs的复杂性，并利用ONNX的便携性和简化内存一致性验证的优势，实现在设备上进行加密验证。

Method: Jolt Atlas通过扩展Jolt证明系统，采用查找中心方法直接应用于ONNX张量操作，避免了对CPU寄存器的需求。它利用基于和校验协议的查找论证来处理非线性函数，并通过神经瞬移（neural teleportation）等优化技术减少查找表大小并保持模型精度。零知识特性通过Vega中引入的BlindFold技术实现。

Result: Jolt Atlas能够在内存受限的环境中证明模型推理（即流式证明），并对分类、嵌入、自动推理和小型语言模型展示了实际可行的证明时间。它支持在无需专用硬件的情况下进行设备上的加密验证，生成的证明简洁可验证。

Conclusion: Jolt Atlas是一个高效、实用的零知识机器学习框架，特别适用于需要隐私保护和面对对抗性环境的应用场景，通过其独特的架构和优化，实现了在设备上对ML推理进行密码学验证，且生成的证明简洁可验证。

Abstract: We present Jolt Atlas, a zero-knowledge machine learning (zkML) framework that extends the Jolt proving system to model inference. Unlike zkVMs (zero-knowledge virtual machines), which emulate CPU instruction execution, Jolt Atlas adapts Jolt's lookup-centric approach and applies it directly to ONNX tensor operations. The ONNX computational model eliminates the need for CPU registers and simplifies memory consistency verification. In addition, ONNX is an open-source, portable format, which makes it easy to share and deploy models across different frameworks, hardware platforms, and runtime environments without requiring framework-specific conversions. Our lookup arguments, which use sumcheck protocol, are well-suited for non-linear functions -- key building blocks in modern ML. We apply optimisations such as neural teleportation to reduce the size of lookup tables while preserving model accuracy, as well as several tensor-level verification optimisations detailed in this paper. We demonstrate that Jolt Atlas can prove model inference in memory-constrained environments -- a prover property commonly referred to as \textit{streaming}. Furthermore, we discuss how Jolt Atlas achieves zero-knowledge through the BlindFold technique, as introduced in Vega. In contrast to existing zkML frameworks, we show practical proving times for classification, embedding, automated reasoning, and small language models. Jolt Atlas enables cryptographic verification that can be run on-device, without specialised hardware. The resulting proofs are succinctly verifiable. This makes Jolt Atlas well-suited for privacy-centric and adversarial environments. In a companion work, we outline various use cases of Jolt Atlas, including how it serves as guardrails in agentic commerce and for trustless AI context (often referred to as \textit{AI memory}).

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [91] [Hybrid-Gym: Training Coding Agents to Generalize Across Tasks](https://arxiv.org/abs/2602.16819)
*Yiqing Xie,Emmy Liu,Gaokai Zhang,Nachiket Kotalwar,Shubham Gandhi,Sathwik Acharya,Xingyao Wang,Carolyn Rose,Graham Neubig,Daniel Fried*

Main category: cs.SE

TL;DR: 该论文通过分解任务轨迹识别可迁移技能，并提出Hybrid-Gym训练环境及其合成任务，显著提高了编码智能体在复杂真实世界任务上的泛化能力，并在多个基准测试中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前评估编码智能体的基准（如SWE-Bench）主要关注解决GitHub上的单一问题，而真实应用中智能体需处理更广泛、更复杂的任务，涉及代码库探索、软件测试和架构设计等多种技能。

Method: 通过将任务轨迹分解为细粒度组件，识别出可迁移技能，并推导设计辅助训练任务的原则。基于这些原则，提出了一个训练环境Hybrid-Gym，包含函数定位和依赖搜索等可扩展的合成任务。

Result: 在合成任务上训练的智能体能有效泛化到训练中未出现的真实世界任务。基础模型在SWE-Bench Verified上绝对增益25.4%，SWT-Bench Verified上7.9%，Commit-0 Lite上5.1%。Hybrid-Gym还能补充下游任务数据集，例如将SWE-Play在SWT-Bench Verified上的表现提高4.9%。

Conclusion: Hybrid-Gym及其合成任务能有效提升编码智能体在真实世界复杂任务中的泛化能力，并通过辅助训练显著改善现有模型在多个基准上的表现。

Abstract: When assessing the quality of coding agents, predominant benchmarks focus on solving single issues on GitHub, such as SWE-Bench. In contrast, in real use, these agents solve more various and complex tasks that involve other skills such as exploring codebases, testing software, and designing architecture. In this paper, we first characterize some transferable skills that are shared across diverse tasks by decomposing trajectories into fine-grained components, and derive a set of principles for designing auxiliary training tasks to teach language models these skills. Guided by these principles, we propose a training environment, Hybrid-Gym, consisting of a set of scalable synthetic tasks, such as function localization and dependency search. Experiments show that agents trained on our synthetic tasks effectively generalize to diverse real-world tasks that are not present in training, improving a base model by 25.4% absolute gain on SWE-Bench Verified, 7.9% on SWT-Bench Verified, and 5.1% on Commit-0 Lite. Hybrid-Gym also complements datasets built for the downstream tasks (e.g., improving SWE-Play by 4.9% on SWT-Bench Verified). Code available at: .

</details>


### [92] [Exploring LLMs for User Story Extraction from Mockups](https://arxiv.org/abs/2602.16997)
*Diego Firmenich,Leandro Antonelli,Bruno Pazos,Fabricio Lozada,Leonardo Morales*

Main category: cs.SE

TL;DR: 本文探索了如何结合用户故事、高保真模型和大型语言模型（LLMs）来从模型中敏捷且自动化地生成用户故事。


<details>
  <summary>Details</summary>
Motivation: 在软件行业中，用户故事和高保真模型被广泛用于定义功能需求并促进最终用户参与。本文旨在探索如何结合这些技术与大型语言模型，实现从模型中敏捷、自动化地生成用户故事。

Method: 通过一个案例研究，分析了大型语言模型从高保真模型中提取用户故事的能力，并比较了在提示中包含或不包含扩展词典语言（LEL）术语表的效果。

Result: 结果表明，整合扩展词典语言（LEL）显著提高了生成用户故事的准确性和适用性。

Conclusion: 这种方法代表了人工智能在需求工程中整合的进步，并有潜力改善用户和开发者之间的沟通。

Abstract: User stories are one of the most widely used artifacts in the software industry to define functional requirements. In parallel, the use of high-fidelity mockups facilitates end-user participation in defining their needs. In this work, we explore how combining these techniques with large language models (LLMs) enables agile and automated generation of user stories from mockups. To this end, we present a case study that analyzes the ability of LLMs to extract user stories from high-fidelity mockups, both with and without the inclusion of a glossary of the Language Extended Lexicon (LEL) in the prompts. Our results demonstrate that incorporating the LEL significantly enhances the accuracy and suitability of the generated user stories. This approach represents a step forward in the integration of AI into requirements engineering, with the potential to improve communication between users and developers.

</details>


### [93] [Wink: Recovering from Misbehaviors in Coding Agents](https://arxiv.org/abs/2602.17037)
*Rahul Nanda,Chandra Maddila,Smriti Jha,Euna Mehnaz Khan,Matteo Paltenghi,Satish Chandra*

Main category: cs.SE

TL;DR: 本论文提出了一种名为 Wink 的轻量级异步自干预系统，旨在自动恢复大型语言模型驱动的自主编码智能体常见的异常行为，并在大规模生产环境中成功解决了 90% 的异常行为，显著减少了工程师干预。


<details>
  <summary>Details</summary>
Motivation: 自主编码智能体（由大型语言模型驱动）在软件行业中被广泛采用，但存在多种异常行为，如偏离指令、陷入循环或工具使用失败。这些问题会扰乱开发工作流程并需要大量手动干预。

Method: 作者首先基于对生产流量的分析，提出了智能体异常行为的三类分类法：规范漂移、推理问题和工具调用失败。然后，开发了一个名为 Wink 的轻量级异步自干预系统，该系统观察智能体轨迹并提供有针对性的纠正指导。

Result: 该系统在超过 10,000 条真实世界智能体轨迹上进行了评估，成功解决了 90% 的需要单次干预的异常行为。在生产环境中的 A/B 测试表明，该系统显著减少了工具调用失败、每次会话的 Token 数量和每次会话的工程师干预次数。

Conclusion: 本研究设计并部署了一个大规模的弹性智能体系统，提供了在构建此类系统时面临的挑战和经验见解。

Abstract: Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getting stuck in repetitive loops, or failing to use tools correctly. These failures disrupt the development workflow and often require resource-intensive manual intervention. In this paper, we present a system for automatically recovering from agentic misbehaviors at scale. We first introduce a taxonomy of misbehaviors grounded in an analysis of production traffic, identifying three primary categories: Specification Drift, Reasoning Problems, and Tool Call Failures, which we find occur in about 30% of all agent trajectories. To address these issues, we developed a lightweight, asynchronous self-intervention system named Wink. Wink observes agent trajectories and provides targeted course-correction guidance to nudge the agent back to a productive path. We evaluated our system on over 10,000 real world agent trajectories and found that it successfully resolves 90% of the misbehaviors that require a single intervention. Furthermore, a live A/B test in our production environment demonstrated that our system leads to a statistically significant reduction in Tool Call Failures, Tokens per Session and Engineer Interventions per Session. We present our experience designing and deploying this system, offering insights into the challenges of building resilient agentic systems at scale.

</details>


### [94] [Robustness and Reasoning Fidelity of Large Language Models in Long-Context Code Question Answering](https://arxiv.org/abs/2602.17183)
*Kishan Maharaj,Nandakishore Menon,Ashita Saxena,Srikanth Tamilselvam*

Main category: cs.SE

TL;DR: 本研究系统评估了大型语言模型在长代码上下文问答中的鲁棒性，发现模型在不同答案格式、干扰项和上下文规模下性能显著下降，并对不相关信息表现出脆弱性，揭示了当前长上下文评估的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在需要对长代码上下文进行推理的软件工程任务中发挥越来越大的作用，但它们在不同输入条件下的鲁棒性尚不明确。

Method: 通过受控消融实验系统研究了长上下文代码问答，测试了对答案格式、干扰项和上下文规模的敏感性。通过新增COBOL和Java问答集扩展了LongCodeBench Python数据集，并在三种设置下评估了最先进的模型：(i) 打乱的多项选择题，(ii) 开放式问题，以及 (iii) 包含相关和对抗性不相关信息的“大海捞针”上下文。

Result: 在打乱的多项选择题和开放式问题中，性能均出现显著下降；在存在不相关线索的情况下，模型表现出脆弱的行为。

Conclusion: 当前长上下文评估的局限性，并为评估传统和现代系统中的代码推理提供更广泛的基准。

Abstract: Large language models (LLMs) increasingly assist software engineering tasks that require reasoning over long code contexts, yet their robustness under varying input conditions remains unclear. We conduct a systematic study of long-context code question answering using controlled ablations that test sensitivity to answer format, distractors, and context scale. Extending LongCodeBench Python dataset with new COBOL and Java question-answer sets, we evaluate state-of-the-art models under three settings: (i) shuffled multiple-choice options, (ii) open-ended questions and (iii) needle-in-a-haystack contexts containing relevant and adversarially irrelevant information. Results show substantial performance drops in both shuffled multiple-choice options and open-ended questions, and brittle behavior in the presence of irrelevant cues. Our findings highlight limitations of current long-context evaluations and provide a broader benchmark for assessing code reasoning in both legacy and modern systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [95] [Fuse3D: Generating 3D Assets Controlled by Multi-Image Fusion](https://arxiv.org/abs/2602.17040)
*Xuancheng Jin,Rengan Xie,Wenting Zheng,Rui Wang,Hujun Bao,Yuchi Huo*

Main category: cs.GR

TL;DR: Fuse3D提出了一种新颖方法，通过多条件图像控制生成3D资产，实现多级区域控制的无缝融合。


<details>
  <summary>Details</summary>
Motivation: 现有的3D生成方法在处理单一控制目标时表现良好，但无法利用多张图像独立控制3D资产的不同区域，这限制了其在应用中的灵活性。

Method: 论文提出了Fuse3D。首先，引入多条件融合模块以整合来自多个图像区域的视觉特征。其次，提出一种方法，基于语义线索自动对齐用户选择的2D图像区域与相关的3D区域。最后，为解决控制冲突并增强多条件图像的局部控制特征，引入局部注意力增强策略，灵活平衡区域特定的特征融合。

Result: 实验结果表明，Fuse3D能将多个2D图像区域灵活地融合到连贯的3D结构中，生成高质量的3D资产。

Conclusion: Fuse3D是第一个能够从多个条件图像进行可控3D资产生成的方法，实现了从全局视图到复杂局部细节的多级区域控制的无缝融合。

Abstract: Recently, generating 3D assets with the control of condition images has achieved impressive quality. However, existing 3D generation methods are limited to handling a single control objective and lack the ability to utilize multiple images to independently control different regions of a 3D asset, which hinders their flexibility in applications. We propose Fuse3D, a novel method that enables generating 3D assets under the control of multiple images, allowing for the seamless fusion of multi-level regional controls from global views to intricate local details. First, we introduce a Multi-Condition Fusion Module to integrate the visual features from multiple image regions. Then, we propose a method to automatically align user-selected 2D image regions with their associated 3D regions based on semantic cues. Finally, to resolve control conflicts and enhance local control features from multi-condition images, we introduce a Local Attention Enhancement Strategy that flexibly balances region-specific feature fusion. Overall, we introduce the first method capable of controllable 3D asset generation from multiple condition images. The experimental results indicate that Fuse3D can flexibly fuse multiple 2D image regions into coherent 3D structures, resulting in high-quality 3D assets. Code and data for this paper are at .

</details>


### [96] [InstantRetouch: Personalized Image Retouching without Test-time Fine-tuning Using an Asymmetric Auto-Encoder](https://arxiv.org/abs/2602.17044)
*Temesgen Muruts Weldengus,Binnan Liu,Fei Kou,Youwei Lyu,Jinwei Chen,Qingnan Fan,Changqing Zou*

Main category: cs.GR

TL;DR: InstantRetouch是一个通用的个性化图像修饰框架，它使用非对称自编码器和检索增强修饰（RAR），无需测试时微调即可即时适应用户修饰风格，实现卓越且通用的内容感知修饰个性化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在个性化图像修饰中通常需要用户特定的微调，或者泛化能力不足。

Method: InstantRetouch采用一个非对称自编码器，将来自配对示例的修饰风格编码成内容解耦的潜在表示，以实现忠实的风格迁移。此外，它提出了检索增强修饰（RAR），通过检索并聚合与查询图像内容最相似的参考对的风格潜在表示，来自适应地应用编码的修饰风格。

Result: InstantRetouch在单参考、多参考和混合风格等多种场景中实现了卓越且通用的内容感知修饰个性化，并且能够开箱即用地泛化到真实感风格迁移。

Conclusion: InstantRetouch提供了一种即时且自适应的个性化图像修饰解决方案，克服了现有方法在微调和泛化方面的局限性。

Abstract: Personalized image retouching aims to adapt retouching style of individual users from reference examples, but existing methods often require user-specific fine-tuning or fail to generalize effectively. To address these challenges, we introduce $\textbf{InstantRetouch}$, a general framework for personalized image retouching that instantly adapts to user retouching styles without any test-time fine-tuning. It employs an $\textit{asymmetric auto-encoder}$ to encode the retouching style from paired examples into a content disentangled latent representation that enables faithful transfer of the retouching style to new images. To adaptively apply the encoded retouching style to new images, we further propose $\textit{retrieval-augmented retouching}$ (RAR), which retrieves and aggregates style latents from reference pairs most similar in content to the query image. With these components, $\textbf{InstantRetouch}$ enables superior and generic content-aware retouching personalization across diverse scenarios, including single-reference, multi-reference, and mixed-style setups, while also generalizing out of the box to photorealistic style transfer.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [97] [Federated Latent Space Alignment for Multi-user Semantic Communications](https://arxiv.org/abs/2602.17271)
*Giuseppe Di Poce,Mario Edoardo Pandolfo,Emilio Calvanese Strinati,Paolo Di Lorenzo*

Main category: cs.IT

TL;DR: 本研究提出了一种在AI原生语义通信中，通过AP和用户设备上的语义均衡器以及联邦优化来缓解潜在空间不对齐的方法，以提升相互理解和任务执行效率。


<details>
  <summary>Details</summary>
Motivation: 语义通信旨在为有效执行任务传达意义，但AI原生设备中不同的潜在表示可能导致语义不匹配，从而阻碍相互理解。

Method: 提出了一种缓解多智能体AI原生语义通信中潜在空间不对齐的新方法。该方法在下行链路场景中，通过在AP共享语义预均衡器，并在用户设备部署本地语义均衡器来促进相互理解和面向任务的通信。同时，考虑了功耗和复杂性限制，并采用联邦优化对AP和用户侧的语义均衡器进行分布式训练。

Result: 数值结果验证了所提出的方法在面向目标的语义通信中的有效性，并揭示了准确性、通信开销、复杂性和AI原生通信设备的语义接近度之间的关键权衡。

Conclusion: 数值结果验证了该方法在面向目标的语义通信中的有效性，并揭示了准确性、通信开销、复杂性和AI原生通信设备的语义接近度之间的关键权衡。

Abstract: Semantic communication aims to convey meaning for effective task execution, but differing latent representations in AI-native devices can cause semantic mismatches that hinder mutual understanding. This paper introduces a novel approach to mitigating latent space misalignment in multi-agent AI- native semantic communications. In a downlink scenario, we consider an access point (AP) communicating with multiple users to accomplish a specific AI-driven task. Our method implements a protocol that shares a semantic pre-equalizer at the AP and local semantic equalizers at user devices, fostering mutual understanding and task-oriented communication while considering power and complexity constraints. To achieve this, we employ a federated optimization for the decentralized training of the semantic equalizers at the AP and user sides. Numerical results validate the proposed approach in goal-oriented semantic communication, revealing key trade-offs among accuracy, com- munication overhead, complexity, and the semantic proximity of AI-native communication devices.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [98] [Discovering Multiagent Learning Algorithms with Large Language Models](https://arxiv.org/abs/2602.16928)
*Zun Li,John Schultz,Daniel Hennes,Marc Lanctot*

Main category: cs.GT

TL;DR: 本文提出AlphaEvolve，一种由大型语言模型驱动的演化编码智能体，用于自动发现多智能体学习算法。通过将AlphaEvolve应用于遗憾最小化（CFR）和基于种群的训练（PSRO）两种范式，分别发现了新算法VAD-CFR和SHOR-PSRO。这些新算法采用了非直觉机制，并在经验收敛性上超越了各自领域的现有先进基线。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在不完美信息博弈中的进展，在很大程度上依赖于基线的迭代式人工改进。尽管CFR和PSRO等基础理论体系坚实，但其最有效变体的设计通常依赖于人类直觉来探索巨大的算法设计空间，这限制了算法发现的效率和创新性。

Method: 本文提出了AlphaEvolve，一种由大型语言模型驱动的演化编码智能体，用于自动发现新的多智能体学习算法。该框架被应用于两种不同的博弈论学习范式：1) 在迭代遗憾最小化领域，通过演化遗憾累积和策略推导逻辑，发现了Volatility-Adaptive Discounted (VAD-)CFR算法；2) 在基于种群的训练算法领域，通过演化训练时和评估时的元策略求解器，发现了Smoothed Hybrid Optimistic Regret (SHOR-)PSRO算法。

Result: 1) VAD-CFR在迭代遗憾最小化领域被发现，它采用了新颖的非直觉机制，包括波动敏感折扣、一致性强制乐观和硬启动策略积累计划，性能超越了Discounted Predictive CFR+等最先进的基线算法。2) SHOR-PSRO在基于种群的训练算法领域被发现，它引入了一种混合元求解器，将乐观遗憾匹配与平滑的、温度控制的最佳纯策略分布线性融合。通过动态退火该融合因子和多样性奖励，该算法实现了从种群多样性到严格均衡寻找的自动化过渡，与标准的静态元求解器相比，显示出更优越的经验收敛性。

Conclusion: AlphaEvolve框架能够自动发现新颖、非直觉的多智能体学习算法，并在迭代遗憾最小化和基于种群的训练算法这两种不同的博弈论学习范式中，超越了现有的先进基线算法。

Abstract: Much of the advancement of Multi-Agent Reinforcement Learning (MARL) in imperfect-information games has historically depended on manual iterative refinement of baselines. While foundational families like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (PSRO) rest on solid theoretical ground, the design of their most effective variants often relies on human intuition to navigate a vast algorithmic design space. In this work, we propose the use of AlphaEvolve, an evolutionary coding agent powered by large language models, to automatically discover new multiagent learning algorithms. We demonstrate the generality of this framework by evolving novel variants for two distinct paradigms of game-theoretic learning. First, in the domain of iterative regret minimization, we evolve the logic governing regret accumulation and policy derivation, discovering a new algorithm, Volatility-Adaptive Discounted (VAD-)CFR. VAD-CFR employs novel, non-intuitive mechanisms-including volatility-sensitive discounting, consistency-enforced optimism, and a hard warm-start policy accumulation schedule-to outperform state-of-the-art baselines like Discounted Predictive CFR+. Second, in the regime of population based training algorithms, we evolve training-time and evaluation-time meta strategy solvers for PSRO, discovering a new variant, Smoothed Hybrid Optimistic Regret (SHOR-)PSRO. SHOR-PSRO introduces a hybrid meta-solver that linearly blends Optimistic Regret Matching with a smoothed, temperature-controlled distribution over best pure strategies. By dynamically annealing this blending factor and diversity bonuses during training, the algorithm automates the transition from population diversity to rigorous equilibrium finding, yielding superior empirical convergence compared to standard static meta-solvers.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [99] [Bluetooth Phased-array Aided Inertial Navigation Using Factor Graphs: Experimental Verification](https://arxiv.org/abs/2602.17407)
*Glen Hjelmerud Mørkbak Sørensen,Torleiv H. Bryne,Kristoffer Gryte,Tor Arne Johansen*

Main category: eess.SY

TL;DR: 本文比较了在GNSS拒绝环境下，利用相控阵蓝牙系统进行辅助惯性导航的不同鲁棒估计策略。研究使用多旋翼无人机飞行实验数据，评估了蓝牙角度测量、测距或气压辅助下的性能。


<details>
  <summary>Details</summary>
Motivation: 相控阵蓝牙系统为GNSS拒绝环境（如仓库物流、无人机着陆和自主对接）中的辅助惯性导航提供了一种低成本的替代方案。使用商用现成组件可以降低相控阵无线电导航系统的进入门槛，尽管代价是测量噪声显著增加和可行范围相对较短。

Method: 本文比较了基于因子图优化的估计器所采用的鲁棒估计策略，并使用了多旋翼无人机飞行的实验数据。评估了在GNSS丢失场景下，由蓝牙角度测量以及测距或气压辅助时的性能。

Result: 评估了在GNSS丢失场景下，由蓝牙角度测量以及测距或气压辅助时的性能。

Conclusion: （抽象中未明确给出结论，但研究目标是评估不同鲁棒估计策略在GNSS拒绝环境中，利用蓝牙、测距或气压辅助惯性导航的性能。）

Abstract: Phased-array Bluetooth systems have emerged as a low-cost alternative for performing aided inertial navigation in GNSS-denied use cases such as warehouse logistics, drone landings, and autonomous docking. Basing a navigation system off of commercial-off-the-shelf components may reduce the barrier of entry for phased-array radio navigation systems, albeit at the cost of significantly noisier measurements and relatively short feasible range. In this paper, we compare robust estimation strategies for a factor graph optimisation-based estimator using experimental data collected from multirotor drone flight. We evaluate performance in loss-of-GNSS scenarios when aided by Bluetooth angular measurements, as well as range or barometric pressure.

</details>


### [100] [Dodging the Moose: Experimental Insights in Real-Life Automated Collision Avoidance](https://arxiv.org/abs/2602.17512)
*Leila Gharavi,Simone Baldi,Yuki Hosomi,Tona Sato,Bart De Schutter,Binh-Minh Nguyen,Hiroshi Fujimoto*

Main category: eess.SY

TL;DR: 该研究通过提出一种类人前馈规划器辅助MPC，实现了在紧急避障场景中自动驾驶车辆的实时碰撞避免实验，解决了纯MPC计算需求高和实时性差的问题。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，紧急避障场景（如麋鹿测试）的实时碰撞避免仍然是一个挑战，因为模型预测控制（MPC）在处理此类危险情况下的规避动作时计算需求高，导致难以实时实现。最先进的非线性MPC在实时提供可接受解决方案方面能力有限。

Method: 该论文提出了一种类人前馈规划器，用于辅助最先进的非线性模型预测控制（MPC），以解决MPC优化问题不可行或由于初始猜测不佳而无法找到合适解决方案的情况。前馈规划器通过“最大转向操纵”概念设计，以模拟人类在检测到障碍物后的反应。通过使用FPEV2-Kanon电动车在不同速度和紧急程度下进行真实实验。

Result: 研究人员使用FPEV2-Kanon电动车在不同速度和紧急程度下进行了真实实验。结果表明，所提出的规划策略与最先进的MPC运动规划器相比，有效性得到了验证。

Conclusion: 该论文通过在紧急避障场景中结合MPC和类人前馈规划器，实现了实时碰撞避免的实验性部署，克服了纯MPC在计算需求和实时性方面的限制。

Abstract: The sudden appearance of a static obstacle on the road, i.e. the moose test, is a well-known emergency scenario in collision avoidance for automated driving. Model Predictive Control (MPC) has long been employed for planning and control of automated vehicles in the state of the art. However, real-time implementation of automated collision avoidance in emergency scenarios such as the moose test remains unaddressed due to the high computational demand of MPC for evasive action in such hazardous scenarios. This paper offers new insights into real-time collision avoidance via the experimental imple- mentation of MPC for motion planning after a sudden and unexpected appearance of a static obstacle. As the state-of-the-art nonlinear MPC shows limited capability to provide an acceptable solution in real-time, we propose a human-like feed-forward planner to assist when the MPC optimization problem is either infeasible or unable to find a suitable solution due to the poor quality of its initial guess. We introduce the concept of maximum steering maneuver to design the feed-forward planner and mimic a human-like reaction after detecting the static obstacle on the road. Real-life experiments are conducted across various speeds and level of emergency using FPEV2-Kanon electric vehicle. Moreover, we demonstrate the effectiveness of our planning strategy via comparison with the state-of- the-art MPC motion planner.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [101] [Application and Evaluation of the Common Circles Method](https://arxiv.org/abs/2602.17353)
*Michael Quellmalz,Mia Kvåle Løvmo,Simon Moser,Franziska Strasser,Monika Ritsch-Marte*

Main category: math.NA

TL;DR: 该研究将通用圆法应用于光学衍射断层扫描 (ODT) 中亚毫米级生物组织样本运动的估计，并通过结合时间一致性约束实现了稳定的重建，证明其在运动检测方面是全优化方法的一种计算高效的替代方案。


<details>
  <summary>Details</summary>
Motivation: 在光学衍射断层扫描 (ODT) 中，当样本通过非接触式声学力场限制时，需要从捕获的图像中估计其运动。

Method: 采用通用圆法，通过识别傅里叶空间中埃瓦尔德球体的交点来确定旋转运动，并引入时间一致性约束以实现稳定的重建。

Result: 在模拟和真实世界数据上的结果表明，通用圆法为运动检测提供了比全优化方法计算效率更高的替代方案。

Conclusion: 通用圆法是一种计算高效的运动检测方法，可作为全优化方法的替代，用于光学衍射断层扫描中的样本运动估计。

Abstract: We investigate the application of the common circle method for estimating sample motion in optical diffraction tomography (ODT) of sub-millimeter sized biological tissue. When samples are confined via contact-free acoustical force fields, their motion must be estimated from the captured images. The common circle method identifies intersections of Ewald spheres in Fourier space to determine rotational motion. This paper presents a practical implementation, incorporating temporal consistency constraints to achieve stable reconstructions. Our results on both simulated and real-world data demonstrate that the common circle method provides a computationally efficient alternative to full optimization methods for motion detection.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [102] [AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence](https://arxiv.org/abs/2602.16873)
*Geunbin Yu*

Main category: cs.MA

TL;DR: 随着大型语言模型性能趋同，本文提出 AdaptOrch 框架，通过动态选择多智能体编排拓扑（并行、顺序、分层、混合），显著提升系统级性能，而非依赖单一模型选择。研究表明，编排设计独立于模型扩展，是首要优化目标，可带来 12-23% 的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着来自不同提供商的大型语言模型在基准性能上趋于一致，为每个任务选择单一最佳模型的传统范式收益递减。本文认为，编排拓扑（即多个智能体如何协调、并行和合成的结构组成）现在在系统级性能上优于单个模型能力。

Method: 本文提出了 AdaptOrch，一个任务自适应多智能体编排的正式框架，它根据任务依赖图和经验推导的领域特征，动态选择四种典型拓扑结构（并行、顺序、分层和混合）。该框架引入了三个关键贡献：(1) 性能收敛比例定律，形式化了编排选择优于模型选择的条件；(2) 拓扑路由算法，将任务分解的DAG映射到最优编排模式；(3) 具有可证明终止保证和启发式一致性评分的自适应合成协议，用于并行智能体输出。

Result: AdaptOrch 在编码、推理和检索增强生成任务中验证，即使使用相同的底层模型，拓扑感知编排也比静态单一拓扑基线提高了 12-23%。

Conclusion: 编排设计是独立于模型扩展的首要优化目标。

Abstract: As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, parallelized, and synthesized -- now dominates system-level performance over individual model capability. We present AdaptOrch, a formal framework for task-adaptive multi-agent orchestration that dynamically selects among four canonical topologies (parallel, sequential, hierarchical, and hybrid) based on task dependency graphs and empirically derived domain characteristics. Our framework introduces three key contributions: (1) a Performance Convergence Scaling Law, formalizing conditions under which orchestration selection outweighs model selection; (2) a Topology Routing Algorithm that maps task decomposition DAGs to optimal orchestration patterns in O(|V| + |E|) time; and (3) an Adaptive Synthesis Protocol with provable termination guarantees and heuristic consistency scoring for parallel agent outputs. We validate AdaptOrch across coding (SWE-bench), reasoning (GPQA), and retrieval-augmented generation tasks, demonstrating that topology-aware orchestration achieves 12-23% improvement over static single-topology baselines, even when using identical underlying models. Our results establish orchestration design as a first-class optimization target independent of model scaling.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [103] [Deeper detection limits in astronomical imaging using self-supervised spatiotemporal denoising](https://arxiv.org/abs/2602.17205)
*Yuduo Guo,Hao Zhang,Mingyu Li,Fujiang Yu,Yunjing Wu,Yuhan Hao,Song Huang,Yongming Liang,Xiaojing Lin,Xinyang Li,Jiamin Wu,Zheng Cai,Qionghai Dai*

Main category: astro-ph.IM

TL;DR: ASTERIS是一种基于自监督Transformer的天文去噪算法，通过整合多曝光时空信息，将天文图像的探测极限提高了1.0星等，并发现了更暗的物体。


<details>
  <summary>Details</summary>
Motivation: 天文成像观测受到多种噪声源的限制，其中一些噪声在相邻像素和曝光之间存在关联，原则上可以学习和校正。

Method: 本文提出了一种名为ASTERIS的天文自监督Transformer去噪算法，该算法整合了多个曝光的时空信息。

Result: 基准测试表明，ASTERIS在90%的完整性和纯度下将探测极限提高了1.0星等，同时保持了点扩散函数和测光精度。通过JWST和Subaru望远镜的观测数据验证，ASTERIS识别出以前无法检测到的特征，包括低表面亮度星系结构和引力透镜弧。应用于JWST深空图像，ASTERIS比以前的方法多识别出三倍的红移>9星系候选体，其静止帧紫外光度暗1.0星等。

Conclusion: ASTERIS显著提升了天文观测的探测能力，从而发现了更暗和以前隐藏的天体。

Abstract: The detection limit of astronomical imaging observations is limited by several noise sources. Some of that noise is correlated between neighbouring image pixels and exposures, so in principle could be learned and corrected. We present an astronomical self-supervised transformer-based denoising algorithm (ASTERIS), that integrates spatiotemporal information across multiple exposures. Benchmarking on mock data indicates that ASTERIS improves detection limits by 1.0 magnitude at 90% completeness and purity, while preserving the point spread function and photometric accuracy. Observational validation using data from the James Webb Space Telescope (JWST) and Subaru telescope identifies previously undetectable features, including low-surface-brightness galaxy structures and gravitationally-lensed arcs. Applied to deep JWST images, ASTERIS identifies three times more redshift > 9 galaxy candidates, with rest-frame ultraviolet luminosity 1.0 magnitude fainter, than previous methods.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [104] [The Compute ICE-AGE: Invariant Compute Envelope under Addressable Graph Evolution](https://arxiv.org/abs/2602.16736)
*Raymond Jay Martin II*

Main category: cs.OS

TL;DR: 本文提出了一种新的确定性语义状态基板，与现有AI架构不同，其计算成本不随token量扩展，而是由内存容量决定，并在2500万节点下实现了不变的计算性能。


<details>
  <summary>Details</summary>
Motivation: 当代的推理驱动AI架构通过概率重构来重建语义状态，导致计算成本随token量和上下文范围的增加而扩展。本文旨在提出一种替代方案，其计算成本不随token量扩展。

Method: 本文基于之前关于有界局部生成器类（Bounded Local Generator Classes）的正式工作，实现了生产级的C++确定性语义状态基板。该系统在数学规范化后被实现为一个CPU驻留的图引擎，在有时变局部算子g(t)的作用下进行有界局部状态演化，将语义连续性表示为持久的、可寻址的内存图。计算量由局部语义变化Delta s决定，与总内存基数M无关。

Result: 在Apple M2级芯片上的实证测量显示，在1M到25M节点范围内持续运行，遍历延迟不变（约0.25至0.32毫秒），CPU利用率稳定（基线约17.2%，Delta CPU约0至0.2%），且无随规模相关的热特征。测得的每节点密度范围从约1.3 KB（Float64基线）到约687字节（压缩Float32）。按二进制内存计算，1 TiB内存可支持16亿个节点。

Conclusion: 结果表明，该系统处于经验上不变的计算热力学状态，其扩展性由内存容量而非推理重构决定。这定义了高达2500万节点的“可寻址图演化下的不变计算包络”（Compute ICE-AGE）机制。

Abstract: This paper presents empirical results from a production-grade C++ implementation of a deterministic semantic state substrate derived from prior formal work on Bounded Local Generator Classes (Martin, 2026). The system was mathematically specified prior to implementation and realized as a CPU-resident graph engine operating under bounded local state evolution. Contemporary inference-driven AI architectures reconstruct semantic state through probabilistic recomposition, producing compute cost that scales with token volume and context horizon. In contrast, the substrate described here represents semantic continuity as a persistent, addressable memory graph evolved under a time-modulated local operator g(t). Work is bounded by local semantic change Delta s, independent of total memory cardinality M. Empirical measurements on Apple M2-class silicon demonstrate invariant traversal latency (approximately 0.25 to 0.32 ms), stable CPU utilization (approximately 17.2 percent baseline with Delta CPU approximately 0 to 0.2 percent), and no scale-correlated thermal signature across 1M to 25M node regimes under sustained operation. Measured per-node density ranges from approximately 1.3 KB (Float64 baseline) to approximately 687 bytes (compressed Float32 accounting). Under binary memory accounting, this yields a 1.6 billion node capacity projection within a 1 TiB envelope. These results indicate an empirically invariant thermodynamic regime in which scaling is governed by memory capacity rather than inference-bound recomposition. The Compute ICE-AGE is defined as the Invariant Compute Envelope under Addressable Graph Evolution, and the empirical evidence presented demonstrates this regime up to 25M nodes.

</details>


<div id='physics.acc-ph'></div>

# physics.acc-ph [[Back]](#toc)

### [105] [Toward a Fully Autonomous, AI-Native Particle Accelerator](https://arxiv.org/abs/2602.17536)
*Chris Tennant*

Main category: physics.acc-ph

TL;DR: 这篇定位论文提出了一个关于自驱动粒子加速器的愿景，该加速器通过AI协同设计，从初始阶段就实现自主运行，以最大限度地提高性能和科学产出。


<details>
  <summary>Details</summary>
Motivation: 通过AI协同设计和自主操作，实现前所未有的科学产出和可靠性。

Method: 提出未来设施应通过人工智能(AI)协同设计，共同优化加速器晶格、诊断和科学应用，并概述了包括智能控制架构、知识集成、自适应学习、数字孪生、健康监测、安全框架、模块化硬件设计、多模态数据融合和跨领域协作在内的九个关键研究方向。

Result: 设想将设施设计为AI原生平台，以实现AI驱动的设计和操作，从而提供前所未有的科学产出和可靠性。

Conclusion: 该路线图旨在引导加速器社区迈向一个由AI驱动设计和操作带来前所未有科学产出和可靠性的未来。

Abstract: This position paper presents a vision for self-driving particle accelerators that operate autonomously with minimal human intervention. We propose that future facilities be designed through artificial intelligence (AI) co-design, where AI jointly optimizes the accelerator lattice, diagnostics, and science application from inception to maximize performance while enabling autonomous operation. Rather than retrofitting AI onto human-centric systems, we envision facilities designed from the ground up as AI-native platforms. We outline nine critical research thrusts spanning agentic control architectures, knowledge integration, adaptive learning, digital twins, health monitoring, safety frameworks, modular hardware design, multimodal data fusion, and cross-domain collaboration. This roadmap aims to guide the accelerator community toward a future where AI-driven design and operation deliver unprecedented science output and reliability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [106] [AIdentifyAGE Ontology for Decision Support in Forensic Dental Age Assessment](https://arxiv.org/abs/2602.16714)
*Renato Marcelo,Ana Rodrigues,Cristiana Palmela Pereira,António Figueiras,Rui Santos,José Rui Figueira,Alexandre P Francisco,Cátia Vaz*

Main category: cs.AI

TL;DR: AIdentifyAGE本体论旨在通过提供一个标准化、语义连贯的框架，解决法医牙龄评估中现有方法的异质性、数据碎片化和互操作性有限等挑战，从而提高透明度、可解释性和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 法医和司法决策中的年龄评估至关重要，特别是在涉及无证人员和无人陪伴未成年人的案件中。然而，当前牙龄评估实践面临方法学异质性、数据表示碎片化以及临床、法医和法律信息系统之间互操作性有限的挑战，阻碍了透明度和可重复性，尤其是在AI方法日益普及的情况下。

Method: 该论文提出并开发了AIdentifyAGE本体论，这是一个领域特定且语义连贯的标准化框架。它涵盖了手动和AI辅助的法医牙龄评估工作流程，并建模了完整的医疗-法律工作流程，集成了司法背景、个体信息、法医检查数据、牙齿发育评估方法、影像学、统计参考研究和基于AI的估计方法。该本体论与领域专家共同开发，并建立在现有生物医学、牙科和机器学习本体论之上。

Result: AIdentifyAGE本体论能够实现观察结果、方法、参考数据和报告结果之间的可追溯链接。它确保了互操作性、可扩展性并符合FAIR原则。

Conclusion: AIdentifyAGE本体论是提高法医牙龄评估一致性、透明度和可解释性的关键一步，为医疗-法律和司法背景下的本体驱动决策支持系统奠定了坚实的基础。

Abstract: Age assessment is crucial in forensic and judicial decision-making, particularly in cases involving undocumented individuals and unaccompanied minors, where legal thresholds determine access to protection, healthcare, and judicial procedures. Dental age assessment is widely recognized as one of the most reliable biological approaches for adolescents and young adults, but current practices are challenged by methodological heterogeneity, fragmented data representation, and limited interoperability between clinical, forensic, and legal information systems. These limitations hinder transparency and reproducibility, amplified by the increasing adoption of AI- based methods. The AIdentifyAGE ontology is domain-specific and provides a standardized, semantically coherent framework, encompassing both manual and AI-assisted forensic dental age assessment workflows, and enabling traceable linkage between observations, methods, reference data, and reported outcomes. It models the complete medico-legal workflow, integrating judicial context, individual-level information, forensic examination data, dental developmental assessment methods, radiographic imaging, statistical reference studies, and AI-based estimation methods. It is being developed together with domain experts, and it builds on upper and established biomedical, dental, and machine learning ontologies, ensuring interoperability, extensibility, and compliance with FAIR principles. The AIdentifyAGE ontology is a fundamental step to enhance consistency, transparency, and explainability, establishing a robust foundation for ontology-driven decision support systems in medico-legal and judicial contexts.

</details>


### [107] [Contextuality from Single-State Representations: An Information-Theoretic Principle for Adaptive Intelligence](https://arxiv.org/abs/2602.16716)
*Song-Ju Kim*

Main category: cs.AI

TL;DR: 本研究表明，语境性是经典概率表征中单一状态重用的必然结果，而非量子力学独有。任何经典模型若要再现语境结果统计，都必须付出不可约的信息论代价，即对语境的依赖不能仅通过内部状态来调节。非经典概率框架可通过放宽单一全局联合概率空间假设来避免此问题。


<details>
  <summary>Details</summary>
Motivation: 自适应系统通常在多个上下文中运行，由于内存、表征或物理资源的限制，它们会重用固定的内部状态空间。这种单一状态重用在自然和人工智能中无处不在，但其基本的表征结果却知之甚少。该研究旨在探究语境性作为经典概率表征中单一状态重用的必然结果。

Method: 通过将上下文建模为作用于共享内部状态的干预，该研究证明了任何重现上下文结果统计的经典模型都必须承担不可约的信息论代价。该研究提供了一个最小的建设性例子来明确地实现这种代价并阐明其操作意义。

Result: 语境性不是量子力学的特有现象，而是经典概率表征中单一状态重用的必然结果。任何重现上下文结果统计的经典模型都必须承担不可约的信息论代价：对上下文的依赖不能仅仅通过内部状态来调节。

Conclusion: 语境性是自适应智能的一种普遍的表征约束，与具体的物理实现无关。非经典概率框架可以通过放宽单一全局联合概率空间的假设来避免这种障碍，而无需引入量子动力学或希尔伯特空间结构。

Abstract: Adaptive systems often operate across multiple contexts while reusing a fixed internal state space due to constraints on memory, representation, or physical resources. Such single-state reuse is ubiquitous in natural and artificial intelligence, yet its fundamental representational consequences remain poorly understood. We show that contextuality is not a peculiarity of quantum mechanics, but an inevitable consequence of single-state reuse in classical probabilistic representations. Modeling contexts as interventions acting on a shared internal state, we prove that any classical model reproducing contextual outcome statistics must incur an irreducible information-theoretic cost: dependence on context cannot be mediated solely through the internal state. We provide a minimal constructive example that explicitly realizes this cost and clarifies its operational meaning. We further explain how nonclassical probabilistic frameworks avoid this obstruction by relaxing the assumption of a single global joint probability space, without invoking quantum dynamics or Hilbert space structure. Our results identify contextuality as a general representational constraint on adaptive intelligence, independent of physical implementation.

</details>


### [108] [When AI Benchmarks Plateau: A Systematic Study of Benchmark Saturation](https://arxiv.org/abs/2602.16763)
*Mubashara Akhtar,Anka Reuel,Prajna Soni,Sanchit Ahuja,Pawan Sasanka Ammanamanchi,Ruchit Rawal,Vilém Zouhar,Srishti Yadav,Chenxi Whitehouse,Dayeon Ki,Jennifer Mickel,Leshem Choshen,Marek Šuppa,Jan Batzner,Jenny Chim,Jeba Sania,Yanan Long,Hossein A. Rahmani,Christina Knight,Yiyang Nan,Jyoutir Raj,Yu Fan,Shubham Singh,Subramanyam Sahoo,Eliya Habba,Usman Gohar,Siddhesh Pawar,Robert Scholz,Arjun Subramonian,Jingwei Ni,Mykel Kochenderfer,Sanmi Koyejo,Mrinmaya Sachan,Stella Biderman,Zeerak Talat,Avijit Ghosh,Irene Solaiman*

Main category: cs.AI

TL;DR: AI基准测试饱和迅速，失去价值。本研究分析了60个LLM基准测试，发现近一半已饱和，且饱和率随时间增加。专家策划的基准测试比众包的更能抵抗饱和，而隐藏测试数据无效。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）基准测试很快就会饱和，无法区分表现最佳的模型，从而降低了其长期价值。

Method: 该研究分析了来自主要模型开发者的60个大型语言模型（LLM）基准测试的饱和度。通过14个特性（任务设计、数据构建、评估格式）对基准进行分类，并检验了五个假设，以探究各特性如何影响饱和率。

Result: 近一半的基准测试表现出饱和，且饱和率随基准测试老化而增加。隐藏测试数据（即公开与私有）没有显示出保护作用，而专家策划的基准测试比众包基准测试更能抵抗饱和。

Conclusion: 研究结果揭示了延长基准测试生命周期的设计选择，并为更持久的评估策略提供了信息。

Abstract: Artificial Intelligence (AI) benchmarks play a central role in measuring progress in model development and guiding deployment decisions. However, many benchmarks quickly become saturated, meaning that they can no longer differentiate between the best-performing models, diminishing their long-term value. In this study, we analyze benchmark saturation across 60 Large Language Model (LLM) benchmarks selected from technical reports by major model developers. To identify factors driving saturation, we characterize benchmarks along 14 properties spanning task design, data construction, and evaluation format. We test five hypotheses examining how each property contributes to saturation rates. Our analysis reveals that nearly half of the benchmarks exhibit saturation, with rates increasing as benchmarks age. Notably, hiding test data (i.e., public vs. private) shows no protective effect, while expert-curated benchmarks resist saturation better than crowdsourced ones. Our findings highlight which design choices extend benchmark longevity and inform strategies for more durable evaluation.

</details>


### [109] [Simple Baselines are Competitive with Code Evolution](https://arxiv.org/abs/2602.16805)
*Yonatan Gideoni,Sebastian Risi,Yarin Gal*

Main category: cs.AI

TL;DR: 本研究评估了代码演化方法，发现简单基线在数学边界、智能体支架和机器学习竞赛三个领域中表现与复杂方法相当或更优，并指出了代码演化开发和使用中的不足，提出了改进评估和未来实践的建议。


<details>
  <summary>Details</summary>
Motivation: 许多提议的代码演化流程表现出色，但通常没有与更简单的基线进行比较。本研究旨在评估简单基线与更复杂方法相比的表现。

Method: 论文通过在三个领域测试了两个简单的基线方法：寻找更好的数学边界、设计智能体支架和机器学习竞赛。

Result: 研究发现，在所有三个领域中，简单基线方法都匹配或超越了更复杂的方法。具体来说：
1.  **数学边界**：问题的搜索空间和提示中的领域知识是决定搜索性能上限和效率的主要因素，代码演化流程是次要的。找到改进边界的主要挑战是设计好的搜索空间，而非搜索本身。
2.  **智能体支架**：支架的高方差与小数据集结合导致选择了次优的支架，使得手动设计的多数投票支架表现最佳。

Conclusion: 通过分析结果，论文发现了代码演化在开发和使用中的各种缺点。作者提出了更好的评估方法，以减少评估的随机性并保持经济可行性，并讨论了未来工作中实现更严谨代码演化的途径和最佳实践。

Abstract: Code evolution is a family of techniques that rely on large language models to search through possible computer programs by evolving or mutating existing code. Many proposed code evolution pipelines show impressive performance but are often not compared to simpler baselines. We test how well two simple baselines do over three domains: finding better mathematical bounds, designing agentic scaffolds, and machine learning competitions. We find that simple baselines match or exceed much more sophisticated methods in all three. By analyzing these results we find various shortcomings in how code evolution is both developed and used. For the mathematical bounds, a problem's search space and domain knowledge in the prompt are chiefly what dictate a search's performance ceiling and efficiency, with the code evolution pipeline being secondary. Thus, the primary challenge in finding improved bounds is designing good search spaces, which is done by domain experts, and not the search itself. When designing agentic scaffolds we find that high variance in the scaffolds coupled with small datasets leads to suboptimal scaffolds being selected, resulting in hand-designed majority vote scaffolds performing best. We propose better evaluation methods that reduce evaluation stochasticity while keeping the code evolution economically feasible. We finish with a discussion of avenues and best practices to enable more rigorous code evolution in future work.

</details>


### [110] [Improved Upper Bounds for Slicing the Hypercube](https://arxiv.org/abs/2602.16807)
*Duncan Soiffer,Nathaniel Itty,Christopher D. Rosin,Blake Bruell,Mason DiCicco,Gábor N. Sárközy,Ryan Offstein,Daniel Reichman*

Main category: cs.AI

TL;DR: 该论文提高了切开n维超立方体所有边所需的最小超平面数S(n)的已知上限，并获得新的下限。


<details>
  <summary>Details</summary>
Motivation: 改进1971年Paterson提出的S(n) ≤ ⌈5n/6⌉的旧上限。

Method: 通过构造8个超平面来切开Q10，证明了S(n)的改进上限，并借助CPro1（一种结合LLMs和自动超参数调优的自动化工具）来创建搜索算法以发现数学构造。

Result: 证明了S(n) ≤ ⌈4n/5⌉，除了n是5的奇数倍时S(n) ≤ 4n/5 + 1，这改进了Paterson先前的工作。同时，还获得了使用k<n个超平面切开Qn中最大边数的新下限。

Conclusion: 该研究显著提高了超立方体切片问题的上限，并引入了利用LLMs和自动化工具进行数学构造发现的新方法。

Abstract: A collection of hyperplanes $\mathcal{H}$ slices all edges of the $n$-dimensional hypercube $Q_n$ with vertex set $\{-1,1\}^n$ if, for every edge $e$ in the hypercube, there exists a hyperplane in $\mathcal{H}$ intersecting $e$ in its interior. Let $S(n)$ be the minimum number of hyperplanes needed to slice $Q_n$. We prove that $S(n) \leq \lceil \frac{4n}{5} \rceil$, except when $n$ is an odd multiple of $5$, in which case $S(n) \leq \frac{4n}{5} +1$. This improves upon the previously known upper bound of $S(n) \leq \lceil\frac{5n}{6} \rceil$ due to Paterson reported in 1971. We also obtain new lower bounds on the maximum number of edges in $Q_n$ that can be sliced using $k<n$ hyperplanes. We prove the improved upper bound on $S(n)$ by constructing $8$ hyperplanes slicing $Q_{10}$ aided by the recently introduced CPro1: an automatic tool that uses reasoning LLMs coupled with automated hyperparameter tuning to create search algorithms for the discovery of mathematical constructions.

</details>


### [111] [Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI](https://arxiv.org/abs/2602.16814)
*Eiman Kanjo,Mustafa Aslanov*

Main category: cs.AI

TL;DR: 本文提出了一种名为“节点学习”的去中心化学习范式，旨在解决边缘AI中集中式智能的成本和脆弱性问题，通过让智能驻留在单个边缘节点并通过选择性对等交互进行扩展。


<details>
  <summary>Details</summary>
Motivation: AI向边缘的扩展日益暴露出集中式智能的成本和脆弱性。数据传输、延迟、能耗以及对大型数据中心的依赖造成了瓶颈，在异构、移动和资源受限的环境中扩展性差。

Method: 本文引入了节点学习（Node Learning），一种去中心化学习范式，其中智能驻留在单个边缘节点中，并通过选择性对等交互进行扩展。节点持续从本地数据中学习，维护自己的模型状态，并在协作有利时机会性地交换学习到的知识。学习通过重叠和扩散传播，而非全局同步或中心聚合，统一了自主和合作行为，并适应数据、硬件、目标和连接的异构性。

Result: 本文阐述了节点学习范式的概念基础，将其与现有去中心化方法进行了对比，并探讨了其对通信、硬件、信任和治理的影响。节点学习并非摒弃现有范式，而是将其置于更广泛的去中心化视角下。

Conclusion: 节点学习提供了一种创新的去中心化学习范式，解决了边缘AI中集中式智能的局限性，通过赋能本地智能和机会性对等交互，为未来的边缘AI系统提供了新的视角和可能性。

Abstract: The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments. In this paper, we introduce Node Learning, a decen- tralised learning paradigm in which intelligence resides at individual edge nodes and expands through selective peer interaction. Nodes learn continuously from local data, maintain their own model state, and exchange learned knowledge opportunistically when collaboration is beneficial. Learning propagates through overlap and diffusion rather than global synchro- nisation or central aggregation. It unifies autonomous and cooperative behaviour within a single abstraction and accommodates heterogeneity in data, hardware, objectives, and connectivity. This concept paper develops the conceptual foundations of this paradigm, contrasts it with existing decentralised approaches, and examines implications for communi- cation, hardware, trust, and governance. Node Learning does not discard existing paradigms, but places them within a broader decentralised perspective

</details>


### [112] [An order-oriented approach to scoring hesitant fuzzy elements](https://arxiv.org/abs/2602.16827)
*Luis Merino,Gabriel Navarro,Carlos Salvatierra,Evangelina Santos*

Main category: cs.AI

TL;DR: 该论文提出了一个统一的框架，其中每个分数都是根据给定顺序明确定义的，从而实现了更灵活和连贯的评分机制。研究了犹豫模糊元素的经典排序，并证明它们不诱导格结构。定义了以对称顺序为参照的分数，满足评分函数的关键规范标准。引入了一类称为支配函数的函数来排序犹豫模糊元素，并提供了具体示例，可用于构建模糊偏好关系并支持群体决策。


<details>
  <summary>Details</summary>
Motivation: 传统的犹豫模糊集评分方法缺乏序理论的正式基础，导致评分机制不够灵活和连贯。

Method: 论文提出了一个统一的框架，其中每个分数都是根据给定顺序明确定义的。检验了几种犹豫模糊元素上的经典排序。证明了以对称顺序为参照定义的分数满足关键的规范标准。引入了一类称为支配函数的函数，用于根据包含最小可接受性阈值的控制集来比较犹豫模糊元素，并提供了离散支配函数和相对支配函数两个具体例子。

Result: 经典犹豫模糊元素排序不能诱导格结构。以对称顺序为参照定义的分数满足评分函数的关键规范标准，包括对并集的强单调性和Gärdenfors条件。支配函数可以用来构建典型犹豫模糊集上的模糊偏好关系，并支持群体决策。

Conclusion: 提出的基于序理论的统一评分框架和支配函数为犹豫模糊集的评分和排序提供了一种更灵活和连贯的方法，适用于群体决策。

Abstract: Traditional scoring approaches on hesitant fuzzy sets often lack a formal base in order theory. This paper proposes a unified framework, where each score is explicitly defined with respect to a given order. This order-oriented perspective enables more flexible and coherent scoring mechanisms. We examine several classical orders on hesitant fuzzy elements, that is, nonempty subsets in [0,1], and show that, contrary to prior claims, they do not induce lattice structures. In contrast, we prove that the scores defined with respect to the symmetric order satisfy key normative criteria for scoring functions, including strong monotonicity with respect to unions and the Gärdenfors condition. Following this analysis, we introduce a class of functions, called dominance functions, for ranking hesitant fuzzy elements. They aim to compare hesitant fuzzy elements relative to control sets incorporating minimum acceptability thresholds. Two concrete examples of dominance functions for finite sets are provided: the discrete dominance function and the relative dominance function. We show that these can be employed to construct fuzzy preference relations on typical hesitant fuzzy sets and support group decision-making.

</details>


### [113] [OpenSage: Self-programming Agent Generation Engine](https://arxiv.org/abs/2602.16891)
*Hongwei Li,Zhun Wang,Qinrun Dai,Yuzhou Nie,Jinjun Peng,Ruitong Liu,Jingyang Zhang,Kaijie Zhu,Jingxuan He,Lun Wang,Yangruibo Ding,Yueqi Chen,Wenbo Guo,Dawn Song*

Main category: cs.AI

TL;DR: OpenSage是一个智能体开发工具包，它允许LLMs自动创建具有自生成拓扑和工具集的智能体，并提供结构化的记忆支持，实验证明其性能优于现有ADK。


<details>
  <summary>Details</summary>
Motivation: 当前的智能体开发工具包（ADKs）在功能支持上不足，或者需要人类手动设计智能体拓扑、工具和记忆组件，这限制了智能体的泛化能力和整体性能。

Method: 提出OpenSage，这是一个智能体开发工具包（ADK），它使大型语言模型（LLMs）能够自动创建具有自生成拓扑和工具集的智能体，并提供全面的结构化记忆支持。OpenSage具备智能体创建和管理子智能体及工具包的功能，采用分层图基记忆系统进行高效管理，并为软件工程任务提供了专门的工具包。

Result: 在三个最先进的基准测试中，使用不同的骨干模型进行了广泛的实验，结果表明OpenSage优于现有ADK。严格的消融研究也证明了其每个设计组件的有效性。

Conclusion: OpenSage有望开创下一代智能体开发，将范式从以人为中心转向以AI为中心。

Abstract: Agent development kits (ADKs) provide effective platforms and tooling for constructing agents, and their designs are critical to the constructed agents' performance, especially the functionality for agent topology, tools, and memory. However, current ADKs either lack sufficient functional support or rely on humans to manually design these components, limiting agents' generalizability and overall performance. We propose OpenSage, the first ADK that enables LLMs to automatically create agents with self-generated topology and toolsets while providing comprehensive and structured memory support. OpenSage offers effective functionality for agents to create and manage their own sub-agents and toolkits. It also features a hierarchical, graph-based memory system for efficient management and a specialized toolkit tailored to software engineering tasks. Extensive experiments across three state-of-the-art benchmarks with various backbone models demonstrate the advantages of OpenSage over existing ADKs. We also conduct rigorous ablation studies to demonstrate the effectiveness of our design for each component. We believe OpenSage can pave the way for the next generation of agent development, shifting the focus from human-centered to AI-centered paradigms.

</details>


### [114] [AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks](https://arxiv.org/abs/2602.16901)
*Tanqiu Jiang,Yuhui Wang,Jiacheng Liang,Ting Wang*

Main category: cs.AI

TL;DR: LLM智能体在复杂环境中容易受到长程攻击。AgentLAB是首个评估LLM智能体对适应性长程攻击易感性的基准，研究发现当前智能体高度易受攻击，且针对单轮交互的防御措施未能有效缓解长程威胁。


<details>
  <summary>Details</summary>
Motivation: LLM智能体越来越多地部署在长周期、复杂环境中，以解决挑战性问题。这种扩展使它们面临长程攻击，这些攻击利用多轮用户-智能体-环境交互来实现单轮设置中无法实现的目标。因此，需要衡量智能体对此类风险的漏洞。

Method: 提出AgentLAB，这是首个专门评估LLM智能体对适应性长程攻击易感性的基准。AgentLAB目前支持五种新颖的攻击类型，包括意图劫持、工具链攻击、任务注入、目标漂移和内存中毒，涵盖28个现实的智能体环境和644个安全测试用例。

Result: 利用AgentLAB评估了有代表性的LLM智能体，发现它们仍然高度易受长程攻击；此外，为单轮交互设计的防御措施未能可靠地缓解长程威胁。

Conclusion: AgentLAB将成为一个有价值的基准，用于跟踪在实际环境中保护LLM智能体方面的进展。

Abstract: LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulnerabilities to such risks, we present AgentLAB, the first benchmark dedicated to evaluating LLM agent susceptibility to adaptive, long-horizon attacks. Currently, AgentLAB supports five novel attack types including intent hijacking, tool chaining, task injection, objective drifting, and memory poisoning, spanning 28 realistic agentic environments, and 644 security test cases. Leveraging AgentLAB, we evaluate representative LLM agents and find that they remain highly susceptible to long-horizon attacks; moreover, defenses designed for single-turn interactions fail to reliably mitigate long-horizon threats. We anticipate that AgentLAB will serve as a valuable benchmark for tracking progress on securing LLM agents in practical settings. The benchmark is publicly available at .

</details>


### [115] [LLM-WikiRace: Benchmarking Long-term Planning and Reasoning over Real-World Knowledge Graphs](https://arxiv.org/abs/2602.16902)
*Juliusz Ziomek,William Bankes,Lorenz Wolf,Shyam Sundhar Ramesh,Xiaohang Tang,Ilija Bogunovic*

Main category: cs.AI

TL;DR: LLM-Wikirace是一个评估LLM规划、推理和世界知识的新基准。顶尖模型在简单任务上表现超人，但在困难任务上性能急剧下降，揭示了长程规划和失败后重新规划的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在规划、推理和世界知识方面的能力，并识别其在复杂任务中的局限性。现有基准可能未能充分捕捉LLM在需要长程规划和概念连接推理任务中的真实表现。

Method: 引入LLM-Wikirace基准，该基准要求LLM通过逐步导航维基百科超链接从源页面到达目标页面。该任务评估模型的规划、推理和世界知识能力。对包括Gemini-3、GPT-5和Claude Opus 4.5在内的多种开源和闭源模型进行了评估，并在容易和困难级别上进行测试，同时进行轨迹级别分析。

Result: 在容易级别任务上，Gemini-3、GPT-5和Claude Opus 4.5等模型表现出色，达到超人水平。然而，在困难级别上，性能急剧下降，表现最佳的Gemini-3成功率仅为23%。分析表明，世界知识是成功的基础，但超过一定阈值后，规划和长程推理能力成为关键。轨迹分析显示，即使是最强的模型在失败后也难以重新规划，经常陷入循环。

Conclusion: LLM-Wikirace基准揭示了当前LLM推理系统的明显局限性，尤其是在长程规划和失败后重新规划方面。世界知识是必要条件，但达到一定阈值后，规划和长程推理能力成为主导因素。未来的LLM仍需在规划能力上进行大量改进。

Abstract: We introduce LLM-Wikirace, a benchmark for evaluating planning, reasoning, and world knowledge in large language models (LLMs). In LLM-Wikirace, models must efficiently navigate Wikipedia hyperlinks step by step to reach a target page from a given source, requiring look-ahead planning and the ability to reason about how concepts are connected in the real world. We evaluate a broad set of open- and closed-source models, including Gemini-3, GPT-5, and Claude Opus 4.5, which achieve the strongest results on the easy level of the task and demonstrate superhuman performance. Despite this, performance drops sharply on hard difficulty: the best-performing model, Gemini-3, succeeds in only 23\% of hard games, highlighting substantial remaining challenges for frontier models. Our analysis shows that world knowledge is a necessary ingredient for success, but only up to a point, beyond this threshold, planning and long-horizon reasoning capabilities become the dominant factors. Trajectory-level analysis further reveals that even the strongest models struggle to replan after failure, frequently entering loops rather than recovering. LLM-Wikirace is a simple benchmark that reveals clear limitations in current reasoning systems, offering an open arena where planning-capable LLMs still have much to prove. Our code and leaderboard available at .

</details>


### [116] [Narrow fine-tuning erodes safety alignment in vision-language agents](https://arxiv.org/abs/2602.16931)
*Idhant Gulati,Shivam Raval*

Main category: cs.AI

TL;DR: 本文研究了在有害数据集上微调对齐的视觉-语言模型（Gemma3-4B）后出现的失准问题。研究发现，失准程度随LoRA秩单调增加，多模态评估结果（70.71 ± 1.22）远高于文本单模态评估（41.19 ± 2.51），即使10%的有害数据也会导致显著失准。几何分析表明，有害行为存在于低维子空间中。两种缓解策略（良性窄域微调和基于激活的引导）均能减少失准，但无法完全消除，强调了稳健持续学习框架的必要性。


<details>
  <summary>Details</summary>
Motivation: 终身多模态智能体需要通过训练后持续适应新任务，但这在获取能力和保持安全对齐之间产生了根本性的矛盾。

Method: 在狭域有害数据集上对齐对齐的视觉-语言模型（Gemma3-4B）进行微调。通过多模态评估与文本单模态评估对比，量化失准程度随LoRA秩的变化。分析训练混合数据中不同比例有害数据的影响。进行几何分析以确定有害行为的子空间。评估良性窄域微调和基于激活的引导两种缓解策略。

Result: 在有害数据集上微调会导致严重的突发性失准，并广泛泛化到不相关任务和模态。失准程度与LoRA秩单调相关，多模态评估的失准率（70.71 ± 1.22）远高于文本单模态评估（41.19 ± 2.51）。即使训练混合数据中含有10%的有害数据也会导致显著的对齐退化。几何分析显示有害行为占据一个极低维的子空间，大部分失准信息由10个主成分捕获。良性窄域微调和基于激活的引导这两种缓解策略都能显著减少失准，但都未能完全消除学习到的有害行为。

Conclusion: 目前的训练后范式可能不足以在部署后环境中充分保持对齐，这突出表明需要稳健的持续学习框架来解决终身多模态智能体在获取能力和保持安全对齐之间的紧张关系。

Abstract: Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe emergent misalignment that generalizes broadly across unrelated tasks and modalities. Through experiments on Gemma3-4B, we show that misalignment scales monotonically with LoRA rank, and that multimodal evaluation reveals substantially higher misalignment ($70.71 \pm 1.22$ at $r=128$) than text-only evaluation ($41.19 \pm 2.51$), suggesting that unimodal safety benchmarks may underestimate alignment degradation in vision-language models. Critically, even 10\% harmful data in the training mixture induces substantial alignment degradation. Geometric analysis reveals that harmful behaviors occupy a remarkably low-dimensional subspace, with the majority of misalignment information captured in 10 principal components. To mitigate misalignment, we evaluate two strategies: benign narrow fine-tuning and activation-based steering. While both approaches substantially reduce misalignment, neither completely removes the learned harmful behaviors. Our findings highlight the need for robust continual learning frameworks, as current post-training paradigms may not sufficiently preserve alignment in post-deployment settings.

</details>


### [117] [LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation](https://arxiv.org/abs/2602.16953)
*Hejia Zhang,Zhongming Yu,Chia-Tung Ho,Haoxing Ren,Brucek Khailany,Jishen Zhao*

Main category: cs.AI

TL;DR: LLM4Cov是一个离线智能体学习框架，通过解决昂贵且缓慢的反馈问题，使LLM智能体能够在硬件验证等领域进行可扩展学习，并在紧凑模型上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 执行感知LLM智能体在从工具反馈中学习方面具有潜力，但反馈获取成本高且速度慢，使得在线强化学习不切实际。高覆盖率硬件验证尤其面临此挑战，因为它依赖于工业模拟器和不可微分的执行信号。

Method: LLM4Cov是一个离线智能体学习框架，将验证建模为由确定性评估器引导的无记忆状态转换。该框架引入了执行验证数据整理、策略感知智能体数据合成以及最差状态优先采样，以在执行约束下实现可扩展学习。此外，作者还基于现有验证套件调整了评估协议，构建了一个现实对齐的基准。

Result: 通过所提出的流程，一个紧凑的4B参数模型在智能体评估下实现了69.2%的覆盖率通过率，比其教师模型高出5.3%，并与大一个数量级的模型表现出竞争性。

Conclusion: LLM4Cov框架使LLM智能体能够在执行约束下进行可扩展学习，并在硬件验证任务中，使用紧凑型模型实现了优异的覆盖率通过率。

Abstract: Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simulators and non-differentiable execution signals. We propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Building on this formulation, we introduce execution-validated data curation, policy-aware agentic data synthesis, and worst-state-prioritized sampling to enable scalable learning under execution constraints. We further curate a reality-aligned benchmark adapted from an existing verification suite through a revised evaluation protocol. Using the proposed pipeline, a compact 4B-parameter model achieves 69.2% coverage pass rate under agentic evaluation, outperforming its teacher by 5.3% and demonstrating competitive performance against models an order of magnitude larger.

</details>


### [118] [Fundamental Limits of Black-Box Safety Evaluation: Information-Theoretic and Computational Barriers from Latent Context Conditioning](https://arxiv.org/abs/2602.16984)
*Vishal Srivastava*

Main category: cs.AI

TL;DR: 本文挑战了AI系统黑盒安全评估的假设，指出当模型行为依赖于评估时罕见但在部署时普遍存在的潜在上下文时，黑盒评估不可靠。通过理论证明和量化界限，论文揭示了黑盒评估的根本局限性，并强调了额外安全措施的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统黑盒安全评估假设测试分布能够可靠预测部署性能。然而，当模型行为依赖于在评估期间罕见但在部署期间普遍存在的未观测内部变量（即潜在上下文条件策略）时，这一假设被挑战。本文旨在形式化并量化这种假设失效的情况。

Method: 1. 形式化了潜在上下文条件策略模型。2. 建立了黑盒评估的理论极限：a) 对被动评估，通过Le Cam's 方法证明了极小极大下界。b) 对自适应评估，利用基于哈希的触发器构造和Yao的极小极大原理。c) 在活板门单向函数假设下，展示了计算分离。3. 对于白盒探测，量化了估计部署风险所需的样本复杂度，并提供了探测错误下的偏差校正。

Result: 1. **根本局限性**：任何黑盒评估器都无法可靠估计具有潜在上下文条件策略的模型的部署风险。2. **量化误差界限**：a) 被动评估的预期绝对误差 >= (5/24)*delta*L。b) 自适应评估的最坏情况误差仍 >= delta*L/16，且检测需要Theta(1/epsilon)次查询。3. **计算分离**：拥有特权信息的部署环境可以激活不安全行为，而没有陷门的任何多项式时间评估器都无法区分。4. **白盒探测效率**：要将部署风险估计到精度epsilon_R，需要O(1/(gamma^2 * epsilon_R^2))个样本。

Conclusion: 本文结果量化了黑盒测试在统计上何时是不确定的。它为在最坏情况安全保障下，何时需要额外的安全措施（例如架构约束、训练时保证、可解释性和部署监控）提供了明确的数学标准。

Abstract: Black-box safety evaluation of AI systems assumes model behavior on test distributions reliably predicts deployment performance. We formalize and challenge this assumption through latent context-conditioned policies -- models whose outputs depend on unobserved internal variables that are rare under evaluation but prevalent under deployment. We establish fundamental limits showing that no black-box evaluator can reliably estimate deployment risk for such models. (1) Passive evaluation: For evaluators sampling i.i.d. from D_eval, we prove minimax lower bounds via Le Cam's method: any estimator incurs expected absolute error >= (5/24)*delta*L approximately 0.208*delta*L, where delta is trigger probability under deployment and L is the loss gap. (2) Adaptive evaluation: Using a hash-based trigger construction and Yao's minimax principle, worst-case error remains >= delta*L/16 even for fully adaptive querying when D_dep is supported over a sufficiently large domain; detection requires Theta(1/epsilon) queries. (3) Computational separation: Under trapdoor one-way function assumptions, deployment environments possessing privileged information can activate unsafe behaviors that any polynomial-time evaluator without the trapdoor cannot distinguish. For white-box probing, estimating deployment risk to accuracy epsilon_R requires O(1/(gamma^2 * epsilon_R^2)) samples, where gamma = alpha_0 + alpha_1 - 1 measures probe quality, and we provide explicit bias correction under probe error. Our results quantify when black-box testing is statistically underdetermined and provide explicit criteria for when additional safeguards -- architectural constraints, training-time guarantees, interpretability, and deployment monitoring -- are mathematically necessary for worst-case safety assurance.

</details>


### [119] [Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation](https://arxiv.org/abs/2602.16990)
*Yan Wang,Yi Han,Lingfei Qian,Yueru He,Xueqing Peng,Dongji Feng,Zhuohan Xie,Vincent Jim Zhang,Rosie Guo,Fengran Mo,Jimin Huang,Yankai Chen,Xue Liu,Jian-Yun Nie*

Main category: cs.AI

TL;DR: Conv-FinRe是一个新的会话式长期股票推荐基准，旨在评估LLM超越行为匹配的能力。它通过提供多视角参考来区分描述性行为和规范性效用，发现理性决策质量与行为一致性之间存在持续的矛盾。


<details>
  <summary>Details</summary>
Motivation: 大多数推荐基准评估模型模仿用户行为的程度。然而，在金融咨询中，观察到的行为在市场波动下可能存在噪音或短视，并可能与用户的长期目标冲突。因此，将用户的选择视为唯一的事实真相，混淆了行为模仿与决策质量。

Method: 引入了Conv-FinRe，这是一个用于股票推荐的会话式和长期基准，它超越了行为匹配来评估LLM。该基准要求模型根据入职访谈、逐步市场背景和咨询对话，生成固定投资期限内的排名。Conv-FinRe提供多视角参考，区分描述性行为和基于投资者特定风险偏好的规范性效用，从而诊断LLM是遵循理性分析、模仿用户噪音，还是受市场动量驱动。该基准建立在真实市场数据和人类决策轨迹之上，实例化了受控咨询对话，并评估了一系列最先进的LLM。

Result: 结果揭示了理性决策质量与行为一致性之间长期存在的矛盾：在基于效用的排名上表现良好的模型往往无法匹配用户的选择，而行为一致性模型则可能过度拟合短期噪音。

Conclusion: 结果揭示了理性决策质量与行为一致性之间长期存在的矛盾：在基于效用的排名上表现良好的模型往往无法匹配用户的选择，而行为一致性模型则可能过度拟合短期噪音。

Abstract: Most recommendation benchmarks evaluate how well a model imitates user behavior. In financial advisory, however, observed actions can be noisy or short-sighted under market volatility and may conflict with a user's long-term goals. Treating what users chose as the sole ground truth, therefore, conflates behavioral imitation with decision quality. We introduce Conv-FinRe, a conversational and longitudinal benchmark for stock recommendation that evaluates LLMs beyond behavior matching. Given an onboarding interview, step-wise market context, and advisory dialogues, models must generate rankings over a fixed investment horizon. Crucially, Conv-FinRe provides multi-view references that distinguish descriptive behavior from normative utility grounded in investor-specific risk preferences, enabling diagnosis of whether an LLM follows rational analysis, mimics user noise, or is driven by market momentum. We build the benchmark from real market data and human decision trajectories, instantiate controlled advisory conversations, and evaluate a suite of state-of-the-art LLMs. Results reveal a persistent tension between rational decision quality and behavioral alignment: models that perform well on utility-based ranking often fail to match user choices, whereas behaviorally aligned models can overfit short-term noise. The dataset is publicly released on Hugging Face, and the codebase is available on GitHub.

</details>


### [120] [Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases](https://arxiv.org/abs/2602.17001)
*Zhao Tan,Yiji Zhao,Shiyu Wang,Chang Xu,Yuxuan Liang,Xiping Liu,Shirui Pan,Ming Jin*

Main category: cs.AI

TL;DR: 本文提出了Sonar-TS，一个用于时间序列数据库自然语言查询（NLQ4TSDB）的神经符号框架，它采用“搜索-验证”管道来解决现有方法在处理形态意图和超长历史方面的局限性。同时，本文还引入了NLQTSBench，一个大规模基准，并证明Sonar-TS在复杂时间查询中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 自然语言查询时间序列数据库（NLQ4TSDB）旨在帮助非专业用户从海量时间记录中检索有意义的事件、时间间隔和摘要。然而，现有的Text-to-SQL方法并非为连续的形态意图（如形状或异常）而设计，而时间序列模型难以处理超长历史。

Method: 本文提出了一个名为Sonar-TS的神经符号框架，通过“搜索-验证（Search-Then-Verify）”管道解决NLQ4TSDB问题。它利用特征索引通过SQL“ping”候选窗口，然后通过生成的Python程序根据原始信号锁定并验证候选。为了有效评估，本文还引入了NLQTSBench，这是第一个专为TSDB规模历史上的NLQ设计的大规模基准。

Result: 实验表明，Sonar-TS能够有效处理传统方法无法解决的复杂时间查询，突显了该领域独特的挑战。

Conclusion: 这项工作首次对NLQ4TSDB进行了系统研究，提供了一个通用框架和评估标准，以促进未来的研究。

Abstract: Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records. However, existing Text-to-SQL methods are not designed for continuous morphological intents such as shapes or anomalies, while time series models struggle to handle ultra-long histories. To address these challenges, we propose Sonar-TS, a neuro-symbolic framework that tackles NLQ4TSDB via a Search-Then-Verify pipeline. Analogous to active sonar, it utilizes a feature index to ping candidate windows via SQL, followed by generated Python programs to lock on and verify candidates against raw signals. To enable effective evaluation, we introduce NLQTSBench, the first large-scale benchmark designed for NLQ over TSDB-scale histories. Our experiments highlight the unique challenges within this domain and demonstrate that Sonar-TS effectively navigates complex temporal queries where traditional methods fail. This work presents the first systematic study of NLQ4TSDB, offering a general framework and evaluation standard to facilitate future research.

</details>


### [121] [Cinder: A fast and fair matchmaking system](https://arxiv.org/abs/2602.17015)
*Saurav Pal*

Main category: cs.AI

TL;DR: 本文提出了Cinder，一个两阶段匹配系统，通过结合Ruzicka相似性指数和基于Kantorovich距离的Sanction Score来解决多人在线游戏中技能异构预组队的公平快速匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现代多人在线游戏中，公平快速的匹配系统对玩家留存和满意度至关重要。然而，为技能水平异构的预组队（lobbies）创建公平匹配是一个重大挑战，因为简单地基于平均技能指标（如平均或中位数评分）往往导致不平衡和单边游戏，尤其当技能分布广泛或偏斜时。

Method: Cinder是一个两阶段匹配系统。第一阶段通过Ruzicka相似性指数比较队伍的“非异常值”技能范围进行快速初步筛选。第二阶段将玩家等级映射到非线性技能桶（由倒置正态分布生成，在中等技能水平提供更高粒度），然后使用Kantorovich距离计算Sanction Score来量化潜在匹配的公平性。

Result: 系统通过分析1.4亿次模拟队伍配对的Sanction Scores分布，证明了其可行性，并为公平匹配阈值奠定了坚实基础。

Conclusion: Cinder系统通过对1.4亿次模拟配对Sanction Scores的分析，为公平匹配阈值提供了坚实的基础，并展示了其在提供快速公平匹配方面的可行性。

Abstract: A fair and fast matchmaking system is an important component of modern multiplayer online games, directly impacting player retention and satisfaction. However, creating fair matches between lobbies (pre-made teams) of heterogeneous skill levels presents a significant challenge. Matching based simply on average team skill metrics, such as mean or median rating or rank, often results in unbalanced and one-sided games, particularly when skill distributions are wide or skewed. This paper introduces Cinder, a two-stage matchmaking system designed to provide fast and fair matches. Cinder first employs a rapid preliminary filter by comparing the "non-outlier" skill range of lobbies using the Ruzicka similarity index. Lobbies that pass this initial check are then evaluated using a more precise fairness metric. This second stage involves mapping player ranks to a non-linear set of skill buckets, generated from an inverted normal distribution, to provide higher granularity at average skill levels. The fairness of a potential match is then quantified using the Kantorovich distance on the lobbies' sorted bucket indices, producing a "Sanction Score." We demonstrate the system's viability by analyzing the distribution of Sanction Scores from 140 million simulated lobby pairings, providing a robust foundation for fair matchmaking thresholds.

</details>


### [122] [M2F: Automated Formalization of Mathematical Literature at Scale](https://arxiv.org/abs/2602.17016)
*Zichen Wang,Wanli Ma,Zhenyu Ming,Gong Zhang,Kun Yuan,Zaiwen Wen*

Main category: cs.AI

TL;DR: M2F是首个端到端、项目级数学自动化形式化框架，能够将长篇数学文献转化为可编译的Lean库，并在效率和证明成功率上显著超越现有方法，证明了大规模自动化形式化的可行性。


<details>
  <summary>Details</summary>
Motivation: 自动化数学形式化虽然实现了机械验证，但目前仅限于孤立的定理和短片段。将该技术扩展到教科书和研究论文，需要管理跨文件依赖、解析导入并确保整个项目端到端编译，这仍然是一个未解决的挑战。

Method: M2F是一个两阶段的智能体框架。第一阶段是语句编译，它将文档分解为原子块，通过推断的依赖关系对其进行排序，并修复声明骨架直到项目编译，允许证明中的占位符。第二阶段是证明修复，它在固定签名下通过目标条件局部编辑来填补这些空缺。在整个过程中，M2F保持验证器在循环中，仅在工具链反馈确认改进时才提交编辑。

Result: M2F在约三周内，将实分析和凸分析的479页教科书转换为一个包含153,853行Lean代码的HFL项目级Lean库，其中包含完整的Lean声明和证明。在FATE-H数据集上，M2F实现了96%的证明成功率，而强大的基线模型为80%。

Conclusion: 大规模数学文献的自动化形式化是切实可行的。

Abstract: Automated formalization of mathematics enables mechanical verification but remains limited to isolated theorems and short snippets. Scaling to textbooks and research papers is largely unaddressed, as it requires managing cross-file dependencies, resolving imports, and ensuring that entire projects compile end-to-end. We present M2F (Math-to-Formal), the first agentic framework for end-to-end, project-scale autoformalization in Lean. The framework operates in two stages. The statement compilation stage splits the document into atomic blocks, orders them via inferred dependencies, and repairs declaration skeletons until the project compiles, allowing placeholders in proofs. The proof repair stage closes these holes under fixed signatures using goal-conditioned local edits. Throughout both stages, M2F keeps the verifier in the loop, committing edits only when toolchain feedback confirms improvement. In approximately three weeks, M2F converts long-form mathematical sources into a project-scale Lean library of 153,853 lines from 479 pages textbooks on real analysis and convex analysis, fully formalized as Lean declarations with accompanying proofs. This represents textbook-scale formalization at a pace that would typically require months or years of expert effort. On FATE-H, we achieve $96\%$ proof success (vs.\ $80\%$ for a strong baseline). Together, these results demonstrate that practical, large-scale automated formalization of mathematical literature is within reach. The full generated Lean code from our runs is available at .

</details>


### [123] [Sales Research Agent and Sales Research Bench](https://arxiv.org/abs/2602.17017)
*Deepanjan Bhol*

Main category: cs.AI

TL;DR: 本文介绍了Microsoft Dynamics 365 Sales中的Sales Research Agent，一个利用实时CRM数据提供决策洞察的AI应用，并提出了Sales Research Bench基准来评估其质量。在测试中，Sales Research Agent的表现优于Claude Sonnet 4.5和ChatGPT-5。


<details>
  <summary>Details</summary>
Motivation: 企业需要能够在实时、定制化CRM数据上回答销售领导问题的AI系统，但大多数现有模型未能提供透明、可重复的质量证据。

Method: 本文描述了Sales Research Agent，一个连接实时CRM数据、在复杂模式上进行推理并生成洞察的AI应用。为评估质量，引入了Sales Research Bench基准测试，该基准在八个客户加权维度（包括文本和图表基础性、相关性、可解释性、模式准确性和图表质量）上对系统进行评分。

Result: 在2025年10月19日针对定制企业模式进行的200个问题测试中，Sales Research Agent在100分综合得分上，比Claude Sonnet 4.5高出13分，比ChatGPT-5高出24.1分。

Conclusion: Sales Research Agent在定制化的企业CRM数据上提供了可重复的AI解决方案比较方式，并通过文本和图表输出提供决策就绪的洞察。

Abstract: Enterprises increasingly need AI systems that can answer sales-leader questions over live, customized CRM data, but most available models do not expose transparent, repeatable evidence of quality. This paper describes the Sales Research Agent in Microsoft Dynamics 365 Sales, an AI-first application that connects to live CRM and related data, reasons over complex schemas, and produces decision-ready insights through text and chart outputs. To make quality observable, we introduce the Sales Research Bench, a purpose-built benchmark that scores systems on eight customer-weighted dimensions, including text and chart groundedness, relevance, explainability, schema accuracy, and chart quality. In a 200-question run on a customized enterprise schema on October 19, 2025, the Sales Research Agent outperformed Claude Sonnet 4.5 by 13 points and ChatGPT-5 by 24.1 points on the 100-point composite score, giving customers a repeatable way to compare AI solutions.

</details>


### [124] [IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents](https://arxiv.org/abs/2602.17049)
*Seoyoung Lee,Seobin Yoon,Seongbeen Lee,Yoojung Chun,Dayoung Park,Doyeon Kim,Joo Yong Sim*

Main category: cs.AI

TL;DR: IntentCUA是一个多智能体计算机使用框架，通过意图对齐的计划记忆来稳定长程执行，实现了74.83%的任务成功率和0.91的步骤效率比，优于现有的RL基线和以轨迹为中心的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机使用智能体在噪声感知、多窗口上下文和动态环境下的长程操作中，常偏离用户意图，重复解决例行子问题，导致错误累积和效率低下。

Method: IntentCUA采用多智能体框架，由规划器、计划优化器和评论器组成，通过共享记忆进行协作。该记忆将原始交互轨迹抽象为多视角意图表示和可重用技能。运行时，意图原型检索子组对齐的技能并将其注入部分计划，从而减少冗余的重新规划并减轻跨桌面应用程序的错误传播。

Result: IntentCUA在端到端评估中取得了74.83%的任务成功率和0.91的步骤效率比，优于基于RL和以轨迹为中心的基线。消融实验表明，多视角意图抽象和共享计划记忆共同提高了执行稳定性，其中合作多智能体循环在长程任务中提供了最大的收益。

Conclusion: 系统级意图抽象和基于记忆的协调是动态环境中可靠和高效桌面自动化的关键。

Abstract: Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate over shared memory that abstracts raw interaction traces into multi-view intent representations and reusable skills. At runtime, intent prototypes retrieve subgroup-aligned skills and inject them into partial plans, reducing redundant re-planning and mitigating error propagation across desktop applications. In end-to-end evaluations, IntentCUA achieved a 74.83% task success rate with a Step Efficiency Ratio of 0.91, outperforming RL-based and trajectory-centric baselines. Ablations show that multi-view intent abstraction and shared plan memory jointly improve execution stability, with the cooperative multi-agent loop providing the largest gains on long-horizon tasks. These results highlight that system-level intent abstraction and memory-grounded coordination are key to reliable and efficient desktop automation in large, dynamic environments.

</details>


### [125] [RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models](https://arxiv.org/abs/2602.17053)
*Yunseok Han,Yejoon Lee,Jaeyoung Do*

Main category: cs.AI

TL;DR: 大型推理模型 (LRM) 经常产生听起来合理但未能反映其真实决策过程的解释，这损害了可靠性和信任。本文引入了一个推理忠实度的形式框架，由两个可测试的条件定义：立场一致性（将推理与答案联系起来的连贯立场）和因果影响（在输出级干预下，所陈述的推理因果地驱动答案），并明确与准确性解耦。为了实现这一点，我们提出了 RFEval，一个包含 7,186 个实例的基准测试，跨越七个任务，通过受控的输出级反事实干预来探究忠实度。评估了十二个开源 LRM 后，我们发现 49.7% 的输出不忠实，主要源于立场不一致。失败集中在数学和代码等脆弱、收敛的领域，并且与后训练方案的相关性高于与规模的相关性：家族内部的消融实验表明，在监督微调之上添加当前的 RL 风格目标可以降低推理忠实度，即使准确性得以保持。关键是，准确性既不是忠实度的充分条件也不是可靠的替代指标：一旦控制了模型和任务，准确性与忠实度的联系是微弱且在统计上不显著的。我们的工作建立了一种审计 LRM 可靠性的严格方法，并表明可信赖的 AI 不仅需要优化正确的结果，还需要优化推理过程的结构完整性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型 (LRM) 尽管表现出色，但其生成的理由往往听起来合理却未能反映其真实的决策过程，这损害了模型的可靠性和用户信任。因此，需要一个严谨的框架和评估方法来解决推理忠实度问题。

Method: 本文引入了一个推理忠实度的形式框架，其由两个可测试条件定义：立场一致性（将推理与答案联系起来的连贯立场）和因果影响（在输出级干预下，所陈述的推理因果地驱动答案），并明确与准确性解耦。为了操作化这个框架，本文提出了 RFEval，一个包含 7,186 个实例的基准测试，跨越七个任务，通过受控的输出级反事实干预来探究忠实度。该研究评估了十二个开源 LRM。

Result: 研究发现，49.7% 的 LRM 输出存在不忠实性，主要源于立场不一致。不忠实性问题集中在数学和代码等脆弱、收敛的领域，并且与后训练方案的相关性高于与模型规模的相关性。家族内部的消融实验表明，在监督微调之上添加当前的 RL 风格目标可以降低推理忠实度，即使准确性得以保持。此外，准确性既不是忠实度的充分条件也不是可靠的替代指标：一旦控制了模型和任务，准确性与忠实度的联系是微弱且在统计上不显著的。

Conclusion: 本文建立了一种审计 LRM 可靠性的严格方法。研究强调，可信赖的 AI 不仅需要优化正确的结果，还需要优化推理过程的结构完整性。

Abstract: Large Reasoning Models (LRMs) exhibit strong performance, yet often produce rationales that sound plausible but fail to reflect their true decision process, undermining reliability and trust. We introduce a formal framework for reasoning faithfulness, defined by two testable conditions: stance consistency (a coherent stance linking reasoning to answer) and causal influence (the stated reasoning causally drives the answer under output-level interventions), explicitly decoupled from accuracy. To operationalize this, we present RFEval, a benchmark of 7,186 instances across seven tasks that probes faithfulness via controlled, output-level counterfactual interventions. Evaluating twelve open-source LRMs, we find unfaithfulness in 49.7% of outputs, predominantly from stance inconsistency. Failures are concentrated in brittle, convergent domains such as math and code, and correlate more with post-training regimes than with scale: within-family ablations indicate that adding current RL-style objectives on top of supervised fine-tuning can reduce reasoning faithfulness, even when accuracy is maintained. Crucially, accuracy is neither a sufficient nor a reliable proxy for faithfulness: once controlling for model and task, the accuracy-faithfulness link is weak and statistically insignificant. Our work establishes a rigorous methodology for auditing LRM reliability and shows that trustworthy AI requires optimizing not only for correct outcomes but also for the structural integrity of the reasoning process. Our code and dataset can be found at project page: $\href{ }{ }$

</details>


### [126] [Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17062)
*Yonghyeon Jo,Sunwoo Lee,Seungyul Han*

Main category: cs.AI

TL;DR: S2Q通过学习多个子价值函数来解决多智能体强化学习中单最优动作价值分解的局限性，通过持续探索提高了适应性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习(MARL)价值分解方法依赖于单一最优动作，在训练过程中当底层价值函数发生变化时，难以适应并经常收敛到次优策略。

Method: 本文提出了Successive Sub-value Q-learning (S2Q) 方法。S2Q学习多个子价值函数以保留替代高价值动作，并将这些子价值函数整合到基于Softmax的行为策略中，以鼓励持续探索并使Q_tot能够快速适应变化的最佳值。

Result: 在具有挑战性的MARL基准测试上的实验证实，S2Q始终优于各种MARL算法，表现出更好的适应性和整体性能。

Conclusion: S2Q通过学习多个子价值函数以保留替代高价值动作，并通过基于Softmax的行为策略鼓励持续探索，从而提高了多智能体强化学习的适应性和整体性能，优于现有方法。

Abstract: Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this limitation, we propose Successive Sub-value Q-learning (S2Q), which learns multiple sub-value functions to retain alternative high-value actions. Incorporating these sub-value functions into a Softmax-based behavior policy, S2Q encourages persistent exploration and enables $Q^{\text{tot}}$ to adjust quickly to the changing optima. Experiments on challenging MARL benchmarks confirm that S2Q consistently outperforms various MARL algorithms, demonstrating improved adaptability and overall performance. Our code is available at .

</details>


### [127] [Predictive Batch Scheduling: Accelerating Language Model Training Through Loss-Aware Sample Prioritization](https://arxiv.org/abs/2602.17066)
*Sumedh Rasal*

Main category: cs.AI

TL;DR: 引入了预测批次调度（PBS），一种通过动态优先处理高损失样本来加速语言模型收敛的新型训练优化技术。PBS使用轻量级在线训练的线性预测器，从静态词元级特征估计样本难度，实现了0.44的损失相关性。在1.3亿参数的Transformer上，PBS将收敛速度提高了6-13%。


<details>
  <summary>Details</summary>
Motivation: 现有课程学习方法需要预定义难度指标，或硬样本挖掘方法需要昂贵的逐样本损失跟踪，这些都有局限性。本研究旨在开发一种更高效且计算开销可忽略的语言模型训练加速技术。

Method: 提出了预测批次调度（PBS）。该方法在批次构建期间动态优先处理高损失样本。它采用一个轻量级的线性预测器，在线训练以利用静态词元级特征（如词元频率、序列长度、词汇多样性和稀有词元比例）来估计样本难度。

Result: 在一个1.3亿参数的Transformer模型上，PBS在评估损失方面实现了6-13%的收敛速度提升。预测器与实际损失的相关性在10,000个训练步骤中从0.14提高到0.44，最终使用四个简单特征达到了0.44的相关性。

Conclusion: 词元频率统计数据编码了关于样本难度的有意义信息，使得在可忽略的计算开销下实现有效的课程学习成为可能。

Abstract: We introduce Predictive Batch Scheduling (PBS), a novel training optimization technique that accelerates language model convergence by dynamically prioritizing high-loss samples during batch construction. Unlike curriculum learning approaches that require predefined difficulty metrics or hard example mining methods that demand expensive per-sample loss tracking, PBS employs a lightweight linear predictor trained online to estimate sample difficulty from static token-level features. Our predictor achieves 0.44 correlation with actual loss using only four simple features: token frequency, sequence length, vocabulary diversity, and rare token ratio. Experiments on a 130M parameter transformer demonstrate that PBS achieves 6-13\% faster convergence measured by evaluation loss across training checkpoints, with the predictor's correlation improving from 0.14 to 0.44 over 10,000 training steps. These results validate that token frequency statistics encode meaningful information about sample difficulty, enabling effective curriculum learning with negligible computational overhead.

</details>


### [128] [Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction](https://arxiv.org/abs/2602.17106)
*Xiaoran Cai,Wang Yang,Xiyu Ren,Chekun Law,Rohit Sharma,Peng Qi*

Main category: cs.AI

TL;DR: 该论文提出了一种通用人机协作框架（STRIDE和SR-Delta），用于生成可信赖的基准数据集，以评估和协调可持续发展评级方法，从而解决各机构间评级差异大的问题。


<details>
  <summary>Details</summary>
Motivation: 可持续性或ESG评级机构对同一公司的评级差异很大，这限制了其可比性、可信度和对决策的相关性。需要协调评级结果。

Method: 论文提出了一种通用人机协作框架，该框架包含两个互补部分：STRIDE（可持续发展信任评级和完整性数据方程），提供指导原则和评分系统，使用大型语言模型（LLMs）构建公司层面的基准数据集；以及SR-Delta，一个差异分析程序框架，用于发现潜在调整的见解。

Result: 该框架能够对可持续发展评级方法进行可扩展和可比较的评估。

Conclusion: 该论文呼吁更广泛的AI社区采用AI驱动的方法来加强和推进可持续发展评级方法，以支持和执行紧迫的可持续发展议程。

Abstract: Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability, credibility, and relevance to decision-making. To harmonize the rating results, we propose adopting a universal human-AI collaboration framework to generate trustworthy benchmark datasets for evaluating sustainability rating methodologies. The framework comprises two complementary parts: STRIDE (Sustainability Trust Rating & Integrity Data Equation) provides principled criteria and a scoring system that guide the construction of firm-level benchmark datasets using large language models (LLMs), and SR-Delta, a discrepancy-analysis procedural framework that surfaces insights for potential adjustments. The framework enables scalable and comparable assessment of sustainability rating methodologies. We call on the broader AI community to adopt AI-powered approaches to strengthen and advance sustainability rating methodologies that support and enforce urgent sustainability agendas.

</details>


### [129] [Owen-based Semantics and Hierarchy-Aware Explanation (O-Shap)](https://arxiv.org/abs/2602.17107)
*Xiangyu Zhou,Chenhan Xiao,Yang Weng*

Main category: cs.AI

TL;DR: Shapley值方法在可解释AI中因特征依赖性问题（尤其在视觉任务中）面临挑战。现代SHAP使用Owen值进行组归因，但分组方式至关重要。本文提出了一种满足T属性的新分割方法，以确保语义对齐，从而提高归因准确性、可解释性和计算效率，实验证明其优于现有SHAP变体。


<details>
  <summary>Details</summary>
Motivation: Shapley值方法在可解释人工智能（XAI）中，因其合作博弈论的基础，为特征归因提供了理论依据。然而，在实际应用中，尤其是在视觉任务中，特征独立性的假设被打破，因为特征（即像素）通常表现出强烈的空间和语义依赖性。为了解决这个问题，现代SHAP实现包含了Owen值，它是Shapley值的层次化推广，支持组归因。虽然Owen值保留了Shapley值的基础，但其有效性关键取决于特征组的定义。常用的分割方法（例如轴对齐或SLIC）违反了关键的一致性属性。

Method: 本文提出了一种新的分割方法，该方法满足T属性，以确保在层次结构级别之间实现语义对齐。这种层次结构还能够实现计算剪枝，同时提高归因准确性和可解释性。

Result: 在图像和表格数据集上的实验表明，O-Shap在归因精度、语义连贯性和运行时效率方面优于基线SHAP变体，尤其是在结构很重要的情况下。

Conclusion: 本文提出的满足T属性的分割方法，用于Owen值计算，通过提高归因精度、语义连贯性和运行时效率，显著优于现有SHAP变体，尤其在处理具有复杂结构的数据时，其性能优势更为突出。

Abstract: Shapley value-based methods have become foundational in explainable artificial intelligence (XAI), offering theoretically grounded feature attributions through cooperative game theory. However, in practice, particularly in vision tasks, the assumption of feature independence breaks down, as features (i.e., pixels) often exhibit strong spatial and semantic dependencies. To address this, modern SHAP implementations now include the Owen value, a hierarchical generalization of the Shapley value that supports group attributions. While the Owen value preserves the foundations of Shapley values, its effectiveness critically depends on how feature groups are defined. We show that commonly used segmentations (e.g., axis-aligned or SLIC) violate key consistency properties, and propose a new segmentation approach that satisfies the $T$-property to ensure semantic alignment across hierarchy levels. This hierarchy enables computational pruning while improving attribution accuracy and interpretability. Experiments on image and tabular datasets demonstrate that O-Shap outperforms baseline SHAP variants in attribution precision, semantic coherence, and runtime efficiency, especially when structure matters.

</details>


### [130] [Instructor-Aligned Knowledge Graphs for Personalized Learning](https://arxiv.org/abs/2602.17111)
*Abdulrahman AlRabah,Priyanka Kargupta,Jiawei Han,Abdussalam Alawini*

Main category: cs.AI

TL;DR: InstructKG是一个框架，它利用讲义材料的教学信号和大型语言模型的通用性，自动构建与教师教学对齐的知识图谱，以捕获课程概念及其学习依赖关系，从而识别学生的知识差距并实现个性化学习。


<details>
  <summary>Details</summary>
Motivation: 在大规模课程中，识别学生的知识差距并提供个性化学习干预是一个挑战。现有知识图谱方法未能有效捕捉教学材料中丰富的教学信号和深层概念关系，无法实现大规模的个性化学习诊断和干预。

Method: 我们提出了InstructKG框架，该框架通过结合教育材料中独特的时序和语义信号（例如，“递归”在“归并排序”之前教授；“递归”在“归并排序”的定义中被提及）与大型语言模型的通用性，自动从课程讲义材料中提取重要概念作为节点，并推断出学习依赖关系作为有向边（例如，“部分属于”或“依赖于”关系）。

Result: 通过在多个课程的真实多样讲义材料上进行实验和基于人类的评估，我们证明了InstructKG能够捕获丰富且与教师教学对齐的学习路径。

Conclusion: InstructKG框架能够有效地从教学材料中构建出高质量、与教师教学对齐的知识图谱，从而为识别学生知识差距和实现个性化学习提供支持。

Abstract: Mastering educational concepts requires understanding both their prerequisites (e.g., recursion before merge sort) and sub-concepts (e.g., merge sort as part of sorting algorithms). Capturing these dependencies is critical for identifying students' knowledge gaps and enabling targeted intervention for personalized learning. This is especially challenging in large-scale courses, where instructors cannot feasibly diagnose individual misunderstanding or determine which concepts need reinforcement. While knowledge graphs offer a natural representation for capturing these conceptual relationships at scale, existing approaches are either surface-level (focusing on course-level concepts like "Algorithms" or logistical relationships such as course enrollment), or disregard the rich pedagogical signals embedded in instructional materials. We propose InstructKG, a framework for automatically constructing instructor-aligned knowledge graphs that capture a course's intended learning progression. Given a course's lecture materials (slides, notes, etc.), InstructKG extracts significant concepts as nodes and infers learning dependencies as directed edges (e.g., "part-of" or "depends-on" relationships). The framework synergizes the rich temporal and semantic signals unique to educational materials (e.g., "recursion" is taught before "mergesort"; "recursion" is mentioned in the definition of "merge sort") with the generalizability of large language models. Through experiments on real-world, diverse lecture materials across multiple courses and human-based evaluation, we demonstrate that InstructKG captures rich, instructor-aligned learning progressions.

</details>


### [131] [Epistemology of Generative AI: The Geometry of Knowing](https://arxiv.org/abs/2602.17116)
*Ilya Levin*

Main category: cs.AI

TL;DR: 生成式AI的知识生产机制模糊，本文提出一种基于高维几何和符号学的“高维空间索引认识论”，将生成模型重构为流形导航器，并引入“导航知识”作为一种新的知识生产模式。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的知识生产机制在认识论上模糊不清，阻碍了其负责任的整合。需要一种新的哲学范式来理解它如何将符号输入转换为高维空间中的语义意义，这与传统计算模式有所不同。

Method: 本文通过分析高维几何的四个结构特性（测度集中、近正交性、指数方向容量和流形规律性），发展了一种“高维空间索引认识论”。它借鉴皮尔斯符号学和帕珀特建构主义，将生成模型重新概念化为“学习流形的导航者”。

Result: 本文提出“导航知识”作为一种独特的第三种知识生产模式，区别于符号推理和统计重组。这一成果源于对生成模型在高维语义空间中运作方式的理解。

Conclusion: 理解生成式AI需要一种新的哲学范式，即以其在高维语义空间中的操作为基础的“导航知识”。这种“高维空间索引认识论”为其负责任的整合提供了原则性基础。

Abstract: Generative AI presents an unprecedented challenge to our understanding of knowledge and its production. Unlike previous technological transformations, where engineering understanding preceded or accompanied deployment, generative AI operates through mechanisms whose epistemic character remains obscure, and without such understanding, its responsible integration into science, education, and institutional life cannot proceed on a principled basis. This paper argues that the missing account must begin with a paradigmatic break that has not yet received adequate philosophical attention. In the Turing-Shannon-von Neumann tradition, information enters the machine as encoded binary vectors, and semantics remains external to the process. Neural network architectures rupture this regime: symbolic input is instantly projected into a high-dimensional space where coordinates correspond to semantic parameters, transforming binary code into a position in a geometric space of meanings. It is this space that constitutes the active epistemic condition shaping generative production. Drawing on four structural properties of high-dimensional geometry concentration of measure, near-orthogonality, exponential directional capacity, and manifold regularity the paper develops an Indexical Epistemology of High-Dimensional Spaces. Building on Peirce semiotics and Papert constructionism, it reconceptualizes generative models as navigators of learned manifolds and proposes navigational knowledge as a third mode of knowledge production, distinct from both symbolic reasoning and statistical recombination.

</details>


### [132] [Efficient Parallel Algorithm for Decomposing Hard CircuitSAT Instances](https://arxiv.org/abs/2602.17130)
*Victor Kondratiev,Irina Gribanova,Alexander Semenov*

Main category: cs.AI

TL;DR: 提出了一种新的并行算法，用于分解难的CircuitSAT实例。


<details>
  <summary>Details</summary>
Motivation: 旨在有效分解硬CircuitSAT实例。

Method: 该技术采用专门的约束将原始SAT实例划分为一系列弱化公式。该方法作为参数化并行算法实现，通过调整参数，在并行计算的硬度估计指导下，高效识别高质量的分解。

Result: 该算法在具有挑战性的CircuitSAT实例上表现出实际的有效性，包括编码布尔电路逻辑等价检查和密码哈希函数原像攻击的实例。

Conclusion: 该并行算法在分解具有挑战性的CircuitSAT实例方面具有实际效用。

Abstract: We propose a novel parallel algorithm for decomposing hard CircuitSAT instances. The technique employs specialized constraints to partition an original SAT instance into a family of weakened formulas. Our approach is implemented as a parameterized parallel algorithm, where adjusting the parameters allows efficient identification of high-quality decompositions, guided by hardness estimations computed in parallel. We demonstrate the algorithm's practical efficacy on challenging CircuitSAT instances, including those encoding Logical Equivalence Checking of Boolean circuits and preimage attacks on cryptographic hash functions.

</details>


### [133] [JEPA-DNA: Grounding Genomic Foundation Models through Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.17162)
*Ariel Larey,Elay Dahan,Amit Bleiweiss,Raizy Kellerman,Guy Leib,Omri Nayshool,Dan Ofer,Tal Zinger,Dan Dominissini,Gideon Rechavi,Nicole Bussola,Simon Lee,Shane O'Connell,Dung Hoang,Marissa Wirth,Alexander W. Charney,Nati Daniel,Yoli Shavit*

Main category: cs.AI

TL;DR: JEPA-DNA通过将联合嵌入预测架构（JEPA）与传统生成目标相结合，学习同时捕获局部基因组语法和全局功能背景的基因组表征，性能优于仅基于生成的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的基因组基础模型（GFMs）主要依赖于掩码语言建模（MLM）或下一令牌预测（NTP），虽然擅长捕获局部基因组语法和精细的基序模式，但未能捕获更广泛的功能背景，导致表征缺乏全局生物学视角。

Method: JEPA-DNA是一种新颖的预训练框架，将联合嵌入预测架构（JEPA）与传统生成目标相结合。它通过将令牌级恢复与潜在空间中的预测目标（通过监督一个CLS令牌）相结合，引入了潜在接地。这使得模型能够预测被掩码基因组片段的高级功能嵌入，而不是仅仅关注单个核苷酸。JEPA-DNA扩展了NTP和MLM范式，可以作为独立的从头开始的目标，或作为现有GFMs的持续预训练增强。

Result: JEPA-DNA在各种基因组基准测试的监督和零样本任务中，始终优于仅基于生成的基线模型，表现出卓越的性能。

Conclusion: JEPA-DNA提供了更强大且具有生物学基础的表征，为理解基因组字母和序列潜在功能逻辑的基础模型提供了一条可扩展的路径。

Abstract: Genomic Foundation Models (GFMs) have largely relied on Masked Language Modeling (MLM) or Next Token Prediction (NTP) to learn the language of life. While these paradigms excel at capturing local genomic syntax and fine-grained motif patterns, they often fail to capture the broader functional context, resulting in representations that lack a global biological perspective. We introduce JEPA-DNA, a novel pre-training framework that integrates the Joint-Embedding Predictive Architecture (JEPA) with traditional generative objectives. JEPA-DNA introduces latent grounding by coupling token-level recovery with a predictive objective in the latent space by supervising a CLS token. This forces the model to predict the high-level functional embeddings of masked genomic segments rather than focusing solely on individual nucleotides. JEPA-DNA extends both NTP and MLM paradigms and can be deployed either as a standalone from-scratch objective or as a continual pre-training enhancement for existing GFMs. Our evaluations across a diverse suite of genomic benchmarks demonstrate that JEPA-DNA consistently yields superior performance in supervised and zero-shot tasks compared to generative-only baselines. By providing a more robust and biologically grounded representation, JEPA-DNA offers a scalable path toward foundation models that understand not only the genomic alphabet, but also the underlying functional logic of the sequence.

</details>


### [134] [From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences](https://arxiv.org/abs/2602.17221)
*Yi-Chih Huang*

Main category: cs.AI

TL;DR: 本研究提出并验证了一种基于AI Agent的七阶段协作研究工作流（Agentic Workflow），用于人文社科研究。通过分析台湾AEI数据，该研究展示了工作流的可行性，并识别了三种人机协作模式，强调了人类判断在关键研究环节的不可替代性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在软件工程和自然科学领域，对人文社科领域中生成式AI的应用缺乏方法论探索。本研究旨在填补这一空白，为人文社科研究提出并验证一种AI Agent协作研究工作流。

Method: 本研究采用了“方法论实验”的方式，提出了一个基于AI Agent的协作研究工作流（Agentic Workflow），包含七个模块化阶段，并遵循任务模块化、人机分工和可验证性三项原则。每个阶段明确了人类研究者（研究判断和伦理决策）和AI Agent（信息检索和文本生成）的角色。研究使用台湾Anthropic Economic Index (AEI) 的7,729次对话数据作为实证验证工具，展示了该工作流在二手数据研究中的应用过程和产出质量。

Result: 研究成功设计并验证了一个七阶段的模块化AI Agent协作工作流，并通过AEI台湾数据的实证分析展示了其可行性和有效性。通过对操作过程的反思性记录，研究识别了人机协作的三种操作模式：直接执行、迭代细化和人类主导。研究强调了人类判断在研究问题制定、理论解释、情境化推理和伦理反思中的不可替代性。

Conclusion: 本研究提出了一种可复制的人工智能协作框架，并识别了人机协作的三种操作模式：直接执行、迭代细化和人类主导。这些模式强调了人类判断在研究问题制定、理论解释、情境化推理和伦理反思中的不可替代性。研究承认了平台单一数据、横断面设计和人工智能可靠性风险等局限性。

Abstract: Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a "methodological experiment," this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index (AEI) serves as the empirical vehicle for validating the feasibility of this methodology. This study operates on two levels: the primary level is the design and validation of a methodological framework - a seven-stage modular workflow grounded in three principles: task modularization, human-AI division of labor, and verifiability, with each stage delineating clear roles for human researchers (research judgment and ethical decisions) and AI Agents (information retrieval and text generation); the secondary level is the empirical analysis of AEI Taiwan data - serving as an operational demonstration of the workflow's application to secondary data research, showcasing both the process and output quality (see Appendix A). This study contributes by proposing a replicable AI collaboration framework for humanities and social science researchers, and identifying three operational modes of human-AI collaboration - direct execution, iterative refinement, and human-led - through reflexive documentation of the operational process. This taxonomy reveals the irreplaceability of human judgment in research question formulation, theoretical interpretation, contextualized reasoning, and ethical reflection. Limitations including single-platform data, cross-sectional design, and AI reliability risks are acknowledged.

</details>


### [135] [Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight](https://arxiv.org/abs/2602.17222)
*Ben Yellin,Ehud Ezra,Mark Foreman,Shula Grinapol*

Main category: cs.AI

TL;DR: 该论文介绍了大行为模型（LBM），这是一种行为基础模型，通过条件化结构化、高维度的特质档案来预测个体战略选择，克服了大型语言模型在生成一致的、个体特定行为方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在预测人类决策方面，尤其是在需要复杂心理特质和情境约束交互时，难以生成一致的、个体特定行为。基于提示的方法在这种情况下表现脆弱，存在身份漂移和利用详细角色描述能力有限的问题。

Method: 引入了大型行为模型（LBM），这是一个行为基础模型，通过对源自综合心理测量电池的结构化、高维度特质档案进行条件化来预测个体战略选择，从而从短暂的角色提示转向行为嵌入。LBM在一个专有数据集上进行训练，该数据集将稳定的倾向、动机状态和情境约束与观察到的选择联系起来。

Result: LBM微调在行为预测方面相对于未调整的Llama-3.1-8B-Instruct骨干模型有所改进，并且在以“大五”特质为条件时，表现与前沿基线相当。此外，基于提示的基线存在复杂性上限，而LBM能够从日益密集的特质档案中持续受益，随着额外特质维度的提供，性能会提高。

Conclusion: LBM被确立为一种高保真行为模拟的可扩展方法，可应用于战略预测、谈判分析、认知安全和决策支持。

Abstract: Predicting human decision-making in high-stakes environments remains a central challenge for artificial intelligence. While large language models (LLMs) demonstrate strong general reasoning, they often struggle to generate consistent, individual-specific behavior, particularly when accurate prediction depends on complex interactions between psychological traits and situational constraints. Prompting-based approaches can be brittle in this setting, exhibiting identity drift and limited ability to leverage increasingly detailed persona descriptions. To address these limitations, we introduce the Large Behavioral Model (LBM), a behavioral foundation model fine-tuned to predict individual strategic choices with high fidelity. LBM shifts from transient persona prompting to behavioral embedding by conditioning on a structured, high-dimensional trait profile derived from a comprehensive psychometric battery. Trained on a proprietary dataset linking stable dispositions, motivational states, and situational constraints to observed choices, LBM learns to map rich psychological profiles to discrete actions across diverse strategic dilemmas. In a held-out scenario evaluation, LBM fine-tuning improves behavioral prediction relative to the unadapted Llama-3.1-8B-Instruct backbone and performs comparably to frontier baselines when conditioned on Big Five traits. Moreover, we find that while prompting-based baselines exhibit a complexity ceiling, LBM continues to benefit from increasingly dense trait profiles, with performance improving as additional trait dimensions are provided. Together, these results establish LBM as a scalable approach for high-fidelity behavioral simulation, enabling applications in strategic foresight, negotiation analysis, cognitive security, and decision support.

</details>


### [136] [Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy](https://arxiv.org/abs/2602.17229)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在内部表示中编码了布鲁姆分类法定义的认知复杂性，通过线性分类器可实现约95%的准确率进行识别，且这种编码在模型前向传播的早期阶段形成。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的黑箱性质要求新的评估框架，超越表面级的性能指标。本研究旨在探究认知复杂度的内部神经表示。

Method: 本研究利用布鲁姆分类法作为认知复杂度的分层透镜，分析了不同大型语言模型的高维激活向量。通过使用线性分类器，探究了模型残差流中从基本回忆（记忆）到抽象综合（创造）等不同认知水平的线性可分离性。

Result: 线性分类器在所有布鲁姆认知水平上实现了大约95%的平均准确率。结果表明，认知水平被编码在模型表示的线性可访问子空间中，并且模型在前向传播的早期阶段就解决了提示的认知难度，其表示在层间变得越来越可分离。

Conclusion: 认知难度在大型语言模型的内部表示中以线性可访问的子空间编码，并在前向传播的早期阶段得到解决，其表示在不同层之间变得越来越可分离。

Abstract: The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional activation vectors from different LLMs, we probe whether different cognitive levels, ranging from basic recall (Remember) to abstract synthesis (Create), are linearly separable within the model's residual streams. Our results demonstrate that linear classifiers achieve approximately 95% mean accuracy across all Bloom levels, providing strong evidence that cognitive level is encoded in a linearly accessible subspace of the model's representations. These findings provide evidence that the model resolves the cognitive difficulty of a prompt early in the forward pass, with representations becoming increasingly separable across layers.

</details>


### [137] [All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting](https://arxiv.org/abs/2602.17234)
*Zeyu Zhang,Ryan Chen,Bradly C. Stadie*

Main category: cs.AI

TL;DR: 本研究提出Shapley-DCLR框架来检测和量化LLM在回溯测试中的时间知识泄露，并引入TimeSPEC方法主动过滤泄露信息，结果显示TimeSPEC能有效减少泄露而不影响性能，提高了回溯测试的可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）准确预测未来事件的能力需要对其进行“回溯测试”（backtest），即模型仅使用特定过去日期可用的信息进行推理。然而，LLMs在训练过程中可能会无意中泄露截止日期后的知识，从而损害回顾性评估的有效性。

Method: 1. 提出“时间知识泄露”检测和量化框架，将模型推理分解为原子声明，并按时间可验证性分类。
2. 应用Shapley值衡量每个声明对预测的贡献，得到可解释的决策关键泄露率（Shapley-DCLR）度量。
3. 提出时间监督预测与提取声明（TimeSPEC）方法，该方法通过交错生成、声明验证和重新生成来主动过滤时间污染，确保所有支持声明都可追溯到截止日期前的信息源。

Result: 在对美国最高法院案件预测、NBA薪资估算和股票收益排名等350个实例的实验中，发现标准提示基线存在大量时间知识泄露。TimeSPEC方法在保持任务性能的同时，显著降低了Shapley-DCLR，证明了显式的、可解释的声明级验证在减少时间泄露方面优于基于提示的时间约束。

Conclusion: 通过显式、可解释的声明级验证，可以有效地减少LLM在回溯测试中的时间知识泄露，并优于基于提示的时间约束方法，从而实现更可靠的预测。

Abstract: To evaluate whether LLMs can accurately predict future events, we need the ability to \textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded during training, undermining the validity of retrospective evaluation. We introduce a claim-level framework for detecting and quantifying this \emph{temporal knowledge leakage}. Our approach decomposes model rationales into atomic claims and categorizes them by temporal verifiability, then applies \textit{Shapley values} to measure each claim's contribution to the prediction. This yields the \textbf{Shapley}-weighted \textbf{D}ecision-\textbf{C}ritical \textbf{L}eakage \textbf{R}ate (\textbf{Shapley-DCLR}), an interpretable metric that captures what fraction of decision-driving reasoning derives from leaked information. Building on this framework, we propose \textbf{Time}-\textbf{S}upervised \textbf{P}rediction with \textbf{E}xtracted \textbf{C}laims (\textbf{TimeSPEC}), which interleaves generation with claim verification and regeneration to proactively filter temporal contamination -- producing predictions where every supporting claim can be traced to sources available before the cutoff date. Experiments on 350 instances spanning U.S. Supreme Court case prediction, NBA salary estimation, and stock return ranking reveal substantial leakage in standard prompting baselines. TimeSPEC reduces Shapley-DCLR while preserving task performance, demonstrating that explicit, interpretable claim-level verification outperforms prompt-based temporal constraints for reliable backtesting.

</details>


### [138] [ArXiv-to-Model: A Practical Study of Scientific LM Training](https://arxiv.org/abs/2602.17288)
*Anuj Gupta*

Main category: cs.AI

TL;DR: 本文详细介绍了从原始 arXiv LaTeX 来源训练一个 1.36B 参数科学语言模型的过程，包括端到端的数据处理流程、训练稳定性、扩展行为、数据产出损失和基础设施瓶颈分析，为中等计算预算下构建领域专业模型的研究人员提供工程实践洞察。


<details>
  <summary>Details</summary>
Motivation: 尽管前沿大型语言模型展现出强大的推理和数学能力，但从原始来源训练领域专业科学语言模型的实际过程仍缺乏详细记录。

Method: 本研究以一个 1.36B 参数的科学语言模型为例，直接从涵盖数学、计算机科学和理论物理的原始 arXiv LaTeX 来源进行训练。方法涵盖了一个端到端的流程，包括元数据过滤、档案验证、LaTeX 提取、文本标准化、领域感知分词，以及在有限计算资源（2xA100 GPU）下进行密集 Transformer 训练。通过 24 次实验运行，分析了训练稳定性、扩展行为、数据产出损失和基础设施瓶颈。

Result: 研究发现，预处理决策显著影响可用 token 量，分词影响符号稳定性，存储和 I/O 约束可能与计算资源一样成为限制因素。此外，分析了收敛动态，并在数据丰富的状态（52B 预训练 token）下展示了稳定的训练行为。

Conclusion: 这项工作没有提出新颖的架构，而是提供了一个基于工程实践的、透明的从零开始训练小型科学语言模型的案例。希望这些见解能为在适度计算预算下寻求构建领域专业模型的研究人员提供支持。

Abstract: While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scientific language model directly from raw arXiv LaTeX sources spanning mathematics, computer science, and theoretical physics. We describe an end-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training under constrained compute (2xA100 GPUs). Through 24 experimental runs, we analyze training stability, scaling behavior, data yield losses, and infrastructure bottlenecks. Our findings highlight how preprocessing decisions significantly affect usable token volume, how tokenization impacts symbolic stability, and how storage and I/O constraints can rival compute as limiting factors. We further analyze convergence dynamics and show stable training behavior in a data-rich regime (52B pretraining tokens). Rather than proposing a novel architecture, this work provides an engineering-grounded, transparent account of training a small scientific language model from scratch. We hope these insights support researchers operating under moderate compute budgets who seek to build domain-specialized models.

</details>


### [139] [Dataless Weight Disentanglement in Task Arithmetic via Kronecker-Factored Approximate Curvature](https://arxiv.org/abs/2602.17385)
*Angelo Porrello,Pietro Buzzega,Felix Dangel,Thomas Sommariva,Riccardo Salami,Lorenzo Bonicelli,Simone Calderara*

Main category: cs.AI

TL;DR: 该论文提出了一种无数据方法，通过将表示漂移的正则化框架为曲率矩阵近似问题，以解决组合任务向量时跨任务干扰导致的表示漂移和性能下降。该方法利用 Kronecker 因子近似曲率，在任务加法和减法方面取得了最先进的结果，并且具有恒定的任务数量复杂度，提高了对任务向量重新缩放的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 组合多个任务向量会导致跨任务干扰，引起表示漂移和性能下降。现有的表示漂移正则化方法通常需要外部任务数据，这与模块化和数据可用性限制（如隐私要求）相冲突。

Method: 提出一种无数据方法，将表示漂移的正则化框架为曲率矩阵近似问题。具体地，采用 Kronecker 因子近似曲率 (Kronecker-Factored Approximate Curvature) 来获得一个实用的正则化器。

Result: 在任务加法和减法中取得了最先进的结果。该方法在任务数量上具有恒定的复杂度，并增强了对任务向量重新缩放的鲁棒性，无需保留调整。

Conclusion: 通过将表示漂移正则化为曲率矩阵近似问题，并利用Kronecker因子近似曲率，提出了一种高效且无需数据的解决方案，有效解决了多任务向量组合中的表示漂移问题，达到了优异的性能和鲁棒性。

Abstract: Task Arithmetic yields a modular, scalable way to adapt foundation models. Combining multiple task vectors, however, can lead to cross-task interference, causing representation drift and degraded performance. Representation drift regularization provides a natural remedy to disentangle task vectors; however, existing approaches typically require external task data, conflicting with modularity and data availability constraints (e.g., privacy requirements). We propose a dataless approach by framing regularization against representation drift as a curvature matrix approximation problem. This allows us to leverage well-established techniques; in particular, we adopt Kronecker-Factored Approximate Curvature and obtain a practical regularizer that achieves state-of-the-art results in task addition and negation. Our method has constant complexity in the number of tasks and promotes robustness to task vector rescaling, eliminating the need for held-out tuning.

</details>


### [140] [Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval](https://arxiv.org/abs/2602.17386)
*Adrià Molina,Oriol Ramos Terrades,Josep Lladós*

Main category: cs.AI

TL;DR: 该研究提出一个将形式化验证与深度学习结合的图像检索框架，以解决现有模型在处理复杂自然语言查询时的不可靠性，通过显式验证查询约束，提供可信、可验证且透明的检索结果，并增强了基于嵌入的方法的效果。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言搜索虽然取得了巨大进步，但在处理涉及复杂关系、对象组合或精确约束（如身份、计数和比例）的查询时，现有框架仍存在未解决或不可靠的问题。传统的向量表示方法通常存在模糊性和近似性。

Method: 该论文提出了一种新颖的框架，通过图形化验证方法和神经代码生成的协同组合，将形式化验证集成到基于深度学习的图像检索中。它通过形式化推理系统来验证检索结果，并明确验证用户查询中的每个原子事实。

Result: 该方法旨在支持开放词汇的自然语言查询，同时产生可信和可验证的结果。它不仅能返回匹配结果，还能识别和标记哪些特定约束已满足，哪些未满足，从而提供更透明和负责任的检索过程，并提升了最流行的基于嵌入方法的检索效果。

Conclusion: 该框架通过将形式化验证与深度学习相结合，为图像检索提供了一种可信、可验证、透明且负责任的方法，克服了现有基于嵌入模型在处理复杂查询时的局限性。

Abstract: Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve complex relationships, object compositions, or precise constraints such as identities, counts and proportions often remain unresolved or unreliable within current frameworks. In this paper, we propose a novel framework that integrates formal verification into deep learning-based image retrieval through a synergistic combination of graph-based verification methods and neural code generation. Our approach aims to support open-vocabulary natural language queries while producing results that are both trustworthy and verifiable. By grounding retrieval results in a system of formal reasoning, we move beyond the ambiguity and approximation that often characterize vector representations. Instead of accepting uncertainty as a given, our framework explicitly verifies each atomic truth in the user query against the retrieved content. This allows us to not only return matching results, but also to identify and mark which specific constraints are satisfied and which remain unmet, thereby offering a more transparent and accountable retrieval process while boosting the results of the most popular embedding-based approaches.

</details>


### [141] [A Contrastive Variational AutoEncoder for NSCLC Survival Prediction with Missing Modalities](https://arxiv.org/abs/2602.17402)
*Michele Zanitti,Vanja Miskovic,Francesco Trovò,Alessandra Laura Giulia Pedrocchi,Ming Shen,Yan Kyaw Tun,Arsela Prelaj,Sokol Kosta*

Main category: cs.AI

TL;DR: 针对非小细胞肺癌生存预测中多模态数据缺失的挑战，本研究提出了一种多模态对比变分自编码器（MCVAE），该模型对数据缺失具有鲁棒性，并在TCGA数据集上表现出优越的性能，并发现多模态集成并非总是有效。


<details>
  <summary>Details</summary>
Motivation: 非小细胞肺癌（NSCLC）患者的生存预测因个体预后特征差异而充满挑战。尽管整合全玻片图像、批量转录组学和DNA甲基化等互补模态有助于此任务，但现实世界临床数据集常存在模态缺失问题。现有模型在数据严重缺失时鲁棒性不足。

Method: 提出了一种多模态对比变分自编码器（MCVAE），通过模态特异性变分编码器捕捉各数据源的不确定性，并引入具有学习门控机制的融合瓶颈来标准化现有模态的贡献。模型采用结合生存损失和重建损失的多任务目标来正则化患者表征，并使用跨模态对比损失来强制潜在空间中的跨模态对齐。训练期间，应用随机模态掩蔽以提高对任意缺失模式的鲁棒性。

Result: 在TCGA-LUAD (n=475) 和TCGA-LUSC (n=446) 数据集上的广泛评估表明，与两种现有先进模型相比，本方法在预测疾病特异性生存期（DSS）方面有效，并对严重缺失情况具有鲁棒性。研究还通过测试模型在所有模态子集上的表现，澄清了多模态集成的一些问题，发现集成并非总能带来益处。

Conclusion: 本研究提出的MCVAE模型在非小细胞肺癌患者的生存预测中表现出有效性和对严重数据缺失的鲁棒性，并揭示了多模态数据融合并非总是对任务有益的。

Abstract: Predicting survival outcomes for non-small cell lung cancer (NSCLC) patients is challenging due to the different individual prognostic features. This task can benefit from the integration of whole-slide images, bulk transcriptomics, and DNA methylation, which offer complementary views of the patient's condition at diagnosis. However, real-world clinical datasets are often incomplete, with entire modalities missing for a significant fraction of patients. State-of-the-art models rely on available data to create patient-level representations or use generative models to infer missing modalities, but they lack robustness in cases of severe missingness. We propose a Multimodal Contrastive Variational AutoEncoder (MCVAE) to address this issue: modality-specific variational encoders capture the uncertainty in each data source, and a fusion bottleneck with learned gating mechanisms is introduced to normalize the contributions from present modalities. We propose a multi-task objective that combines survival loss and reconstruction loss to regularize patient representations, along with a cross-modal contrastive loss that enforces cross-modal alignment in the latent space. During training, we apply stochastic modality masking to improve the robustness to arbitrary missingness patterns. Extensive evaluations on the TCGA-LUAD (n=475) and TCGA-LUSC (n=446) datasets demonstrate the efficacy of our approach in predicting disease-specific survival (DSS) and its robustness to severe missingness scenarios compared to two state-of-the-art models. Finally, we bring some clarifications on multimodal integration by testing our model on all subsets of modalities, finding that integration is not always beneficial to the task.

</details>


### [142] [A Privacy by Design Framework for Large Language Model-Based Applications for Children](https://arxiv.org/abs/2602.17418)
*Diana Addae,Diana Rogachova,Nafiseh Kahani,Masoud Barati,Michael Christensen,Chen Zhou*

Main category: cs.AI

TL;DR: 本文提出了一个基于隐私设计的框架，整合了多项隐私法规和儿童设计指南，以帮助开发者在LLM应用生命周期中，通过技术和组织控制以及适合年龄的设计决策，降低儿童AI产品的隐私风险并符合法律要求。


<details>
  <summary>Details</summary>
Motivation: 儿童越来越多地使用人工智能（AI）技术，但随之而来的是对隐私风险的日益担忧，特别是针对儿童的风险。尽管现有隐私法规要求公司和组织实施保护措施，但这在实践中往往充满挑战。

Method: 本文提出了一个基于隐私设计（PbD）的框架，旨在指导设计者和开发者主动、规避风险地进行技术设计。该框架整合了来自GDPR、PIPEDA和COPPA等隐私法规的原则，并将其映射到大语言模型（LLM）应用的各个阶段（数据收集、模型训练、操作监控和持续验证）。对于每个阶段，文章讨论了学术文献中的操作控制措施。此外，框架还纳入了基于UNCRC、AADC和最新学术研究的儿童设计指南。通过一个针对13岁以下儿童的LLM教育辅导案例研究，展示了该框架的实际应用。

Result: 该框架能够帮助AI服务提供商和开发者在降低隐私风险的同时，符合法律标准。通过案例研究和分析，表明采用数据保护策略（如技术和组织控制）和在LLM生命周期中进行适合年龄的设计决策，可以支持开发具有隐私保护并符合法律要求的儿童AI应用。

Conclusion: 该框架通过在LLM生命周期中应用数据保护策略（如技术和组织控制）和适合年龄的设计决策，能够支持开发既能提供隐私保护又符合法律要求的儿童AI应用。

Abstract: Children are increasingly using technologies powered by Artificial Intelligence (AI). However, there are growing concerns about privacy risks, particularly for children. Although existing privacy regulations require companies and organizations to implement protections, doing so can be challenging in practice. To address this challenge, this article proposes a framework based on Privacy-by-Design (PbD), which guides designers and developers to take on a proactive and risk-averse approach to technology design. Our framework includes principles from several privacy regulations, such as the General Data Protection Regulation (GDPR) from the European Union, the Personal Information Protection and Electronic Documents Act (PIPEDA) from Canada, and the Children's Online Privacy Protection Act (COPPA) from the United States. We map these principles to various stages of applications that use Large Language Models (LLMs), including data collection, model training, operational monitoring, and ongoing validation. For each stage, we discuss the operational controls found in the recent academic literature to help AI service providers and developers reduce privacy risks while meeting legal standards. In addition, the framework includes design guidelines for children, drawing from the United Nations Convention on the Rights of the Child (UNCRC), the UK's Age-Appropriate Design Code (AADC), and recent academic research. To demonstrate how this framework can be applied in practice, we present a case study of an LLM-based educational tutor for children under 13. Through our analysis and the case study, we show that by using data protection strategies such as technical and organizational controls and making age-appropriate design decisions throughout the LLM life cycle, we can support the development of AI applications for children that provide privacy protections and comply with legal requirements.

</details>


### [143] [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442)
*Marco Avolio,Potito Aghilar,Sabino Roccotelli,Vito Walter Anelli,Chiara Mallamaci,Vincenzo Paparella,Marco Valentini,Alejandro Bellogín,Michelantonio Trizio,Joseph Trotta,Antonio Ferrara,Tommaso Di Noia*

Main category: cs.AI

TL;DR: WarpRec是一个高性能、后端无关的推荐系统框架，它弥合了学术研究和工业部署之间的鸿沟，支持从本地到分布式无缝过渡，并具备可持续性和面向Agentic AI的未来发展潜力。


<details>
  <summary>Details</summary>
Motivation: 当前的推荐系统创新受到碎片化生态系统的阻碍，研究人员必须在内存实验的便捷性和分布式工业引擎所需的昂贵且复杂的重写之间做出选择，这限制了学术研究向工业部署的转化。

Method: WarpRec是一个高性能、后端无关的推荐系统框架，通过消除内存实验与分布式工业引擎之间的权衡来解决现有问题。它集成了50多种最先进算法、40种评估指标以及19种过滤和拆分策略，支持从本地执行到分布式训练和优化的无缝过渡。此外，WarpRec通过集成CodeCarbon进行实时能耗跟踪，强制执行生态责任。

Result: WarpRec提供了一个高性能框架，该框架包含大量最先进的算法、指标和策略，并实现了从本地到分布式训练和优化的无缝过渡。它通过实时能耗跟踪，确保了可扩展性与可持续性。此外，WarpRec预见了向Agentic AI的转变，使推荐系统能够演变为生成式AI生态系统中的互动工具。

Conclusion: WarpRec不仅弥合了学术界和工业界之间的差距，还为下一代可持续的、支持Agentic AI的推荐系统提供了架构支柱，使其从静态排序引擎演变为生成式AI生态系统中的互动工具。

Abstract: Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly transition from local execution to distributed training and optimization. The framework enforces ecological responsibility by integrating CodeCarbon for real-time energy tracking, showing that scalability need not come at the cost of scientific integrity or sustainability. Furthermore, WarpRec anticipates the shift toward Agentic AI, leading Recommender Systems to evolve from static ranking engines into interactive tools within the Generative AI ecosystem. In summary, WarpRec not only bridges the gap between academia and industry but also can serve as the architectural backbone for the next generation of sustainable, agent-ready Recommender Systems. Code is available at

</details>


### [144] [Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems](https://arxiv.org/abs/2602.17508)
*Pranay Jain,Maximilian Kasper,Göran Köber,Axel Plinge,Dominik Seuß*

Main category: cs.AI

TL;DR: 本研究提出了一个实用的基准测试框架，用于在ARM Cortex处理器（M0+、M4、M7）上优化AI模型，侧重于嵌入式系统中的能效、准确性和资源利用率。通过自动化测试台和帕累托分析，研究揭示了FLOPs与推理时间之间的相关性，并针对不同处理器和推理任务给出了最佳实践，旨在指导开发者设计高能效AI系统。


<details>
  <summary>Details</summary>
Motivation: 在嵌入式系统中，优化ARM Cortex处理器上AI模型的能效、准确性和资源利用率。

Method: 设计自动化测试台，采用系统方法评估关键性能指标（KPIs），识别处理器和AI模型的最佳组合。使用帕累托分析平衡能耗和模型准确性之间的权衡。

Result: 发现浮点运算（FLOPs）与推理时间之间存在近似线性相关性，为估算计算需求提供可靠指标。M7处理器适用于短推理周期，M4处理器在较长推理任务中能效更优，M0+处理器适用于简单任务。

Conclusion: 该工作为开发者提供了设计能效高、性能卓越的AI系统的见解，以满足实际应用需求。

Abstract: This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systematic approach to evaluate across key performance indicators (KPIs) and identify optimal combinations of processor and AI model. The research highlights a nearlinear correlation between floating-point operations (FLOPs) and inference time, offering a reliable metric for estimating computational demands. Using Pareto analysis, we demonstrate how to balance trade-offs between energy consumption and model accuracy, ensuring that AI applications meet performance requirements without compromising sustainability. Key findings indicate that the M7 processor is ideal for short inference cycles, while the M4 processor offers better energy efficiency for longer inference tasks. The M0+ processor, while less efficient for complex AI models, remains suitable for simpler tasks. This work provides insights for developers, guiding them to design energy-efficient AI systems that deliver high performance in realworld applications.

</details>


### [145] [Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation](https://arxiv.org/abs/2602.17529)
*Dun Yuan,Hao Zhou,Xue Liu,Hao Chen,Yan Xin,Jianzhong,Zhang*

Main category: cs.AI

TL;DR: 本文提出KG-RAG框架，通过结合知识图谱和RAG来增强LLM在电信领域的表现，有效解决了领域复杂性导致的幻觉问题，并在准确性上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在电信领域的应用面临挑战，原因在于领域复杂性、不断演进的标准和专业术语。因此，通用领域的LLMs可能难以在该背景下提供准确可靠的输出，导致幻觉增加和实用性降低。

Method: 本文提出了一种名为KG-RAG的新型框架，它将知识图谱（KGs）与检索增强生成（RAG）相结合，以增强大型语言模型在电信特定任务中的能力。其中，知识图谱提供了从电信标准和技术文档中提取的结构化领域知识，而RAG则实现了相关事实的动态检索，从而为模型的输出提供依据。这种结合能够提高事实准确性，减少幻觉，并确保符合电信标准。

Result: 在基准数据集上的实验结果表明，KG-RAG的表现优于仅使用LLM和标准RAG的基线模型。具体来说，KG-RAG的平均准确率比RAG提高了14.3%，比仅使用LLM的模型提高了21.6%。

Conclusion: KG-RAG在复杂的电信场景中能够生成准确、可靠且可解释的输出，证明了其有效性。

Abstract: Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable outputs in this context, leading to increased hallucinations and reduced utility in telecom address these limitations, this work introduces KG-RAG-a novel framework that integrates knowledge graphs (KGs) with retrieval-augmented generation (RAG) to enhance LLMs for telecom-specific tasks. In particular, the KG provides a structured representation of domain knowledge derived from telecom standards and technical documents, while RAG enables dynamic retrieval of relevant facts to ground the model's outputs. Such a combination improves factual accuracy, reduces hallucination, and ensures compliance with telecom results across benchmark datasets demonstrate that KG-RAG outperforms both LLM-only and standard RAG baselines, e.g., KG-RAG achieves an average accuracy improvement of 14.3% over RAG and 21.6% over LLM-only models. These results highlight KG-RAG's effectiveness in producing accurate, reliable, and explainable outputs in complex telecom scenarios.

</details>


### [146] [Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability](https://arxiv.org/abs/2602.17544)
*Shashank Aggarwal,Ram Vikas Mishra,Amit Awekar*

Main category: cs.AI

TL;DR: 论文提出了衡量LLM CoT质量的两个新指标：可重用性和可验证性，发现它们与传统准确性不相关，且专业推理模型的CoT不一定优于通用LLM。


<details>
  <summary>Details</summary>
Motivation: 当前针对大语言模型（LLM）的思维链（CoT）评估主要集中在目标任务准确性上，但这种度量方式未能评估推理过程本身的质量或效用。

Method: 引入了可重用性（Executor重用Thinker的CoT的难易程度）和可验证性（Executor通过CoT匹配Thinker答案的频率）这两个新度量指标。使用Thinker-Executor框架将CoT生成与执行解耦。在五个基准上，评估了四个Thinker模型和十个Executor模型。

Result: 可重用性和可验证性与标准的任务准确性不相关，这暴露了当前基于准确性的推理能力排行榜的一个盲点。令人惊讶的是，来自专业推理模型的CoT在可重用性或可验证性方面并不总是优于Llama和Gemma等通用LLM。

Conclusion: 仅凭任务准确性无法全面评估LLM的推理能力，需要考虑可重用性和可验证性等过程质量指标，并且发现专业推理模型的优势并非普遍存在。

Abstract: In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusability measures how easily an Executor can reuse the Thinker's CoT. Verifiability measures how frequently an Executor can match the Thinker's answer using the CoT. We evaluated four Thinker models against a committee of ten Executor models across five benchmarks. Our results reveal that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, we find that CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.

</details>


### [147] [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560)
*Hongjue Zhao,Haosen Sun,Jiangtao Kong,Xiaochang Li,Qineng Wang,Liwei Jiang,Qi Zhu,Tarek Abdelzaher,Yejin Choi,Manling Li,Huajie Shao*

Main category: cs.AI

TL;DR: 该论文提出了一种基于常微分方程（ODE）的激活引导理论框架，并引入了ODESteer方法，通过势函数实现多步自适应引导，从而在LLM对齐方面取得了显著的实证改进。


<details>
  <summary>Details</summary>
Motivation: 当前的激活引导方法存在两个主要限制：缺乏统一的理论框架指导引导方向的设计，以及过度依赖无法捕捉复杂激活分布模式的“一步引导”。

Method: 本文提出了一种基于常微分方程（ODE）的LLM对齐激活引导理论框架。该框架将传统的激活加法解释为ODE解的一阶近似，并将引导方向的识别等同于设计控制理论中的“势函数”。在此基础上，提出了ODESteer方法，它将势函数定义为正负激活之间的对数密度比，并利用它构建ODE进行多步自适应引导。

Result: ODESteer在各种LLM对齐基准测试中取得了持续的实证改进，相较于最先进的激活引导方法，在TruthfulQA上提升了5.7%，在UltraFeedback上提升了2.5%，在RealToxicityPrompts上提升了2.4%。

Conclusion: 该工作通过统一基于ODE的理论基础，并通过提出的ODESteer方法进行经验验证，为LLM对齐中的激活引导建立了全新的原理性视角。

Abstract: Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \textit{(i)} the lack of a unified theoretical framework for guiding the design of steering directions, and \textit{(ii)} an over-reliance on \textit{one-step steering} that fail to capture complex patterns of activation distributions. In this work, we propose a unified ordinary differential equations (ODEs)-based \textit{theoretical} framework for activation steering in LLM alignment. We show that conventional activation addition can be interpreted as a first-order approximation to the solution of an ODE. Based on this ODE perspective, identifying a steering direction becomes equivalent to designing a \textit{barrier function} from control theory. Derived from this framework, we introduce ODESteer, a kind of ODE-based steering guided by barrier functions, which shows \textit{empirical} advancement in LLM alignment. ODESteer identifies steering directions by defining the barrier function as the log-density ratio between positive and negative activations, and employs it to construct an ODE for \textit{multi-step and adaptive} steering. Compared to state-of-the-art activation steering methods, ODESteer achieves consistent empirical improvements on diverse LLM alignment benchmarks, a notable $5.7\%$ improvement over TruthfulQA, $2.5\%$ over UltraFeedback, and $2.4\%$ over RealToxicityPrompts. Our work establishes a principled new view of activation steering in LLM alignment by unifying its theoretical foundations via ODEs, and validating it empirically through the proposed ODESteer method.

</details>


### [148] [A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN](https://arxiv.org/abs/2602.17566)
*Asif Hasan Chowdhury,Md. Fahim Islam,M Ragib Anjum Riad,Faiyaz Bin Hashem,Md Tanzim Reza,Md. Golam Rabiul Alam*

Main category: cs.AI

TL;DR: 该研究提出了一种混合联邦学习（FL）支持的集成方法，结合SWIN Transformer和CNN模型，用于基于X射线报告诊断肺部疾病（COVID-19和肺炎），旨在提供一个安全、分布式、高效和可靠的医疗数据处理系统，以辅助医生。


<details>
  <summary>Details</summary>
Motivation: 计算能力的显著进步为人工智能在医疗保健领域的应用创造了巨大机会。医疗专家和医院需要一个共享的数据空间，以实现安全、分布式和高效可靠的医疗数据处理，特别是在肺部疾病诊断方面（如COVID-19和肺炎）。同时，需要确保医疗数据处理的安全性、分布式性和数据真实性。

Method: 该方法是一种混合联邦学习支持的集成方法，结合了SWIN Transformer和多种CNN模型（DenseNet201、Inception V3、VGG 19）。它利用Tensorflow、Keras以及微软开发的Vision Transformer技术，基于X射线报告进行诊断。研究中采用实时持续学习方法，并集成联邦学习以确保模型安全和信息真实性。

Result: 所提出的混合模型能够基于X射线报告检测COVID-19和肺炎。该系统旨在提高疾病诊断和严重程度预测的准确性，并创建一个安全、分布式、高效且可靠的医疗数据处理系统。

Conclusion: 联邦学习支持的混合人工智能模型能够提高疾病诊断和严重程度预测的准确性，并利用实时持续学习方法，同时联邦学习的整合能够确保混合模型的安全性并保持信息的真实性。该模型为医疗领域的医生提供了可靠的辅助解决方案。

Abstract: The significant advancements in computational power cre- ate a vast opportunity for using Artificial Intelligence in different ap- plications of healthcare and medical science. A Hybrid FL-Enabled Ensemble Approach For Lung Disease Diagnosis Leveraging a Combination of SWIN Transformer and CNN is the combination of cutting-edge technology of AI and Federated Learning. Since, medi- cal specialists and hospitals will have shared data space, based on that data, with the help of Artificial Intelligence and integration of federated learning, we can introduce a secure and distributed system for medical data processing and create an efficient and reliable system. The proposed hybrid model enables the detection of COVID-19 and Pneumonia based on x-ray reports. We will use advanced and the latest available tech- nology offered by Tensorflow and Keras along with Microsoft-developed Vision Transformer, that can help to fight against the pandemic that the world has to fight together as a united. We focused on using the latest available CNN models (DenseNet201, Inception V3, VGG 19) and the Transformer model SWIN Transformer in order to prepare our hy- brid model that can provide a reliable solution as a helping hand for the physician in the medical field. In this research, we will discuss how the Federated learning-based Hybrid AI model can improve the accuracy of disease diagnosis and severity prediction of a patient using the real-time continual learning approach and how the integration of federated learn- ing can ensure hybrid model security and keep the authenticity of the information.

</details>


### [149] [AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games](https://arxiv.org/abs/2602.17594)
*Lance Ying,Ryan Truong,Prafull Sharma,Kaiya Ivy Zhao,Nathan Cloos,Kelsey R. Allen,Thomas L. Griffiths,Katherine M. Collins,José Hernández-Orallo,Phillip Isola,Samuel J. Gershman,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 该论文提出通过评估AI玩所有人类可想象的游戏的能力来衡量其通用智能，并介绍了AI GameStore平台用于合成新游戏。研究表明，当前的前沿模型在这些游戏中的表现远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 传统AI基准测试范围狭窄且静态，无法有效评估机器的通用智能，导致快速饱和。

Method: 论文提出通过通用游戏玩法（“人类游戏多元宇宙”）来评估AI的类人通用智能，即AI玩和学习玩所有可想象的人类游戏的能力。为此，引入了AI GameStore平台，该平台是一个可扩展的、开放式的平台，利用大型语言模型（LLMs）和人类参与来合成新的代表性人类游戏，方法是自动获取并改编来自流行人类数字游戏平台的标准化和容器化游戏环境变体。作为概念验证，基于Apple App Store和Steam的排行榜生成了100个此类游戏，并评估了七个前沿视觉-语言模型（VLMs）在短时游戏中的表现。

Result: 最佳模型在大多数游戏中的得分不到人类平均得分的10%，尤其是在需要世界模型学习、记忆和规划的游戏中表现不佳。

Conclusion: AI GameStore提供了一种衡量和推动机器实现类人通用智能的实用方法。

Abstract: Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. Most are also static, quickly saturating as developers explicitly or implicitly optimize for them. We propose that a more promising way to evaluate human-like general intelligence in AI systems is through a particularly strong form of general game playing: studying how and how well they play and learn to play \textbf{all conceivable human games}, in comparison to human players with the same level of experience, time, or other resources. We define a "human game" to be a game designed by humans for humans, and argue for the evaluative suitability of this space of all such games people can imagine and enjoy -- the "Multiverse of Human Games". Taking a first step towards this vision, we introduce the AI GameStore, a scalable and open-ended platform that uses LLMs with humans-in-the-loop to synthesize new representative human games, by automatically sourcing and adapting standardized and containerized variants of game environments from popular human digital gaming platforms. As a proof of concept, we generated 100 such games based on the top charts of Apple App Store and Steam, and evaluated seven frontier vision-language models (VLMs) on short episodes of play. The best models achieved less than 10\% of the human average score on the majority of the games, and especially struggled with games that challenge world-model learning, memory and planning. We conclude with a set of next steps for building out the AI GameStore as a practical way to measure and drive progress toward human-like general intelligence in machines.

</details>


### [150] [MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models](https://arxiv.org/abs/2602.17602)
*Hojung Jung,Rodrigo Hormazabal,Jaehyeong Jo,Youngrok Park,Kyunggeun Roh,Se-Young Yun,Sehui Han,Dae-Woong Jeong*

Main category: cs.AI

TL;DR: MolHIT是一种新型分子图生成框架，它利用分层离散扩散模型和解耦原子编码，首次在图扩散领域实现了接近完美的化学有效性，并在MOSES数据集上取得了最先进的性能，在多项指标上超越了强大的1D基线，同时在下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的图扩散模型在分子生成方面存在化学有效性低和难以满足所需性质的问题，尤其是在与1D建模相比时，这限制了AI驱动药物发现和材料科学中扩散模型的潜力。

Method: MolHIT基于分层离散扩散模型，该模型将离散扩散推广到编码化学先验的附加类别。它还采用了分离原子编码，根据原子的化学作用对其类型进行划分。

Result: MolHIT在MOSES数据集上取得了新的最先进性能，首次在图扩散中实现了接近完美的有效性，在多项指标上超越了强大的1D基线。它还在多性质引导生成和支架扩展等下游任务中表现出强大的性能。

Conclusion: MolHIT成功克服了现有分子图生成方法中长期存在的性能限制，在化学有效性和整体性能方面树立了新标杆，使其成为AI驱动药物发现和材料科学的强大框架。

Abstract: Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to meet the desired properties compared to 1D modeling. In this work, we introduce MolHIT, a powerful molecular graph generation framework that overcomes long-standing performance limitations in existing methods. MolHIT is based on the Hierarchical Discrete Diffusion Model, which generalizes discrete diffusion to additional categories that encode chemical priors, and decoupled atom encoding that splits the atom types according to their chemical roles. Overall, MolHIT achieves new state-of-the-art performance on the MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. We further demonstrate strong performance in downstream tasks, including multi-property guided generation and scaffold extension.

</details>


### [151] [CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts](https://arxiv.org/abs/2602.17663)
*Juri Opitz,Corina Raclé,Emanuela Boros,Andrianos Michail,Matteo Romanello,Maud Ehrmann,Simon Clematide*

Main category: cs.AI

TL;DR: HIPE-2026是一个CLEF评估实验室，专注于从嘈杂、多语言历史文本中提取人物-地点关系，识别“at”和“isAt”两种关系，并通过准确性、效率和泛化能力进行评估，以支持数字人文应用。


<details>
  <summary>Details</summary>
Motivation: HIPE-2026建立在HIPE-2020和HIPE-2022活动的基础上，旨在将系列研究扩展到语义关系提取，特别是识别多语言和多时间段中的人物-地点关联，以支持知识图谱构建、历史传记重建和数字人文中的空间分析等下游应用。

Method: HIPE-2026实验室要求系统从嘈杂的、多语言的历史文本中识别人物-地点关联，并将关系分为“at”（人物是否曾在此地）和“isAt”（人物在出版时是否在此地）两种类型，需要系统对时间和地理线索进行推理。评估采用三重评估标准，综合考量准确性、计算效率和领域泛化能力。

Result: 该实验室成功建立了从嘈杂、多语言历史文本中提取人物-地点关系的任务框架，并定义了两种具体的关系类型（at和isAt）及其评估标准（准确性、计算效率和领域泛化能力）。这一框架为未来的系统开发和评估奠定了基础。

Conclusion: HIPE-2026作为一个评估实验室，旨在将关系提取与大规模历史数据处理相结合，支持数字人文领域在知识图谱构建、历史传记重建和空间分析等方面的下游应用。

Abstract: HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ ("Has the person ever been at this place?") and $isAt$ ("Is the person located at this place around publication time?") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [152] [Neural Implicit Representations for 3D Synthetic Aperture Radar Imaging](https://arxiv.org/abs/2602.17556)
*Nithin Sugavanam,Emre Ertin*

Main category: eess.SP

TL;DR: 该论文回顾了利用神经结构对表面散射进行建模的最新工作，实现了3D SAR成像的最新技术水平，通过将物体表面编码为符号距离函数，并通过隐式表面采样对表面估计进行正则化。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达（SAR）在傅里叶域中测量的二维切片不能完全填充三维空间，导致重建图像中存在明显的伪影。传统上使用简单的先验（如图像域中的稀疏性）来正则化逆问题，但这些方法不足以解决该问题。

Method: 该论文采用神经结构来建模表面散射，将物体表面编码为从稀疏散射数据中学习到的符号距离函数。为了解决从稀疏和噪声点云估计平滑表面的病态问题，在训练步骤中从隐式表面表示中采样点来正则化表面估计。

Result: 该模型能够使用来自单个车辆和包含大量车辆的更大场景的测量和模拟数据来表示目标散射，并实现了3D SAR成像的最新技术水平。

Conclusion: 未来的研究方向包括开发学习复数值神经表示的方法，以从体积神经隐式表示中合成新的集合。

Abstract: Synthetic aperture radar (SAR) is a tomographic sensor that measures 2D slices of the 3D spatial Fourier transform of the scene. In many operational scenarios, the measured set of 2D slices does not fill the 3D space in the Fourier domain, resulting in significant artifacts in the reconstructed imagery. Traditionally, simple priors, such as sparsity in the image domain, are used to regularize the inverse problem. In this paper, we review our recent work that achieves state-of-the-art results in 3D SAR imaging employing neural structures to model the surface scattering that dominates SAR returns. These neural structures encode the surface of the objects in the form of a signed distance function learned from the sparse scattering data. Since estimating a smooth surface from a sparse and noisy point cloud is an ill-posed problem, we regularize the surface estimation by sampling points from the implicit surface representation during the training step. We demonstrate the model's ability to represent target scattering using measured and simulated data from single vehicles and a larger scene with a large number of vehicles. We conclude with future research directions calling for methods to learn complex-valued neural representations to enable synthesizing new collections from the volumetric neural implicit representation.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [153] [RankEvolve: Automating the Discovery of Retrieval Algorithms via LLM-Driven Evolution](https://arxiv.org/abs/2602.16932)
*Jinming Nian,Fangchen Li,Dae Hoon Park,Yi Fang*

Main category: cs.IR

TL;DR: RankEvolve是一个由评估器引导的LLM程序演化系统，它基于AlphaEvolve，通过对BM25和查询似然等可执行代码进行演化，自动发现新颖且有效的词法检索算法，并在多个IR数据集上表现出良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: BM25和带有Dirichlet平滑的查询似然等检索算法仍然是强大而高效的第一阶段排序器，但其改进主要依赖于参数调整和人工直觉。本文研究了由评估器和演化搜索引导的大型语言模型是否能自动发现改进的词法检索算法。

Method: 本文介绍了RankEvolve，一个基于AlphaEvolve的程序演化设置。候选排序算法以可执行代码的形式表示，并根据在来自BEIR和BRIGHT的12个IR数据集上的检索性能进行迭代突变、重组和选择。RankEvolve以BM25和Dirichlet平滑查询似然作为初始种子程序。

Result: 演化出的算法是新颖、有效的，并显示出对完整的BEIR和BRIGHT基准测试以及TREC DL 19和20的良好泛化能力。

Conclusion: 评估器引导的大型语言模型程序演化是自动发现新颖排序算法的实用途径。

Abstract: Retrieval algorithms like BM25 and query likelihood with Dirichlet smoothing remain strong and efficient first-stage rankers, yet improvements have mostly relied on parameter tuning and human intuition. We investigate whether a large language model, guided by an evaluator and evolutionary search, can automatically discover improved lexical retrieval algorithms. We introduce RankEvolve, a program evolution setup based on AlphaEvolve, in which candidate ranking algorithms are represented as executable code and iteratively mutated, recombined, and selected based on retrieval performance across 12 IR datasets from BEIR and BRIGHT. RankEvolve starts from two seed programs: BM25 and query likelihood with Dirichlet smoothing. The evolved algorithms are novel, effective, and show promising transfer to the full BEIR and BRIGHT benchmarks as well as TREC DL 19 and 20. Our results suggest that evaluator-guided LLM program evolution is a practical path towards automatic discovery of novel ranking algorithms.

</details>


### [154] [Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers](https://arxiv.org/abs/2602.17410)
*Bingqian Li,Bowen Zheng,Xiaolei Wang,Long Zhang,Jinpeng Wang,Sheng Chen,Wayne Xin Zhao,Ji-rong Wen*

Main category: cs.IR

TL;DR: ILRec是一个新颖的偏好微调框架，通过利用从中间层提取的自困难负样本信号，改进了基于LLM的推荐系统中的偏好学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于序列级、离线生成的负样本，在处理大型负样本空间时，判别性和信息量不足，难以有效适应LLM到推荐任务。

Method: 提出ILRec框架，该框架利用从中间层提取的自困难负样本信号来改进偏好学习。具体地，框架包含两阶段：跨层偏好优化和跨层偏好蒸馏。此外，引入一个轻量级协同过滤模型来分配token级别的奖励，以缓解过度惩罚假阴性的风险。

Result: 在三个数据集上的广泛实验表明，ILRec在提升基于LLM的推荐系统性能方面是有效的。

Conclusion: ILRec通过利用自困难负样本信号，有效解决了基于LLM的推荐系统中负样本的挑战，显著提升了推荐性能。

Abstract: Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [155] [Multi-Objective Alignment of Language Models for Personalized Psychotherapy](https://arxiv.org/abs/2602.16053)
*Mehrab Beikzadeh,Yasaman Asadollah Salmanpour,Ashima Suvarna,Sriram Sankararaman,Matteo Malgaroli,Majid Sarrafzadeh,Saadia Gabriel*

Main category: cs.LG

TL;DR: 开发了一种多目标直接偏好优化（MODPO）框架，用于平衡心理健康AI系统中患者偏好与临床安全，通过患者调查和多目标奖励模型训练，实现了比单目标优化更优的平衡，并获得临床医生认可。


<details>
  <summary>Details</summary>
Motivation: 全球超过10亿人受精神健康障碍影响，但人力短缺和成本限制导致护理可及性有限。AI系统虽有治疗潜力，但现有对齐方法独立优化目标，未能平衡患者偏好与临床安全。

Method: 1. 调查了335名有心理健康经验的个体，收集治疗维度上的偏好排名。
2. 开发了一个使用直接偏好优化（DPO）的多目标对齐框架。
3. 针对同理心、安全、积极倾听、自我激励改变、信任/融洽关系和患者自主权六个标准训练了奖励模型。
4. 系统地将多目标方法与单目标优化、监督微调和参数合并进行了比较。

Result: 1. 多目标DPO (MODPO) 实现了比单目标优化更优的平衡（同理心77.6%，安全62.6% vs. 单目标同理心93.6%，安全47.8%）。
2. 治疗标准比通用沟通原则表现高出17.2%。
3. 盲法临床医生评估证实MODPO持续受到青睐，LLM评估者与临床医生之间的意见一致性可与临床医生间的可靠性相媲美。

Conclusion: 多目标直接偏好优化（MODPO）框架能够有效平衡心理健康AI中的患者偏好与临床安全，并通过多目标优化实现了优越的治疗效果和临床医生认可，为解决精神健康护理的可及性问题提供了有前景的AI解决方案。

Abstract: Mental health disorders affect over 1 billion people worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI systems show therapeutic promise, current alignment approaches optimize objectives independently, failing to balance patient preferences with clinical safety. We survey 335 individuals with lived mental health experience to collect preference rankings across therapeutic dimensions, then develop a multi-objective alignment framework using direct preference optimization. We train reward models for six criteria -- empathy, safety, active listening, self-motivated change, trust/rapport, and patient autonomy -- and systematically compare multi-objective approaches against single-objective optimization, supervised fine-tuning, and parameter merging. Multi-objective DPO (MODPO) achieves superior balance (77.6% empathy, 62.6% safety) compared to single-objective optimization (93.6% empathy, 47.8% safety), and therapeutic criteria outperform general communication principles by 17.2%. Blinded clinician evaluation confirms MODPO is consistently preferred, with LLM-evaluator agreement comparable to inter-clinician reliability.

</details>


### [156] [Omitted Variable Bias in Language Models Under Distribution Shift](https://arxiv.org/abs/2602.16784)
*Victoria Lin,Louis-Philippe Morency,Eli Ben-Michael*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Despite their impressive performance on a wide variety of tasks, modern language models remain susceptible to distribution shifts, exhibiting brittle behavior when evaluated on data that differs in distribution from their training data. In this paper, we describe how distribution shifts in language models can be separated into observable and unobservable components, and we discuss how established approaches for dealing with distribution shift address only the former. Importantly, we identify that the resulting omitted variable bias from unobserved variables can compromise both evaluation and optimization in language models. To address this challenge, we introduce a framework that maps the strength of the omitted variables to bounds on the worst-case generalization performance of language models under distribution shift. In empirical experiments, we show that using these bounds directly in language model evaluation and optimization provides more principled measures of out-of-distribution performance, improves true out-of-distribution performance relative to standard distribution shift adjustment methods, and further enables inference about the strength of the omitted variables when target distribution labels are available.

</details>


### [157] [Better Think Thrice: Learning to Reason Causally with Double Counterfactual Consistency](https://arxiv.org/abs/2602.16787)
*Victoria Lin,Xinnuo Xu,Rachel Lawrence,Risa Ueno,Amit Sharma,Javier Gonzalez,Niranjani Prasad*

Main category: cs.LG

TL;DR: 本文提出了一种名为双重反事实一致性（DCC）的轻量级推理时方法，用于在无需标记数据的情况下衡量和提升大型语言模型（LLMs）的因果推理能力，并展示了其在提高推理任务性能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理基准上表现出色，但在面对反事实问题时表现脆弱，这表明其因果推理能力存在弱点。尽管现有研究表明标记的反事实任务可作为LLM因果推理的有用基准，但生成覆盖庞大潜在反事实空间的此类数据受到限制。

Method: 本文提出了“双重反事实一致性（DCC）”，这是一种轻量级的推理时方法，用于衡量和引导LLM的因果推理能力，无需标记反事实数据。DCC通过验证模型执行因果干预和反事实预测的能力来评估其因果推理。

Result: 通过使用DCC，作者评估了各种领先LLM在一系列推理任务和干预措施中的因果推理能力。此外，DCC被证明是一种有效的免训练测试时拒绝采样标准，并且可以跨多个模型家族直接提高推理任务的性能。

Conclusion: DCC提供了一种有效且数据高效的方法来衡量和提升LLM的因果推理能力，解决了标记反事实数据难以大规模生成的问题。

Abstract: Despite their strong performance on reasoning benchmarks, large language models (LLMs) have proven brittle when presented with counterfactual questions, suggesting weaknesses in their causal reasoning ability. While recent work has demonstrated that labeled counterfactual tasks can be useful benchmarks of LLMs' causal reasoning, producing such data at the scale required to cover the vast potential space of counterfactuals is limited. In this work, we introduce double counterfactual consistency (DCC), a lightweight inference-time method for measuring and guiding the ability of LLMs to reason causally. Without requiring labeled counterfactual data, DCC verifies a model's ability to execute two important elements of causal reasoning: causal intervention and counterfactual prediction. Using DCC, we evaluate the causal reasoning abilities of various leading LLMs across a range of reasoning tasks and interventions. Moreover, we demonstrate the effectiveness of DCC as a training-free test-time rejection sampling criterion and show that it can directly improve performance on reasoning tasks across multiple model families.

</details>


### [158] [Quantifying LLM Attention-Head Stability: Implications for Circuit Universality](https://arxiv.org/abs/2602.16740)
*Karan Bali,Jack Stanley,Praneet Suresh,Danilo Bzdok*

Main category: cs.LG

TL;DR: 本研究系统地探究了在不同初始化训练运行中，Transformer语言模型中注意力头学习表征的稳定性。研究发现，中间层头部最不稳定但最具代表性，深度模型中的中层分歧更强，更深层的不稳定头部功能更重要，应用权重衰减优化可显著提高注意力头的稳定性，而残差流相对稳定。这些发现强调了电路的跨实例鲁棒性对可扩展监督的重要性。


<details>
  <summary>Details</summary>
Motivation: 在机械可解释性中，Transformer“电路”的稳定性尚未在同一深度学习架构的不同实例中进行充分测试。这种不稳定性可能限制了人们对电路普遍性的信心，尤其是在安全关键型应用中，因此有必要系统地研究这种稳定性。

Method: 本研究系统地在不同尺寸的复杂Transformer语言模型中，研究了跨重新拟合的稳定性。通过逐层量化注意力头在独立初始化的训练运行中学习表示的相似性来完成。

Result: 1. 中间层头部最不稳定但最具代表性。2. 更深层的模型表现出更强的中层分歧。3. 更深层的不稳定头部比同层中的其他头部在功能上更重要。4. 应用权重衰减优化可以显著提高随机模型初始化下注意力头的稳定性。5. 残差流相对稳定。

Conclusion: 本研究的发现确立了电路的跨实例鲁棒性是可扩展监督的一个基本但未被充分认识的先决条件，为人工智能系统的白盒可监控性描绘了轮廓。

Abstract: In mechanistic interpretability, recent work scrutinizes transformer "circuits" - sparse, mono or multi layer sub computations, that may reflect human understandable functions. Yet, these network circuits are rarely acid-tested for their stability across different instances of the same deep learning architecture. Without this, it remains unclear whether reported circuits emerge universally across labs or turn out to be idiosyncratic to a particular estimation instance, potentially limiting confidence in safety-critical settings. Here, we systematically study stability across-refits in increasingly complex transformer language models of various sizes. We quantify, layer by layer, how similarly attention heads learn representations across independently initialized training runs. Our rigorous experiments show that (1) middle-layer heads are the least stable yet the most representationally distinct; (2) deeper models exhibit stronger mid-depth divergence; (3) unstable heads in deeper layers become more functionally important than their peers from the same layer; (4) applying weight decay optimization substantially improves attention-head stability across random model initializations; and (5) the residual stream is comparatively stable. Our findings establish the cross-instance robustness of circuits as an essential yet underappreciated prerequisite for scalable oversight, drawing contours around possible white-box monitorability of AI systems.

</details>


### [159] [DeepVision-103K: A Visually Diverse, Broad-Coverage, and Verifiable Mathematical Dataset for Multimodal Reasoning](https://arxiv.org/abs/2602.16742)
*Haoxiang Sun,Lizhen Xu,Bing Zhao,Wotao Yin,Wei Wang,Boyu Yang,Rui Wang,Hu Wei*

Main category: cs.LG

TL;DR: 本文介绍了DeepVision-103K数据集，用于可验证奖励强化学习（RLVR）训练，以增强大型多模态模型（LMMs）的视觉反思和推理能力，解决了现有数据集多样性不足的问题。在DeepVision上训练的模型在多模态数学和通用推理任务中表现出强大的性能和增强的能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要通过小规模手动构建或现有资源重组获得，限制了数据多样性和覆盖范围，从而制约了模型性能的进一步提升。

Method: 引入了DeepVision-103K数据集，用于可验证奖励强化学习（RLVR）训练。该数据集涵盖了多样化的K12数学主题、广泛的知识点和丰富的视觉元素。

Result: 在DeepVision上训练的模型在多模态数学基准测试中表现出色，并能有效泛化到一般多模态推理任务。进一步分析表明，训练后的模型视觉感知、反思和推理能力得到增强。

Conclusion: DeepVision数据集有效提升了大型多模态模型的视觉感知、反思和推理能力，推动了多模态推理的进步。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has been shown effective in enhancing the visual reflection and reasoning capabilities of Large Multimodal Models (LMMs). However, existing datasets are predominantly derived from either small-scale manual construction or recombination of prior resources, which limits data diversity and coverage, thereby constraining further gains in model performance. To this end, we introduce \textbf{DeepVision-103K}, a comprehensive dataset for RLVR training that covers diverse K12 mathematical topics, extensive knowledge points, and rich visual elements. Models trained on DeepVision achieve strong performance on multimodal mathematical benchmarks, and generalize effectively to general multimodal reasoning tasks. Further analysis reveals enhanced visual perception, reflection and reasoning capabilities in trained models, validating DeepVision's effectiveness for advancing multimodal reasoning. Data: \href{ }{this url}.

</details>


### [160] [Training Large Reasoning Models Efficiently via Progressive Thought Encoding](https://arxiv.org/abs/2602.16839)
*Zeliang Zhang,Xiaodong Liu,Hao Cheng,Hao Sun,Chenliang Xu,Jianfeng Gao*

Main category: cs.LG

TL;DR: 该论文提出了一种名为“渐进式思维编码”（Progressive Thought Encoding）的参数高效微调方法，使大型推理模型（LRMs）能够在固定大小的缓存下有效推理，从而显著提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在复杂问题上表现出色，但面临效率瓶颈：强化学习（RL）训练需要长时间的展开以获取基于结果的奖励，其中自回归解码占据了时间和内存。滑动窗口缓存策略可以限制内存，但会破坏长上下文推理并降低性能。

Method: 渐进式思维编码（Progressive Thought Encoding）是一种参数高效的微调方法。它通过将中间推理逐步编码为固定大小的向量表示，消除了通过完整缓存展开进行反向传播的需要，从而减少了内存使用，并在推理期间保持恒定内存。

Result: 在Qwen2.5-3B-Instruct、Qwen2.5-7B-Instruct和DeepSeek-R1-Distill-Llama-8B三种模型上，通过六个广泛使用的数学基准测试，实验结果显示：与基于LoRA的微调相比，平均提升了19.3%；与未经微调的LRM相比，平均提升了29.9%。在相同的严格缓存预算下，AIME2024/2025的准确率最高提升了23.4%。

Conclusion: 渐进式思维编码不仅提高了推理准确性，而且在实际内存限制下，显著提高了LRM的强化学习训练效率和可扩展性。

Abstract: Large reasoning models (LRMs) excel on complex problems but face a critical barrier to efficiency: reinforcement learning (RL) training requires long rollouts for outcome-based rewards, where autoregressive decoding dominates time and memory usage. While sliding-window cache strategies can bound memory, they disrupt long-context reasoning and degrade performance. We introduce Progressive Thought Encoding, a parameter-efficient fine-tuning method that enables LRMs to reason effectively under fixed-size caches. By progressively encoding intermediate reasoning into fixed-size vector representations, our approach eliminates the need to backpropagate through full-cache rollouts, thereby reducing memory usage, while maintaining constant memory during inference. Experiments on three models, including Qwen2.5-3B-Instruct, Qwen2.5-7B-Instruct, and DeepSeek-R1-Distill-Llama-8B, on six widely used challenging mathematical benchmarks show consistent gains: our method achieves +19.3% improvement over LoRA-based fine-tuning and +29.9% over LRMs without fine-tuning on average, with up to +23.4 accuracy improvement on AIME2024/2025 under the same tight cache budgets. These results demonstrate that Progressive Thought Encoding not only improves reasoning accuracy but also makes RL training of LRMs substantially more efficient and scalable under real-world memory constraints.

</details>


### [161] [PETS: A Principled Framework Towards Optimal Trajectory Allocation for Efficient Test-Time Self-Consistency](https://arxiv.org/abs/2602.16745)
*Zhangyi Liu,Huaizhi Qu,Xiaowei Yin,He Sun,Yanjun Han,Tianlong Chen,Zhun Deng*

Main category: cs.LG

TL;DR: PETS提出了一种原则性且高效的方法，通过引入自洽率和连接众包理论，解决了有限预算下测试时自洽性的挑战，显著提高了采样效率并超越了统一分配。


<details>
  <summary>Details</summary>
Motivation: 测试时尺度缩放可以通过聚合随机推理轨迹来提高模型性能，但在有限预算下实现样本高效的测试时自洽性仍然是一个开放性挑战。

Method: 引入PETS，通过优化框架对轨迹分配进行研究。定义自洽率作为与无限预算多数投票的一致性衡量标准。离线场景下，将轨迹分配与众包联系起来，利用现有理论提出基于多数投票的分配算法。在线场景下，提出一种新方法，根据问题难度调整预算，同时保留理论保证和计算效率。

Result: PETS始终优于统一分配。在GPQA上，PETS在两种设置下均实现了完美的自洽性，并且相对于统一分配，采样预算在离线情况下减少了高达75%，在线情况下减少了55%。

Conclusion: PETS为测试时间自洽性提供了一种原则性且高效的方法，显著提高了模型性能和采样效率。

Abstract: Test-time scaling can improve model performance by aggregating stochastic reasoning trajectories. However, achieving sample-efficient test-time self-consistency under a limited budget remains an open challenge. We introduce PETS (Principled and Efficient Test-TimeSelf-Consistency), which initiates a principled study of trajectory allocation through an optimization framework. Central to our approach is the self-consistency rate, a new measure defined as agreement with the infinite-budget majority vote. This formulation makes sample-efficient test-time allocation theoretically grounded and amenable to rigorous analysis. We study both offline and online settings. In the offline regime, where all questions are known in advance, we connect trajectory allocation to crowdsourcing, a classic and well-developed area, by modeling reasoning traces as workers. This perspective allows us to leverage rich existing theory, yielding theoretical guarantees and an efficient majority-voting-based allocation algorithm. In the online streaming regime, where questions arrive sequentially and allocations must be made on the fly, we propose a novel method inspired by the offline framework. Our approach adapts budgets to question difficulty while preserving strong theoretical guarantees and computational efficiency. Experiments show that PETS consistently outperforms uniform allocation. On GPQA, PETS achieves perfect self-consistency in both settings while reducing the sampling budget by up to 75% (offline) and 55% (online) relative to uniform allocation. Code is available at .

</details>


### [162] [Low-Dimensional and Transversely Curved Optimization Dynamics in Grokking](https://arxiv.org/abs/2602.16746)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 该研究通过几何分析揭示了在小型算法任务中，Transformer模型从记忆到泛化的延迟过渡（即Grokking现象）的机制。Grokking反映了模型逃离了一个以低维限制和横向曲率累积为特征的亚稳态区域。


<details>
  <summary>Details</summary>
Motivation: Grokking——即在小型算法任务中，模型从记忆到泛化之间的延迟转换——仍然知之甚少，本研究旨在通过几何分析深入理解其内在机制。

Method: 研究方法包括对在模运算任务上训练的Transformer模型的优化动态进行几何分析，利用主成分分析（PCA）揭示注意力权重轨迹在低维执行子空间内的演变。通过测量连续梯度步长的非交换性（换向子缺陷）并将其投影到学习到的子空间来探究损失景观几何。此外，还进行了因果干预实验以验证关键发现。

Result: 研究发现，模型训练主要在一个低维执行子空间内进行，其中一个主成分捕获了68-83%的轨迹方差。曲率在正交于执行子空间的方向上急剧增长，而轨迹仍 largely 局限于该子空间。重要的是，曲率增长始终早于泛化，且其提前时间与Grokking时间尺度呈幂律关系。因果干预实验表明，沿学习子空间运动对于Grokking是必要的，而人为增加曲率不足以引发Grokking。正交梯度流是必要的但不足以实现Grokking：抑制它会阻止泛化，而人为提升曲率缺陷没有效果。这些发现在一系列学习率、不同定性缓慢机制和三个随机种子下均能复现。

Conclusion: 这些结果支持一种几何解释，即Grokking反映了模型逃离了一个以低维限制和横向曲率累积为特征的亚稳态区域。

Abstract: Grokking -- the delayed transition from memorization to generalization in small algorithmic tasks -- remains poorly understood. We present a geometric analysis of optimization dynamics in transformers trained on modular arithmetic. PCA of attention weight trajectories reveals that training evolves predominantly within a low-dimensional execution subspace, with a single principal component capturing 68-83% of trajectory variance. To probe loss-landscape geometry, we measure commutator defects -- the non-commutativity of successive gradient steps -- and project them onto this learned subspace. We find that curvature grows sharply in directions orthogonal to the execution subspace while the trajectory remains largely confined to it. Importantly, curvature growth consistently precedes generalization across learning rates and hyperparameter regimes, with the lead time obeying a power law in the grokking timescale. Causal intervention experiments show that motion along the learned subspace is necessary for grokking, while artificially increasing curvature is insufficient. Together, these results support a geometric account in which grokking reflects escape from a metastable regime characterized by low-dimensional confinement and transverse curvature accumulation. All findings replicate across this learning-rate range, a qualitatively different slow regime (lr=5e-5, wd=0.1, 3 layers), and three random seeds, though alignment dynamics differ quantitatively between regimes. Causal intervention experiments establish that orthogonal gradient flow is necessary but not sufficient for grokking: suppressing it prevents generalization with a monotonic dose-response across four operations, while artificially boosting curvature defects has no effect.

</details>


### [163] [LiveClin: A Live Clinical Benchmark without Leakage](https://arxiv.org/abs/2602.16747)
*Xidong Wang,Shuqi Guo,Yue Shen,Junying Chen,Jian Wang,Jinjie Gu,Ping Zhang,Lei Liu,Benyou Wang*

Main category: cs.LG

TL;DR: LiveClin是一个实时、抗污染、最新的医学大模型基准测试，它从真实的病例中构建，揭示了医学大模型与人类医生相比的低性能（最高准确率仅35.7%）。


<details>
  <summary>Details</summary>
Motivation: 数据污染和知识过时严重损害了医学大模型评估的可靠性，导致在静态基准测试中得分虚高。

Method: 本文引入了LiveClin，一个实时的基准测试，通过当代、同行评审的病例报告构建，每半年更新一次，旨在模拟真实的临床实践。它使用一个经过验证的AI-人类工作流，涉及239名医生，将真实的病例转化为涵盖整个临床路径的复杂、多模态评估场景。

Result: 对26个模型在LiveClin上的评估显示，在这些真实世界场景中，表现最好的模型病例准确率仅为35.7%，表明其难度巨大。人类专家（主任医师和主治医师）的表现优于大多数模型。该基准目前包含1,407个病例报告和6,605个问题。

Conclusion: LiveClin提供了一个持续演进、临床实用的框架，以指导医学大模型的发展，缩小与人类的差距，实现更高的可靠性和实际应用价值。

Abstract: The reliability of medical LLM evaluation is critically undermined by data contamination and knowledge obsolescence, leading to inflated scores on static benchmarks. To address these challenges, we introduce LiveClin, a live benchmark designed for approximating real-world clinical practice. Built from contemporary, peer-reviewed case reports and updated biannually, LiveClin ensures clinical currency and resists data contamination. Using a verified AI-human workflow involving 239 physicians, we transform authentic patient cases into complex, multimodal evaluation scenarios that span the entire clinical pathway. The benchmark currently comprises 1,407 case reports and 6,605 questions. Our evaluation of 26 models on LiveClin reveals the profound difficulty of these real-world scenarios, with the top-performing model achieving a Case Accuracy of just 35.7%. In benchmarking against human experts, Chief Physicians achieved the highest accuracy, followed closely by Attending Physicians, with both surpassing most models. LiveClin thus provides a continuously evolving, clinically grounded framework to guide the development of medical LLMs towards closing this gap and achieving greater reliability and real-world utility. Our data and code are publicly available at .

</details>


### [164] [Attending to Routers Aids Indoor Wireless Localization](https://arxiv.org/abs/2602.16762)
*Ayush Roy,Tahsin Fuad Hassan,Roshan Ayyalasomayajula,Vishnu Suresh Lokhande*

Main category: cs.LG

TL;DR: 本论文引入了“路由器注意力”的概念，通过对不同路由器在聚合信息时进行差异化加权，显著提升了基于Wi-Fi信号的机器学习无线定位的准确性，在公开数据集中比基准架构提高了30%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于机器学习的Wi-Fi无线定位算法未能恰当地加权来自不同路由器的信息，导致收敛次优和精度降低，难以在不同环境中实现突破性性能。

Method: 受传统加权三角测量方法的启发，论文引入了“路由器注意力”的概念，通过将注意力层整合到标准的机器学习定位架构中，在聚合多个路由器的信息进行三角测量时，差异化地加权每个路由器的贡献。

Result: 强调每个路由器的相关性可以显著提高整体性能。通过在开源数据集上的评估，证明“路由器注意力”在准确性上优于基准架构30%以上。

Conclusion: 通过引入“路由器注意力”机制，智能地加权不同路由器的贡献，可以显著提高基于Wi-Fi信号的机器学习无线定位的准确性和性能。

Abstract: Modern machine learning-based wireless localization using Wi-Fi signals continues to face significant challenges in achieving groundbreaking performance across diverse environments. A major limitation is that most existing algorithms do not appropriately weight the information from different routers during aggregation, resulting in suboptimal convergence and reduced accuracy. Motivated by traditional weighted triangulation methods, this paper introduces the concept of attention to routers, ensuring that each router's contribution is weighted differently when aggregating information from multiple routers for triangulation. We demonstrate, by incorporating attention layers into a standard machine learning localization architecture, that emphasizing the relevance of each router can substantially improve overall performance. We have also shown through evaluation over the open-sourced datasets and demonstrate that Attention to Routers outperforms the benchmark architecture by over 30% in accuracy.

</details>


### [165] [Sign Lock-In: Randomly Initialized Weight Signs Persist and Bottleneck Sub-Bit Model Compression](https://arxiv.org/abs/2602.17063)
*Akira Sakai,Yuma Ichikawa*

Main category: cs.LG

TL;DR: 本研究发现模型权重符号的随机性主要继承自初始化，并提出通过符号锁定理论、基于间隙的初始化和外漂正则化器，将亚比特模型压缩中的符号翻转率显著降低至$10^{-3}$，仅带来极小的困惑度增加。


<details>
  <summary>Details</summary>
Motivation: 在亚比特模型压缩中，当幅度被积极压缩时，符号位成为固定成本的瓶颈。研究发现，学习到的符号矩阵抵抗低秩近似，并且在谱上与i.i.d. Rademacher基线无法区分，但大多数权重保留了其初始化时的符号。

Method: 通过符号锁定理论和SGD噪声下符号翻转的停时分析来形式化权重符号行为。在此机制基础上，引入了基于间隙的初始化（gap-based initialization）和轻量级外漂正则化器（outward-drift regularizer）。

Result: 大多数权重保留了其初始化时的符号；翻转主要通过罕见的接近零的边界交叉发生，表明符号模式的随机性主要来源于初始化。在有界更新和罕见地重新进入零附近小区域的条件下，有效符号翻转的数量呈现几何尾部。通过所提出的方法，有效翻转率降低至约$10^{-3}$，而困惑度仅增加约一个点。

Conclusion: 该研究通过提出的基于间隙的初始化和轻量级外漂正则化器，有效地将有效符号翻转率降低至约$10^{-3}$，同时仅增加约1个困惑度，为亚比特模型压缩中的符号位瓶颈问题提供了解决方案。

Abstract: Sub-bit model compression seeks storage below one bit per weight; as magnitudes are aggressively compressed, the sign bit becomes a fixed-cost bottleneck. Across Transformers, CNNs, and MLPs, learned sign matrices resist low-rank approximation and are spectrally indistinguishable from an i.i.d. Rademacher baseline. Despite this apparent randomness, most weights retain their initialization signs; flips primarily occur via rare near-zero boundary crossings, suggesting that sign-pattern randomness is largely inherited from initialization. We formalize this behavior with sign lock-in theory, a stopping-time analysis of sign flips under SGD noise. Under bounded updates and a rare re-entry condition into a small neighborhood around zero, the number of effective sign flips exhibits a geometric tail. Building on this mechanism, we introduce a gap-based initialization and a lightweight outward-drift regularizer, reducing the effective flip rate to approximately $10^{-3}$ with only about a one-point increase in perplexity.

</details>


### [166] [Unified Latents (UL): How to train your latents](https://arxiv.org/abs/2602.17270)
*Jonathan Heek,Emiel Hoogeboom,Thomas Mensink,Tim Salimans*

Main category: cs.LG

TL;DR: Unified Latents (UL) 是一种框架，通过扩散先验和扩散解码器学习潜在表示，实现了具有竞争力的 FID、高 PSNR 和最先进的 FVD，同时需要更少的训练 FLOPs。


<details>
  <summary>Details</summary>
Motivation: 学习由扩散先验联合正则化并由扩散模型解码的潜在表示，以获得一个提供潜在比特率紧密上限的简单训练目标。

Method: 该方法名为 Unified Latents (UL)，它通过将编码器的输出噪声与先验的最小噪声水平相关联，从而获得一个简单的训练目标，该目标提供了潜在比特率的紧密上限。

Result: 在 ImageNet-512 上，实现了 1.4 的 FID 和高重建质量（PSNR），所需训练 FLOPs 少于在 Stable Diffusion 潜在空间上训练的模型。在 Kinetics-600 上，创下了 1.3 的新 FVD 最佳性能。

Conclusion: Unified Latents (UL) 框架能有效学习高质量的潜在表示，在图像和视频生成任务中表现出强大的性能（具有竞争力的 FID、高 PSNR、SOTA FVD），同时计算效率高。

Abstract: We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model. By linking the encoder's output noise to the prior's minimum noise level, we obtain a simple training objective that provides a tight upper bound on the latent bitrate. On ImageNet-512, our approach achieves competitive FID of 1.4, with high reconstruction quality (PSNR) while requiring fewer training FLOPs than models trained on Stable Diffusion latents. On Kinetics-600, we set a new state-of-the-art FVD of 1.3.

</details>


### [167] [HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind](https://arxiv.org/abs/2602.16826)
*Nigel Doering,Rahath Malladi,Arshia Sangwan,David Danks,Tauhidur Rahman*

Main category: cs.LG

TL;DR: HiVAE是一种分层变分架构，可将ToM推理扩展到现实时空领域，在大型导航任务中取得了显著性能提升，但其潜在表示缺乏对实际心理状态的明确基础。


<details>
  <summary>Details</summary>
Motivation: 现有ToM方法主要集中在小型、人类可理解的网格世界空间中，难以扩展到现实时空领域。

Method: 引入了HiVAE，一种受人类认知中的信念-欲望-意图结构启发的三级分层变分架构，用于将ToM推理扩展到现实时空领域。

Result: HiVAE在3,185个节点的校园导航任务中取得了显著的性能提升。

Conclusion: 尽管HiVAE的分层结构改善了预测，但学习到的潜在表示缺乏与实际心理状态的明确关联。作者提出了自监督对齐策略，并寻求社区对基础化方法的反馈。

Abstract: Theory of mind (ToM) enables AI systems to infer agents' hidden goals and mental states, but existing approaches focus mainly on small human understandable gridworld spaces. We introduce HiVAE, a hierarchical variational architecture that scales ToM reasoning to realistic spatiotemporal domains. Inspired by the belief-desire-intention structure of human cognition, our three-level VAE hierarchy achieves substantial performance improvements on a 3,185-node campus navigation task. However, we identify a critical limitation: while our hierarchical structure improves prediction, learned latent representations lack explicit grounding to actual mental states. We propose self-supervised alignment strategies and present this work to solicit community feedback on grounding approaches.

</details>


### [168] [VAM: Verbalized Action Masking for Controllable Exploration in RL Post-Training -- A Chess Case Study](https://arxiv.org/abs/2602.16833)
*Zhicheng Zhang,Ziyan Wang,Yali Du,Fei Fang*

Main category: cs.LG

TL;DR: 提出了一种名为VAM的机制，通过提示词中的言语化动作掩码和迭代剪枝来改善LLM强化学习后训练中的探索效率和性能，并在国际象棋中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 强化学习对大型语言模型（LLM）的后训练中，探索仍然是一个关键瓶颈，稀疏的反馈和巨大的动作空间可能导致模型过早陷入重复行为。

Method: 提出言语化动作掩码（VAM），通过在提示中言语化动作掩码并强制模型从掩码集合中输出动作。在此基础上，引入迭代动作空间剪枝：如果未采样到目标动作，则从掩码中移除已采样的有效动作，并在缩减的候选集中重新采样，重复此过程直到采样到目标或预算耗尽。在国际象棋中，VAM在两种训练模式下进行评估：一种是通过与引擎对手对弈生成状态的引擎对弈模式，另一种是使用带有验证器得分的固定位置数据集进行训练的固定数据集模式。

Result: 在国际象棋谜题和以平均车兵损失（ACPL）衡量的完整对局中，VAM在学习效率和最终性能上都优于强大的基线。

Conclusion: 言语化掩码是LLM强化学习后训练中实现可控探索的实用机制。

Abstract: Exploration remains a key bottleneck for reinforcement learning (RL) post-training of large language models (LLMs), where sparse feedback and large action spaces can lead to premature collapse into repetitive behaviors. We propose Verbalized Action Masking (VAM), which verbalizes an action mask in the prompt and enforces that the model outputs an action from the masked set. Building on this interface, we introduce iterative action-space pruning: if the target action is not sampled, we remove valid sampled actions from the mask and resample under the reduced candidate set, repeating until the target is sampled or a fixed budget is exhausted. We study VAM in chess and evaluate it under two training regimes: an engine-play regime that generates states via play against an engine opponent and a fixed-dataset regime that trains from a fixed dataset of positions with verifier scores. Across held-out chess puzzles and full-game play measured by average centipawn loss (ACPL), VAM improves learning efficiency and final performance over strong baselines, highlighting verbalized masking as a practical mechanism for controllable exploration in LLM RL post-training.

</details>


### [169] [Position: Why a Dynamical Systems Perspective is Needed to Advance Time Series Modeling](https://arxiv.org/abs/2602.16864)
*Daniel Durstewitz,Christoph Jürgen Hemmer,Florian Hess,Charlotte Ricarda Doll,Lukas Eisenmann*

Main category: cs.LG

TL;DR: 本文主张将时间序列(TS)建模从传统方法转向动力系统(DS)视角，并通过动力系统重构(DSR)方法，以实现更优的预测、理解长期统计数据以及提供机制洞察，从而推动TS建模的发展。


<details>
  <summary>Details</summary>
Motivation: 时间序列(TS)建模领域虽然取得了进展，但其真实进步程度尚不明确。为了将TS预测和分析提升到新水平，本文认为需要引入动力系统(DS)视角。观察到的TS几乎都源于某种潜在的DS，获取其控制方程将带来理论上最优的预测。

Method: 本文将回顾动力系统理论和动力系统重构(DSR)中的一些核心概念、方法、度量和模型。DSR是一类机器学习/人工智能方法，旨在从数据中推断出潜在动力系统的替代模型。通过讨论这些领域的见解如何推动TS建模，实现更好的预测和更低的计算与内存消耗。

Result: 基于动力系统原理的模型除了短期预测外，还能预测观测系统的长期统计数据，这在许多实际场景中可能更为相关。动力系统理论还提供了领域无关的理论洞察，揭示了TS生成机制，从而有助于了解任何TS模型的性能上限、在未知情景（如临界点）下的泛化能力或潜在的控制策略。这些见解能够以关键方式推进TS建模，实现更好的预测，并显著降低计算和内存占用。

Conclusion: 本文最后将提出将动力系统重构(DSR)的见解转化为时间序列(TS)建模的具体建议。

Abstract: Time series (TS) modeling has come a long way from early statistical, mainly linear, approaches to the current trend in TS foundation models. With a lot of hype and industrial demand in this field, it is not always clear how much progress there really is. To advance TS forecasting and analysis to the next level, here we argue that the field needs a dynamical systems (DS) perspective. TS of observations from natural or engineered systems almost always originate from some underlying DS, and arguably access to its governing equations would yield theoretically optimal forecasts. This is the promise of DS reconstruction (DSR), a class of ML/AI approaches that aim to infer surrogate models of the underlying DS from data. But models based on DS principles offer other profound advantages: Beyond short-term forecasts, they enable to predict the long-term statistics of an observed system, which in many practical scenarios may be the more relevant quantities. DS theory furthermore provides domain-independent theoretical insight into mechanisms underlying TS generation, and thereby will inform us, e.g., about upper bounds on performance of any TS model, generalization into unseen regimes as in tipping points, or potential control strategies. After reviewing some of the central concepts, methods, measures, and models in DS theory and DSR, we will discuss how insights from this field can advance TS modeling in crucial ways, enabling better forecasting with much lower computational and memory footprints. We conclude with a number of specific suggestions for translating insights from DSR into TS modeling.

</details>


### [170] [The Anxiety of Influence: Bloom Filters in Transformer Attention Heads](https://arxiv.org/abs/2602.17526)
*Peter Balogh*

Main category: cs.LG

TL;DR: 一些Transformer注意力头在早期层（0-1）中充当成员测试器，形成一个多分辨率系统。这些头以不同的策略（包括高精度过滤器和Bloom滤波器）检测上下文中的重复token，并通过混淆控制和消融实验验证了其功能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer模型中某些注意力头的功能，特别是它们是否作为成员测试器，以及它们如何实现这一功能。

Method: 识别并分析了四种语言模型（GPT-2 small, medium, large; Pythia-160M）中的注意力头。通过评估其错误率和容量曲线来区分不同的成员测试策略（如高精度过滤器、经典Bloom滤波器）。使用混淆控制对最初识别的头进行重新分类，并通过消融实验探究其对token处理的贡献。

Result: 在早期层（0-1）中发现了三个真正的成员测试头，它们形成一个多分辨率系统。其中一些头表现出高精度成员过滤功能（错误率0-4%），另一些则表现出经典的Bloom滤波器容量曲线（R^2 = 1.0，容量约5比特）。这些头对任何重复token类型都具有广泛的泛化能力，比仅针对重复token的头泛化能力高43%。消融实验表明它们有助于重复和新颖token的处理。L3H0头在混淆控制后被重新分类为通用前缀注意力头。

Conclusion: Transformer模型中的早期注意力层包含专门的成员测试头，它们以多种策略检测token重复，并对模型的token处理（包括重复和新颖token）具有重要贡献。经过严格混淆控制验证的幸存成员测试头，证实了这种机制的存在及其重要性。

Abstract: Some transformer attention heads appear to function as membership testers, dedicating themselves to answering the question "has this token appeared before in the context?" We identify these heads across four language models (GPT-2 small, medium, and large; Pythia-160M) and show that they form a spectrum of membership-testing strategies. Two heads (L0H1 and L0H5 in GPT-2 small) function as high-precision membership filters with false positive rates of 0-4\% even at 180 unique context tokens -- well above the $d_\text{head} = 64$ bit capacity of a classical Bloom filter. A third head (L1H11) shows the classic Bloom filter capacity curve: its false positive rate follows the theoretical formula $p \approx (1 - e^{-kn/m})^k$ with $R^2 = 1.0$ and fitted capacity $m \approx 5$ bits, saturating by $n \approx 20$ unique tokens. A fourth head initially identified as a Bloom filter (L3H0) was reclassified as a general prefix-attention head after confound controls revealed its apparent capacity curve was a sequence-length artifact. Together, the three genuine membership-testing heads form a multi-resolution system concentrated in early layers (0-1), taxonomically distinct from induction and previous-token heads, with false positive rates that decay monotonically with embedding distance -- consistent with distance-sensitive Bloom filters. These heads generalize broadly: they respond to any repeated token type, not just repeated names, with 43\% higher generalization than duplicate-token-only heads. Ablation reveals these heads contribute to both repeated and novel token processing, indicating that membership testing coexists with broader computational roles. The reclassification of L3H0 through confound controls strengthens rather than weakens the case: the surviving heads withstand the scrutiny that eliminated a false positive in our own analysis.

</details>


### [171] [Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting](https://arxiv.org/abs/2602.17645)
*Xiaohan Zhao,Zhaoyi Li,Yaxin Luo,Jiacheng Cui,Zhiqiang Shen*

Main category: cs.LG

TL;DR: 该论文提出M-Attack-V2，是对M-Attack的升级版，通过多裁剪对齐（MCA）、辅助目标对齐（ATA）以及结合补丁动量和补丁大小集成（PE+）来解决梯度不稳定性问题，从而显著提高对LVLM的黑盒对抗性攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 由于缺少梯度和复杂的多模态边界，对大型视觉语言模型（LVLMs）进行黑盒对抗性攻击具有挑战性。现有的M-Attack等基于迁移的先进方法，通过源图像和目标图像之间的局部裁剪级匹配表现良好，但存在高方差、近乎正交的梯度，违反了连贯的局部对齐并破坏了优化稳定性。这归因于ViT的翻译敏感性（导致尖峰状梯度）和源裁剪与目标裁剪之间的结构不对称性。

Method: 该论文将局部匹配重新表述为源变换和目标语义上的非对称期望，并对M-Attack进行了梯度去噪升级，形成了M-Attack-V2。具体方法包括：1. 多裁剪对齐（MCA）：在源侧，通过平均每次迭代中多个独立采样的局部视图的梯度来减少方差。2. 辅助目标对齐（ATA）：在目标侧，用语义相关分布中的小型辅助集取代激进的目标增强，生成更平滑、低方差的目标流形。3. 补丁动量：将动量重新解释为回放历史裁剪梯度。4. 补丁大小集成（PE+）：结合补丁动量和改进的补丁大小集成，增强可迁移方向。

Result: M-Attack-V2显著提高了对前沿LVLM的基于迁移的黑盒攻击成功率：Claude-4.0的成功率从8%提高到30%，Gemini-2.5-Pro从83%提高到97%，GPT-5从98%提高到100%，性能优于先前的黑盒LVLM攻击。

Conclusion: M-Attack-V2是M-Attack的一个简单、模块化增强，它通过稳定优化和改善梯度可迁移性，有效解决了LVLM黑盒对抗性攻击的挑战，从而显著提高了攻击成功率。

Abstract: Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we find this induces high-variance, nearly orthogonal gradients across iterations, violating coherent local alignment and destabilizing optimization. We attribute this to (i) ViT translation sensitivity that yields spike-like gradients and (ii) structural asymmetry between source and target crops. We reformulate local matching as an asymmetric expectation over source transformations and target semantics, and build a gradient-denoising upgrade to M-Attack. On the source side, Multi-Crop Alignment (MCA) averages gradients from multiple independently sampled local views per iteration to reduce variance. On the target side, Auxiliary Target Alignment (ATA) replaces aggressive target augmentation with a small auxiliary set from a semantically correlated distribution, producing a smoother, lower-variance target manifold. We further reinterpret momentum as Patch Momentum, replaying historical crop gradients; combined with a refined patch-size ensemble (PE+), this strengthens transferable directions. Together these modules form M-Attack-V2, a simple, modular enhancement over M-Attack that substantially improves transfer-based black-box attacks on frontier LVLMs: boosting success rates on Claude-4.0 from 8% to 30%, Gemini-2.5-Pro from 83% to 97%, and GPT-5 from 98% to 100%, outperforming prior black-box LVLM attacks. Code and data are publicly available at: .

</details>


### [172] [A Unified Framework for Locality in Scalable MARL](https://arxiv.org/abs/2602.16966)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 本文通过提出一种策略依赖的局部性视角和策略诱导互依矩阵的新颖分解，解决了多智能体强化学习（MARL）中维度灾难带来的可伸缩性挑战，从而导出了一个更紧密的指数衰减谱条件，并将其应用于局部块坐标策略改进框架。


<details>
  <summary>Details</summary>
Motivation: 可伸缩的多智能体强化学习（MARL）面临维度灾难的根本挑战。现有解决方案利用基于价值函数指数衰减特性（EDP）的局部性，但现有保证EDP的条件往往过于保守，因为它们基于最坏情况、仅环境的边界，未能捕捉到策略本身的正则化效应。

Method: 本文确立了局部性也可以是策略依赖的现象。其核心贡献是对策略诱导的互依矩阵 $H^\pi$ 进行了一种新颖的分解，将环境对状态的敏感性 ($E^{\mathrm{s}}$) 和对动作的敏感性 ($E^{\mathrm{a}}$) 与策略对状态的敏感性 ($\Pi(\pi)$) 分离开来。利用此框架推导了一个通用的指数衰减谱条件 $ho(E^{\mathrm{s}}+E^{\mathrm{a}}\Pi(\pi)) < 1$。最终，利用该理论分析了一个经过验证的局部块坐标策略改进框架。

Result: 分解揭示了即使在环境强动作耦合的情况下，光滑策略（小的 $\Pi(\pi)$）也能诱导局部性，揭示了基本的局部性-最优性权衡。导出的通用谱条件 $ho(E^{\mathrm{s}}+E^{\mathrm{a}}\Pi(\pi)) < 1$ 比先前的基于范数的条件更为严格。提出了一个经过验证的局部块坐标策略改进框架，其保证直接与该谱半径相关。

Conclusion: 本文提出了一种新的视角，认为MARL中的局部性是一个策略依赖的现象，从而导出了一个更紧密的指数衰减条件，并提供了一个更有效的局部策略改进框架。

Abstract: Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP are often conservative, as they are based on worst-case, environment-only bounds (e.g., supremums over actions) and fail to capture the regularizing effect of the policy itself. In this work, we establish that locality can also be a \emph{policy-dependent} phenomenon. Our central contribution is a novel decomposition of the policy-induced interdependence matrix, $H^\pi$, which decouples the environment's sensitivity to state ($E^{\mathrm{s}}$) and action ($E^{\mathrm{a}}$) from the policy's sensitivity to state ($\Pi(\pi)$). This decomposition reveals that locality can be induced by a smooth policy (small $\Pi(\pi)$) even when the environment is strongly action-coupled, exposing a fundamental locality-optimality tradeoff. We use this framework to derive a general spectral condition $\rho(E^{\mathrm{s}}+E^{\mathrm{a}}\Pi(\pi)) < 1$ for exponential decay, which is strictly tighter than prior norm-based conditions. Finally, we leverage this theory to analyze a provably-sound localized block-coordinate policy improvement framework with guarantees tied directly to this spectral radius.

</details>


### [173] [Early-Warning Signals of Grokking via Loss-Landscape Geometry](https://arxiv.org/abs/2602.16967)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 该研究发现，在Transformer模型中，换向器缺陷（commutator defect）是一个稳健、与架构无关且具有因果关系的早期预警信号，可用于预测延迟泛化（grokking）现象。


<details>
  <summary>Details</summary>
Motivation: 探究“顿悟”（grokking）现象（从记忆到泛化的突然转变）的机制是否超越了模块化算术领域，扩展到其他任务。

Method: 研究了SCAN组合泛化和Dyck-1深度预测这两个序列学习基准。通过在广泛的学习率下观察换向器缺陷，并使用权重空间PCA进行分析。此外，还进行了因果干预实验，通过放大或抑制非交换梯度流来观察其对顿悟的影响。

Result: 在SCAN和Dyck任务中，换向器缺陷在泛化之前明显上升，其提前时间遵循超线性幂律。权重空间PCA显示频谱集中不是普遍先兆，而换向器缺陷是。因果干预表明，放大非交换性可以加速顿悟（SCAN约32%，Dyck约50%），而抑制正交梯度流则会延迟或阻止顿悟。抑制作用在所有任务家族中都延迟或阻止了顿悟，证实了其普遍的必要性。

Conclusion: 换向器缺陷是Transformer模型中延迟泛化（grokking）的一个鲁棒、与架构无关、具有因果关系的早期预警信号。

Abstract: Grokking -- the abrupt transition from memorization to generalization after prolonged training -- has been linked to confinement on low-dimensional execution manifolds in modular arithmetic. Whether this mechanism extends beyond arithmetic remains open. We study two sequence-learning benchmarks: SCAN compositional generalization and Dyck-1 depth prediction. Across both tasks and a wide range of learning rates, the commutator defect -- a curvature measure derived from non-commuting gradient updates -- rises well before generalization, with lead times following a superlinear power law (alpha approximately 1.18 for SCAN, approximately 1.13 for Dyck), consistent with prior results on modular arithmetic. Weight-space PCA reveals that spectral concentration is not a universal precursor; the commutator defect is. Causal interventions demonstrate a mechanistic role: amplifying non-commutativity accelerates grokking (roughly 32% on SCAN, roughly 50% on Dyck), while suppressing orthogonal gradient flow delays or prevents it. The three task families form a spectrum of causal sensitivity -- modular arithmetic is rigid, Dyck is responsive, SCAN is intermediate -- yet suppression delays or prevents grokking in all cases, establishing necessity as a universal finding. These results identify the commutator defect as a robust, architecture-agnostic, causally implicated early-warning signal for delayed generalization in transformers.

</details>


### [174] [Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods](https://arxiv.org/abs/2602.17027)
*Paimon Goulart,Jordan Steinhauser,Dawon Ahn,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 本文提出了一种AI增强管道，利用上下文学习（ICL）和改进的张量分解模型，简化了行为神经科学中的科学发现过程。该管道在数据准备和模式解释方面表现出色，并得到了领域专家的验证。


<details>
  <summary>Details</summary>
Motivation: 科学发现流程通常复杂、僵化且耗时，从数据准备到结果分析和解释。领域专家将大量时间花费在调试僵硬的管道或手动标注数据上，而非解释和理解发现。因此，需要利用AI改进这些流程，以加速洞察力的产生，尤其是在行为神经科学（例如，恐惧泛化和PTSD）等领域。

Method: 1. 开发了一个AI增强管道。
2. 采用“上下文学习”（ICL）作为接口，使领域专家无需AI模型训练和微调即可自动化部分管道。
3. 引入了对张量分解模型的新颖AI增强，以实现从异构数据中更无缝的模式发现。
4. 将该管道应用于行为神经科学领域，研究小鼠的恐惧泛化。
5. 通过实验评估了所提出的管道，并与该领域的标准实践以及不属于ICL范畴的合理机器学习基线进行了比较。

Result: 1. 该管道在数据准备和模式解释方面表现出显著的功效。
2. 与该领域的标准实践以及非ICL范式的合理机器学习基线相比，展示了卓越的性能。
3. 实现了有效的发现，并得到了团队中领域专家的验证。

Conclusion: 该AI增强的管道，利用上下文学习和新颖的张量分解，为领域专家提供了一个无缝且易于使用的界面，显著提高了科学发现（特别是行为神经科学）的效率和有效性，且不影响性能。它使专家能够专注于结果的解释，从而实现经专家验证的有效发现。

Abstract: Scientific discovery pipelines typically involve complex, rigid, and time-consuming processes, from data preparation to analyzing and interpreting findings. Recent advances in AI have the potential to transform such pipelines in a way that domain experts can focus on interpreting and understanding findings, rather than debugging rigid pipelines or manually annotating data. As part of an active collaboration between data science/AI researchers and behavioral neuroscientists, we showcase an example AI-enhanced pipeline, specifically designed to transform and accelerate the way that the domain experts in the team are able to gain insights out of experimental data. The application at hand is in the domain of behavioral neuroscience, studying fear generalization in mice, an important problem whose progress can advance our understanding of clinically significant and often debilitating conditions such as PTSD (Post-Traumatic Stress Disorder). We identify the emerging paradigm of "In-Context Learning" (ICL) as a suitable interface for domain experts to automate parts of their pipeline without the need for or familiarity with AI model training and fine-tuning, and showcase its remarkable efficacy in data preparation and pattern interpretation. Also, we introduce novel AI-enhancements to tensor decomposition model, which allows for more seamless pattern discovery from the heterogeneous data in our application. We thoroughly evaluate our proposed pipeline experimentally, showcasing its superior performance compared to what is standard practice in the domain, as well as against reasonable ML baselines that do not fall under the ICL paradigm, to ensure that we are not compromising performance in our quest for a seamless and easy-to-use interface for domain experts. Finally, we demonstrate effective discovery, with results validated by the domain experts in the team.

</details>


### [175] [FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and Procrustes Alignment](https://arxiv.org/abs/2602.17095)
*Chuiyang Meng,Ming Tang,Vincent W.S. Wong*

Main category: cs.LG

TL;DR: FLoRG是一个联邦微调框架，它通过使用单个低秩矩阵并聚合其Gram矩阵，解决了联邦学习中LoRA微调的聚合误差和分解漂移问题，同时显著降低了通信开销并提高了下游任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，LoRA微调引入的两个独立的低秩矩阵带来了挑战：一是单独聚合这两个矩阵导致的聚合误差；二是即使聚合两个低秩矩阵的乘积，服务器也需要通过矩阵分解恢复因子，这不仅是非唯一的，还可能引入分解漂移。

Method: 本文提出了FLoRG框架，该框架采用单个低秩矩阵进行微调并聚合其Gram矩阵，从而消除了聚合误差并减少了通信开销。FLoRG通过引入Procrustes对齐方法来最小化分解漂移，该方法在连续的微调轮次之间对齐分解后的矩阵以实现一致的更新。作者还从理论上分析了FLoRG的收敛性，并证明Procrustes对齐能带来更紧密的收敛界。

Result: 在多个大型语言模型微调基准上的实验结果表明，FLoRG在下游任务准确性方面优于五种最先进的基线方案，并且可以将通信开销降低高达2041倍。

Conclusion: FLoRG通过创新性地使用单个低秩矩阵和Gram矩阵聚合，并结合Procrustes对齐方法，有效解决了联邦学习中LoRA微调的挑战，显著提升了性能并降低了通信成本，为LLM的联邦微调提供了高效且稳健的解决方案。

Abstract: Parameter-efficient fine-tuning techniques such as low-rank adaptation (LoRA) enable large language models (LLMs) to adapt to downstream tasks efficiently. Federated learning (FL) further facilitates this process by enabling collaborative fine-tuning across distributed clients without sharing private data. However, the use of two separate low-rank matrices in LoRA for federated fine-tuning introduces two types of challenges. The first challenge arises from the error induced by separately aggregating those two low-rank matrices. The second challenge occurs even when the product of two low-rank matrices is aggregated. The server needs to recover factors via matrix decomposition, which is non-unique and can introduce decomposition drift. To tackle the aforementioned challenges, we propose FLoRG, a federated fine-tuning framework which employs a single low-rank matrix for fine-tuning and aggregates its Gram matrix (i.e., the matrix of inner products of its column vectors), eliminating the aggregation error while also reducing the communication overhead. FLoRG minimizes the decomposition drift by introducing a Procrustes alignment approach which aligns the decomposed matrix between consecutive fine-tuning rounds for consistent updates. We theoretically analyze the convergence of FLoRG and prove that adopting the Procrustes alignment results in a tighter convergence bound. Experimental results across multiple LLM fine-tuning benchmarks demonstrate that FLoRG outperforms five state-of-the-art baseline schemes in the downstream task accuracy and can reduce the communication overhead by up to 2041$\times$.

</details>


### [176] [TIFO: Time-Invariant Frequency Operator for Stationarity-Aware Representation Learning in Time Series](https://arxiv.org/abs/2602.17122)
*Xihao Piao,Zheng Chen,Lingwei Zhu,Yushun Dong,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 该论文提出了一种时间不变频率算子（TIFO），通过在频域学习平稳性感知权重来解决非平稳时间序列预测中的分布偏移问题，从而提高预测性能并显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 非平稳时间序列预测面临训练和测试数据分布不同的问题，现有方法未能捕捉样本间底层的时间演化结构。

Method: 提出时间不变频率算子（TIFO），在整个数据集的频率谱上学习平稳性感知权重，突出平稳频率分量并抑制非平稳分量，以减轻时间序列中的分布偏移问题。该方法是即插即用的，可以无缝集成到各种预测模型中。

Result: 在28种预测设置中获得18个第一名和6个第二名；在ETTm2数据集上平均MSE分别提高了33.3%和55.3%；与基线方法相比，计算成本降低了60%-70%。

Conclusion: TIFO通过有效处理频域的分布偏移问题，显著提升了非平稳时间序列预测的准确性和效率，并展现出强大的可扩展性。

Abstract: Nonstationary time series forecasting suffers from the distribution shift issue due to the different distributions that produce the training and test data. Existing methods attempt to alleviate the dependence by, e.g., removing low-order moments from each individual sample. These solutions fail to capture the underlying time-evolving structure across samples and do not model the complex time structure. In this paper, we aim to address the distribution shift in the frequency space by considering all possible time structures. To this end, we propose a Time-Invariant Frequency Operator (TIFO), which learns stationarity-aware weights over the frequency spectrum across the entire dataset. The weight representation highlights stationary frequency components while suppressing non-stationary ones, thereby mitigating the distribution shift issue in time series. To justify our method, we show that the Fourier transform of time series data implicitly induces eigen-decomposition in the frequency space. TIFO is a plug-and-play approach that can be seamlessly integrated into various forecasting models. Experiments demonstrate our method achieves 18 top-1 and 6 top-2 results out of 28 forecasting settings. Notably, it yields 33.3% and 55.3% improvements in average MSE on the ETTm2 dataset. In addition, TIFO reduces computational costs by 60% -70% compared to baseline methods, demonstrating strong scalability across diverse forecasting models.

</details>


### [177] [VP-VAE: Rethinking Vector Quantization via Adaptive Vector Perturbation](https://arxiv.org/abs/2602.17133)
*Linwei Zhai,Han Ding,Mingzhi Lin,Cui Zhao,Fei Wang,Ge Wang,Wang Zhi,Wei Xi*

Main category: cs.LG

TL;DR: VP-VAE通过解耦表示学习和离散化，消除了训练过程中对显式码本的需求，通过Metropolis-Hastings采样生成潜在空间扰动实现稳定训练，并引入轻量级变体FSP。


<details>
  <summary>Details</summary>
Motivation: 现有的VQ-VAE由于表示学习和离散码本优化的内在耦合，常出现训练不稳定和“码本崩溃”问题。

Method: 提出VP-VAE，通过在训练期间消除显式码本，解耦表示学习和离散化。VP-VAE的核心思想是将量化视为在潜在空间中注入结构化扰动。它使用通过Metropolis-Hastings采样生成的与分布一致且尺度自适应的潜在扰动来替代不可微分的量化器。此外，基于近似均匀潜在变量的假设，提出了轻量级变体FSP，为FSQ风格的固定量化器提供了统一的理论解释和实际改进。

Result: 在图像和音频基准测试上的大量实验表明，VP-VAE和FSP提高了重建保真度，实现了更平衡的token使用，并避免了传统耦合码本训练固有的不稳定性。

Conclusion: VP-VAE通过解耦表示学习和离散化，解决了VQ-VAE的训练不稳定和码本崩溃问题，提供了更稳定的训练和对推理时量化误差的鲁棒性。FSP作为其轻量级变体，进一步扩展了理论和实践应用。

Abstract: Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental to modern generative modeling, yet they often suffer from training instability and "codebook collapse" due to the inherent coupling of representation learning and discrete codebook optimization. In this paper, we propose VP-VAE (Vector Perturbation VAE), a novel paradigm that decouples representation learning from discretization by eliminating the need for an explicit codebook during training. Our key insight is that, from the neural network's viewpoint, performing quantization primarily manifests as injecting a structured perturbation in latent space. Accordingly, VP-VAE replaces the non-differentiable quantizer with distribution-consistent and scale-adaptive latent perturbations generated via Metropolis--Hastings sampling. This design enables stable training without a codebook while making the model robust to inference-time quantization error. Moreover, under the assumption of approximately uniform latent variables, we derive FSP (Finite Scalar Perturbation), a lightweight variant of VP-VAE that provides a unified theoretical explanation and a practical improvement for FSQ-style fixed quantizers. Extensive experiments on image and audio benchmarks demonstrate that VP-VAE and FSP improve reconstruction fidelity and achieve substantially more balanced token usage, while avoiding the instability inherent to coupled codebook training.

</details>


### [178] [TimeOmni-VL: Unified Models for Time Series Understanding and Generation](https://arxiv.org/abs/2602.17149)
*Tong Guan,Sheng Pan,Johan Barthelemy,Zhao Li,Yujun Cai,Cesare Alippi,Ming Jin,Shirui Pan*

Main category: cs.LG

TL;DR: TimeOmni-VL是首个统一时间序列理解和生成的视觉中心框架，通过保真双向映射和理解引导生成弥合了当前模型在数值生成和语义理解之间的鸿沟，并通过实验证明其能显著提高两者性能。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列建模在数值生成和语义理解之间存在明显鸿沟：生成模型常依赖表层模式匹配，而理解模型难以产生高保真数值输出。尽管统一多模态模型（UMMs）已在视觉领域弥合了这一差距，但在时间序列领域其潜力尚未被挖掘。

Method: 本文提出了TimeOmni-VL，这是一个以视觉为中心，统一时间序列理解和生成的框架。其核心创新包括：1) 保真双向映射（Bi-TSI），实现了近乎无损的时间序列到图像（TS2I）和图像到时间序列（I2TS）转换。2) 理解引导的生成。此外，还引入了TSUMM-Suite数据集，其中包含六个时间序列分析理解任务和两个生成任务。TimeOmni-VL利用校准的思维链，首次将时间序列理解作为高保真生成的明确控制信号。

Result: 实验证明，TimeOmni-VL这种统一方法显著提升了时间序列的语义理解能力和数值精度。

Conclusion: TimeOmni-VL通过统一时间序列的理解和生成，显著提高了语义理解和数值精度，为多模态时间序列建模开辟了新领域。

Abstract: Recent time series modeling faces a sharp divide between numerical generation and semantic understanding, with research showing that generation models often rely on superficial pattern matching, while understanding-oriented models struggle with high-fidelity numerical output. Although unified multimodal models (UMMs) have bridged this gap in vision, their potential for time series remains untapped. We propose TimeOmni-VL, the first vision-centric framework that unifies time series understanding and generation through two key innovations: (1) Fidelity-preserving bidirectional mapping between time series and images (Bi-TSI), which advances Time Series-to-Image (TS2I) and Image-to-Time Series (I2TS) conversions to ensure near-lossless transformations. (2) Understanding-guided generation. We introduce TSUMM-Suite, a novel dataset consists of six understanding tasks rooted in time series analytics that are coupled with two generation tasks. With a calibrated Chain-of-Thought, TimeOmni-VL is the first to leverage time series understanding as an explicit control signal for high-fidelity generation. Experiments confirm that this unified approach significantly improves both semantic understanding and numerical precision, establishing a new frontier for multimodal time series modeling.

</details>


### [179] [In-Context Learning in Linear vs. Quadratic Attention Models: An Empirical Study on Regression Tasks](https://arxiv.org/abs/2602.17171)
*Ayush Goel,Arjun Kohli,Sarvagya Somvanshi*

Main category: cs.LG

TL;DR: 本文经验性地研究了Transformer（二次注意力）和线性注意力模型在典型线性回归任务上的上下文学习（ICL）行为差异，评估了学习质量、收敛性和泛化能力，并分析了模型深度增加对ICL性能的影响。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，Transformer和线性注意力模型可以在线性回归等简单函数类别上执行上下文学习（ICL）。本文旨在实证研究这两种注意力机制在ICL行为上的具体差异。

Method: 本文在Garg等人提出的典型线性回归任务上，经验性地比较了Transformer和线性注意力模型，评估了它们的学习质量（MSE）、收敛性和泛化行为，并分析了增加模型深度对ICL性能的影响。

Result: 研究结果揭示了在此设置下，线性注意力相对于二次注意力的相似之处和局限性。

Conclusion: 研究结果表明，线性注意力在上下文学习方面与二次注意力（Transformer）既有相似之处，也存在一定的局限性。

Abstract: Recent work has demonstrated that transformers and linear attention models can perform in-context learning (ICL) on simple function classes, such as linear regression. In this paper, we empirically study how these two attention mechanisms differ in their ICL behavior on the canonical linear-regression task of Garg et al. We evaluate learning quality (MSE), convergence, and generalization behavior of each architecture. We also analyze how increasing model depth affects ICL performance. Our results illustrate both the similarities and limitations of linear attention relative to quadratic attention in this setting.

</details>


### [180] [Flickering Multi-Armed Bandits](https://arxiv.org/abs/2602.17315)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 本文引入了闪烁多臂老虎机（FMAB）框架，其中可用臂随时间动态变化且依赖于先前选择。该框架通过随机图过程建模，并针对i.i.d. Erdős--Rényi和边-马尔可夫模型进行了分析。提出了一种两阶段算法（惰性随机游走探索与导航开发），并建立了近乎最优的次线性遗憾界限和匹配的信息论下界。通过数值模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 提出了一种新的多臂老虎机（MAB）框架——闪烁多臂老虎机（Flickering Multi-Armed Bandits, FMAB），其中可用臂集在每个回合都可能变化，并且在任何给定时间，可用集可能取决于智能体先前选择的臂。这种模型旨在处理臂的可用性受限且动态演变，且智能体移动受限于局部邻域的现实场景，例如机器人探索。

Method: 1. 引入FMAB框架，将受限的、不断变化的臂可用性建模为随机图过程，其中臂是节点，智能体的移动受限于其局部邻域。
2. 在两种随机图模型下（i.i.d. Erdős--Rényi (ER)过程和边-马尔可夫过程）分析了该问题。
3. 提出并分析了一种两阶段算法：
    * 探索阶段：采用惰性随机游走（lazy random walk）来高效识别最优臂。
    * 开发阶段：采用导航和承诺阶段（navigation and commitment phase）。
4. 通过数值模拟补充理论保证，包括机器人地面车辆侦察受灾区域的场景。

Result: 1. 为所提出的算法在两种图设置下（ER和边-马尔可夫）建立了高概率和期望的次线性遗憾界限。
2. 通过为该问题类别建立匹配的信息论下界，证明了算法的探索成本接近最优。
3. 阐明了局部移动约束下探索的基本成本。
4. 数值模拟验证了理论保证。

Conclusion: 该论文引入了FMAB框架，提出了一种两阶段算法，该算法具有可证明的近乎最优的次线性遗憾界限，并确定了局部移动约束下探索成本的基本限制，展示了其理论健壮性和实际适用性。

Abstract: We introduce Flickering Multi-Armed Bandits (FMAB), a new MAB framework where the set of available arms (or actions) can change at each round, and the available set at any time may depend on the agent's previously selected arm. We model this constrained, evolving availability using random graph processes, where arms are nodes and the agent's movement is restricted to its local neighborhood. We analyze this problem under two random graph models: an i.i.d. Erdős--Rényi (ER) process and an Edge-Markovian process. We propose and analyze a two-phase algorithm that employs a lazy random walk for exploration to efficiently identify the optimal arm, followed by a navigation and commitment phase for exploitation. We establish high-probability and expected sublinear regret bounds for both graph settings. We show that the exploration cost of our algorithm is near-optimal by establishing a matching information-theoretic lower bound for this problem class, highlighting the fundamental cost of exploration under local-move constraints. We complement our theoretical guarantees with numerical simulations, including a scenario of a robotic ground vehicle scouting a disaster-affected region.

</details>


### [181] [SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework](https://arxiv.org/abs/2602.17330)
*Rong Fu,Zijian Zhang,Wenxin Zhang,Kun Liu,Jiekai Wu,Xianda Li,Simon Fong*

Main category: cs.LG

TL;DR: SubQuad是一个解决自适应免疫库群体规模比较分析瓶颈的端到端管线。它通过抗原感知、近亚二次检索、GPU加速、多模态融合和公平性约束聚类，提高了吞吐量和内存使用效率，同时保持或改进了召回率、聚类纯度和亚组公平性，为免疫库挖掘提供了可扩展、偏倚感知的平台。


<details>
  <summary>Details</summary>
Motivation: 群体规模的自适应免疫库比较分析面临两个主要瓶颈：成对亲和评估的近二次成本，以及掩盖临床重要少数克隆型的数据不平衡问题。

Method: 本研究引入了SubQuad，一个端到端管线。该管线结合了抗原感知、近亚二次检索、GPU加速的亲和核、学习型多模态融合和公平性约束聚类。具体方法包括紧凑的MinHash预过滤以大幅减少候选比较，一个可微分门控模块以自适应地权重互补的对齐和嵌入通道，以及一个自动化校准程序以强制稀有抗原特异性亚组的比例代表。

Result: 在大型病毒和肿瘤免疫库上，SubQuad在保持或改进召回率@k、聚类纯度和亚组公平性的同时，实现了吞吐量和峰值内存使用的显著提升。

Conclusion: 通过协同设计索引、相似性融合和公平性感知目标，SubQuad为免疫库挖掘和下游转化任务（如疫苗靶点优先排序和生物标志物发现）提供了一个可扩展、偏倚感知的平台。

Abstract: Comparative analysis of adaptive immune repertoires at population scale is hampered by two practical bottlenecks: the near-quadratic cost of pairwise affinity evaluations and dataset imbalances that obscure clinically important minority clonotypes. We introduce SubQuad, an end-to-end pipeline that addresses these challenges by combining antigen-aware, near-subquadratic retrieval with GPU-accelerated affinity kernels, learned multimodal fusion, and fairness-constrained clustering. The system employs compact MinHash prefiltering to sharply reduce candidate comparisons, a differentiable gating module that adaptively weights complementary alignment and embedding channels on a per-pair basis, and an automated calibration routine that enforces proportional representation of rare antigen-specific subgroups. On large viral and tumor repertoires SubQuad achieves measured gains in throughput and peak memory usage while preserving or improving recall@k, cluster purity, and subgroup equity. By co-designing indexing, similarity fusion, and equity-aware objectives, SubQuad offers a scalable, bias-aware platform for repertoire mining and downstream translational tasks such as vaccine target prioritization and biomarker discovery.

</details>


### [182] [A feature-stable and explainable machine learning framework for trustworthy decision-making under incomplete clinical data](https://arxiv.org/abs/2602.17364)
*Justyna Andrys-Olek,Paulina Tworek,Luca Gherardini,Mark W. Ruddock,Mary Jo Kurt,Peter Fitzgerald,Jose Sousa*

Main category: cs.LG

TL;DR: CACTUS是一种可解释的机器学习框架，旨在解决小型、异构和不完整的临床数据集中的鲁棒性、可解释性和特征稳定性问题。它在预测性能方面具有竞争力，并在数据缺失增加时保持了显着更高的特征稳定性，这对于生物医学数据中机器学习模型的可靠性至关重要。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在生物医学数据中的应用受到鲁棒性差、可解释性有限以及在现实数据扰动（如缺失数据）下学习特征不稳定性等问题的限制，这阻碍了它们在高风险领域的采用，并损害了可信度、可重复性和下游决策。

Method: CACTUS（Comprehensive Abstraction and Classification Tool for Uncovering Structures）是一个可解释的机器学习框架。它整合了特征抽象、可解释分类和系统性特征稳定性分析，以量化数据质量下降时信息性特征的保存一致性。该方法在一个包含568名膀胱癌评估患者的真实血尿队列中进行基准测试，并在受控的随机缺失数据水平下，与随机森林和梯度提升方法等广泛使用的机器学习方法进行了比较。

Result: CACTUS在预测性能方面达到了竞争或卓越的水平。更重要的是，随着缺失数据的增加，包括在按性别分层的分析中，CACTUS保持了排名靠前特征的显着更高稳定性。结果表明，特征稳定性提供了与传统性能指标互补的信息。

Conclusion: 特征稳定性对于评估应用于生物医学数据的机器学习模型的可靠性至关重要。CACTUS通过明确量化对缺失数据的鲁棒性并优先考虑可解释、稳定的特征，为值得信赖的数据驱动决策支持提供了一个通用的框架。

Abstract: Machine learning models are increasingly applied to biomedical data, yet their adoption in high stakes domains remains limited by poor robustness, limited interpretability, and instability of learned features under realistic data perturbations, such as missingness. In particular, models that achieve high predictive performance may still fail to inspire trust if their key features fluctuate when data completeness changes, undermining reproducibility and downstream decision-making. Here, we present CACTUS (Comprehensive Abstraction and Classification Tool for Uncovering Structures), an explainable machine learning framework explicitly designed to address these challenges in small, heterogeneous, and incomplete clinical datasets. CACTUS integrates feature abstraction, interpretable classification, and systematic feature stability analysis to quantify how consistently informative features are preserved as data quality degrades. Using a real-world haematuria cohort comprising 568 patients evaluated for bladder cancer, we benchmark CACTUS against widely used machine learning approaches, including random forests and gradient boosting methods, under controlled levels of randomly introduced missing data. We demonstrate that CACTUS achieves competitive or superior predictive performance while maintaining markedly higher stability of top-ranked features as missingness increases, including in sex-stratified analyses. Our results show that feature stability provides information complementary to conventional performance metrics and is essential for assessing the trustworthiness of machine learning models applied to biomedical data. By explicitly quantifying robustness to missing data and prioritising interpretable, stable features, CACTUS offers a generalizable framework for trustworthy data-driven decision support.

</details>


### [183] [LORA-CRAFT: Cross-layer Rank Adaptation via Frozen Tucker Decomposition of Pre-trained Attention Weights](https://arxiv.org/abs/2602.17510)
*Kasun Dewage,Marianna Pensky,Suranadi De Silva,Shankadeep Mondal*

Main category: cs.LG

TL;DR: CRAFT是一种参数高效的微调（PEFT）方法，它对跨层Transformer注意力权重矩阵进行Tucker分解，冻结分解因子，并通过训练小型适应矩阵来微调模型，在GLUE基准上实现了竞争性性能，且参数量极少（41K），与模型大小无关。


<details>
  <summary>Details</summary>
Motivation: 现有的张量PEFT方法通常分解梯度更新（如LoTR、SuperLoRA），或独立地对每层的预训练权重进行SVD分解（如PiSSA）。这些方法未能有效地结合跨层信息并直接对预训练权重进行统一且参数高效的适应。CRAFT旨在弥合这两种方法之间的差距。

Method: CRAFT首先将跨Transformer层的预训练注意力权重矩阵堆叠成一个跨层3D张量，然后通过高阶SVD（HOSVD）对其进行全Tucker分解。分解得到的所有因子被冻结，模型通过对每个因子矩阵应用轻量级的可训练变换（小型方形适应矩阵）进行参数适应。

Result: 在GLUE基准测试中，使用RoBERTa-base和RoBERTa-large模型的实验表明，CRAFT达到了与现有方法相当的性能，同时仅需要41K的Tucker适应参数。值得注意的是，在固定Tucker秩的情况下，所需的参数量与模型的维度和深度无关。

Conclusion: CRAFT通过创新的跨层Tucker分解和冻结因子适应策略，实现了参数效率极高的PEFT，为大型Transformer模型的微调提供了一种有效且资源友好的方法。

Abstract: We introduce CRAFT (Cross-layer Rank Adaptation via Frozen Tucker), a parameter-efficient fine-tuning (PEFT) method that applies Tucker tensor decomposition to pre-trained attention weight matrices stacked across transformer layers and trains only small square adaptation matrices on the resulting frozen Tucker factors. Existing tensor-based PEFT methods decompose gradient updates: LoTR applies Tucker decomposition with shared factor matrices, while SuperLoRA groups and reshapes $\Delta W$ across layers before applying Tucker decomposition. Separately, methods like PiSSA apply SVD to pre-trained weights but operate independently per layer. CRAFT bridges these two lines of work: it performs full Tucker decomposition via Higher-Order SVD (HOSVD) directly on pre-trained weights organized as cross-layer 3D tensors, freezes all resulting factors, and adapts the model through lightweight trainable transformations applied to each factor matrix. Experiments on the GLUE benchmark using RoBERTa-base and RoBERTa-large demonstrate that CRAFT achieves competitive performance with existing methods while requiring only 41K Tucker adaptation parameters--a count independent of model dimension and depth at fixed Tucker ranks.

</details>


### [184] [Position: Evaluation of ECG Representations Must Be Fixed](https://arxiv.org/abs/2602.17531)
*Zachary Berger,Daniel Prakah-Asante,John Guttag,Collin M. Stultz*

Main category: cs.LG

TL;DR: 该论文指出当前心电图表示学习的基准测试存在缺陷，并提议扩展评估至结构性心脏病和患者预测等更广泛的临床目标。研究发现，改进的评估方法会改变现有模型性能结论，并且一个随机编码器在许多任务上能达到最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 当前的12导联心电图表示学习基准测试（PTB-XL、CPSC2018、CSN）主要关注心律失常和波形形态标签，未能涵盖心电图所包含的更广泛临床信息，如结构性心脏病和患者水平预测。这阻碍了该领域的可靠进展和临床相关性。

Method: 该论文提出了多标签、不平衡设置下的评估最佳实践。通过对三种代表性心电图预训练方法在六种评估设置（三个标准基准、结构性疾病数据集、血流动力学推断和患者预测）中进行实证评估，并使用随机初始化编码器进行线性评估作为基线。

Result: 当应用所提出的评估最佳实践时，文献中关于哪种表示效果最佳的现有结论发生了改变。此外，一个随机初始化的编码器在许多任务上的线性评估表现出人意料地与最先进的预训练方法持平。

Conclusion: 当前12导联心电图表示学习的基准测试需要改进，以确保进展的可靠性并与临床有意义的目标保持一致。评估应扩展到包括结构性心脏病和患者水平预测。随机初始化编码器可作为合理的基线模型。

Abstract: This position paper argues that current benchmarking practice in 12-lead ECG representation learning must be fixed to ensure progress is reliable and aligned with clinically meaningful objectives. The field has largely converged on three public multi-label benchmarks (PTB-XL, CPSC2018, CSN) dominated by arrhythmia and waveform-morphology labels, even though the ECG is known to encode substantially broader clinical information. We argue that downstream evaluation should expand to include an assessment of structural heart disease and patient-level forecasting, in addition to other evolving ECG-related endpoints, as relevant clinical targets. Next, we outline evaluation best practices for multi-label, imbalanced settings, and show that when they are applied, the literature's current conclusion about which representations perform best is altered. Furthermore, we demonstrate the surprising result that a randomly initialized encoder with linear evaluation matches state-of-the-art pre-training on many tasks. This motivates the use of a random encoder as a reasonable baseline model. We substantiate our observations with an empirical evaluation of three representative ECG pre-training approaches across six evaluation settings: the three standard benchmarks, a structural disease dataset, hemodynamic inference, and patient forecasting.

</details>


### [185] [MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning](https://arxiv.org/abs/2602.17550)
*Xiaoliang Fu,Jiaye Lin,Yangyi Fang,Binbin Zheng,Chaowen Hu,Zekai Shao,Cong Qin,Lu Pan,Ke Zeng,Xunliang Cai*

Main category: cs.LG

TL;DR: MASPO是一种新颖的强化学习算法，通过解决现有RLVR算法在LLM优化中的三个关键挑战（梯度利用效率低下、概率质量不敏感、信号可靠性不对称），显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有可验证奖励强化学习（RLVR）算法（如GRPO）采用的刚性、统一、对称的信任区域机制与大型语言模型（LLM）复杂的优化动力学不匹配，导致了三个关键挑战：硬裁剪的二元截止导致梯度利用效率低下；统一比率约束忽略了token分布，导致概率质量不敏感；正负样本之间信用分配模糊性不同，导致信号可靠性不对称。

Method: 本文提出了Mass-Adaptive Soft Policy Optimization (MASPO) 框架。MASPO整合了可微分的软高斯门控以最大化梯度效用，质量自适应限制器以平衡概率谱上的探索，以及非对称风险控制器以使更新幅度与信号置信度对齐。

Result: 广泛评估表明，MASPO作为一种稳健、一体化的RLVR解决方案，显著优于强大的基线模型。

Conclusion: MASPO框架通过解决现有RLVR算法的局限性，提供了一种强大且全面的解决方案，有效地提升了LLM的强化学习性能。

Abstract: Existing Reinforcement Learning with Verifiable Rewards (RLVR) algorithms, such as GRPO, rely on rigid, uniform, and symmetric trust region mechanisms that are fundamentally misaligned with the complex optimization dynamics of Large Language Models (LLMs). In this paper, we identify three critical challenges in these methods: (1) inefficient gradient utilization caused by the binary cutoff of hard clipping, (2) insensitive probability mass arising from uniform ratio constraints that ignore the token distribution, and (3) asymmetric signal reliability stemming from the disparate credit assignment ambiguity between positive and negative samples. To bridge these gaps, we propose Mass-Adaptive Soft Policy Optimization (MASPO), a unified framework designed to harmonize these three dimensions. MASPO integrates a differentiable soft Gaussian gating to maximize gradient utility, a mass-adaptive limiter to balance exploration across the probability spectrum, and an asymmetric risk controller to align update magnitudes with signal confidence. Extensive evaluations demonstrate that MASPO serves as a robust, all-in-one RLVR solution, significantly outperforming strong baselines. Our code is available at: .

</details>


### [186] [Be Wary of Your Time Series Preprocessing](https://arxiv.org/abs/2602.17568)
*Sofiane Ennadir,Tianze Wang,Oleg Smirnov,Sahar Asadi,Lele Cao*

Main category: cs.LG

TL;DR: 本文理论分析了不同归一化策略对Transformer模型时间序列表示学习表达能力的影响，并发现没有单一最佳策略，有时甚至无需归一化。


<details>
  <summary>Details</summary>
Motivation: Transformer模型中归一化和缩放的作用在理论层面尚未得到充分探索。

Method: 提出了一个针对时间序列的表达能力框架，用于量化模型在表示空间中区分相似和不相似输入的能力。使用该框架，推导了标准归一化和Min-Max缩放两种常用归一化方法的理论界限，并通过分类和预测基准上的多个基于Transformer的模型进行实证验证。

Result: 归一化策略的选择会显著影响模型的表示能力，具体取决于任务和数据特性。没有单一的归一化方法能始终优于其他方法，在某些情况下，完全省略归一化会带来更好的性能。

Conclusion: 预处理在时间序列学习中的关键作用，并强调需要针对特定任务和数据集制定更规范的归一化策略。

Abstract: Normalization and scaling are fundamental preprocessing steps in time series modeling, yet their role in Transformer-based models remains underexplored from a theoretical perspective. In this work, we present the first formal analysis of how different normalization strategies, specifically instance-based and global scaling, impact the expressivity of Transformer-based architectures for time series representation learning. We propose a novel expressivity framework tailored to time series, which quantifies a model's ability to distinguish between similar and dissimilar inputs in the representation space. Using this framework, we derive theoretical bounds for two widely used normalization methods: Standard and Min-Max scaling. Our analysis reveals that the choice of normalization strategy can significantly influence the model's representational capacity, depending on the task and data characteristics. We complement our theory with empirical validation on classification and forecasting benchmarks using multiple Transformer-based models. Our results show that no single normalization method consistently outperforms others, and in some cases, omitting normalization entirely leads to superior performance. These findings highlight the critical role of preprocessing in time series learning and motivate the need for more principled normalization strategies tailored to specific tasks and datasets.

</details>


### [187] [Towards Anytime-Valid Statistical Watermarking](https://arxiv.org/abs/2602.17608)
*Baihe Huang,Eric Xu,Kannan Ramchandran,Jiantao Jiao,Michael I. Jordan*

Main category: cs.LG

TL;DR: 本文提出了Anchored E-Watermarking，一个基于e值的大型语言模型内容检测框架，提供最优采样和随时有效的推断，将样本效率提高了13-15%。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）统计水印方法存在两个关键限制：缺乏选择采样分布的原则性方法，以及依赖固定视野假设检验，这排除了有效的提前停止，导致检测效率低下。

Method: 本文开发了Anchored E-Watermarking，这是第一个基于e值的水印框架。它通过构建一个用于检测过程的测试超鞅（supermartingale），将最优采样与随时有效（anytime-valid）的推断统一起来。该方法利用锚点分布（anchor distribution）近似目标模型，根据最坏情况对数增长率（worst-case log-growth rate）来表征最优e值，并推导出最优期望停止时间（optimal expected stopping time）。

Result: 该框架显著提高了样本效率，与现有最先进的基线相比，将检测所需的平均令牌预算减少了13-15%。

Conclusion: Anchored E-Watermarking提供了一种原则性的、高效的、随时有效的解决方案，用于区分机器生成的内容，通过最优采样和基于e值推断解决了先前方法的局限性。

Abstract: The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach for selecting sampling distributions and the reliance on fixed-horizon hypothesis testing, which precludes valid early stopping. In this paper, we bridge this gap by developing the first e-value-based watermarking framework, Anchored E-Watermarking, that unifies optimal sampling with anytime-valid inference. Unlike traditional approaches where optional stopping invalidates Type-I error guarantees, our framework enables valid, anytime-inference by constructing a test supermartingale for the detection process. By leveraging an anchor distribution to approximate the target model, we characterize the optimal e-value with respect to the worst-case log-growth rate and derive the optimal expected stopping time. Our theoretical claims are substantiated by simulations and evaluations on established benchmarks, showing that our framework can significantly enhance sample efficiency, reducing the average token budget required for detection by 13-15% relative to state-of-the-art baselines.

</details>


### [188] [Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs](https://arxiv.org/abs/2602.17616)
*Luke Huang,Zhuoyang Zhang,Qinghao Hu,Shang Yang,Song Han*

Main category: cs.LG

TL;DR: 针对LLM异步RL训练中策略梯度方差过高导致的不稳定问题，本文提出VCPO方法，通过动态学习率和最小方差基线有效控制方差，显著提高训练鲁棒性并缩短训练时间。


<details>
  <summary>Details</summary>
Motivation: 异步强化学习训练能提高端到端吞吐量，但对于REINFORCE和GRPO等无批评者策略梯度方法，高异步性导致策略梯度估计方差显著增高，训练不稳定，甚至崩溃。

Method: 提出方差控制策略优化（VCPO）方法，包含两部分：1) 根据有效样本大小（ESS）调整学习率以抑制不可靠的更新；2) 为离策略设置应用闭式最小方差基线，避免了辅助价值模型，只增加了极少的开销。

Result: VCPO在数学、通用推理和工具使用任务上显著提高了异步训练的鲁棒性，优于现有基线方法。它将长上下文、多轮训练时间缩短了2.5倍，同时达到了同步训练的性能。

Conclusion: VCPO通过明确控制策略梯度的方差，使得大规模异步强化学习训练更加可靠，并能显著减少训练时间。

Abstract: Reinforcement learning (RL) is widely used to improve large language models on reasoning tasks, and asynchronous RL training is attractive because it increases end-to-end throughput. However, for widely adopted critic-free policy-gradient methods such as REINFORCE and GRPO, high asynchrony makes the policy-gradient estimator markedly $\textbf{higher variance}$: training on stale rollouts creates heavy-tailed importance ratios, causing a small fraction of samples to dominate updates. This amplification makes gradients noisy and learning unstable relative to matched on-policy training. Across math and general reasoning benchmarks, we find collapse is reliably predicted by effective sample size (ESS) and unstable gradient norms. Motivated by this diagnosis, we propose $\textbf{V}$ariance $\textbf{C}$ontrolled $\textbf{P}$olicy $\textbf{O}$ptimization ($\textbf{VCPO}$), a general stabilization method for REINFORCE/GRPO-style algorithms that (i) scales learning rate based on effective sample size to dampen unreliable updates, and (ii) applies a closed-form minimum-variance baseline for the off-policy setting, avoiding an auxiliary value model and adding minimal overhead. Empirically, VCPO substantially improves robustness for asynchronous training across math, general reasoning, and tool-use tasks, outperforming a broad suite of baselines spanning masking/clipping stabilizers and algorithmic variants. This reduces long-context, multi-turn training time by 2.5$\times$ while matching synchronous performance, demonstrating that explicit control of policy-gradient variance is key for reliable asynchronous RL at scale.

</details>


### [189] [Reverso: Efficient Time Series Foundation Models for Zero-shot Forecasting](https://arxiv.org/abs/2602.17634)
*Xinghong Fu,Yanhong Li,Georgios Papaioannou,Yoon Kim*

Main category: cs.LG

TL;DR: 本文提出了一种构建高效零样本时间序列基础模型的简单方法，该方法使用小型混合模型（如DeltaNet），其性能可与大型Transformer模型媲美，但体积小数百倍，显著提升了性能效率。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型虽然性能良好，但参数量达数亿，导致在实际使用中效率低下且成本高昂。文章旨在解决这一效率问题。

Method: 本文提出了一种学习高效基础模型的简单方法，用于零样本时间序列预测。该方法采用小型混合模型，交错使用长卷积层和线性RNN层（特别是DeltaNet层）。此外，还描述了几种数据增强和推理策略来进一步提高性能。

Result: 该方法证明大型Transformer模型并非必需，小型混合模型（DeltaNet层）在尺寸小一百多倍的情况下，能与大型Transformer模型表现持平。通过这种方法，Reverso系列高效时间序列基础模型显著推动了性能-效率的帕累托前沿。

Conclusion: 提出了一种简单的方案，利用小型混合模型（特别是DeltaNet层）和数据增强及推理策略，可以构建出高效且高性能的零样本时间序列基础模型（Reverso），这些模型比基于Transformer的模型小很多。

Abstract: Learning time series foundation models has been shown to be a promising approach for zero-shot time series forecasting across diverse time series domains. Insofar as scaling has been a critical driver of performance of foundation models in other modalities such as language and vision, much recent work on time series foundation modeling has focused on scaling. This has resulted in time series foundation models with hundreds of millions of parameters that are, while performant, inefficient and expensive to use in practice. This paper describes a simple recipe for learning efficient foundation models for zero-shot time series forecasting that are orders of magnitude smaller. We show that large-scale transformers are not necessary: small hybrid models that interleave long convolution and linear RNN layers (in particular DeltaNet layers) can match the performance of larger transformer-based models while being more than a hundred times smaller. We also describe several data augmentation and inference strategies that further improve performance. This recipe results in Reverso, a family of efficient time series foundation models for zero-shot forecasting that significantly push the performance-efficiency Pareto frontier.

</details>


### [190] [FAMOSE: A ReAct Approach to Automated Feature Discovery](https://arxiv.org/abs/2602.17641)
*Keith Burghardt,Jienan Liu,Sadman Sakib,Yuning Hao,Bo Li*

Main category: cs.LG

TL;DR: FAMOSE是一个基于ReAct范式的AI智能体框架，用于自动化表格数据的特征工程，在回归任务中达到SOTA并接近分类任务SOTA，通过自主探索和优化特征解决了传统特征工程的瓶颈，证明了AI智能体在创新性问题解决中的有效性。


<details>
  <summary>Details</summary>
Motivation: 特征工程在机器学习中仍然是一个关键但具有挑战性的瓶颈，特别是对于表格数据，因为从指数级大的特征空间中识别最优特征传统上需要大量的领域专业知识。

Method: 我们引入了FAMOSE（特征增强和最优选择智能体），这是一个新颖的框架，它利用ReAct范式自主探索、生成和改进特征，同时将特征选择和评估工具整合到智能体架构中。FAMOSE是第一个将智能体ReAct框架应用于自动化特征工程，特别是回归和分类任务的尝试。

Result: 广泛的实验表明，FAMOSE在分类任务上达到了或接近了最先进水平（尤其是在超过10K实例的任务中，ROC-AUC平均提高了0.23%），并且通过平均降低RMSE 2.0%实现了回归任务的最先进水平，同时比其他算法对错误更具鲁棒性。研究人员推测，FAMOSE的强大性能是由于ReAct允许LLM上下文窗口记录（通过迭代特征发现和评估步骤）哪些特征有效或无效，这类似于少样本提示，并指导LLM发明更好、更具创新性的特征。

Conclusion: 我们的工作证明了AI智能体在解决需要高度创新性解决方案（例如特征工程）的问题时非常有效。

Abstract: Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature AugMentation and Optimal Selection agEnt), a novel framework that leverages the ReAct paradigm to autonomously explore, generate, and refine features while integrating feature selection and evaluation tools within an agent architecture. To our knowledge, FAMOSE represents the first application of an agentic ReAct framework to automated feature engineering, especially for both regression and classification tasks. Extensive experiments demonstrate that FAMOSE is at or near the state-of-the-art on classification tasks (especially tasks with more than 10K instances, where ROC-AUC increases 0.23% on average), and achieves the state-of-the-art for regression tasks by reducing RMSE by 2.0% on average, while remaining more robust to errors than other algorithms. We hypothesize that FAMOSE's strong performance is because ReAct allows the LLM context window to record (via iterative feature discovery and evaluation steps) what features did or did not work. This is similar to a few-shot prompt and guides the LLM to invent better, more innovative features. Our work offers evidence that AI agents are remarkably effective in solving problems that require highly inventive solutions, such as feature engineering.

</details>


### [191] [MARS: Margin-Aware Reward-Modeling with Self-Refinement](https://arxiv.org/abs/2602.17658)
*Payel Bhattacharjee,Osvaldo Simeone,Ravi Tandon*

Main category: cs.LG

TL;DR: 本文提出MARS，一种自适应、边距感知的数据增强和采样策略，通过关注奖励模型不确定的低裕度样本来提高奖励模型的鲁棒性，并通过理论和实验证明其优于统一增强。


<details>
  <summary>Details</summary>
Motivation: 奖励模型训练严重依赖于昂贵且有限的人类标注偏好数据，这促使人们使用数据增强。然而，现有的增强方法通常在表示或语义层面操作，并且对奖励模型的估计难度不敏感。

Method: 本文提出了MARS，一种自适应、边距感知的数据增强和采样策略。它将增强集中在奖励模型最不确定的低裕度（模糊）偏好对上，并通过硬样本增强迭代地完善训练分布，以明确针对奖励模型的模糊和失败模式。

Result: 理论上，该策略增加了损失函数的平均曲率，从而增强了信息并改善了条件。经验上，与统一增强相比，MARS在鲁棒奖励建模方面表现出持续的性能提升。

Conclusion: MARS通过关注低裕度样本和使用硬样本增强，为鲁棒奖励模型提供了一种有效的自适应策略，解决了人类偏好数据成本高昂和有限的问题，并优于统一增强方法。

Abstract: Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of data augmentation. Existing augmentation approaches typically operate at the representation or semantic level and remain agnostic to the reward model's estimation difficulty. In this paper, we propose MARS, an adaptive, margin-aware augmentation and sampling strategy that explicitly targets ambiguous and failure modes of the reward model. Our proposed framework, MARS, concentrates augmentation on low-margin (ambiguous) preference pairs where the reward model is most uncertain, and iteratively refines the training distribution via hard-sample augmentation. We provide theoretical guarantees showing that this strategy increases the average curvature of the loss function hence enhance information and improves conditioning, along with empirical results demonstrating consistent gains over uniform augmentation for robust reward modeling.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [192] [General sample size analysis for probabilities of causation: a delta method approach](https://arxiv.org/abs/2602.17070)
*Tianyuan Cheng,Ruirui Mao,Judea Pearl,Ang Li*

Main category: stat.ME

TL;DR: 本文提出了一种基于delta方法的通用样本量框架，用于分析因果概率（PoCs）的界限，解决了现有研究中样本量分析不足的问题，并通过模拟证明了其稳定性。


<details>
  <summary>Details</summary>
Motivation: 尽管因果概率（PoCs）是决策的重要工具且现有研究已利用实验和观察数据推导其界限，但关于如何确定达到所需误差范围的实验和观察样本量的研究非常有限。

Method: 本文提出了一种基于delta方法的通用样本量框架。该方法适用于目标因果概率界限可表示为实验和观察概率的线性组合的有限最小值或最大值的情况。

Result: 通过模拟研究，本文证明了所提出的样本量计算方法能够实现这些界限的稳定估计。

Conclusion: 本文成功建立了一个基于delta方法的样本量分析框架，有效解决了因果概率界限估计中样本量不足的问题，并通过实践证明了其有效性和稳定性。

Abstract: Probabilities of causation (PoCs), such as the probability of necessity and sufficiency (PNS), are important tools for decision making but are generally not point identifiable. Existing work has derived bounds for these quantities using combinations of experimental and observational data. However, there is very limited research on sample size analysis, namely, how many experimental and observational samples are required to achieve a desired margin of error. In this paper, we propose a general sample size framework based on the delta method. Our approach applies to settings in which the target bounds of PoCs can be expressed as finite minima or maxima of linear combinations of experimental and observational probabilities. Through simulation studies, we demonstrate that the proposed sample size calculations lead to stable estimation of these bounds.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [193] [ICP-Based Pallet Tracking for Unloading on Inclined Surfaces by Autonomous Forklifts](https://arxiv.org/abs/2602.16744)
*Takuro Kato,Mitsuharu Morisawa*

Main category: cs.RO

TL;DR: 一种自动叉车在斜面上卸载托盘时避免拖拽的控制方法。


<details>
  <summary>Details</summary>
Motivation: 解决自动叉车在斜面上卸载托盘时叉子拖拽托盘的问题。

Method: 应用迭代最近点（ICP）算法实时跟踪托盘与叉车之间的相对位置和姿态角差异，根据跟踪结果将叉子与目标表面对齐，然后沿倾斜方向收回叉子完成卸载。

Result: 通过动态仿真和真实叉车实验验证了所提方法的有效性。

Conclusion: 该方法能够使自动叉车在斜面上成功卸载托盘，并有效避免托盘拖拽。

Abstract: This paper proposes a control method for autonomous forklifts to unload pallets on inclined surfaces, enabling the fork to be withdrawn without dragging the pallets. The proposed method applies the Iterative Closest Point (ICP) algorithm to point clouds measured from the upper region of the pallet and thereby tracks the relative position and attitude angle difference between the pallet and the fork during the unloading operation in real-time. According to the tracking result, the fork is aligned parallel to the target surface. After the fork is aligned, it is possible to complete the unloading process by withdrawing the fork along the tilt, preventing any dragging of the pallet. The effectiveness of the proposed method is verified through dynamic simulations and experiments using a real forklift that replicate unloading operations onto the inclined bed of a truck.

</details>


### [194] [RRT$^η$: Sampling-based Motion Planning and Control from STL Specifications using Arithmetic-Geometric Mean Robustness](https://arxiv.org/abs/2602.16825)
*Ahmad Ahmad,Shuo Liu,Roberto Tron,Calin Belta*

Main category: cs.RO

TL;DR: 提出了一种名为 RRT$^\eta$ 的采样规划框架，它使用算术几何平均（AGM）鲁棒性度量来克服传统基于 STL 的规划器在非光滑优化景观中的局限性，实现高鲁棒性、动态可行的轨迹，并优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于信号时序逻辑（STL）的采样运动规划方法依赖于 min-max 鲁棒性度量，该度量仅关注关键时间点和子公式，导致优化景观不平滑和决策边界尖锐，从而阻碍了高效的树探索。

Method: 提出了一种名为 RRT$^\eta$ 的采样规划框架，该框架将算术几何平均（AGM）鲁棒性度量集成进来，以评估所有时间点和子公式的满足度。关键贡献包括：(1) 用于在树构建过程中推理部分轨迹的 AGM 鲁棒性区间语义；(2) 一种计算这些区间的有效增量监测算法；(3) 利用履行优先级逻辑（FPL）增强的满意度提升方向向量，实现有原则的目标组合。

Result: 该框架能够合成动态可行的控制序列，以高鲁棒性满足 STL 规范，同时保持 RRT$^\ast$ 的概率完备性和渐近最优性。在双积分器点机器人、独轮移动机器人和 7 自由度机械臂这三个机器人系统上进行了验证，在多约束、引导信号有限的场景中，表现出优于传统基于 STL 鲁棒性的规划器的性能。

Conclusion: RRT$^\eta$ 框架通过引入 AGM 鲁棒性度量，成功解决了传统 STL 规划中非光滑优化景观的问题，实现了高鲁棒性、动态可行的轨迹，并保持了 RRT$^\ast$ 的理论特性，在实践中表现出优越性。

Abstract: Sampling-based motion planning has emerged as a powerful approach for robotics, enabling exploration of complex, high-dimensional configuration spaces. When combined with Signal Temporal Logic (STL), a temporal logic widely used for formalizing interpretable robotic tasks, these methods can address complex spatiotemporal constraints. However, traditional approaches rely on min-max robustness measures that focus only on critical time points and subformulae, creating non-smooth optimization landscapes with sharp decision boundaries that hinder efficient tree exploration. We propose RRT$^\eta$, a sampling-based planning framework that integrates the Arithmetic-Geometric Mean (AGM) robustness measure to evaluate satisfaction across all time points and subformulae. Our key contributions include: (1) AGM robustness interval semantics for reasoning about partial trajectories during tree construction, (2) an efficient incremental monitoring algorithm computing these intervals, and (3) enhanced Direction of Increasing Satisfaction vectors leveraging Fulfillment Priority Logic (FPL) for principled objective composition. Our framework synthesizes dynamically feasible control sequences satisfying STL specifications with high robustness while maintaining the probabilistic completeness and asymptotic optimality of RRT$^\ast$. We validate our approach on three robotic systems. A double integrator point robot, a unicycle mobile robot, and a 7-DOF robot arm, demonstrating superior performance over traditional STL robustness-based planners in multi-constraint scenarios with limited guidance signals.

</details>


### [195] [Sound of Touch: Active Acoustic Tactile Sensing via String Vibrations](https://arxiv.org/abs/2602.16846)
*Xili Yi,Ying Xing,Zachary Manchester,Nima Fazeli*

Main category: cs.RO

TL;DR: “Sound of Touch”是一种主动声学触觉传感方法，利用振动的张紧弦作为传感元件，通过观察接触引起的频谱变化来估计接触位置、法向力并检测滑动，实现了毫米级定位、可靠的力估计和实时滑动检测，适用于机器人表面的可扩展触觉传感。


<details>
  <summary>Details</summary>
Motivation: 分布式触觉传感难以在大面积上扩展：密集的传感器阵列会增加布线、成本和脆弱性，而许多替代方案覆盖范围有限或无法捕捉快速交互动态。

Method: 本文提出“Sound of Touch”，一种主动声学触觉传感方法，使用振动的张紧弦作为传感元件。弦被电磁连续激励，少量拾音器（接触麦克风）观察接触引起的频谱变化。系统从短时音频信号中估计接触位置和法向力，并检测滑动。为了指导设计和解释传感机制，本文推导了一个基于物理的弦振动模拟器，预测接触位置和力如何改变振动模式。

Result: 实验证明了毫米级定位、可靠的力估计和实时滑动检测。主要贡献包括：(i) 一种轻量级、可扩展的基于弦的触觉传感硬件概念，用于装备扩展的机器人表面；(ii) 一种基于物理的模拟和分析工具，用于接触引起的频谱偏移；(iii) 一个将振动测量映射到接触状态的实时推理管道。

Conclusion: 该研究提供了一种轻量级、可扩展的基于弦的触觉传感硬件概念，能够通过物理模拟和实时推理，实现高精度的接触位置、法向力估计以及滑移检测，克服了传统分布式触觉传感的挑战。

Abstract: Distributed tactile sensing remains difficult to scale over large areas: dense sensor arrays increase wiring, cost, and fragility, while many alternatives provide limited coverage or miss fast interaction dynamics. We present Sound of Touch, an active acoustic tactile-sensing methodology that uses vibrating tensioned strings as sensing elements. The string is continuously excited electromagnetically, and a small number of pickups (contact microphones) observe spectral changes induced by contact. From short-duration audio signals, our system estimates contact location and normal force, and detects slip. To guide design and interpret the sensing mechanism, we derive a physics-based string-vibration simulator that predicts how contact position and force shift vibration modes. Experiments demonstrate millimeter-scale localization, reliable force estimation, and real-time slip detection. Our contributions are: (i) a lightweight, scalable string-based tactile sensing hardware concept for instrumenting extended robot surfaces; (ii) a physics-grounded simulation and analysis tool for contact-induced spectral shifts; and (iii) a real-time inference pipeline that maps vibration measurements to contact state.

</details>


### [196] ["Hello, I'm Delivering. Let Me Pass By": Navigating Public Pathways with Walk-along with Robots in Crowded City Streets](https://arxiv.org/abs/2602.16861)
*EunJeong Cheon,Do Yeon Shin*

Main category: cs.RO

TL;DR: 本论文提出了“与机器人同行（WawR）”方法论，旨在研究公共空间中的自主机器人，该方法论受到城市研究、地理学和社会学中公共领域民族志的启发。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互（HRI）研究中的实地研究通常局限于受控实验或结构化观察方法，这不适用于研究在研究人员控制之外、在动态且不可预测环境中运行的自主移动机器人。因此，需要一种更审慎的方法。

Method: 本文提出了“与机器人同行（WawR）”方法论。该方法论从城市研究、地理学和社会学中的公共领域民族志中汲取灵感。论文概述了该方法的关键特征、应用步骤、独特的见解以及评估方式。

Result: 本文提出了一种新的研究方法论（WawR），并详细阐述了其特点、实施步骤、所能提供的独特见解以及如何对其进行评估。

Conclusion: 本文希望激发关于研究公共空间中自主机器人的研究方法论的进一步讨论。

Abstract: As the presence of autonomous robots in public spaces increases-whether navigating campus walkways or neighborhood sidewalks-understanding how to carefully study these robots becomes critical. While HRI research has conducted field studies in public spaces, these are often limited to controlled experiments with prototype robots or structured observational methods, such as the Wizard of Oz technique. However, the autonomous mobile robots we encounter today, particularly delivery robots, operate beyond the control of researchers, navigating dynamic routes and unpredictable environments. To address this challenge, a more deliberate approach is required. Drawing inspiration from public realm ethnography in urban studies, geography, and sociology, this paper proposes the Walk-Along with Robots (WawR) methodology. We outline the key features of this method, the steps we applied in our study, the unique insights it offers, and the ways it can be evaluated. We hope this paper stimulates further discussion on research methodologies for studying autonomous robots in public spaces.

</details>


### [197] [SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation](https://arxiv.org/abs/2602.16863)
*Kushal Kedia,Tyler Ga Wei Lum,Jeannette Bohg,C. Karen Liu*

Main category: cs.RO

TL;DR: SimToolReal提出了一种sim-to-real强化学习方法，通过在模拟中程序化生成大量工具状物体，训练一个单一策略，实现通用的灵巧工具操作，其性能优于现有方法，并具有强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 工具操作能显著扩展机器人执行任务的范围，但由于需要抓取薄物体、手内物体旋转和强力交互，这是一项具有挑战性的灵巧任务。收集这些行为的遥操作数据很困难，因此sim-to-real强化学习是一个有前景的替代方案。然而，以往的方法通常需要大量的工程投入来为每个任务建模物体和调整奖励函数。本研究旨在解决sim-to-real强化学习策略在工具操作中的泛化问题。

Method: SimToolReal方法在模拟中程序化生成各种工具状物体基元，并训练一个单一的强化学习策略，其通用目标是将每个物体操作到随机的目标姿态，从而在测试时无需任何物体或任务特定训练即可执行通用的灵巧工具操作。

Result: SimToolReal的性能比现有的重定向和固定抓取方法提高了37%，同时与针对特定目标物体和任务训练的专家强化学习策略性能相当。SimToolReal在多样化的日常工具中实现了泛化，在120次真实世界运行中（涵盖24个任务、12个物体实例和6个工具类别）取得了强大的零样本性能。

Conclusion: SimToolReal为灵巧工具操作提供了一种通用化的sim-to-real强化学习方法，消除了对物体或任务特定训练的需求，并展示了卓越和可泛化的性能。

Abstract: The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behaviors is challenging, sim-to-real reinforcement learning (RL) is a promising alternative. However, prior approaches typically require substantial engineering effort to model objects and tune reward functions for each task. In this work, we propose SimToolReal, taking a step towards generalizing sim-to-real RL policies for tool manipulation. Instead of focusing on a single object and task, we procedurally generate a large variety of tool-like object primitives in simulation and train a single RL policy with the universal goal of manipulating each object to random goal poses. This approach enables SimToolReal to perform general dexterous tool manipulation at test-time without any object or task-specific training. We demonstrate that SimToolReal outperforms prior retargeting and fixed-grasp methods by 37% while matching the performance of specialist RL policies trained on specific target objects and tasks. Finally, we show that SimToolReal generalizes across a diverse set of everyday tools, achieving strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.

</details>


### [198] [Boreas Road Trip: A Multi-Sensor Autonomous Driving Dataset on Challenging Roads](https://arxiv.org/abs/2602.16870)
*Daniil Lisus,Katya M. Papais,Cedric Le Gentil,Elliot Preston-Krebs,Andrew Lambert,Keith Y.K. Leung,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: Boreas-RT数据集扩展了Boreas数据集，包含了60个序列和643公里多样化路线的数据，配备多模态传感器和厘米级真值。基准测试显示，现有最先进的算法在Boreas-RT的挑战性路线上性能显著下降，该数据集为多模态算法评估提供了一个统一平台。


<details>
  <summary>Details</summary>
Motivation: 现代自动驾驶算法常常在简单驾驶环境中出现过拟合。需要一个能够在新颖和多样化挑战中评估这些算法的数据集，以应对不同路况以及交通和天气变化。

Method: 该论文介绍了Boreas Road Trip (Boreas-RT) 数据集。
- **数据采集**：在9条真实世界路线上采集了60个序列，总计643公里驾驶里程。每条路线被多次遍历，涵盖了不同的交通和天气条件。
- **传感器**：包括5MP FLIR Blackfly S相机、360度Navtech RAS6多普勒雷达、128通道360度Velodyne Alpha Prime激光雷达、Aeva Aeries II FMCW多普勒激光雷达、Silicon Sensing DMU41惯性测量单元和Dynapar车轮编码器。
- **真值**：通过后处理的Applanix POS LV GNSS-INS数据提供厘米级地面真值。
- **资源**：数据集包含精确的外参和内参校准、公开的开发工具包以及用于里程计和度量定位的实时排行榜。

Result: 基准测试结果表明，许多最先进的里程计和定位算法对简单的驾驶环境存在过拟合，在更具挑战性的Boreas-RT路线上性能显著下降。Boreas-RT数据集为评估多模态算法在多样化路况下的性能提供了一个统一的数据集。

Conclusion: Boreas-RT是一个评估多模态自动驾驶算法在挑战性和多样化环境中性能的宝贵数据集，它揭示了当前最先进方法的局限性，并为未来的开发和基准测试提供了一个平台。

Abstract: The Boreas Road Trip (Boreas-RT) dataset extends the multi-season Boreas dataset to new and diverse locations that pose challenges for modern autonomous driving algorithms. Boreas-RT comprises 60 sequences collected over 9 real-world routes, totalling 643 km of driving. Each route is traversed multiple times, enabling evaluation in identical environments under varying traffic and, in some cases, weather conditions. The data collection platform includes a 5MP FLIR Blackfly S camera, a 360 degree Navtech RAS6 Doppler-enabled spinning radar, a 128-channel 360 degree Velodyne Alpha Prime lidar, an Aeva Aeries II FMCW Doppler-enabled lidar, a Silicon Sensing DMU41 inertial measurement unit, and a Dynapar wheel encoder. Centimetre-level ground truth is provided via post-processed Applanix POS LV GNSS-INS data. The dataset includes precise extrinsic and intrinsic calibrations, a publicly available development kit, and a live leaderboard for odometry and metric localization. Benchmark results show that many state-of-the-art odometry and localization algorithms overfit to simple driving environments and degrade significantly on the more challenging Boreas-RT routes. Boreas-RT provides a unified dataset for evaluating multi-modal algorithms across diverse road conditions. The dataset, leaderboard, and development kit are available at .

</details>


### [199] [MALLVI: a multi agent framework for integrated generalized robotics manipulation](https://arxiv.org/abs/2602.16898)
*Iman Ahmadi,Mehrshad Taji,Arad Mahdinezhad Kashani,AmirHossein Jadidi,Saina Kashani,Babak Khalaj*

Main category: cs.RO

TL;DR: MALLVi是一个闭环多智能体LLM+视觉框架，通过Decomposer、Localizer、Thinker、Reflector等协同工作，实现鲁棒的机器人操作任务规划，相比传统开环方法，显著提高了零样本任务的成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLMs）的机器人操作任务规划方法依赖于专业模型、微调或提示调优，并且通常以开环方式运行，缺乏鲁棒的环境反馈，这使得它们在动态环境中表现脆弱。

Method: MALLVi是一个多智能体大语言和视觉框架，它接收自然语言指令和环境图像。它生成可执行的原子动作，并通过视觉语言模型（VLM）评估环境反馈，以决定是重复过程还是继续下一步。MALLVi协调专门的智能体：Decomposer（分解器）、Localizer（定位器）、Thinker（思考者）和Reflector（反射器），分别管理感知、定位、推理和高级规划。可选的Descriptor（描述器）智能体提供初始状态的视觉记忆。Reflector智能体通过仅重新激活相关智能体来支持有针对性的错误检测和恢复。

Result: 在模拟和真实世界环境中的实验表明，迭代闭环多智能体协调提高了泛化能力，并增加了零样本操作的成功率。

Conclusion: MALLVi通过迭代闭环的多智能体协调，提高了泛化能力，并显著提升了零样本操作的成功率。它通过协调专门的智能体来管理感知、定位、推理和高级规划，并支持有针对性的错误检测和恢复。

Abstract: Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic present MALLVi, a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation available at .

</details>


### [200] [SparTa: Sparse Graphical Task Models from a Handful of Demonstrations](https://arxiv.org/abs/2602.16911)
*Adrian Röfer,Nick Heppert,Abhinav Valada*

Main category: cs.RO

TL;DR: 本研究提出了一种基于图形对象关系的方法，通过演示分割和池化来学习长时程机器人操作任务的语义表示，并在仿真和真实机器人上验证了其可靠性。


<details>
  <summary>Details</summary>
Motivation: 高效地学习长时程操作任务是机器人从演示中学习的核心挑战。该研究侧重于推断机器人应该在任务中实现什么（即目标），而非如何实现（即动作），以应对这一挑战。

Method: 该方法通过一系列图形化对象关系表示场景状态。它提出了一个演示分割和池化方法，用于提取一系列操作图并估计跨任务阶段的对象状态分布。与现有方法不同，该方法捕获从控制开始到操作结束的完整对象交互。为提高从多个演示中学习的鲁棒性，还使用预训练的视觉特征进行对象匹配。

Result: 在广泛的实验中，该研究评估了其方法的演示分割准确性以及从多个演示中学习以找到所需最小任务模型的效用。最终，部署在仿真和真实机器人上的拟合模型，展示了所产生的任务表示支持跨环境的可靠执行。

Conclusion: 该研究证明了其任务表示能够支持在不同环境中进行可靠的机器人操作执行。

Abstract: Learning long-horizon manipulation tasks efficiently is a central challenge in robot learning from demonstration. Unlike recent endeavors that focus on directly learning the task in the action domain, we focus on inferring what the robot should achieve in the task, rather than how to do so. To this end, we represent evolving scene states using a series of graphical object relationships. We propose a demonstration segmentation and pooling approach that extracts a series of manipulation graphs and estimates distributions over object states across task phases. In contrast to prior graph-based methods that capture only partial interactions or short temporal windows, our approach captures complete object interactions spanning from the onset of control to the end of the manipulation. To improve robustness when learning from multiple demonstrations, we additionally perform object matching using pre-trained visual features. In extensive experiments, we evaluate our method's demonstration segmentation accuracy and the utility of learning from multiple demonstrations for finding a desired minimal task model. Finally, we deploy the fitted models both in simulation and on a real robot, demonstrating that the resulting task representations support reliable execution across environments.

</details>


### [201] [Benchmarking the Effects of Object Pose Estimation and Reconstruction on Robotic Grasping Success](https://arxiv.org/abs/2602.17101)
*Varun Burde,Pavel Burget,Torsten Sattler*

Main category: cs.RO

TL;DR: 该论文引入了一个大规模的、基于物理的基准，用于评估6D姿态估计器和3D网格模型在抓取功能效用方面的表现。研究发现，重建伪影显著减少了抓取姿态候选数量，但在姿态估计准确的情况下，对抓取性能的影响可以忽略不计。抓取成功与姿态误差的关系主要由空间误差决定，即使是简单的平移误差也能为对称物体的抓取姿态成功提供洞察。


<details>
  <summary>Details</summary>
Motivation: 现有的3D重建方法在视觉和几何上表现出色，但标准的几何评估未能反映重建质量对机器人操作等下游任务的影响。

Method: 引入了一个大规模、基于物理的基准，通过在各种重建的3D网格上生成抓取，并在真实模型上执行这些抓取，来评估6D姿态估计器和3D网格模型在抓取功能效用方面的表现。这模拟了不完美模型生成的抓取姿态如何影响与真实物体的交互，评估了姿态误差、抓取鲁棒性和3D重建几何不准确性的综合影响。

Result: 重建伪影显著减少了抓取姿态候选的数量，但在给定准确估计的姿态时，对抓取性能的影响可以忽略不计。抓取成功与姿态误差之间的关系主要由空间误差决定，即使是简单的平移误差也能为对称物体的抓取姿态成功提供洞察。

Conclusion: 这项工作为感知系统如何与机器人操纵物体相关联提供了深入见解。

Abstract: 3D reconstruction serves as the foundational layer for numerous robotic perception tasks, including 6D object pose estimation and grasp pose generation. Modern 3D reconstruction methods for objects can produce visually and geometrically impressive meshes from multi-view images, yet standard geometric evaluations do not reflect how reconstruction quality influences downstream tasks such as robotic manipulation performance. This paper addresses this gap by introducing a large-scale, physics-based benchmark that evaluates 6D pose estimators and 3D mesh models based on their functional efficacy in grasping. We analyze the impact of model fidelity by generating grasps on various reconstructed 3D meshes and executing them on the ground-truth model, simulating how grasp poses generated with an imperfect model affect interaction with the real object. This assesses the combined impact of pose error, grasp robustness, and geometric inaccuracies from 3D reconstruction. Our results show that reconstruction artifacts significantly decrease the number of grasp pose candidates but have a negligible effect on grasping performance given an accurately estimated pose. Our results also reveal that the relationship between grasp success and pose error is dominated by spatial error, and even a simple translation error provides insight into the success of the grasping pose of symmetric objects. This work provides insight into how perception systems relate to object manipulation using robots.

</details>


### [202] [Grasp Synthesis Matching From Rigid To Soft Robot Grippers Using Conditional Flow Matching](https://arxiv.org/abs/2602.17110)
*Tanisha Parulekar,Ge Shi,Josh Pinskier,David Howard,Jen Jen Chung*

Main category: cs.RO

TL;DR: 本文提出了一种利用条件流匹配（CFM）模型将刚性夹持器的抓取姿态映射到软性夹持器的新框架，该框架通过深度图像条件化，实现了对已知和未知物体更高的抓取成功率，并能有效泛化。


<details>
  <summary>Details</summary>
Motivation: 刚性夹持器和软性夹持器之间的抓取合成存在表征差距。Anygrasp及许多其他抓取合成方法是为刚性平行夹持器设计的，将其应用于软性夹持器通常无法捕捉其独特的柔顺行为，导致数据密集且不准确的模型。为了弥补这一差距，本文旨在提出一种有效的方法。

Method: 该论文提出了一种新颖的框架，用于将刚性夹持器的抓取姿态映射到软性Fin-ray夹持器。它利用条件流匹配（CFM）这一生成模型来学习这种复杂的转换。方法包括一个数据收集管道，用于生成成对的刚性-软性抓取姿态。一个U-Net自编码器根据来自深度图像的物体几何形状对CFM模型进行条件化，使其能够学习从初始Anygrasp姿态到稳定的Fin-ray夹持器姿态的连续映射。

Result: 在7自由度机器人上的验证表明，与基线刚性姿态（已知物体6%，未知物体25%）相比，CFM生成的姿态在软性夹持器执行时，对已知和未知物体分别达到了更高的总体成功率（34%和46%）。该模型在圆柱形物体（已知物体50%，未知物体100%成功）和球形物体（已知物体25%，未知物体31%成功）上显示出显著改进，并成功泛化到未知物体。

Conclusion: 这项工作表明，条件流匹配（CFM）是一种数据高效且有效的方法，用于转移抓取策略，为其他软机器人系统提供了一种可扩展的方法。

Abstract: A representation gap exists between grasp synthesis for rigid and soft grippers. Anygrasp [1] and many other grasp synthesis methods are designed for rigid parallel grippers, and adapting them to soft grippers often fails to capture their unique compliant behaviors, resulting in data-intensive and inaccurate models. To bridge this gap, this paper proposes a novel framework to map grasp poses from a rigid gripper model to a soft Fin-ray gripper. We utilize Conditional Flow Matching (CFM), a generative model, to learn this complex transformation. Our methodology includes a data collection pipeline to generate paired rigid-soft grasp poses. A U-Net autoencoder conditions the CFM model on the object's geometry from a depth image, allowing it to learn a continuous mapping from an initial Anygrasp pose to a stable Fin-ray gripper pose. We validate our approach on a 7-DOF robot, demonstrating that our CFM-generated poses achieve a higher overall success rate for seen and unseen objects (34% and 46% respectively) compared to the baseline rigid poses (6% and 25% respectively) when executed by the soft gripper. The model shows significant improvements, particularly for cylindrical (50% and 100% success for seen and unseen objects) and spherical objects (25% and 31% success for seen and unseen objects), and successfully generalizes to unseen objects. This work presents CFM as a data-efficient and effective method for transferring grasp strategies, offering a scalable methodology for other soft robotic systems.

</details>


### [203] [Physical Human-Robot Interaction for Grasping in Augmented Reality via Rigid-Soft Robot Synergy](https://arxiv.org/abs/2602.17128)
*Huishi Huang,Jack Klusmann,Haozhe Wang,Shuchen Ji,Fengkang Ying,Yiyuan Zhang,John Nassour,Gordon Cheng,Daniela Rus,Jun Liu,Marcelo H Ang Jr,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本研究提出了一种基于增强现实（AR）的交互框架，以实现混合刚柔机器人的直接遥操作，并通过实物到仿真参数识别解决了建模和控制一致性问题。


<details>
  <summary>Details</summary>
Motivation: 混合刚柔机器人在非结构化环境中进行通用抓取具有前景，但由于建模、感知和跨域运动学方面的困难，协调此类机器人仍然具有挑战性。

Method: 本研究提出了一种基于增强现实（AR）的物理人机交互框架。该框架允许用户通过AR头显与机器人系统的模拟模型进行交互，该模型叠加在真实系统上，并集成到通用物理引擎中，从而在实际部署前进行模拟执行。为确保虚拟和物理机器人行为一致性，引入了一个实物到仿真参数识别流程，利用软机器人固有的几何特性，以精确建模其静态、动态行为和控制系统响应。

Result: 本研究开发了一个AR人机交互框架，实现了混合刚柔机器人简单抓取任务的直接遥操作。通过参数识别流程，确保了虚拟和物理机器人行为的一致性，从而在实际部署前能进行可靠的模拟执行。

Conclusion: 本研究提出了一种增强现实（AR）人机交互框架，通过虚拟与物理机器人的一致行为确保了混合刚柔机器人的直接遥操作，为在非结构化环境中实现多功能抓取提供了一种有前景的解决方案。

Abstract: Hybrid rigid-soft robots combine the precision of rigid manipulators with the compliance and adaptability of soft arms, offering a promising approach for versatile grasping in unstructured environments. However, coordinating hybrid robots remains challenging, due to difficulties in modeling, perception, and cross-domain kinematics. In this work, we present a novel augmented reality (AR)-based physical human-robot interaction framework that enables direct teleoperation of a hybrid rigid-soft robot for simple reaching and grasping tasks. Using an AR headset, users can interact with a simulated model of the robotic system integrated into a general-purpose physics engine, which is superimposed on the real system, allowing simulated execution prior to real-world deployment. To ensure consistent behavior between the virtual and physical robots, we introduce a real-to-simulation parameter identification pipeline that leverages the inherent geometric properties of the soft robot, enabling accurate modeling of its static and dynamic behavior as well as the control system's response.

</details>


### [204] [Geometric Inverse Flight Dynamics on SO(3) and Application to Tethered Fixed-Wing Aircraft](https://arxiv.org/abs/2602.17166)
*Antonio Franchi,Chiara Gabellieri*

Main category: cs.RO

TL;DR: 该论文提出了一种机器人导向的固定翼飞机SO(3)逆飞行动力学无坐标公式，用于轨迹设计和可行性检查。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过连接航空学中的逆仿真与机器人学中的几何建模，为轨迹设计和可行性检查提供一个严谨的基础构建模块。

Method: 该方法提出了固定翼飞机在SO(3)上的逆飞行动力学无坐标公式。它在世界坐标系中描述平移力平衡，在机体坐标系中描述旋转动力学，并几何定义气动方向以避免局部姿态坐标。通过强制协调飞行（无侧滑），推导出一个闭合形式的轨迹到输入映射，该映射可产生姿态、角速度以及推力-迎角对。该方法应用于球形平行线上的系留飞行，以获得所需倾斜角的解析表达式并识别零倾斜轨迹。

Result: 研究结果包括一个闭合形式的轨迹到输入映射，能够得到姿态、角速度和推力-迎角对，并分量恢复气动转矩系数。在系留飞行中，获得了所需倾斜角的解析表达式，并识别了一个特定的零倾斜轨迹，其中系绳张力恰好平衡离心效应，突出了气动协调与表观重力矢量之间的解耦。在简单的升力/阻力定律下，最小推力迎角具有闭合形式。当轨迹和旋转动力学是时不变时，这些逐点准稳态反演解成为稳态飞行配平。

Conclusion: 该框架将航空学中的逆仿真与机器人学中的几何建模相结合，为轨迹设计和可行性检查提供了严谨的基础构建模块。

Abstract: We present a robotics-oriented, coordinate-free formulation of inverse flight dynamics for fixed-wing aircraft on SO(3). Translational force balance is written in the world frame and rotational dynamics in the body frame; aerodynamic directions (drag, lift, side) are defined geometrically, avoiding local attitude coordinates. Enforcing coordinated flight (no sideslip), we derive a closed-form trajectory-to-input map yielding the attitude, angular velocity, and thrust-angle-of-attack pair, and we recover the aerodynamic moment coefficients component-wise. Applying such a map to tethered flight on spherical parallels, we obtain analytic expressions for the required bank angle and identify a specific zero-bank locus where the tether tension exactly balances centrifugal effects, highlighting the decoupling between aerodynamic coordination and the apparent gravity vector. Under a simple lift/drag law, the minimal-thrust angle of attack admits a closed form. These pointwise quasi-steady inversion solutions become steady-flight trim when the trajectory and rotational dynamics are time-invariant. The framework bridges inverse simulation in aeronautics with geometric modeling in robotics, providing a rigorous building block for trajectory design and feasibility checks.

</details>


### [205] [Nonlinear Predictive Control of the Continuum and Hybrid Dynamics of a Suspended Deformable Cable for Aerial Pick and Place](https://arxiv.org/abs/2602.17199)
*Antonio Rapuano,Yaolei Shen,Federico Califano,Chiara Gabellieri,Antonio Franchi*

Main category: cs.RO

TL;DR: 本文提出一个结合高精度PDE模型与降阶模型的空中可伸缩缆绳操作框架，并通过非线性模型预测控制实现无人机携带柔性缆绳的实时动态感知控制。


<details>
  <summary>Details</summary>
Motivation: 实现无人机携带柔性缆绳的实时动态感知控制，解决传统高精度模型计算复杂性高的问题。

Method: 1. 提出一个结合偏微分方程（PDE）高保真模型和降阶（ROM）表示的框架。2. 使用有限差分法对PDE进行离散化。3. 采用本征正交分解（POD）提取降阶模型，以降低计算复杂性。4. 基于ROM构建非线性模型预测控制方案，用于稳定缆绳振荡并处理载荷连接/分离等混合过渡。

Result: 1. 仿真结果证实了ROM的稳定性、效率和鲁棒性。2. 控制器在各种操作条件下调节缆绳动态的有效性。3. ROM在受限环境中轨迹规划的应用展示了该方法的通用性。

Conclusion: 该框架能够实现无人机携带悬挂柔性缆绳的实时、动态感知控制。

Abstract: This paper presents a framework for aerial manipulation of an extensible cable that combines a high-fidelity model based on partial differential equations (PDEs) with a reduced-order representation suitable for real-time control. The PDEs are discretised using a finite-difference method, and proper orthogonal decomposition is employed to extract a reduced-order model (ROM) that retains the dominant deformation modes while significantly reducing computational complexity. Based on this ROM, a nonlinear model predictive control scheme is formulated, capable of stabilizing cable oscillations and handling hybrid transitions such as payload attachment and detachment. Simulation results confirm the stability, efficiency, and robustness of the ROM, as well as the effectiveness of the controller in regulating cable dynamics under a range of operating conditions. Additional simulations illustrate the application of the ROM for trajectory planning in constrained environments, demonstrating the versatility of the proposed approach. Overall, the framework enables real-time, dynamics-aware control of unmanned aerial vehicles (UAVs) carrying suspended flexible cables.

</details>


### [206] [Multi-session Localization and Mapping Exploiting Topological Information](https://arxiv.org/abs/2602.17226)
*Lorenzo Montano-Olivan,Julio A. Placed,Luis Montano,Maria T. Lazaro*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的多会话框架，用于在重复访问的环境中进行基于地图的定位。该框架采用拓扑感知、不确定性感知的决策机制，分析位姿图结构以检测低连通性区域，并选择性地触发建图和闭环模块。最终的地图和位姿图无缝集成到现有模型中，减少累积误差并增强全局一致性。


<details>
  <summary>Details</summary>
Motivation: 在已访问过的环境中运行对于自动驾驶、测量、仓储或家用机器人等自主系统变得越来越重要。然而，重复暴露于相同的区域对建图和定位（实现任何更高级任务的关键组成部分）提出了重大挑战。传统方法是贪婪地运行完整的SLAM会话并尝试在生成的地图之间找到对应关系，但这效率不高。

Method: 提出了一种新颖的多会话框架，该框架建立在基于地图的定位之上，与通常贪婪运行完整SLAM会话并尝试在生成地图之间寻找对应关系的做法不同。该方法结合了拓扑感知、不确定性感知的决策机制，该机制分析位姿图结构以检测低连通性区域，选择性地触发建图和闭环模块。生成的地图和位姿图无缝集成到现有模型中。

Result: 减少了累积误差，增强了全局一致性。

Conclusion: 该方法在数据集的重叠序列上进行了验证，并在真实的类矿井环境中展示了其有效性。

Abstract: Operating in previously visited environments is becoming increasingly crucial for autonomous systems, with direct applications in autonomous driving, surveying, and warehouse or household robotics. This repeated exposure to observing the same areas poses significant challenges for mapping and localization -- key components for enabling any higher-level task. In this work, we propose a novel multi-session framework that builds on map-based localization, in contrast to the common practice of greedily running full SLAM sessions and trying to find correspondences between the resulting maps. Our approach incorporates a topology-informed, uncertainty-aware decision-making mechanism that analyzes the pose-graph structure to detect low-connectivity regions, selectively triggering mapping and loop closing modules. The resulting map and pose-graph are seamlessly integrated into the existing model, reducing accumulated error and enhancing global consistency. We validate our method on overlapping sequences from datasets and demonstrate its effectiveness in a real-world mine-like environment.

</details>


### [207] [FRAPPE: Infusing World Modeling into Generalist Policies via Multiple Future Representation Alignment](https://arxiv.org/abs/2602.17259)
*Han Zhao,Jingbo Wang,Wenxuan Song,Shuai Chen,Yang Liu,Yan Wang,Haoang Li,Donglin Wang*

Main category: cs.RO

TL;DR: FRAPPE通过两阶段微调策略，预测未来观测的潜在表示并与多个视觉基础模型对齐，从而解决VLA世界建模中像素级重建过度强调和推理误差累积的问题，显著提升了泛化能力和数据效率。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在世界建模方面存在两个主要问题：1. 训练目标过分强调像素级重建，限制了语义学习和泛化能力。2. 推理时过度依赖预测的未来观测会导致误差累积。

Method: 本文引入了未来表示对齐的并行渐进扩展（FRAPPE）方法。该方法采用两阶段微调策略：在训练中期，模型学习预测未来观测的潜在表示；在训练后期，并行扩展计算工作量，并同时与多个不同的视觉基础模型对齐表示。

Result: 实验表明，FRAPPE在RoboTwin基准测试和真实世界任务中均优于现有最先进的方法，并在长时程和未见场景中展现出强大的泛化能力。

Conclusion: FRAPPE提供了一种可扩展且数据高效的途径，通过显著提高微调效率并减少对动作标注数据的依赖，增强通用机器人策略的世界感知能力。

Abstract: Enabling VLA models to predict environmental dynamics, known as world modeling, has been recognized as essential for improving robotic reasoning and generalization. However, current approaches face two main issues: 1. The training objective forces models to over-emphasize pixel-level reconstruction, which constrains semantic learning and generalization 2. Reliance on predicted future observations during inference often leads to error accumulation. To address these challenges, we introduce Future Representation Alignment via Parallel Progressive Expansion (FRAPPE). Our method adopts a two-stage fine-tuning strategy: In the mid-training phase, the model learns to predict the latent representations of future observations; In the post-training phase, we expand the computational workload in parallel and align the representation simultaneously with multiple different visual foundation models. By significantly improving fine-tuning efficiency and reducing dependence on action-annotated data, FRAPPE provides a scalable and data-efficient pathway to enhance world-awareness in generalist robotic policies. Experiments on the RoboTwin benchmark and real-world tasks demonstrate that FRAPPE outperforms state-of-the-art approaches and shows strong generalization in long-horizon and unseen scenarios.

</details>


### [208] [Contact-Anchored Proprioceptive Odometry for Quadruped Robots](https://arxiv.org/abs/2602.17393)
*Minxing Sun,Yao Mao*

Main category: cs.RO

TL;DR: 本文提出了一种纯本体感知的状态估计器，仅使用IMU和电机测量来联合估计腿式机器人的身体姿态和速度。该方法将接触腿视为运动学锚点，通过基于关节扭矩的足部力矩估计选择可靠接触，并利用足部落地位置提供间歇性的世界坐标系约束以抑制长期漂移。为防止高程漂移，引入了轻量级高度聚类和时间衰减校正。为改善编码器量化下的足部速度观测，应用了逆运动学容积卡尔曼滤波器。在四种四足机器人平台上进行了评估，并在闭环轨迹中取得了较好的测程精度。


<details>
  <summary>Details</summary>
Motivation: 在没有摄像头或激光雷达的情况下，腿式机器人可靠的里程计仍然具有挑战性，这主要是由于IMU漂移和关节速度测量噪声。

Method: 本文提出了一种纯本体感知状态估计器，仅利用IMU和电机测量来联合估计身体姿态和速度，并适用于双足、四足和轮腿机器人。核心思想是将每个接触的腿视为运动学锚点：通过基于关节扭矩的足部力矩估计来选择可靠的接触点，相应的足部落地位置提供间歇性的世界坐标系约束以抑制长期漂移。为防止长时间行进中的高程漂移，引入了轻量级高度聚类和时间衰减校正，将新记录的足部落地高度与之前观测到的支撑平面进行对齐。为改善编码器量化下的足部速度观测，应用了逆运动学容积卡尔曼滤波器，直接从关节角度和速度中过滤足端速度。该实现还通过多接触几何一致性减轻了偏航漂移，并在IMU偏航约束不可用或不可靠时，能平稳地退化为运动学导出的航向参考。

Result: 该方法在四种四足机器人平台（三台Astrall机器人和一台Unitree Go2 EDU）上使用闭环轨迹进行了评估。在Astrall点足机器人A上，约200米水平环线和约15米垂直环线的误差分别为0.1638米和0.219米；在轮腿机器人B上，相应误差为0.2264米和0.199米。在轮腿机器人C上，约700米水平环线产生7.68米误差，约20米垂直环线产生0.540米误差。Unitree Go2 EDU在约120米水平环线上的误差为2.2138米，在约8米垂直环线上的垂直误差小于0.1米。

Conclusion: 本文提出的纯本体感知状态估计器通过利用运动学锚点、足部落地约束和先进的滤波技术，有效解决了腿式机器人的里程计挑战，并在多种机器人平台上的水平和垂直轨迹中展现出良好的精度。

Abstract: Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents a purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with a unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as a kinematic anchor: joint-torque--based foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce a lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to a kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and a Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot~A, a $\sim$200\,m horizontal loop and a $\sim$15\,m vertical loop return with 0.1638\,m and 0.219\,m error, respectively; on wheel-legged robot~B, the corresponding errors are 0.2264\,m and 0.199\,m. On wheel-legged robot~C, a $\sim$700\,m horizontal loop yields 7.68\,m error and a $\sim$20\,m vertical loop yields 0.540\,m error. Unitree Go2 EDU closes a $\sim$120\,m horizontal loop with 2.2138\,m error and a $\sim$8\,m vertical loop with less than 0.1\,m vertical error.

</details>


### [209] [3D-printed Soft Optical sensor with a Lens (SOLen) for light guidance in mechanosensing](https://arxiv.org/abs/2602.17421)
*Diana Cafiso,Petr Trunin,Carolina Gay,Lucia Beccai*

Main category: cs.RO

TL;DR: 该论文提出了一种名为SOLen的3D打印软光学传感方法，通过变形引起的透镜旋转和焦点平移，实现单材料、一步制造的软体机器人传感，并展示了其可重复的信号切换能力。


<details>
  <summary>Details</summary>
Motivation: 随着增材制造技术使软体机器人能够实现日益复杂的几何形状，对兼容单材料、一步制造的传感解决方案的需求不断增加。尽管光学软传感器在整体打印方面具有吸引力，但其性能常因不受控的光传播（如环境耦合、泄漏、散射）而下降。此外，传统的缓解这些问题的策略通常需要多材料界面，这与单材料制造的需求不符。

Method: 该论文提出了一种名为SOLen的3D打印软光学传感方法。其核心是将一个打印透镜放置在Y形波导内发射器前方。传感机制依赖于变形引起的透镜旋转和焦点平移，从而在两个分支间重新分配光功率，产生编码运动方向和幅度的差分输出。为优化材料性能，研究人员用月桂基丙烯酸酯改性了丙烯酸酯聚氨酯树脂，以提高柔顺性和光学透过率。通过单层光学表征，获得了波长相关的折射率和透过率，并最小化DLP层相关伪影。利用测得的折射率进行模拟，设计出具有亚毫米精度打印的透镜轮廓。

Result: 旋转测试表明，该传感器在多个周期内实现了可重复的分支选择性信号切换。

Conclusion: 这些结果为带透镜的软光学传感器建立了一个可转移的“材料到光学”工作流程，为下一代软体机器人提供了新功能。

Abstract: Additive manufacturing is enabling soft robots with increasingly complex geometries, creating a demand for sensing solutions that remain compatible with single-material, one-step fabrication. Optical soft sensors are attractive for monolithic printing, but their performance is often degraded by uncontrolled light propagation (ambient coupling, leakage, scattering), while common miti- gation strategies typically require multimaterial interfaces. Here, we present an approach for 3D printed soft optical sensing (SOLen), in which a printed lens is placed in front of an emitter within a Y-shaped waveguide. The sensing mechanism relies on deformation-induced lens rotation and focal-spot translation, redistributing optical power between the two branches to generate a differential output that encodes both motion direction and amplitude. An acrylate polyurethane resin was modified with lauryl acrylate to improve compliance and optical transmittance, and single-layer optical characterization was used to derive wavelength-dependent refractive index and transmittance while minimizing DLP layer-related artifacts. The measured refractive index was used in simulations to design a lens profile for a target focal distance, which was then printed with sub-millimeter fidelity. Rotational tests demonstrated reproducible branch-selective signal switching over multiple cycles. These results establish a transferable material-to-optics workflow for soft optical sensors with lens with new functionalities for next-generation soft robots

</details>


### [210] [A Cost-Effective and Climate-Resilient Air Pressure System for Rain Effect Reduction on Automated Vehicle Cameras](https://arxiv.org/abs/2602.17472)
*Mohamed Sabry,Joseba Gorospe,Cristina Olaverri-Monreal*

Main category: cs.RO

TL;DR: 本文提出了一种经济高效、与多摄像头兼容的硬件解决方案，用于改善雨天条件下自动驾驶汽车的感知性能，并将行人检测准确率从8.3%提高到41.6%。


<details>
  <summary>Details</summary>
Motivation: 尽管自动驾驶汽车在恶劣天气条件下的感知性能有所提升，但物理硬件解决方案的研究仍然有限，而现有解决方案（如亲水/疏水透镜和喷雾）只能提供部分缓解，工业保护系统成本高昂且不适用于汽车部署。

Method: 本文提出了一种经济高效的硬件解决方案，可在雨天条件下同时兼容多个摄像头。该方案通过物理硬件改进，以提高感知性能。

Result: 所提出的系统将深度学习模型对行人检测的准确率从8.3%提高到41.6%。

Conclusion: 该系统通过与现有基于摄像头的传感平台兼容，延长了自动驾驶汽车的操作可靠性，降低了资源消耗，支持模块化升级，并促进了自动驾驶技术在恶劣天气条件下的成本效益部署。

Abstract: Recent advances in automated vehicles have focused on improving perception performance under adverse weather conditions; however, research on physical hardware solutions remains limited, despite their importance for perception critical applications such as vehicle platooning. Existing approaches, such as hydrophilic or hydrophobic lenses and sprays, provide only partial mitigation, while industrial protection systems imply high cost and they do not enable scalability for automotive deployment. To address these limitations, this paper presents a cost-effective hardware solution for rainy conditions, designed to be compatible with multiple cameras simultaneously. Beyond its technical contribution, the proposed solution supports sustainability goals in transportation systems. By enabling compatibility with existing camera-based sensing platforms, the system extends the operational reliability of automated vehicles without requiring additional high-cost sensors or hardware replacements. This approach reduces resource consumption, supports modular upgrades, and promotes more cost-efficient deployment of automated vehicle technologies, particularly in challenging weather conditions where system failures would otherwise lead to inefficiencies and increased emissions. The proposed system was able to increase pedestrian detection accuracy of a Deep Learning model from 8.3% to 41.6%.

</details>


### [211] [Optically Sensorized Electro-Ribbon Actuator (OS-ERA)](https://arxiv.org/abs/2602.17474)
*Carolina Gay,Petr Trunin,Diana Cafiso,Yuejun Xu,Majid Taghavi,Lucia Beccai*

Main category: cs.RO

TL;DR: OS-ERA是一种光学传感化的电驱动柔性致动器（ERA），它通过嵌入式光学波导传感器提供可靠的本体感受信息，从而实现高精度的弯曲状态分类，解决了ERA长期存在的传感瓶颈，并为闭环控制铺平道路。


<details>
  <summary>Details</summary>
Motivation: 电驱动柔性致动器（ERA）具有超高位移和快速运动的特点，但其嵌入式传感依赖于精度有限的电容式传感器，这阻碍了精确控制。

Method: 引入了OS-ERA，这是一种光学传感化的ERA。设计并嵌入了两个软光学波导传感器来分析ERA运动中的复杂曲率，同时不影响其驱动。训练了一个分类器，将传感信号映射以区分八种弯曲状态。

Result: 传感输出信号遵循训练流形，预测序列与实际性能一致并证实了可重复性。尽管存在驱动速度上的训练-测试不匹配，信号轨迹仍保持其形状，分类结果始终准确，显示出实际的电压和速度不变性。因此，OS-ERA能以高保真度对弯曲状态进行分类，它快速且可重复。

Conclusion: OS-ERA解决了ERA长期存在的传感瓶颈，实现了高精度、快速、可重复的弯曲状态分类，从而向闭环控制迈出了重要一步。

Abstract: Electro-Ribbon Actuators (ERAs) are lightweight flexural actuators that exhibit ultrahigh displacement and fast movement. However, their embedded sensing relies on capacitive sensors with limited precision, which hinders accurate control. We introduce OS-ERA, an optically sensorized ERA that yields reliable proprioceptive information, and we focus on the design and integration of a sensing solution without affecting actuation. To analyse the complex curvature of an ERA in motion, we design and embed two soft optical waveguide sensors. A classifier is trained to map the sensing signals in order to distinguish eight bending states. We validate our model on six held-out trials and compare it against signals' trajectories learned from training runs. Across all tests, the sensing output signals follow the training manifold, and the predicted sequence mirrors real performance and confirms repeatability. Despite deliberate train-test mismatches in actuation speed, the signal trajectories preserve their shape, and classification remains consistently accurate, demonstrating practical voltage- and speed-invariance. As a result, OS-ERA classifies bending states with high fidelity; it is fast and repeatable, solving a longstanding bottleneck of the ERA, enabling steps toward closed-loop control.

</details>


### [212] [Proximal powered knee placement: a case study](https://arxiv.org/abs/2602.17502)
*Kyle R. Embry,Lorenzo Vianello,Jim Lipsey,Frank Ursetta,Michael Stephens,Zhi Wang,Ann M. Simon,Andrea J. Ikeda,Suzanne B. Finucane,Shawana Anarwala,Levi J. Hargrove*

Main category: cs.RO

TL;DR: 本研究探讨了动力假肢膝盖的膝上动力总成放置，发现其能提高步行速度和步频，并具有功能可行性，表明优化质量分布可缓解附加重量带来的负面影响。


<details>
  <summary>Details</summary>
Motivation: 动力假肢膝盖的附加质量可能会降低其改善步态和提高步行速度的益处，并可能增加代谢成本。因此，研究旨在探索优化质量分布（而非简单地最小化总质量）是否能提供更有效的解决方案。

Method: 这项探索性研究评估了在小样本队列中，将动力假肢膝盖的动力总成放置在膝盖上方是否可行。研究将此配置与膝盖下方放置进行了比较，并测试了步行速度、步频、步态对称性、运动学指标以及在坡道和楼梯上的表现。

Result: 与膝下放置相比，膝上配置提高了步行速度（一名参与者提高9.2%）和步频（+3.6%），对步态对称性有混合影响。运动学测量显示，不同配置下膝关节运动范围和峰值速度相似。在坡道和楼梯上的额外测试证实了控制策略在多种运动任务中的稳健性。

Conclusion: 膝上动力总成放置在功能上是可行的，并且通过仔细的质量分布可以保留动力辅助的益处，同时减轻额外重量的不利影响。未来需要进一步研究以证实这些趋势并指导设计和临床建议。

Abstract: Lower limb amputation affects millions worldwide, leading to impaired mobility, reduced walking speed, and limited participation in daily and social activities. Powered prosthetic knees can partially restore mobility by actively assisting knee joint torque, improving gait symmetry, sit-to-stand transitions, and walking speed. However, added mass from powered components may diminish these benefits, negatively affecting gait mechanics and increasing metabolic cost. Consequently, optimizing mass distribution, rather than simply minimizing total mass, may provide a more effective and practical solution. In this exploratory study, we evaluated the feasibility of above-knee powertrain placement for a powered prosthetic knee in a small cohort. Compared to below-knee placement, the above-knee configuration demonstrated improved walking speed (+9.2% for one participant) and cadence (+3.6%), with mixed effects on gait symmetry. Kinematic measures indicated similar knee range of motion and peak velocity across configurations. Additional testing on ramps and stairs confirmed the robustness of the control strategy across multiple locomotion tasks. These preliminary findings suggest that above-knee placement is functionally feasible and that careful mass distribution can preserve the benefits of powered assistance while mitigating adverse effects of added weight. Further studies are needed to confirm these trends and guide design and clinical recommendations.

</details>


### [213] [IRIS: Learning-Driven Task-Specific Cinema Robot Arm for Visuomotor Motion Control](https://arxiv.org/abs/2602.17537)
*Qilong Cheng,Matthew Mackay,Ali Bereyhi*

Main category: cs.RO

TL;DR: 本文介绍了一种低成本（低于1000美元）的3D打印6自由度机器人摄像系统IRIS，它利用基于Transformer的视觉运动模仿学习（ACT），从人类演示中自主学习电影级摄像机轨迹，无需编程，并实现了高精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人摄像系统虽然能够实现超越人类能力的动态、可重复运动，但由于工业级平台的高成本和操作复杂性，其普及受到了限制。

Method: 该研究提出了智能机器人成像系统（IRIS），一个专门用于自主、学习驱动的电影运动控制的6自由度机械臂。IRIS整合了轻量级、完全3D打印的硬件设计与基于Transformer的动作分块（ACT）的目标条件视觉运动模仿学习框架。该系统通过人类演示直接学习物体感知和感知平滑的摄像机轨迹，无需显式几何编程。

Result: 该完整的平台成本低于1000美元，支持1.5公斤的有效载荷，并实现了约1毫米的重复定位精度。真实世界实验证明了准确的轨迹跟踪、可靠的自主执行以及在多种电影运动中的泛化能力。

Conclusion: IRIS通过低成本硬件和学习驱动的控制方法，克服了传统机器人摄像系统在成本和操作复杂性上的限制，实现了自主、多功能的电影级运动控制。

Abstract: Robotic camera systems enable dynamic, repeatable motion beyond human capabilities, yet their adoption remains limited by the high cost and operational complexity of industrial-grade platforms. We present the Intelligent Robotic Imaging System (IRIS), a task-specific 6-DOF manipulator designed for autonomous, learning-driven cinematic motion control. IRIS integrates a lightweight, fully 3D-printed hardware design with a goal-conditioned visuomotor imitation learning framework based on Action Chunking with Transformers (ACT). The system learns object-aware and perceptually smooth camera trajectories directly from human demonstrations, eliminating the need for explicit geometric programming. The complete platform costs under $1,000 USD, supports a 1.5 kg payload, and achieves approximately 1 mm repeatability. Real-world experiments demonstrate accurate trajectory tracking, reliable autonomous execution, and generalization across diverse cinematic motions.

</details>


### [214] [FR-GESTURE: An RGBD Dataset For Gesture-based Human-Robot Interaction In First Responder Operations](https://arxiv.org/abs/2602.17573)
*Konstantinos Foteinos,Georgios Angelidis,Aggelos Psiris,Vasileios Argyriou,Panagiotis Sarigiannidis,Georgios Th. Papadopoulos*

Main category: cs.RO

TL;DR: 创建了一个名为FR-GESTURE的首个手势识别RGBD数据集，用于第一响应者（FRs）通过手势控制无人地面车辆（UGV），并定义了评估协议和基线实验。


<details>
  <summary>Details</summary>
Motivation: 灾害日益频繁和严重，使第一响应者（FRs）的工作面临巨大挑战。人工智能和机器人解决方案有望辅助其操作。本文旨在通过手势控制无人地面车辆（UGV）来减轻FRs的工作负担。

Method: 1. 提出一个用于FRs手势控制UGV的数据集，包含12个命令。2. 这些命令的设计灵感来源于FRs现有手势、战术手语，并结合了有经验FRs的反馈进行优化。3. 数据收集过程生成了3312对RGBD图像，这些图像从2个视角和7个距离捕获。4. 定义了名为FR-GESTURE的RGBD数据集的评估协议。5. 进行了基线实验以供后续改进。

Result: 成功创建了名为FR-GESTURE的RGBD数据集，包含3312对RGBD图像，专门用于第一响应者（FRs）的手势控制无人地面车辆（UGV），据作者所知，这是该领域的首个此类数据集。同时，定义了评估协议并进行了基线实验。

Conclusion: 本文提出了首个专门用于第一响应者（FRs）手势控制无人地面车辆（UGV）的RGBD数据集（FR-GESTURE），并提供了评估协议和基线实验，旨在促进该领域的未来研究。数据集已公开可用。

Abstract: The ever increasing intensity and number of disasters make even more difficult the work of First Responders (FRs). Artificial intelligence and robotics solutions could facilitate their operations, compensating these difficulties. To this end, we propose a dataset for gesture-based UGV control by FRs, introducing a set of 12 commands, drawing inspiration from existing gestures used by FRs and tactical hand signals and refined after incorporating feedback from experienced FRs. Then we proceed with the data collection itself, resulting in 3312 RGBD pairs captured from 2 viewpoints and 7 distances. To the best of our knowledge, this is the first dataset especially intended for gesture-based UGV guidance by FRs. Finally we define evaluation protocols for our RGBD dataset, termed FR-GESTURE, and we perform baseline experiments, which are put forward for improvement. We have made data publicly available to promote future research on the domain: .

</details>


### [215] [Hybrid System Planning using a Mixed-Integer ADMM Heuristic and Hybrid Zonotopes](https://arxiv.org/abs/2602.17574)
*Joshua A. Robbins,Andrew F. Thompson,Jonah J. Glunt,Herschel C. Pangborn*

Main category: cs.RO

TL;DR: 本文提出了一种结合混合带形和新型ADMM混合整数规划启发式方法的框架，用于混合系统运动规划。该方法降低了内存复杂性，提供了更紧密的凸松弛，并提高了收敛速度，并通过自动驾驶应用进行了验证。


<details>
  <summary>Details</summary>
Motivation: 由于使用混合整数规划，混合系统的嵌入式优化规划具有挑战性，因为混合整数规划计算密集且通常对特定的数值公式敏感。

Method: 本文提出了一种混合系统运动规划框架，将混合带形（一种先进的集合表示）与一种新的交替方向乘子法（ADMM）混合整数规划启发式方法相结合。该方法利用混合带形对分段仿射（PWA）系统可达性分析进行一般性处理，并将其扩展以制定最优规划问题。

Result: 使用所提出的方法生成的集合比现有技术产生的等效集合具有更低的内存复杂性和更紧密的凸松弛。所提出的ADMM启发式方法有效利用了混合带形结构，对于以混合带形形式制定的规划问题，与现有最先进的混合整数规划启发式方法相比，实现了改进的收敛速度。该方法已成功应用于自动驾驶的行为和运动规划场景中。

Conclusion: 该框架及其方法在嵌入式混合系统优化规划方面取得了显著改进，尤其是在计算效率和适用性方面，并通过自动驾驶场景得到了验证。

Abstract: Embedded optimization-based planning for hybrid systems is challenging due to the use of mixed-integer programming, which is computationally intensive and often sensitive to the specific numerical formulation. To address that challenge, this article proposes a framework for motion planning of hybrid systems that pairs hybrid zonotopes - an advanced set representation - with a new alternating direction method of multipliers (ADMM) mixed-integer programming heuristic. A general treatment of piecewise affine (PWA) system reachability analysis using hybrid zonotopes is presented and extended to formulate optimal planning problems. Sets produced using the proposed identities have lower memory complexity and tighter convex relaxations than equivalent sets produced from preexisting techniques. The proposed ADMM heuristic makes efficient use of the hybrid zonotope structure. For planning problems formulated as hybrid zonotopes, the proposed heuristic achieves improved convergence rates as compared to state-of-the-art mixed-integer programming heuristics. The proposed methods for hybrid system planning on embedded hardware are experimentally applied in a combined behavior and motion planning scenario for autonomous driving.

</details>


### [216] [Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space](https://arxiv.org/abs/2602.17586)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: Deep-Flow是一种无监督框架，用于L4自动驾驶汽车安全关键异常检测，它利用OT-CFM和PCA稳定地估计对数似然，并通过Transformer处理多模态模糊性，在WOMD上达到0.766的AUC-ROC，并识别出传统方法忽视的分布外安全关键行为。


<details>
  <summary>Details</summary>
Motivation: L4级自动驾驶汽车（AVs）的安全验证目前面临瓶颈，因为传统的基于规则的启发式方法无法规模化检测罕见、高风险的长尾场景。

Method: 该方法名为 Deep-Flow，是一个无监督的安全关键异常检测框架。它使用最优传输条件流匹配（OT-CFM）来表征专家人类驾驶行为的连续概率密度。通过主成分分析（PCA）瓶颈将生成过程限制在低秩谱流形上，以确保运动学平滑性并实现稳定、确定性的对数似然估计。为解决复杂路口的多模态模糊性，采用具有车道感知目标条件的早期融合Transformer编码器，并带有直接跳跃连接到流头以保持意图完整性。在无仿真训练过程中，引入了运动学复杂性加权方案，优先处理高能量机动（通过路径曲折度和急动度量化）。

Result: 在Waymo开放运动数据集（WOMD）上进行评估，该框架针对安全关键事件的启发式黄金集实现了0.766的AUC-ROC。分析揭示了运动学危险和语义不合规之间的根本区别。Deep-Flow通过发现传统安全过滤器忽视的分布外行为（例如，车道边界违规和非规范路口操作），识别了一个关键的可预测性差距。

Conclusion: 这项工作为定义统计安全门提供了数学上严谨的基础，从而为自动驾驶车队的部署实现客观、数据驱动的验证。

Abstract: Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilizes Optimal Transport Conditional Flow Matching (OT-CFM) to characterize the continuous probability density of expert human driving behavior. Unlike standard generative approaches that operate in unstable, high-dimensional coordinate spaces, Deep-Flow constrains the generative process to a low-rank spectral manifold via a Principal Component Analysis (PCA) bottleneck. This ensures kinematic smoothness by design and enables the computation of the exact Jacobian trace for numerically stable, deterministic log-likelihood estimation. To resolve multi-modal ambiguity at complex junctions, we utilize an Early Fusion Transformer encoder with lane-aware goal conditioning, featuring a direct skip-connection to the flow head to maintain intent-integrity throughout the network. We introduce a kinematic complexity weighting scheme that prioritizes high-energy maneuvers (quantified via path tortuosity and jerk) during the simulation-free training process. Evaluated on the Waymo Open Motion Dataset (WOMD), our framework achieves an AUC-ROC of 0.766 against a heuristic golden set of safety-critical events. More significantly, our analysis reveals a fundamental distinction between kinematic danger and semantic non-compliance. Deep-Flow identifies a critical predictability gap by surfacing out-of-distribution behaviors, such as lane-boundary violations and non-normative junction maneuvers, that traditional safety filters overlook. This work provides a mathematically rigorous foundation for defining statistical safety gates, enabling objective, data-driven validation for the safe deployment of autonomous fleets.

</details>
